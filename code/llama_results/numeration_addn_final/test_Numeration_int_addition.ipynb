{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required libraries\n",
    "# %pip install transformers\n",
    "# %pip install torchtext\n",
    "# %pip install sentencepiece\n",
    "# %pip install datasets\n",
    "# %pip install torchmetrics\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# #huggiface download\n",
    "# %pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the model llama 2 13b chat gguf\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is in gguf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf\n"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "#print toal path\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.36 GiB (5.51 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  8555.93 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   400.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    85.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '16'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt= f'''Twelve + 3 = ?'''\n",
    "\n",
    "prompt_template=f'''SYSTEM: You are a math assistant.I will ask you some addition questions. Please answer in word format. Numbers can be in digit or word format. For example, if I ask you 'three + 2 = ?', you should answer 'answer=five'. Do not include any other information in your answer.\n",
    "\n",
    "USER: {prompt}\n",
    "        \n",
    "ASSISTANT:'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     5 runs   (    0.42 ms per token,  2354.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3624.20 ms /    74 tokens (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =    2710.36 ms /     4 runs   (  677.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6349.75 ms /    78 tokens\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Answer=fifteen\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file in data folder int_addition.json\n",
    "with open('numeration_int_addn.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>both positive</th>\n",
       "      <th>word neg digit pos</th>\n",
       "      <th>both negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dw</th>\n",
       "      <td>{'d1': [[0, 'zero', 'zero', 0], [0, 'one', 'on...</td>\n",
       "      <td>{'d1': [[0, 'minus one', 'minus one', -1], [0,...</td>\n",
       "      <td>{'d1': [[-1, 'minus one', 'minus two', -2], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ww</th>\n",
       "      <td>{'d1': [['zero', 'zero', 'zero', 0], ['zero', ...</td>\n",
       "      <td>{'d1': [['zero', 'minus one', 'minus one', -1]...</td>\n",
       "      <td>{'d1': [['minus one', 'minus one', 'minus two'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        both positive  \\\n",
       "dw  {'d1': [[0, 'zero', 'zero', 0], [0, 'one', 'on...   \n",
       "ww  {'d1': [['zero', 'zero', 'zero', 0], ['zero', ...   \n",
       "\n",
       "                                   word neg digit pos  \\\n",
       "dw  {'d1': [[0, 'minus one', 'minus one', -1], [0,...   \n",
       "ww  {'d1': [['zero', 'minus one', 'minus one', -1]...   \n",
       "\n",
       "                                        both negative  \n",
       "dw  {'d1': [[-1, 'minus one', 'minus two', -2], [-...  \n",
       "ww  {'d1': [['minus one', 'minus one', 'minus two'...  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data as pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "gf = pd.DataFrame(data)\n",
    "#last 5 rows\n",
    "gf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(column_name,data_type):\n",
    "    df=pd.DataFrame(gf[column_name][data_type]['d1'],columns=['a','b','sum_word','sum_digit'])\n",
    "    for i in range(2,8):\n",
    "        df=pd.concat([df,pd.DataFrame(gf[column_name][data_type][f'd{i}'],columns=['a','b','sum_word','sum_digit'])],ignore_index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "df=extract_data('word neg digit pos','dw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a           b     sum_word  sum_digit\n",
      "0            0   minus one    minus one         -1\n",
      "1            0   minus two    minus two         -2\n",
      "2  minus three           0  minus three         -3\n",
      "3   minus four           0   minus four         -4\n",
      "4            0  minus five   minus five         -5\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     4 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2386.82 ms /    48 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2024.00 ms /     3 runs   (  674.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4422.62 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /     4 runs   (    0.41 ms per token,  2425.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.75 ms /    12 tokens (   54.98 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =    2009.88 ms /     3 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2679.96 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     4 runs   (    0.42 ms per token,  2388.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.48 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2062.23 ms /     3 runs   (  687.41 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    2901.48 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     5 runs   (    0.43 ms per token,  2322.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.63 ms /    15 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2738.08 ms /     4 runs   (  684.52 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3527.40 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     5 runs   (    0.44 ms per token,  2266.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.50 ms /    16 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2745.61 ms /     4 runs   (  686.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3593.97 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     4 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.23 ms /    16 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2023.95 ms /     3 runs   (  674.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2858.83 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /     5 runs   (    0.45 ms per token,  2228.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.02 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    2751.45 ms /     4 runs   (  687.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3597.89 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     5 runs   (    0.44 ms per token,  2258.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.41 ms /    16 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    2721.09 ms /     4 runs   (  680.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3580.13 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     4 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.15 ms /    15 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2012.36 ms /     3 runs   (  670.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2805.45 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.41 ms /    15 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1993.90 ms /     3 runs   (  664.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    2797.91 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     4 runs   (    0.42 ms per token,  2359.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.45 ms /    15 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    2033.11 ms /     3 runs   (  677.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2828.89 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     4 runs   (    0.42 ms per token,  2390.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.60 ms /    16 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    2089.06 ms /     3 runs   (  696.35 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    2929.59 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     4 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.50 ms /    12 tokens (   55.54 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2030.13 ms /     3 runs   (  676.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2706.99 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     4 runs   (    0.42 ms per token,  2376.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.78 ms /    12 tokens (   58.40 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:        eval time =    2024.06 ms /     3 runs   (  674.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2735.04 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     4 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.14 ms /    12 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1999.85 ms /     3 runs   (  666.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    2663.56 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     4 runs   (    0.45 ms per token,  2235.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.63 ms /    12 tokens (   58.39 ms per token,    17.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2017.93 ms /     3 runs   (  672.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2730.00 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.03 ms /    12 tokens (   59.59 ms per token,    16.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2106.67 ms /     3 runs   (  702.22 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    2832.18 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.22 ms /    16 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1971.33 ms /     3 runs   (  657.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    2840.64 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /     4 runs   (    0.41 ms per token,  2434.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.58 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2011.18 ms /     3 runs   (  670.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2846.31 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2332.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.16 ms /    16 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2055.27 ms /     3 runs   (  685.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    2917.07 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.77 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2028.03 ms /     3 runs   (  676.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2859.08 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2308.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.66 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1986.28 ms /     3 runs   (  662.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    2831.64 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /     5 runs   (    0.44 ms per token,  2289.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.15 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    2667.27 ms /     4 runs   (  666.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3508.92 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.60 ms /    12 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2071.64 ms /     3 runs   (  690.55 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    2735.21 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.10 ms /    16 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2069.26 ms /     3 runs   (  689.75 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    2935.55 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.22 ms /    15 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2035.18 ms /     3 runs   (  678.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    2823.70 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.62 ms /    16 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1966.80 ms /     3 runs   (  655.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    2835.41 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2287.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.81 ms /    15 tokens (   56.25 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2050.72 ms /     3 runs   (  683.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    2905.25 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.43 ms /    12 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2073.28 ms /     3 runs   (  691.09 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    2746.98 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     4 runs   (    0.42 ms per token,  2388.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.22 ms /    12 tokens (   59.27 ms per token,    16.87 tokens per second)\n",
      "llama_print_timings:        eval time =    2010.13 ms /     3 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2731.67 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     5 runs   (    0.42 ms per token,  2382.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.70 ms /    16 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2681.76 ms /     4 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3556.42 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     5 runs   (    0.42 ms per token,  2384.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.53 ms /    15 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    2735.20 ms /     4 runs   (  683.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3540.65 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     5 runs   (    0.42 ms per token,  2374.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.52 ms /    16 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2705.87 ms /     4 runs   (  676.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3563.47 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.78 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1954.63 ms /     3 runs   (  651.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    2799.54 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.67 ms /    16 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2043.18 ms /     3 runs   (  681.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    2893.37 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.81 ms /    12 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2035.77 ms /     3 runs   (  678.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    2697.74 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.39 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1978.30 ms /     3 runs   (  659.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    2815.43 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.27 ms /    15 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2018.29 ms /     3 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2812.02 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.26 ms /    32 runs   (    0.41 ms per token,  2413.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.59 ms /    15 tokens (   54.04 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   20714.51 ms /    31 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21611.90 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     802.69 ms /    15 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2018.29 ms /     3 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2831.39 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     4 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.63 ms /    15 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2047.46 ms /     3 runs   (  682.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    2854.58 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     5 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.43 ms /    15 tokens (   51.96 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    2668.46 ms /     4 runs   (  667.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3461.80 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     5 runs   (    0.43 ms per token,  2335.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.43 ms /    15 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    2643.66 ms /     4 runs   (  660.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    3449.73 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2318.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.21 ms /    16 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1991.40 ms /     3 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    2836.39 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2321.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.49 ms /    16 tokens (   67.53 ms per token,    14.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2035.44 ms /     3 runs   (  678.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3126.62 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /     4 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     872.01 ms /    16 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2041.76 ms /     3 runs   (  680.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    2924.17 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     4 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.47 ms /    16 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    2063.72 ms /     3 runs   (  687.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    2902.04 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2318.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.78 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    2029.50 ms /     3 runs   (  676.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2878.21 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     4 runs   (    0.42 ms per token,  2357.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.02 ms /    16 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2005.49 ms /     3 runs   (  668.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    2867.90 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /     4 runs   (    0.41 ms per token,  2419.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.36 ms /    15 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2032.83 ms /     3 runs   (  677.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2854.53 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.20 ms /    15 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1990.76 ms /     3 runs   (  663.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    2814.70 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.28 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2072.63 ms /     3 runs   (  690.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    2909.98 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /     5 runs   (    0.47 ms per token,  2111.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     862.63 ms /    16 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2766.67 ms /     4 runs   (  691.67 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3644.22 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     4 runs   (    0.44 ms per token,  2258.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.41 ms /    15 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2056.10 ms /     3 runs   (  685.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    2883.48 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     5 runs   (    0.44 ms per token,  2285.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.26 ms /    15 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2722.16 ms /     4 runs   (  680.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3514.01 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     4 runs   (    0.42 ms per token,  2402.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.01 ms /    15 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2029.85 ms /     3 runs   (  676.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2853.74 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.01 ms /    16 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2107.47 ms /     3 runs   (  702.49 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    2974.72 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     4 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.63 ms /    12 tokens (   54.39 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =    2014.78 ms /     3 runs   (  671.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2678.31 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2340.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.38 ms /    16 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2032.83 ms /     3 runs   (  677.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2881.12 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.50 ms /    16 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1992.93 ms /     3 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    2834.02 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     4 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     855.57 ms /    16 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    2026.12 ms /     3 runs   (  675.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2892.80 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.43 ms per token,  2305.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.51 ms /    16 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2042.98 ms /     3 runs   (  680.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    2884.47 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     5 runs   (    0.45 ms per token,  2243.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.53 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2719.41 ms /     4 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3559.21 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     4 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.20 ms /    15 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2075.61 ms /     3 runs   (  691.87 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    2895.47 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     4 runs   (    0.45 ms per token,  2238.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.61 ms /    15 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2075.36 ms /     3 runs   (  691.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    2869.47 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     4 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.51 ms /    15 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2078.59 ms /     3 runs   (  692.86 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    2886.42 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2340.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.16 ms /    16 tokens (   65.70 ms per token,    15.22 tokens per second)\n",
      "llama_print_timings:        eval time =    2080.53 ms /     3 runs   (  693.51 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    3143.05 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     4 runs   (    0.45 ms per token,  2238.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.92 ms /    12 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1992.17 ms /     3 runs   (  664.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    2656.13 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     4 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.27 ms /    12 tokens (   55.11 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1957.90 ms /     3 runs   (  652.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    2630.19 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     4 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.03 ms /    16 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1959.05 ms /     3 runs   (  653.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    2810.30 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.78 ms /    16 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2045.63 ms /     3 runs   (  681.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    2918.18 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     5 runs   (    0.44 ms per token,  2268.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.12 ms /    12 tokens (   57.26 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2588.41 ms /     4 runs   (  647.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    3289.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     5 runs   (    0.44 ms per token,  2284.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.96 ms /    15 tokens (   55.33 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2704.61 ms /     4 runs   (  676.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3548.70 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2281.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.89 ms /    12 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2046.28 ms /     3 runs   (  682.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    2707.34 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     4 runs   (    0.47 ms per token,  2149.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.90 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    2032.54 ms /     3 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2876.93 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /     4 runs   (    0.46 ms per token,  2184.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.37 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2018.85 ms /     3 runs   (  672.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2854.15 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2318.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.84 ms /    12 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1994.09 ms /     3 runs   (  664.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    2666.86 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2313.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.27 ms /    16 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2024.96 ms /     3 runs   (  674.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2883.96 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     4 runs   (    0.45 ms per token,  2243.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.44 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2050.24 ms /     3 runs   (  683.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    2887.63 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     4 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.80 ms /    12 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2032.86 ms /     3 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2706.66 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /     5 runs   (    0.44 ms per token,  2291.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.25 ms /    12 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2724.60 ms /     4 runs   (  681.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3396.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.37 ms /    15 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    2026.93 ms /     3 runs   (  675.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2818.13 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     5 runs   (    0.44 ms per token,  2274.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.29 ms /    12 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    2758.28 ms /     4 runs   (  689.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3419.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2313.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.36 ms /    12 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2079.57 ms /     3 runs   (  693.19 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    2750.38 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.21 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    2027.90 ms /     3 runs   (  675.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2864.37 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /     4 runs   (    0.46 ms per token,  2164.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.66 ms /    15 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2001.13 ms /     3 runs   (  667.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    2798.13 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /     4 runs   (    0.41 ms per token,  2416.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.89 ms /    15 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2028.08 ms /     3 runs   (  676.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    2831.11 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     4 runs   (    0.44 ms per token,  2256.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.46 ms /    16 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2013.18 ms /     3 runs   (  671.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2864.92 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     4 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.62 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1975.81 ms /     3 runs   (  658.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    2625.12 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     4 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     921.41 ms /    16 tokens (   57.59 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2008.87 ms /     3 runs   (  669.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    2940.89 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     8 runs   (    0.43 ms per token,  2326.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     979.80 ms /    18 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4720.40 ms /     7 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5721.83 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     8 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.19 ms /    19 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    4717.89 ms /     7 runs   (  673.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5770.44 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     4 runs   (    0.42 ms per token,  2388.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.48 ms /    18 tokens (   55.30 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2008.83 ms /     3 runs   (  669.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3015.49 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     4 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.77 ms /    20 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2094.27 ms /     3 runs   (  698.09 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    3173.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     5 runs   (    0.42 ms per token,  2355.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     953.72 ms /    17 tokens (   56.10 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2796.89 ms /     4 runs   (  699.22 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    3763.89 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     5 runs   (    0.44 ms per token,  2260.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.15 ms /    20 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2673.31 ms /     4 runs   (  668.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3744.76 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     4 runs   (    0.42 ms per token,  2396.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.01 ms /    19 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =    2008.31 ms /     3 runs   (  669.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3052.60 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     8 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.08 ms /    21 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    4706.98 ms /     7 runs   (  672.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5857.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     7 runs   (    0.44 ms per token,  2274.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.22 ms /    19 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    3981.49 ms /     6 runs   (  663.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5016.08 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2269.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     918.62 ms /    17 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    5409.73 ms /     8 runs   (  676.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6353.76 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     8 runs   (    0.45 ms per token,  2244.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.06 ms /    20 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4707.72 ms /     7 runs   (  672.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5787.43 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     5 runs   (    0.43 ms per token,  2311.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.51 ms /    20 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2698.01 ms /     4 runs   (  674.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3804.20 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     7 runs   (    0.44 ms per token,  2289.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.10 ms /    19 tokens (   60.90 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4049.57 ms /     6 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5225.99 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     5 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.44 ms /    16 tokens (   68.65 ms per token,    14.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2822.69 ms /     4 runs   (  705.67 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    3934.62 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     4 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.91 ms /    20 tokens (   58.45 ms per token,    17.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2015.93 ms /     3 runs   (  671.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3195.51 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /     4 runs   (    0.46 ms per token,  2168.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.74 ms /    19 tokens (   56.25 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2048.30 ms /     3 runs   (  682.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3128.50 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     6 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.53 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    3478.48 ms /     5 runs   (  695.70 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    4317.89 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     4 runs   (    0.42 ms per token,  2385.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.87 ms /    18 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2088.19 ms /     3 runs   (  696.06 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    3061.33 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     7 runs   (    0.44 ms per token,  2282.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.00 ms /    19 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    4067.20 ms /     6 runs   (  677.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5101.43 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     5 runs   (    0.44 ms per token,  2278.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.15 ms /    20 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2776.01 ms /     4 runs   (  694.00 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    3860.27 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.04 ms /    19 tokens (   54.63 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    4715.66 ms /     7 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5776.42 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     8 runs   (    0.44 ms per token,  2285.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.55 ms /    19 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4600.69 ms /     7 runs   (  657.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5630.83 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     7 runs   (    0.43 ms per token,  2306.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.33 ms /    19 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =    4041.37 ms /     6 runs   (  673.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5096.12 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2320.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.47 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    4816.26 ms /     7 runs   (  688.04 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5668.38 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.73 ms /    19 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2052.88 ms /     3 runs   (  684.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3078.00 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.44 ms per token,  2295.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.16 ms /    20 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =    4770.12 ms /     7 runs   (  681.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5892.56 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     4 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     967.56 ms /    18 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2045.60 ms /     3 runs   (  681.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3024.12 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     8 runs   (    0.44 ms per token,  2288.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.62 ms /    20 tokens (   64.88 ms per token,    15.41 tokens per second)\n",
      "llama_print_timings:        eval time =    4751.14 ms /     7 runs   (  678.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6071.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2343.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.71 ms /    21 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2051.58 ms /     3 runs   (  683.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3167.26 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /     8 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.84 ms /    19 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4823.06 ms /     7 runs   (  689.01 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5881.12 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /     4 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     967.92 ms /    18 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2047.99 ms /     3 runs   (  682.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3026.59 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     7 runs   (    0.45 ms per token,  2237.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.98 ms /    19 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    4113.65 ms /     6 runs   (  685.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5154.56 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     5 runs   (    0.46 ms per token,  2193.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     997.37 ms /    18 tokens (   55.41 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2741.47 ms /     4 runs   (  685.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3752.87 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     5 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.05 ms /    17 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    2666.72 ms /     4 runs   (  666.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3611.69 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     5 runs   (    0.42 ms per token,  2356.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.18 ms /    19 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =    2685.48 ms /     4 runs   (  671.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3721.85 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     4 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.96 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1981.26 ms /     3 runs   (  660.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    2823.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2322.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.27 ms /    19 tokens (   55.91 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4706.84 ms /     7 runs   (  672.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5791.40 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     7 runs   (    0.43 ms per token,  2314.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.38 ms /    19 tokens (   55.18 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =    4156.90 ms /     6 runs   (  692.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5224.76 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     4 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.08 ms /    19 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    2022.86 ms /     3 runs   (  674.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3062.09 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     4 runs   (    0.46 ms per token,  2152.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.88 ms /    20 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2073.39 ms /     3 runs   (  691.13 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3149.22 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.72 ms /     8 runs   (    0.46 ms per token,  2152.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.66 ms /    19 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4758.07 ms /     7 runs   (  679.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5812.88 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     9 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.00 ms /    19 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    5273.50 ms /     8 runs   (  659.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6328.55 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     5 runs   (    0.46 ms per token,  2185.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.62 ms /    20 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2646.92 ms /     4 runs   (  661.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    3706.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     4 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.87 ms /    17 tokens (   64.05 ms per token,    15.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2002.90 ms /     3 runs   (  667.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3103.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.46 ms /    19 tokens (   57.97 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2051.77 ms /     3 runs   (  683.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3164.61 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2287.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.96 ms /    19 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    2004.34 ms /     3 runs   (  668.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3060.09 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2310.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.15 ms /    19 tokens (   55.43 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4041.88 ms /     6 runs   (  673.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5114.57 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     7 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     981.21 ms /    18 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4079.76 ms /     6 runs   (  679.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5080.53 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2316.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.48 ms /    19 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4699.37 ms /     7 runs   (  671.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5766.05 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     5 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.66 ms /    19 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2725.23 ms /     4 runs   (  681.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3777.29 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2346.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.53 ms /    19 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    4792.24 ms /     7 runs   (  684.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5820.91 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     4 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.26 ms /    19 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1952.32 ms /     3 runs   (  650.77 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    2995.20 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2294.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.61 ms /    19 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4678.17 ms /     7 runs   (  668.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5686.95 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     7 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.62 ms /    19 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    4027.64 ms /     6 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5060.10 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /     9 runs   (    0.44 ms per token,  2248.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.49 ms /    19 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5437.34 ms /     8 runs   (  679.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6459.57 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.43 ms per token,  2305.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     969.84 ms /    18 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    2038.60 ms /     3 runs   (  679.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3020.02 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /     4 runs   (    0.46 ms per token,  2182.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.89 ms /    20 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2001.02 ms /     3 runs   (  667.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3126.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /     5 runs   (    0.47 ms per token,  2119.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     956.91 ms /    16 tokens (   59.81 ms per token,    16.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2723.76 ms /     4 runs   (  680.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3696.12 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     4 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.76 ms /    19 tokens (   56.62 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =    2022.79 ms /     3 runs   (  674.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3110.17 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     4 runs   (    0.45 ms per token,  2235.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.00 ms /    19 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2042.03 ms /     3 runs   (  680.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3078.25 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2304.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     979.71 ms /    18 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4716.77 ms /     7 runs   (  673.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5719.02 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /     5 runs   (    0.45 ms per token,  2201.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.31 ms /    20 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    2710.87 ms /     4 runs   (  677.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3809.84 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     5 runs   (    0.46 ms per token,  2193.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.34 ms /    20 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    2634.35 ms /     4 runs   (  658.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    3732.70 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2314.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     973.39 ms /    18 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    4616.00 ms /     7 runs   (  659.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5611.91 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     7 runs   (    0.43 ms per token,  2316.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.14 ms /    19 tokens (   55.11 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =    4028.97 ms /     6 runs   (  671.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5096.21 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     5 runs   (    0.42 ms per token,  2394.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     954.21 ms /    18 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2701.23 ms /     4 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3669.44 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     5 runs   (    0.45 ms per token,  2240.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     942.48 ms /    17 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2756.28 ms /     4 runs   (  689.07 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3713.26 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /     5 runs   (    0.44 ms per token,  2296.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     925.47 ms /    17 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2751.68 ms /     4 runs   (  687.92 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3691.40 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     5 runs   (    0.41 ms per token,  2411.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.63 ms /    18 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    2694.51 ms /     4 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3709.10 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     5 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.75 ms /    20 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    2708.80 ms /     4 runs   (  677.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3783.60 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     877.48 ms /    16 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    4726.56 ms /     7 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5626.56 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.61 ms /    19 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    4767.27 ms /     7 runs   (  681.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5812.82 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     7 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.87 ms /    19 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    4069.59 ms /     6 runs   (  678.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5092.01 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     7 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.62 ms /    19 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4068.93 ms /     6 runs   (  678.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5115.47 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     6 runs   (    0.46 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.25 ms /    20 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    3373.41 ms /     5 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4458.96 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     7 runs   (    0.42 ms per token,  2353.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.68 ms /    16 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    4112.88 ms /     6 runs   (  685.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    4983.94 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     5 runs   (    0.45 ms per token,  2244.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.34 ms /    21 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2699.56 ms /     4 runs   (  674.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3841.43 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     7 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.86 ms /    18 tokens (   54.83 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4058.83 ms /     6 runs   (  676.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5065.99 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     4 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.58 ms /    19 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2046.63 ms /     3 runs   (  682.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3078.23 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2315.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.02 ms /    17 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    6824.89 ms /    10 runs   (  682.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7784.66 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     4 runs   (    0.46 ms per token,  2151.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.34 ms /    19 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    2039.78 ms /     3 runs   (  679.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3090.34 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /     7 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.07 ms /    20 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    4117.04 ms /     6 runs   (  686.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5231.27 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.09 ms /    21 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1994.82 ms /     3 runs   (  664.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3146.74 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2354.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     940.86 ms /    17 tokens (   55.34 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4768.62 ms /     7 runs   (  681.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5732.26 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     7 runs   (    0.45 ms per token,  2240.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.49 ms /    19 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =    4093.17 ms /     6 runs   (  682.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5132.13 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.21 ms /    19 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    2015.56 ms /     3 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3040.17 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     7 runs   (    0.44 ms per token,  2295.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.46 ms /    19 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    4248.03 ms /     6 runs   (  708.01 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    5296.91 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     4 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.96 ms /    21 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2094.60 ms /     3 runs   (  698.20 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    3207.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     5 runs   (    0.43 ms per token,  2315.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.83 ms /    20 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2730.55 ms /     4 runs   (  682.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3807.77 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2335.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.12 ms /    20 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    4129.11 ms /     6 runs   (  688.18 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5205.00 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /     5 runs   (    0.44 ms per token,  2295.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.73 ms /    19 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =    2726.43 ms /     4 runs   (  681.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3729.74 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /     5 runs   (    0.45 ms per token,  2218.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.18 ms /    19 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2653.31 ms /     4 runs   (  663.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    3693.35 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /     4 runs   (    0.46 ms per token,  2182.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.25 ms /    21 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1957.06 ms /     3 runs   (  652.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    3086.39 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.61 ms /    18 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    4737.91 ms /     7 runs   (  676.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5738.22 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     4 runs   (    0.44 ms per token,  2256.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.00 ms /    19 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1997.80 ms /     3 runs   (  665.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3037.60 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2380.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.33 ms /    17 tokens (   59.02 ms per token,    16.94 tokens per second)\n",
      "llama_print_timings:        eval time =    4764.14 ms /     7 runs   (  680.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5789.86 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2279.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.97 ms /    17 tokens (   56.53 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =    3386.71 ms /     5 runs   (  677.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4364.44 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     7 runs   (    0.43 ms per token,  2322.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.94 ms /    20 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4088.12 ms /     6 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5158.12 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     8 runs   (    0.44 ms per token,  2285.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.90 ms /    18 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    4771.21 ms /     7 runs   (  681.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5754.96 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     7 runs   (    0.43 ms per token,  2318.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.87 ms /    20 tokens (   53.49 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4065.76 ms /     6 runs   (  677.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5155.07 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     7 runs   (    0.44 ms per token,  2295.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.28 ms /    19 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4059.92 ms /     6 runs   (  676.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5104.70 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     7 runs   (    0.43 ms per token,  2341.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.82 ms /    20 tokens (   67.14 ms per token,    14.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4064.66 ms /     6 runs   (  677.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5428.05 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2290.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.36 ms /    20 tokens (   64.87 ms per token,    15.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4711.30 ms /     7 runs   (  673.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6032.10 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     4 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.56 ms /    20 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2059.67 ms /     3 runs   (  686.56 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3121.54 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2335.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.27 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    4015.81 ms /     6 runs   (  669.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4863.78 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.24 ms /    19 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4004.46 ms /     6 runs   (  667.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5045.65 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2308.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.91 ms /    21 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2011.62 ms /     3 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3119.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2307.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.34 ms /    17 tokens (   57.84 ms per token,    17.29 tokens per second)\n",
      "llama_print_timings:        eval time =    4064.58 ms /     6 runs   (  677.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5068.16 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2313.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.27 ms /    19 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4193.46 ms /     6 runs   (  698.91 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    5244.56 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     4 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.29 ms /    20 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2019.73 ms /     3 runs   (  673.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3105.11 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     5 runs   (    0.42 ms per token,  2357.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     940.81 ms /    17 tokens (   55.34 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2689.51 ms /     4 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3643.92 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2335.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.04 ms /    19 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    4611.52 ms /     7 runs   (  658.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5662.98 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     7 runs   (    0.44 ms per token,  2263.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.86 ms /    19 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    3937.92 ms /     6 runs   (  656.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    4976.64 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     4 runs   (    0.42 ms per token,  2393.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.78 ms /    19 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1959.52 ms /     3 runs   (  653.17 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    2993.94 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2332.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.51 ms /    19 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    3999.43 ms /     6 runs   (  666.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5038.29 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     4 runs   (    0.43 ms per token,  2329.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.94 ms /    19 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1976.11 ms /     3 runs   (  658.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    3009.70 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     5 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.29 ms /    18 tokens (   68.74 ms per token,    14.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2659.92 ms /     4 runs   (  664.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3911.48 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     7 runs   (    0.43 ms per token,  2339.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.63 ms /    21 tokens (   56.55 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4022.63 ms /     6 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5229.79 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2311.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.50 ms /    20 tokens (   56.52 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4035.39 ms /     6 runs   (  672.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5185.59 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /     4 runs   (    0.49 ms per token,  2044.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.19 ms /    19 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1955.33 ms /     3 runs   (  651.78 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    3025.73 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /     4 runs   (    0.46 ms per token,  2157.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.28 ms /    19 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1975.38 ms /     3 runs   (  658.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    3037.47 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2337.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.44 ms /    18 tokens (   55.08 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =    3963.24 ms /     6 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    4975.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2281.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.22 ms /    19 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    3409.92 ms /     5 runs   (  681.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4483.16 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /     5 runs   (    0.45 ms per token,  2228.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.80 ms /    20 tokens (   56.44 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2691.47 ms /     4 runs   (  672.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3834.49 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     7 runs   (    0.43 ms per token,  2338.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.22 ms /    18 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    4038.69 ms /     6 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5032.87 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     7 runs   (    0.44 ms per token,  2295.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.57 ms /    20 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4075.79 ms /     6 runs   (  679.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5153.92 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     4 runs   (    0.44 ms per token,  2276.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.53 ms /    20 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2039.56 ms /     3 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3109.53 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /     5 runs   (    0.45 ms per token,  2203.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.95 ms /    19 tokens (   54.16 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    2682.91 ms /     4 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3725.79 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     5 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.57 ms /    20 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2721.64 ms /     4 runs   (  680.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3799.11 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     5 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.40 ms /    20 tokens (   55.02 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2686.08 ms /     4 runs   (  671.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3800.68 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     5 runs   (    0.44 ms per token,  2282.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.25 ms /    15 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =    2742.32 ms /     4 runs   (  685.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3537.77 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.43 ms per token,  2305.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     997.34 ms /    19 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1992.05 ms /     3 runs   (  664.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    3000.88 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2256.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.49 ms /    19 tokens (   63.50 ms per token,    15.75 tokens per second)\n",
      "llama_print_timings:        eval time =    4777.01 ms /     7 runs   (  682.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6006.79 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.84 ms /    18 tokens (   55.49 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =    2057.03 ms /     3 runs   (  685.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3067.23 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.24 ms /    19 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2069.29 ms /     3 runs   (  689.76 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3115.00 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     4 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.26 ms /    19 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2073.76 ms /     3 runs   (  691.25 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3097.16 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     7 runs   (    0.44 ms per token,  2296.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.15 ms /    20 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4067.58 ms /     6 runs   (  677.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5144.43 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     5 runs   (    0.42 ms per token,  2383.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.32 ms /    19 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2706.93 ms /     4 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3728.59 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     7 runs   (    0.44 ms per token,  2275.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.86 ms /    17 tokens (   55.82 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4006.12 ms /     6 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    4975.31 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2332.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     967.65 ms /    18 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4120.93 ms /     6 runs   (  686.82 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5108.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     7 runs   (    0.43 ms per token,  2322.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.20 ms /    18 tokens (   57.73 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =    4002.02 ms /     6 runs   (  667.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5061.24 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     7 runs   (    0.43 ms per token,  2303.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.27 ms /    20 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4047.65 ms /     6 runs   (  674.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5118.46 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     5 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.00 ms /    21 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2688.88 ms /     4 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3811.98 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     5 runs   (    0.43 ms per token,  2344.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.27 ms /    19 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2670.45 ms /     4 runs   (  667.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3734.91 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     4 runs   (    0.42 ms per token,  2373.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.60 ms /    19 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2070.00 ms /     3 runs   (  690.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3109.37 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2354.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.68 ms /    20 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =    5412.43 ms /     8 runs   (  676.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6513.79 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     4 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.45 ms /    21 tokens (   54.78 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2030.29 ms /     3 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3191.73 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     5 runs   (    0.42 ms per token,  2365.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.50 ms /    18 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2722.85 ms /     4 runs   (  680.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3715.43 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     4 runs   (    0.45 ms per token,  2240.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.75 ms /    20 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    2054.92 ms /     3 runs   (  684.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3144.08 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     7 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.55 ms /    20 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    4147.48 ms /     6 runs   (  691.25 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5226.85 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     6 runs   (    0.45 ms per token,  2214.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.74 ms /    23 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    3388.89 ms /     5 runs   (  677.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4597.72 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     5 runs   (    0.46 ms per token,  2190.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.18 ms /    21 tokens (   56.91 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2750.51 ms /     4 runs   (  687.63 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    3960.62 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     8 runs   (    0.44 ms per token,  2264.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.85 ms /    24 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    4757.13 ms /     7 runs   (  679.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6067.58 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2258.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.03 ms /    24 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    7332.14 ms /    11 runs   (  666.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8621.29 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2331.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.37 ms /    22 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4695.59 ms /     7 runs   (  670.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5895.20 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2321.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.76 ms /    23 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =    4749.35 ms /     7 runs   (  678.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5949.91 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2377.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.94 ms /    23 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4727.52 ms /     7 runs   (  675.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5929.36 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2303.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.35 ms /    24 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    6066.59 ms /     9 runs   (  674.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7353.77 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     7 runs   (    0.42 ms per token,  2357.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.06 ms /    20 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    4054.38 ms /     6 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5151.83 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2293.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.53 ms /    23 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    6820.64 ms /    10 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8063.35 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     7 runs   (    0.45 ms per token,  2215.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.57 ms /    23 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4027.93 ms /     6 runs   (  671.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5235.73 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2312.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.91 ms /    22 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    4742.24 ms /     7 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5928.73 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2316.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.47 ms /    22 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6075.13 ms /     9 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7265.57 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     7 runs   (    0.43 ms per token,  2324.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.67 ms /    23 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =    3979.68 ms /     6 runs   (  663.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5176.07 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2381.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.80 ms /    23 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4678.49 ms /     7 runs   (  668.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5899.64 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     7 runs   (    0.44 ms per token,  2286.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.49 ms /    23 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    4051.37 ms /     6 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5286.76 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2316.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.24 ms /    20 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6626.94 ms /    10 runs   (  662.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7708.50 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     4 runs   (    0.44 ms per token,  2287.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.58 ms /    23 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2014.63 ms /     3 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    3218.81 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     4 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.97 ms /    21 tokens (   56.38 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1979.44 ms /     3 runs   (  659.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    3175.03 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2323.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.55 ms /    24 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    5977.31 ms /     9 runs   (  664.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7243.21 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    11 runs   (    0.44 ms per token,  2270.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.22 ms /    23 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6673.04 ms /    10 runs   (  667.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7928.98 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     7 runs   (    0.43 ms per token,  2328.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.08 ms /    21 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4091.07 ms /     6 runs   (  681.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5278.88 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     8 runs   (    0.45 ms per token,  2241.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.32 ms /    24 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    4689.93 ms /     7 runs   (  669.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5988.93 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    12 runs   (    0.43 ms per token,  2313.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.27 ms /    24 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    7336.32 ms /    11 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8605.41 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    12 runs   (    0.43 ms per token,  2302.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.08 ms /    23 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =    7454.77 ms /    11 runs   (  677.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8673.82 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2323.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.50 ms /    20 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6044.62 ms /     9 runs   (  671.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7143.78 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2278.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.97 ms /    17 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =    3404.64 ms /     5 runs   (  680.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4354.30 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     9 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.68 ms /    18 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    5431.10 ms /     8 runs   (  678.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6432.87 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2282.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.50 ms /    23 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3346.56 ms /     5 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4570.45 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     6 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.49 ms /    23 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    3372.56 ms /     5 runs   (  674.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4580.61 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /     9 runs   (    0.44 ms per token,  2279.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.48 ms /    22 tokens (   54.93 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    5470.57 ms /     8 runs   (  683.82 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6705.36 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /     9 runs   (    0.45 ms per token,  2216.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.72 ms /    24 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    5416.43 ms /     8 runs   (  677.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6696.08 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /     6 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.95 ms /    21 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    3447.93 ms /     5 runs   (  689.59 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    4594.09 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     7 runs   (    0.44 ms per token,  2261.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.26 ms /    25 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =    3934.36 ms /     6 runs   (  655.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    5233.42 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     6 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.92 ms /    22 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3310.70 ms /     5 runs   (  662.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    4469.59 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.17 ms /    23 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4810.36 ms /     7 runs   (  687.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6040.85 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     7 runs   (    0.43 ms per token,  2351.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1132.21 ms /    22 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =    4138.57 ms /     6 runs   (  689.76 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5291.10 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2304.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.88 ms /    21 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    5519.36 ms /     8 runs   (  689.92 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6685.05 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /     8 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.81 ms /    23 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    4873.44 ms /     7 runs   (  696.21 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6096.64 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2335.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.86 ms /    23 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    4751.04 ms /     7 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5966.06 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.71 ms /    23 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    4645.01 ms /     7 runs   (  663.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5856.77 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    10 runs   (    0.43 ms per token,  2299.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.59 ms /    24 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    6190.17 ms /     9 runs   (  687.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7445.70 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    11 runs   (    0.43 ms per token,  2349.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.02 ms /    22 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6747.09 ms /    10 runs   (  674.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7948.66 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2307.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.88 ms /    24 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    4019.07 ms /     6 runs   (  669.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5262.64 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    12 runs   (    0.44 ms per token,  2294.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.49 ms /    21 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =    7292.40 ms /    11 runs   (  662.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8409.28 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.58 ms per token,  1738.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.16 ms /    24 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3496.61 ms /     5 runs   (  699.32 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    4818.23 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     7 runs   (    0.44 ms per token,  2271.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.25 ms /    24 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4043.62 ms /     6 runs   (  673.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5329.52 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2289.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.30 ms /    24 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    8240.46 ms /    12 runs   (  686.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9526.78 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2281.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     936.62 ms /    17 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =    3357.81 ms /     5 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4312.16 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     6 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.35 ms /    23 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =    3378.56 ms /     5 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4572.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     6 runs   (    0.46 ms per token,  2181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.55 ms /    24 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    3566.50 ms /     5 runs   (  713.30 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    4828.69 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     8 runs   (    0.45 ms per token,  2228.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.99 ms /    22 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =    4809.20 ms /     7 runs   (  687.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6021.48 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    11 runs   (    0.43 ms per token,  2350.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.64 ms /    23 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    6906.10 ms /    10 runs   (  690.61 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8126.41 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.82 ms /    25 tokens (   61.87 ms per token,    16.16 tokens per second)\n",
      "llama_print_timings:        eval time =    4745.60 ms /     7 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6315.34 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     6 runs   (    0.43 ms per token,  2321.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.20 ms /    22 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    3420.40 ms /     5 runs   (  684.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    4598.76 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2285.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.75 ms /    22 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6114.96 ms /     9 runs   (  679.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7291.68 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     7 runs   (    0.45 ms per token,  2240.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.94 ms /    23 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4119.46 ms /     6 runs   (  686.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5333.76 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    11 runs   (    0.43 ms per token,  2344.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.99 ms /    23 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    6838.02 ms /    10 runs   (  683.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8059.70 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2276.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.50 ms /    24 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    4814.99 ms /     7 runs   (  687.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6073.23 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2310.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.58 ms /    23 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4809.33 ms /     7 runs   (  687.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6037.01 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     8 runs   (    0.44 ms per token,  2272.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.79 ms /    23 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =    4793.66 ms /     7 runs   (  684.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5989.74 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     6 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.80 ms /    23 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =    3411.97 ms /     5 runs   (  682.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4628.11 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2389.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.73 ms /    22 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    5442.65 ms /     8 runs   (  680.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6598.79 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     5 runs   (    0.44 ms per token,  2268.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.66 ms /    23 tokens (   62.25 ms per token,    16.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2705.53 ms /     4 runs   (  676.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4151.51 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2354.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.48 ms /    20 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    4744.07 ms /     7 runs   (  677.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5840.38 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     7 runs   (    0.45 ms per token,  2213.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.72 ms /    21 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    4030.65 ms /     6 runs   (  671.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5150.79 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2302.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.39 ms /    23 tokens (   52.23 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =    6752.01 ms /    10 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7985.82 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     7 runs   (    0.44 ms per token,  2253.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.86 ms /    20 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    4082.59 ms /     6 runs   (  680.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5170.03 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    10 runs   (    0.44 ms per token,  2271.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.08 ms /    25 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6031.30 ms /     9 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7373.59 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     7 runs   (    0.42 ms per token,  2361.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.90 ms /    22 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4057.19 ms /     6 runs   (  676.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5254.67 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /     6 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.43 ms /    21 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3355.94 ms /     5 runs   (  671.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4495.39 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /     9 runs   (    0.44 ms per token,  2273.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.58 ms /    23 tokens (   52.29 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5387.66 ms /     8 runs   (  673.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6616.45 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     6 runs   (    0.44 ms per token,  2255.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.09 ms /    20 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    3369.67 ms /     5 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4470.68 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.52 ms /    22 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4750.76 ms /     7 runs   (  678.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5912.26 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    10 runs   (    0.42 ms per token,  2363.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.81 ms /    21 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    6054.65 ms /     9 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7179.25 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2269.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.81 ms /    22 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5439.03 ms /     8 runs   (  679.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6620.56 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2318.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.95 ms /    21 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4738.92 ms /     7 runs   (  676.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5891.39 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     6 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.01 ms /    22 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    3353.53 ms /     5 runs   (  670.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4532.47 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.43 ms per token,  2300.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.83 ms /    20 tokens (   56.74 ms per token,    17.62 tokens per second)\n",
      "llama_print_timings:        eval time =    4711.91 ms /     7 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5869.83 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1926.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.06 ms /    21 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =    3431.85 ms /     5 runs   (  686.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    4548.83 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     7 runs   (    0.45 ms per token,  2204.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.06 ms /    23 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4117.26 ms /     6 runs   (  686.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5348.24 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     7 runs   (    0.43 ms per token,  2321.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.11 ms /    23 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4087.07 ms /     6 runs   (  681.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5287.26 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2282.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.35 ms /    21 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    6750.81 ms /    10 runs   (  675.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7913.24 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     7 runs   (    0.45 ms per token,  2244.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.64 ms /    21 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    4079.97 ms /     6 runs   (  679.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5220.47 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.88 ms /    21 tokens (   55.76 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6215.41 ms /     9 runs   (  690.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7415.37 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2283.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.14 ms /    22 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    3379.29 ms /     5 runs   (  675.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4539.67 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     7 runs   (    0.44 ms per token,  2283.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.58 ms /    24 tokens (   62.48 ms per token,    16.00 tokens per second)\n",
      "llama_print_timings:        eval time =    4126.27 ms /     6 runs   (  687.71 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5646.94 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /     6 runs   (    0.43 ms per token,  2318.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.39 ms /    20 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    3422.13 ms /     5 runs   (  684.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    4479.68 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.69 ms /    23 tokens (   54.81 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =    6131.99 ms /     9 runs   (  681.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7421.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     6 runs   (    0.43 ms per token,  2310.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.32 ms /    24 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    3352.18 ms /     5 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4626.74 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2300.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.20 ms /    25 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6841.12 ms /    10 runs   (  684.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8174.85 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     6 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.31 ms /    25 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =    3359.38 ms /     5 runs   (  671.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4633.52 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.14 ms /    24 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    6134.59 ms /     9 runs   (  681.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7436.86 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    10 runs   (    0.45 ms per token,  2214.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.88 ms /    24 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    6085.74 ms /     9 runs   (  676.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7363.70 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     8 runs   (    0.44 ms per token,  2268.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.08 ms /    24 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    4724.92 ms /     7 runs   (  674.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6017.59 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /     6 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.16 ms /    22 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    3447.35 ms /     5 runs   (  689.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    4614.75 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.87 ms /    24 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    6192.85 ms /     9 runs   (  688.09 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7444.75 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     7 runs   (    0.43 ms per token,  2327.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.97 ms /    21 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    4047.37 ms /     6 runs   (  674.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5189.75 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     8 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.10 ms /    23 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =    4689.83 ms /     7 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5909.02 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.76 ms /    23 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    6053.80 ms /     9 runs   (  672.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7286.49 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    13 runs   (    0.43 ms per token,  2334.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.54 ms /    21 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    8248.80 ms /    12 runs   (  687.40 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9447.32 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     9 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.91 ms /    23 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5423.99 ms /     8 runs   (  678.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6666.10 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /     6 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.61 ms /    23 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    3390.44 ms /     5 runs   (  678.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4618.83 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2323.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.04 ms /    21 tokens (   54.10 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6194.54 ms /     9 runs   (  688.28 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7360.14 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     7 runs   (    0.46 ms per token,  2182.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1180.85 ms /    23 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =    4072.18 ms /     6 runs   (  678.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5274.04 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2281.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.14 ms /    23 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3394.36 ms /     5 runs   (  678.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4641.26 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.87 ms /    24 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    3388.41 ms /     5 runs   (  677.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4654.89 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /     8 runs   (    0.46 ms per token,  2165.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.83 ms /    22 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    4915.27 ms /     7 runs   (  702.18 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6141.68 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.56 ms /    25 tokens (   57.98 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =    4144.19 ms /     6 runs   (  690.70 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5614.21 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     8 runs   (    0.45 ms per token,  2240.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.98 ms /    21 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4597.12 ms /     7 runs   (  656.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5730.58 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     7 runs   (    0.43 ms per token,  2317.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.20 ms /    22 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =    3998.74 ms /     6 runs   (  666.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5198.58 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    13 runs   (    0.44 ms per token,  2274.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.75 ms /    23 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    7929.08 ms /    12 runs   (  660.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9164.90 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     5 runs   (    0.44 ms per token,  2258.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.74 ms /    24 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2661.95 ms /     4 runs   (  665.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    3955.45 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     6 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.57 ms /    22 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =    3285.85 ms /     5 runs   (  657.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    4468.85 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2312.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.14 ms /    22 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    7964.14 ms /    12 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9164.42 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2340.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.43 ms /    22 tokens (   52.70 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5974.62 ms /     9 runs   (  663.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7163.75 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /     8 runs   (    0.44 ms per token,  2256.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.40 ms /    24 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =    4671.14 ms /     7 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5916.28 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    12 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.13 ms /    21 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =    7433.24 ms /    11 runs   (  675.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8619.88 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     6 runs   (    0.44 ms per token,  2273.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.21 ms /    22 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3329.95 ms /     5 runs   (  665.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    4502.53 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     7 runs   (    0.44 ms per token,  2266.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.06 ms /    25 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =    4024.43 ms /     6 runs   (  670.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5328.61 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.66 ms /     8 runs   (    0.46 ms per token,  2184.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.38 ms /    23 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    4726.53 ms /     7 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5959.53 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     6 runs   (    0.44 ms per token,  2271.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.64 ms /    24 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    3358.49 ms /     5 runs   (  671.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4646.31 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    11 runs   (    0.43 ms per token,  2340.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.43 ms /    23 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    6797.44 ms /    10 runs   (  679.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8005.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     6 runs   (    0.46 ms per token,  2163.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.88 ms /    25 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    3457.32 ms /     5 runs   (  691.46 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    4787.80 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2322.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.61 ms /    20 tokens (   54.88 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =    4697.15 ms /     7 runs   (  671.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5817.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2316.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.60 ms /    21 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6119.07 ms /     9 runs   (  679.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7248.33 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2367.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.67 ms /    22 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4711.73 ms /     7 runs   (  673.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5889.97 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2331.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.89 ms /    22 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6071.40 ms /     9 runs   (  674.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7290.74 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2306.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.10 ms /    21 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6741.73 ms /    10 runs   (  674.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7866.52 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /     9 runs   (    0.44 ms per token,  2248.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.21 ms /    21 tokens (   61.39 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =    5504.54 ms /     8 runs   (  688.07 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6820.08 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     6 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.82 ms /    22 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =    3338.23 ms /     5 runs   (  667.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    4498.57 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2286.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.03 ms /    24 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    6123.56 ms /     9 runs   (  680.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7408.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    10 runs   (    0.44 ms per token,  2297.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.38 ms /    24 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =    6084.91 ms /     9 runs   (  676.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7334.85 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     7 runs   (    0.45 ms per token,  2214.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.46 ms /    21 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    4106.21 ms /     6 runs   (  684.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5236.07 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     6 runs   (    0.44 ms per token,  2258.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.80 ms /    23 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3453.98 ms /     5 runs   (  690.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    4665.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.75 ms /    24 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6756.03 ms /    10 runs   (  675.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8049.50 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     6 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.30 ms /    23 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    3344.87 ms /     5 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4554.88 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /    12 runs   (    0.43 ms per token,  2333.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.55 ms /    22 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    7242.54 ms /    11 runs   (  658.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8431.86 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    12 runs   (    0.43 ms per token,  2326.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1233.95 ms /    24 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    7410.25 ms /    11 runs   (  673.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8679.65 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    10 runs   (    0.46 ms per token,  2177.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.63 ms /    22 tokens (   62.44 ms per token,    16.02 tokens per second)\n",
      "llama_print_timings:        eval time =    6057.78 ms /     9 runs   (  673.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7463.35 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     8 runs   (    0.44 ms per token,  2268.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.28 ms /    25 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4631.76 ms /     7 runs   (  661.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5926.01 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     8 runs   (    0.45 ms per token,  2240.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.55 ms /    23 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4671.14 ms /     7 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5884.38 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    12 runs   (    0.44 ms per token,  2266.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.53 ms /    22 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    7422.12 ms /    11 runs   (  674.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8605.62 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    12 runs   (    0.43 ms per token,  2313.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.84 ms /    23 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    7459.61 ms /    11 runs   (  678.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8692.22 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    12 runs   (    0.42 ms per token,  2370.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.85 ms /    21 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    7489.16 ms /    11 runs   (  680.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8673.81 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.54 ms /    23 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5445.27 ms /     8 runs   (  680.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6677.04 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    11 runs   (    0.46 ms per token,  2170.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.58 ms /    24 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =    6963.22 ms /    10 runs   (  696.32 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8243.46 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     7 runs   (    0.43 ms per token,  2323.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1532.36 ms /    24 tokens (   63.85 ms per token,    15.66 tokens per second)\n",
      "llama_print_timings:        eval time =    4090.62 ms /     6 runs   (  681.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5644.20 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     8 runs   (    0.45 ms per token,  2237.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.02 ms /    24 tokens (   62.46 ms per token,    16.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4774.40 ms /     7 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6298.06 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2318.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.09 ms /    21 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4814.30 ms /     7 runs   (  687.76 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5937.70 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     7 runs   (    0.44 ms per token,  2263.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.83 ms /    28 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =    4063.17 ms /     6 runs   (  677.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5502.80 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2309.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.98 ms /    27 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6811.93 ms /    10 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8233.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     7 runs   (    0.43 ms per token,  2304.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.88 ms /    24 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4076.50 ms /     6 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5327.73 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     7 runs   (    0.45 ms per token,  2199.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.00 ms /    28 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4085.56 ms /     6 runs   (  680.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5508.75 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      25.62 ms /    58 runs   (    0.44 ms per token,  2263.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.49 ms /    28 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   38836.86 ms /    57 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   40423.72 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     9 runs   (    0.43 ms per token,  2313.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.05 ms /    27 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5472.97 ms /     8 runs   (  684.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6848.30 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2290.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.80 ms /    28 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =    8115.31 ms /    12 runs   (  676.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9562.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2311.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.21 ms /    27 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    7951.11 ms /    12 runs   (  662.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9434.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2282.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.71 ms /    26 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =    8036.18 ms /    12 runs   (  669.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9413.65 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     7 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1467.25 ms /    27 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =    4081.82 ms /     6 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5570.24 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2326.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.46 ms /    27 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    8217.79 ms /    12 runs   (  684.82 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9672.22 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2285.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.50 ms /    25 tokens (   59.66 ms per token,    16.76 tokens per second)\n",
      "llama_print_timings:        eval time =    5422.94 ms /     8 runs   (  677.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6941.99 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    11 runs   (    0.43 ms per token,  2343.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.87 ms /    25 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6725.28 ms /    10 runs   (  672.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8043.91 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2310.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.18 ms /    25 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =    4027.97 ms /     6 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5338.91 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     7 runs   (    0.44 ms per token,  2261.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.06 ms /    28 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    4092.26 ms /     6 runs   (  682.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5538.79 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /     8 runs   (    0.46 ms per token,  2189.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.85 ms /    26 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4677.73 ms /     7 runs   (  668.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6067.75 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     7 runs   (    0.42 ms per token,  2356.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.41 ms /    27 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =    4047.84 ms /     6 runs   (  674.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5452.69 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     7 runs   (    0.44 ms per token,  2289.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.09 ms /    27 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    3859.73 ms /     6 runs   (  643.29 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    5271.42 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     7 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.35 ms /    24 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    3955.11 ms /     6 runs   (  659.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5205.92 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    13 runs   (    0.44 ms per token,  2247.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.19 ms /    28 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8052.56 ms /    12 runs   (  671.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9543.54 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2318.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.88 ms /    24 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6575.83 ms /    10 runs   (  657.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7855.61 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     8 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1716.20 ms /    29 tokens (   59.18 ms per token,    16.90 tokens per second)\n",
      "llama_print_timings:        eval time =    4631.70 ms /     7 runs   (  661.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6372.38 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    12 runs   (    0.44 ms per token,  2297.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.00 ms /    27 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =    7183.40 ms /    11 runs   (  653.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    8592.89 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    14 runs   (    0.45 ms per token,  2246.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.92 ms /    27 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8743.46 ms /    13 runs   (  672.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10165.36 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    14 runs   (    0.45 ms per token,  2221.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.37 ms /    28 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =    8622.19 ms /    13 runs   (  663.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10080.89 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.19 ms /    24 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8082.79 ms /    12 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9401.20 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2266.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.84 ms /    28 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    5452.20 ms /     8 runs   (  681.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6915.34 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2276.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.80 ms /    24 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    4728.18 ms /     7 runs   (  675.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6034.14 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    15 runs   (    0.44 ms per token,  2274.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.10 ms /    28 tokens (   50.83 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =    9492.20 ms /    14 runs   (  678.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10960.47 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /     7 runs   (    0.45 ms per token,  2205.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.83 ms /    28 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4021.98 ms /     6 runs   (  670.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5444.29 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     7 runs   (    0.44 ms per token,  2258.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.22 ms /    25 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    3946.89 ms /     6 runs   (  657.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5255.78 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    12 runs   (    0.45 ms per token,  2244.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.00 ms /    29 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =    7451.27 ms /    11 runs   (  677.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8930.03 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2314.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.26 ms /    28 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4708.07 ms /     7 runs   (  672.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6155.50 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /     9 runs   (    0.57 ms per token,  1762.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1324.77 ms /    26 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    5777.13 ms /     8 runs   (  722.14 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    7134.54 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2315.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.64 ms /    26 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    6792.16 ms /    10 runs   (  679.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8169.35 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    19 runs   (    0.43 ms per token,  2303.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.28 ms /    27 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12328.14 ms /    18 runs   (  684.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13793.65 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    14 runs   (    0.44 ms per token,  2287.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.49 ms /    27 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =    8926.27 ms /    13 runs   (  686.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10329.34 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    13 runs   (    0.42 ms per token,  2381.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.81 ms /    24 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =    8125.14 ms /    12 runs   (  677.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9394.54 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    14 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.39 ms /    26 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =    8819.97 ms /    13 runs   (  678.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10208.37 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /     7 runs   (    0.46 ms per token,  2189.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.08 ms /    28 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =    4014.66 ms /     6 runs   (  669.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5454.95 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     5 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.96 ms /    27 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2676.53 ms /     4 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4107.12 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    15 runs   (    0.45 ms per token,  2244.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.47 ms /    25 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9461.21 ms /    14 runs   (  675.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10763.62 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2236.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.74 ms /    27 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6787.05 ms /    10 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8245.62 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    12 runs   (    0.44 ms per token,  2290.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.65 ms /    27 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =    7451.13 ms /    11 runs   (  677.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8905.38 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.13 ms /    27 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    4764.12 ms /     7 runs   (  680.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6173.00 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    12 runs   (    0.43 ms per token,  2326.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.99 ms /    28 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7376.94 ms /    11 runs   (  670.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8830.46 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     5 runs   (    0.43 ms per token,  2311.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.39 ms /    28 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    2675.78 ms /     4 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4140.29 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    14 runs   (    0.44 ms per token,  2288.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.28 ms /    27 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    8799.33 ms /    13 runs   (  676.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10233.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    10 runs   (    0.45 ms per token,  2246.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.80 ms /    25 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    6076.76 ms /     9 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7403.60 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /    12 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.30 ms /    25 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    7417.40 ms /    11 runs   (  674.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8752.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2281.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.96 ms /    27 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    5455.09 ms /     8 runs   (  681.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6882.71 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /     7 runs   (    0.45 ms per token,  2211.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.06 ms /    27 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4084.68 ms /     6 runs   (  680.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5577.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2311.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.08 ms /    25 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =    4050.87 ms /     6 runs   (  675.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5337.71 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /    11 runs   (    0.46 ms per token,  2194.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.00 ms /    28 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =    6747.78 ms /    10 runs   (  674.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8175.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     5 runs   (    0.43 ms per token,  2321.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.12 ms /    25 tokens (   61.84 ms per token,    16.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2699.93 ms /     4 runs   (  674.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4261.01 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    16 runs   (    0.45 ms per token,  2225.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1675.43 ms /    28 tokens (   59.84 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10148.12 ms /    15 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11871.73 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     5 runs   (    0.44 ms per token,  2273.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.15 ms /    29 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2671.28 ms /     4 runs   (  667.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    4135.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2310.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.31 ms /    27 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =    3998.33 ms /     6 runs   (  666.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5399.86 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /     7 runs   (    0.46 ms per token,  2155.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.67 ms /    27 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4018.56 ms /     6 runs   (  669.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5417.73 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2293.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.51 ms /    25 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =    8048.07 ms /    12 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9367.40 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2282.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.69 ms /    27 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =    5427.47 ms /     8 runs   (  678.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6832.35 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.44 ms per token,  2298.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.07 ms /    27 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    8071.79 ms /    12 runs   (  672.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9515.89 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.82 ms /    27 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6675.19 ms /    10 runs   (  667.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8056.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.09 ms /    14 runs   (    0.43 ms per token,  2299.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1589.19 ms /    26 tokens (   61.12 ms per token,    16.36 tokens per second)\n",
      "llama_print_timings:        eval time =    8804.52 ms /    13 runs   (  677.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10435.63 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2305.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.17 ms /    28 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    4873.18 ms /     7 runs   (  696.17 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6348.30 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    12 runs   (    0.44 ms per token,  2274.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.77 ms /    28 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =    7481.95 ms /    11 runs   (  680.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8915.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.06 ms /    14 runs   (    0.43 ms per token,  2308.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.99 ms /    24 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8897.88 ms /    13 runs   (  684.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10158.25 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     7 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.78 ms /    28 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4036.18 ms /     6 runs   (  672.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5465.62 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    16 runs   (    0.44 ms per token,  2276.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.10 ms /    28 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10220.95 ms /    15 runs   (  681.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11664.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2299.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.23 ms /    25 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    6755.06 ms /    10 runs   (  675.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8142.25 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2343.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.04 ms /    25 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6124.98 ms /     9 runs   (  680.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7424.78 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /     6 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.98 ms /    25 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =    3405.22 ms /     5 runs   (  681.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4762.66 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    14 runs   (    0.44 ms per token,  2266.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.83 ms /    28 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    8894.53 ms /    13 runs   (  684.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10375.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    15 runs   (    0.45 ms per token,  2221.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.47 ms /    25 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    9373.35 ms /    14 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10700.48 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2352.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.83 ms /    25 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    5483.85 ms /     8 runs   (  685.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6820.60 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2301.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.29 ms /    28 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =    7935.85 ms /    12 runs   (  661.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9370.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2309.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.01 ms /    25 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6641.03 ms /    10 runs   (  664.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7926.66 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    10 runs   (    0.44 ms per token,  2272.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.00 ms /    25 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    6043.20 ms /     9 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7396.27 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    15 runs   (    0.44 ms per token,  2273.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.03 ms /    27 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =    9244.23 ms /    14 runs   (  660.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10670.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    14 runs   (    0.47 ms per token,  2144.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.43 ms /    26 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    8699.94 ms /    13 runs   (  669.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10099.13 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    11 runs   (    0.45 ms per token,  2244.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.26 ms /    28 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =    6816.77 ms /    10 runs   (  681.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8313.47 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /     6 runs   (    0.42 ms per token,  2360.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.58 ms /    28 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =    3289.84 ms /     5 runs   (  657.97 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    4724.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    13 runs   (    0.49 ms per token,  2050.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.54 ms /    27 tokens (   52.21 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    8073.64 ms /    12 runs   (  672.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9527.65 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    11 runs   (    0.44 ms per token,  2261.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.57 ms /    25 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    6910.84 ms /    10 runs   (  691.08 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8228.71 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     9 runs   (    0.44 ms per token,  2290.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.07 ms /    27 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =    5433.96 ms /     8 runs   (  679.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6830.91 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.77 ms /    22 runs   (    0.44 ms per token,  2252.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.87 ms /    27 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   14272.62 ms /    21 runs   (  679.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15712.76 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     7 runs   (    0.45 ms per token,  2239.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.55 ms /    26 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4135.61 ms /     6 runs   (  689.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5602.50 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2318.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.33 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =    6123.60 ms /     9 runs   (  680.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7429.81 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    11 runs   (    0.44 ms per token,  2264.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.59 ms /    26 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =    6784.96 ms /    10 runs   (  678.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8139.53 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    15 runs   (    0.44 ms per token,  2276.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.38 ms /    27 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =    9441.82 ms /    14 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10844.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    14 runs   (    0.44 ms per token,  2273.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.54 ms /    27 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =    8822.65 ms /    13 runs   (  678.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10226.79 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    12 runs   (    0.43 ms per token,  2301.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.11 ms /    24 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7541.68 ms /    11 runs   (  685.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8852.28 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2334.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.88 ms /    27 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4104.91 ms /     6 runs   (  684.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5501.56 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2267.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.11 ms /    27 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =    8216.13 ms /    12 runs   (  684.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9647.84 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    14 runs   (    0.44 ms per token,  2254.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.35 ms /    21 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =    8787.00 ms /    13 runs   (  675.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9937.24 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2335.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.63 ms /    25 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    6149.87 ms /     9 runs   (  683.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7453.17 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2269.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.09 ms /    24 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =    5485.64 ms /     8 runs   (  685.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6766.67 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    28 runs   (    0.43 ms per token,  2307.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.63 ms /    27 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   18397.60 ms /    27 runs   (  681.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19839.71 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    13 runs   (    0.42 ms per token,  2368.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.33 ms /    19 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    8166.70 ms /    12 runs   (  680.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9211.98 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    13 runs   (    0.46 ms per token,  2184.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.85 ms /    26 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8017.75 ms /    12 runs   (  668.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9379.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     7 runs   (    0.44 ms per token,  2285.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.83 ms /    23 tokens (   61.47 ms per token,    16.27 tokens per second)\n",
      "llama_print_timings:        eval time =    4064.81 ms /     6 runs   (  677.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5499.66 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     7 runs   (    0.44 ms per token,  2261.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.68 ms /    28 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4040.02 ms /     6 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5466.79 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    17 runs   (    0.44 ms per token,  2263.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.28 ms /    27 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10913.01 ms /    16 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12341.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    18 runs   (    0.44 ms per token,  2288.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.25 ms /    27 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11561.46 ms /    17 runs   (  680.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13032.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2311.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.41 ms /    25 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    8387.16 ms /    12 runs   (  698.93 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    9740.72 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2275.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.21 ms /    24 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =    6790.86 ms /    10 runs   (  679.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8061.25 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    14 runs   (    0.43 ms per token,  2314.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.26 ms /    27 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    8763.70 ms /    13 runs   (  674.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10206.86 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2313.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.54 ms /    24 tokens (   60.19 ms per token,    16.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6061.58 ms /     9 runs   (  673.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7535.90 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    13 runs   (    0.43 ms per token,  2323.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.69 ms /    27 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    8015.99 ms /    12 runs   (  668.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9490.65 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2281.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.49 ms /    22 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    5442.37 ms /     8 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6621.06 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     6 runs   (    0.43 ms per token,  2338.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.76 ms /    27 tokens (   49.84 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3385.52 ms /     5 runs   (  677.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4748.80 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     7 runs   (    0.44 ms per token,  2271.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.88 ms /    28 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4099.84 ms /     6 runs   (  683.31 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5526.40 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2331.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1324.48 ms /    26 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    5380.98 ms /     8 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6732.60 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    14 runs   (    0.44 ms per token,  2274.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.88 ms /    27 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =    8792.63 ms /    13 runs   (  676.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10220.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     7 runs   (    0.42 ms per token,  2362.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.31 ms /    28 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =    4116.70 ms /     6 runs   (  686.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5550.62 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.67 ms /    24 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2034.55 ms /     3 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3306.70 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    13 runs   (    0.44 ms per token,  2249.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.92 ms /    29 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8069.69 ms /    12 runs   (  672.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9565.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2333.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.78 ms /    28 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    4722.48 ms /     7 runs   (  674.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6183.80 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2315.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1459.97 ms /    29 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =    8131.40 ms /    12 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9630.84 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2266.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.01 ms /    27 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5988.72 ms /     9 runs   (  665.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7435.87 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2332.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.26 ms /    25 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4695.54 ms /     7 runs   (  670.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6031.86 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     8 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.61 ms /    27 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4724.74 ms /     7 runs   (  674.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6108.40 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    18 runs   (    0.45 ms per token,  2210.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1508.39 ms /    29 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11201.49 ms /    17 runs   (  658.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12765.47 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     8 runs   (    0.44 ms per token,  2274.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.08 ms /    28 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =    4736.50 ms /     7 runs   (  676.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6194.76 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2289.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.84 ms /    26 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4762.82 ms /     7 runs   (  680.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6097.34 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     7 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.15 ms /    27 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =    4135.35 ms /     6 runs   (  689.22 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5542.76 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2309.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.42 ms /    27 tokens (   50.65 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6807.44 ms /    10 runs   (  680.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8208.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     7 runs   (    0.44 ms per token,  2273.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.50 ms /    28 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4177.68 ms /     6 runs   (  696.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5624.35 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    18 runs   (    0.44 ms per token,  2273.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.17 ms /    25 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11601.14 ms /    17 runs   (  682.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12937.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     6 runs   (    0.44 ms per token,  2256.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.44 ms /    27 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =    3388.24 ms /     5 runs   (  677.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4751.67 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2317.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.51 ms /    28 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5493.09 ms /     8 runs   (  686.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6965.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    15 runs   (    0.43 ms per token,  2309.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.07 ms /    27 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9489.43 ms /    14 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10928.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2302.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.29 ms /    28 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =    4733.09 ms /     7 runs   (  676.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6172.25 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    12 runs   (    0.43 ms per token,  2309.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.31 ms /    28 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    7480.82 ms /    11 runs   (  680.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8974.78 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    15 runs   (    0.43 ms per token,  2330.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.76 ms /    22 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    9709.23 ms /    14 runs   (  693.52 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   10896.56 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    11 runs   (    0.43 ms per token,  2346.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.77 ms /    21 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6772.10 ms /    10 runs   (  677.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7893.48 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    15 runs   (    0.44 ms per token,  2278.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.93 ms /    28 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =    9632.22 ms /    14 runs   (  688.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11118.76 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    12 runs   (    0.44 ms per token,  2247.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.52 ms /    27 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    7432.91 ms /    11 runs   (  675.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8866.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    10 runs   (    0.45 ms per token,  2230.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.21 ms /    27 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =    5958.63 ms /     9 runs   (  662.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7360.15 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     7 runs   (    0.45 ms per token,  2223.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.64 ms /    25 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    4059.16 ms /     6 runs   (  676.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5358.50 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    11 runs   (    0.43 ms per token,  2341.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.83 ms /    24 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6739.31 ms /    10 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8069.97 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    12 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.44 ms /    24 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    7484.19 ms /    11 runs   (  680.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8775.27 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    16 runs   (    0.45 ms per token,  2244.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.61 ms /    24 tokens (   61.94 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10087.50 ms /    15 runs   (  672.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11623.55 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    13 runs   (    0.44 ms per token,  2249.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.84 ms /    26 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =    8080.80 ms /    12 runs   (  673.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9454.77 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    15 runs   (    0.44 ms per token,  2268.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.78 ms /    26 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =    9412.79 ms /    14 runs   (  672.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10793.47 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2303.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.40 ms /    28 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    4781.37 ms /     7 runs   (  683.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6291.57 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2306.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.27 ms /    25 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8154.46 ms /    12 runs   (  679.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9467.73 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     5 runs   (    0.43 ms per token,  2313.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.94 ms /    28 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =    2716.84 ms /     4 runs   (  679.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4154.26 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.53 ms /    27 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    8067.70 ms /    12 runs   (  672.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9491.72 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /     9 runs   (    0.45 ms per token,  2226.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.36 ms /    26 tokens (   62.40 ms per token,    16.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5385.30 ms /     8 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7034.63 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    18 runs   (    0.44 ms per token,  2280.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1562.37 ms /    31 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11311.19 ms /    17 runs   (  665.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12927.29 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    16 runs   (    0.44 ms per token,  2251.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1508.92 ms /    30 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10031.99 ms /    15 runs   (  668.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11589.36 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.08 ms /    23 runs   (    0.44 ms per token,  2280.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.76 ms /    32 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   15020.07 ms /    22 runs   (  682.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16696.86 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    17 runs   (    0.44 ms per token,  2291.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.13 ms /    29 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10828.57 ms /    16 runs   (  676.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12357.36 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    17 runs   (    0.44 ms per token,  2258.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.78 ms /    29 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10868.16 ms /    16 runs   (  679.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12405.98 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    16 runs   (    0.45 ms per token,  2243.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.54 ms /    30 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =    9988.54 ms /    15 runs   (  665.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11536.29 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    18 runs   (    0.44 ms per token,  2288.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1567.73 ms /    31 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11347.49 ms /    17 runs   (  667.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12969.33 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    16 runs   (    0.45 ms per token,  2230.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.46 ms /    28 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10122.89 ms /    15 runs   (  674.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11579.33 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    14 runs   (    0.43 ms per token,  2315.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1601.21 ms /    32 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =    8783.75 ms /    13 runs   (  675.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10427.41 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2313.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.63 ms /    28 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10070.53 ms /    15 runs   (  671.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11541.67 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2364.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1685.65 ms /    28 tokens (   60.20 ms per token,    16.61 tokens per second)\n",
      "llama_print_timings:        eval time =    4764.69 ms /     7 runs   (  680.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6474.61 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /     9 runs   (    0.46 ms per token,  2196.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1577.80 ms /    32 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =    5364.25 ms /     8 runs   (  670.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6970.14 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    14 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.99 ms /    30 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8708.96 ms /    13 runs   (  669.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10272.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.80 ms /     4 runs   (    0.45 ms per token,  2225.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1585.43 ms /    32 tokens (   49.54 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1972.15 ms /     3 runs   (  657.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    3569.45 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.05 ms /    26 runs   (    0.42 ms per token,  2353.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1684.50 ms /    33 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   16724.53 ms /    25 runs   (  668.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18488.83 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    28 runs   (    0.43 ms per token,  2305.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.89 ms /    31 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   18193.91 ms /    27 runs   (  673.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19826.92 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    18 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1874.34 ms /    32 tokens (   58.57 ms per token,    17.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11540.20 ms /    17 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13469.79 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    12 runs   (    0.44 ms per token,  2253.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.04 ms /    23 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7536.33 ms /    11 runs   (  685.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8760.98 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    22 runs   (    0.44 ms per token,  2290.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.81 ms /    29 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14242.73 ms /    21 runs   (  678.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15755.59 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    17 runs   (    0.43 ms per token,  2327.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1522.11 ms /    30 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10651.48 ms /    16 runs   (  665.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12225.92 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    15 runs   (    0.45 ms per token,  2229.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.89 ms /    30 tokens (   53.46 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    9679.00 ms /    14 runs   (  691.36 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11330.21 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.69 ms /    55 runs   (    0.41 ms per token,  2423.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1474.33 ms /    29 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   37051.61 ms /    54 runs   (  686.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   38695.69 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    15 runs   (    0.44 ms per token,  2268.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1670.10 ms /    33 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =    9450.97 ms /    14 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11167.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    16 runs   (    0.44 ms per token,  2255.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1572.80 ms /    32 tokens (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10035.84 ms /    15 runs   (  669.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11658.17 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.07 ms /    25 runs   (    0.44 ms per token,  2257.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1581.15 ms /    32 tokens (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   16211.11 ms /    24 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17869.16 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    17 runs   (    0.42 ms per token,  2353.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.35 ms /    28 tokens (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10929.52 ms /    16 runs   (  683.10 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12384.98 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    14 runs   (    0.44 ms per token,  2251.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1459.93 ms /    29 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =    8837.54 ms /    13 runs   (  679.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10339.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    14 runs   (    0.45 ms per token,  2240.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1588.24 ms /    32 tokens (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =    8864.37 ms /    13 runs   (  681.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10497.32 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    15 runs   (    0.44 ms per token,  2262.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1589.23 ms /    32 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =    9549.62 ms /    14 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11185.03 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    15 runs   (    0.43 ms per token,  2315.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1571.95 ms /    31 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =    9512.65 ms /    14 runs   (  679.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11129.83 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    23 runs   (    0.44 ms per token,  2297.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1820.86 ms /    31 tokens (   58.74 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:        eval time =   15173.19 ms /    22 runs   (  689.69 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   17066.21 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    17 runs   (    0.44 ms per token,  2290.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.91 ms /    30 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10854.24 ms /    16 runs   (  678.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12407.03 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.27 ms /    14 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.73 ms /    28 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =    8793.27 ms /    13 runs   (  676.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10249.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    17 runs   (    0.43 ms per token,  2299.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.97 ms /    27 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10909.19 ms /    16 runs   (  681.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12332.85 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    16 runs   (    0.46 ms per token,  2181.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.70 ms /    27 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10135.23 ms /    15 runs   (  675.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11581.29 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    13 runs   (    0.45 ms per token,  2234.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.89 ms /    26 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    8216.56 ms /    12 runs   (  684.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9643.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2285.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1598.74 ms /    32 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10137.49 ms /    15 runs   (  675.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11785.50 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.01 ms /    25 runs   (    0.44 ms per token,  2270.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1590.19 ms /    32 tokens (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   16220.20 ms /    24 runs   (  675.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17886.23 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    16 runs   (    0.45 ms per token,  2220.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.10 ms /    32 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10184.32 ms /    15 runs   (  678.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11845.95 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    18 runs   (    0.44 ms per token,  2276.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1547.91 ms /    30 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11566.09 ms /    17 runs   (  680.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13168.84 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    16 runs   (    0.50 ms per token,  1980.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.55 ms /    25 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10182.66 ms /    15 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11514.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    17 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.84 ms /    28 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10764.01 ms /    16 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12231.89 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.09 ms /    14 runs   (    0.44 ms per token,  2298.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1470.33 ms /    28 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    8997.74 ms /    13 runs   (  692.13 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   10511.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2312.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.00 ms /    30 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =    8134.64 ms /    12 runs   (  677.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9685.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    16 runs   (    0.44 ms per token,  2263.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2251.47 ms /    33 tokens (   68.23 ms per token,    14.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10109.52 ms /    15 runs   (  673.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12409.89 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    23 runs   (    0.44 ms per token,  2269.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1349.56 ms /    27 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   14776.29 ms /    22 runs   (  671.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16195.56 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2284.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1564.01 ms /    26 tokens (   60.15 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10162.21 ms /    15 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11776.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      17.06 ms /    40 runs   (    0.43 ms per token,  2344.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1567.31 ms /    30 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   26300.44 ms /    39 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27989.85 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    10 runs   (    0.45 ms per token,  2246.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.21 ms /    28 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =    5945.04 ms /     9 runs   (  660.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7416.11 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    15 runs   (    0.44 ms per token,  2270.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.55 ms /    28 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =    9366.40 ms /    14 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10841.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    15 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.15 ms /    28 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    9278.73 ms /    14 runs   (  662.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10769.30 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    16 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.16 ms /    29 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10135.86 ms /    15 runs   (  675.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11632.18 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    17 runs   (    0.44 ms per token,  2285.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.08 ms /    28 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10705.90 ms /    16 runs   (  669.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12190.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /     7 runs   (    0.45 ms per token,  2229.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1596.30 ms /    31 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4040.64 ms /     6 runs   (  673.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5658.51 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2269.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.54 ms /    28 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    7997.53 ms /    12 runs   (  666.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9495.35 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    18 runs   (    0.43 ms per token,  2306.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.70 ms /    32 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11426.38 ms /    17 runs   (  672.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13139.19 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    15 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.90 ms /    26 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =    9487.70 ms /    14 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10872.17 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    13 runs   (    0.44 ms per token,  2256.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1687.78 ms /    28 tokens (   60.28 ms per token,    16.59 tokens per second)\n",
      "llama_print_timings:        eval time =    7972.18 ms /    12 runs   (  664.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9700.11 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    15 runs   (    0.43 ms per token,  2343.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.56 ms /    27 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =    9333.43 ms /    14 runs   (  666.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10775.40 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    17 runs   (    0.44 ms per token,  2286.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.81 ms /    28 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10773.85 ms /    16 runs   (  673.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12246.54 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    16 runs   (    0.44 ms per token,  2248.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1567.70 ms /    32 tokens (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10277.50 ms /    15 runs   (  685.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11894.45 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    28 runs   (    0.43 ms per token,  2328.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1560.73 ms /    31 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   18417.48 ms /    27 runs   (  682.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20063.89 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    14 runs   (    0.46 ms per token,  2196.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.73 ms /    28 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8708.24 ms /    13 runs   (  669.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10164.07 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    12 runs   (    0.45 ms per token,  2211.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.37 ms /    28 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    7466.54 ms /    11 runs   (  678.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8956.41 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    16 runs   (    0.45 ms per token,  2234.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.71 ms /    28 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10210.09 ms /    15 runs   (  680.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11712.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.53 ms /    22 runs   (    0.43 ms per token,  2308.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.04 ms /    29 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14068.56 ms /    21 runs   (  669.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15589.69 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2294.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.21 ms /    26 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4625.01 ms /     7 runs   (  660.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6011.36 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    18 runs   (    0.45 ms per token,  2237.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.92 ms /    30 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11562.53 ms /    17 runs   (  680.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13105.49 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2319.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.78 ms /    28 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10039.96 ms /    15 runs   (  669.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11502.73 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    16 runs   (    0.45 ms per token,  2235.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1615.33 ms /    32 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =    9955.18 ms /    15 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11620.45 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    18 runs   (    0.43 ms per token,  2316.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.85 ms /    28 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11337.44 ms /    17 runs   (  666.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12812.77 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.37 ms /    24 runs   (    0.43 ms per token,  2314.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.61 ms /    28 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15479.87 ms /    23 runs   (  673.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16965.26 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2286.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.79 ms /    25 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10175.51 ms /    15 runs   (  678.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11509.07 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    17 runs   (    0.44 ms per token,  2259.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.23 ms /    26 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10783.81 ms /    16 runs   (  673.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12246.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    17 runs   (    0.45 ms per token,  2241.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.69 ms /    29 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10820.70 ms /    16 runs   (  676.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12351.03 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    16 runs   (    0.45 ms per token,  2208.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.29 ms /    28 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10235.29 ms /    15 runs   (  682.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11704.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    18 runs   (    0.44 ms per token,  2251.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.28 ms /    32 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11570.27 ms /    17 runs   (  680.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13231.82 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2284.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.31 ms /    27 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10204.38 ms /    15 runs   (  680.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11643.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    17 runs   (    0.43 ms per token,  2322.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.12 ms /    29 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10802.67 ms /    16 runs   (  675.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12338.41 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    15 runs   (    0.44 ms per token,  2296.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.14 ms /    28 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =    9549.75 ms /    14 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10998.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    18 runs   (    0.43 ms per token,  2307.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.59 ms /    30 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11541.20 ms /    17 runs   (  678.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13104.25 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    17 runs   (    0.44 ms per token,  2273.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1467.15 ms /    29 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10726.80 ms /    16 runs   (  670.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12246.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    25 runs   (    0.44 ms per token,  2291.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1576.33 ms /    31 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   16145.60 ms /    24 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17798.67 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    20 runs   (    0.44 ms per token,  2265.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1641.54 ms /    32 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12764.87 ms /    19 runs   (  671.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14468.51 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    22 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1762.46 ms /    34 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   14151.88 ms /    21 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15982.43 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    16 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.29 ms /    30 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10070.99 ms /    15 runs   (  671.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11612.97 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    16 runs   (    0.45 ms per token,  2207.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.30 ms /    28 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10054.61 ms /    15 runs   (  670.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11562.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    18 runs   (    0.43 ms per token,  2315.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.13 ms /    31 tokens (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11132.70 ms /    17 runs   (  654.86 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12722.98 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    14 runs   (    0.44 ms per token,  2288.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.53 ms /    28 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =    8761.41 ms /    13 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10216.57 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    19 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1514.10 ms /    30 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12049.44 ms /    18 runs   (  669.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13622.01 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     5 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.97 ms /    27 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =    2663.63 ms /     4 runs   (  665.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    4029.73 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    18 runs   (    0.44 ms per token,  2274.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.26 ms /    29 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11589.50 ms /    17 runs   (  681.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13124.82 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    17 runs   (    0.44 ms per token,  2287.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1488.32 ms /    28 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10519.65 ms /    16 runs   (  657.48 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12061.16 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    20 runs   (    0.45 ms per token,  2234.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1646.92 ms /    33 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12552.47 ms /    19 runs   (  660.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14262.22 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    16 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1856.72 ms /    30 tokens (   61.89 ms per token,    16.16 tokens per second)\n",
      "llama_print_timings:        eval time =    9928.28 ms /    15 runs   (  661.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11834.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    17 runs   (    0.43 ms per token,  2335.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1524.18 ms /    30 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10597.32 ms /    16 runs   (  662.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12174.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    19 runs   (    0.43 ms per token,  2319.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.25 ms /    29 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11946.68 ms /    18 runs   (  663.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13456.51 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    15 runs   (    0.44 ms per token,  2262.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.78 ms /    32 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =    9402.86 ms /    14 runs   (  671.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11062.83 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     9 runs   (    0.44 ms per token,  2288.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.40 ms /    27 tokens (   51.53 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =    5405.61 ms /     8 runs   (  675.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6824.31 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    17 runs   (    0.44 ms per token,  2271.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.71 ms /    31 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10831.78 ms /    16 runs   (  676.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12463.19 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    16 runs   (    0.44 ms per token,  2281.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.47 ms /    29 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10047.11 ms /    15 runs   (  669.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11558.34 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    27 runs   (    0.44 ms per token,  2258.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.52 ms /    32 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   17604.39 ms /    26 runs   (  677.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19319.80 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    14 runs   (    0.43 ms per token,  2302.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.43 ms /    28 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8811.35 ms /    13 runs   (  677.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10306.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    17 runs   (    0.44 ms per token,  2298.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.34 ms /    30 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10816.69 ms /    16 runs   (  676.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12360.22 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2289.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.65 ms /    28 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =    8094.75 ms /    12 runs   (  674.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9536.37 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    17 runs   (    0.44 ms per token,  2277.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1531.19 ms /    31 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10801.95 ms /    16 runs   (  675.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12385.85 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    17 runs   (    0.45 ms per token,  2234.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1542.48 ms /    31 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10841.99 ms /    16 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12436.72 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2285.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.91 ms /    26 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10085.68 ms /    15 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11453.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.70 ms /    25 runs   (    0.43 ms per token,  2337.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1774.58 ms /    34 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   15931.85 ms /    24 runs   (  663.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17782.06 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    17 runs   (    0.44 ms per token,  2272.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.35 ms /    28 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10547.99 ms /    16 runs   (  659.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12014.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    19 runs   (    0.45 ms per token,  2213.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1480.87 ms /    30 tokens (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12443.42 ms /    18 runs   (  691.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13984.05 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    17 runs   (    0.43 ms per token,  2302.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1596.07 ms /    32 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10982.63 ms /    16 runs   (  686.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12631.53 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    17 runs   (    0.45 ms per token,  2210.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1614.22 ms /    32 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10841.71 ms /    16 runs   (  677.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12508.98 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    16 runs   (    0.44 ms per token,  2296.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1529.34 ms /    30 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10187.34 ms /    15 runs   (  679.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11766.02 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.14 ms /    14 runs   (    0.44 ms per token,  2280.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.56 ms /    30 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =    8835.07 ms /    13 runs   (  679.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10414.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    17 runs   (    0.45 ms per token,  2239.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.75 ms /    30 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10970.90 ms /    16 runs   (  685.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12540.45 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.99 ms /    20 runs   (    0.45 ms per token,  2224.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1670.47 ms /    33 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12903.37 ms /    19 runs   (  679.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14637.21 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.55 ms /    27 runs   (    0.43 ms per token,  2337.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1676.96 ms /    33 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17538.16 ms /    26 runs   (  674.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19298.12 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    17 runs   (    0.43 ms per token,  2306.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.06 ms /    29 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10918.82 ms /    16 runs   (  682.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12419.25 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    28 runs   (    0.44 ms per token,  2296.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.29 ms /    30 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   18293.46 ms /    27 runs   (  677.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19880.06 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    17 runs   (    0.43 ms per token,  2347.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1561.20 ms /    31 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10787.81 ms /    16 runs   (  674.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12401.64 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    16 runs   (    0.46 ms per token,  2186.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1574.97 ms /    32 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =    9931.25 ms /    15 runs   (  662.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11556.67 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2283.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1488.19 ms /    29 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6616.06 ms /    10 runs   (  661.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8137.54 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    15 runs   (    0.44 ms per token,  2257.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.53 ms /    26 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    9482.65 ms /    14 runs   (  677.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10882.42 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    15 runs   (    0.44 ms per token,  2266.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.64 ms /    31 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =    9428.99 ms /    14 runs   (  673.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11022.24 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    15 runs   (    0.44 ms per token,  2282.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.85 ms /    31 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9517.16 ms /    14 runs   (  679.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11142.60 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    14 runs   (    0.44 ms per token,  2271.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.20 ms /    28 tokens (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =    8743.50 ms /    13 runs   (  672.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10181.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    18 runs   (    0.43 ms per token,  2330.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.72 ms /    29 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11433.06 ms /    17 runs   (  672.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12944.54 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2286.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.62 ms /    30 tokens (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =    5401.65 ms /     8 runs   (  675.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6914.81 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    16 runs   (    0.44 ms per token,  2269.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1612.43 ms /    31 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10191.40 ms /    15 runs   (  679.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11853.70 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    17 runs   (    0.45 ms per token,  2224.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1517.33 ms /    30 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10991.93 ms /    16 runs   (  687.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12561.86 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    16 runs   (    0.45 ms per token,  2219.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.26 ms /    28 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10228.04 ms /    15 runs   (  681.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11680.57 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    14 runs   (    0.43 ms per token,  2302.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.54 ms /    27 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =    8770.65 ms /    13 runs   (  674.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10205.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    15 runs   (    0.45 ms per token,  2229.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1611.78 ms /    32 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =    9526.34 ms /    14 runs   (  680.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11184.59 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    15 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.39 ms /    26 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =    9320.27 ms /    14 runs   (  665.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10692.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    17 runs   (    0.44 ms per token,  2264.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1536.27 ms /    31 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10849.69 ms /    16 runs   (  678.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12438.96 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    18 runs   (    0.45 ms per token,  2209.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.05 ms /    27 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11455.80 ms /    17 runs   (  673.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12900.70 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     5 runs   (    0.44 ms per token,  2271.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1698.88 ms /    29 tokens (   58.58 ms per token,    17.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2746.55 ms /     4 runs   (  686.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    4460.78 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    16 runs   (    0.44 ms per token,  2278.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1721.06 ms /    29 tokens (   59.35 ms per token,    16.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10140.94 ms /    15 runs   (  676.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11911.68 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     7 runs   (    0.45 ms per token,  2221.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.81 ms /    30 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =    4061.00 ms /     6 runs   (  676.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5562.08 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    16 runs   (    0.44 ms per token,  2271.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1590.39 ms /    32 tokens (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10196.75 ms /    15 runs   (  679.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11836.17 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    16 runs   (    0.46 ms per token,  2190.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1505.60 ms /    30 tokens (   50.19 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10243.80 ms /    15 runs   (  682.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11799.90 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    15 runs   (    0.45 ms per token,  2232.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.56 ms /    31 tokens (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9588.23 ms /    14 runs   (  684.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11156.05 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    14 runs   (    0.45 ms per token,  2242.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.19 ms /    31 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8847.41 ms /    13 runs   (  680.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10475.07 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    14 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.69 ms /    30 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =    8880.78 ms /    13 runs   (  683.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10437.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    17 runs   (    0.43 ms per token,  2313.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.72 ms /    26 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10862.87 ms /    16 runs   (  678.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12232.81 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    17 runs   (    0.45 ms per token,  2240.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.32 ms /    29 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10838.94 ms /    16 runs   (  677.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12354.16 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    17 runs   (    0.44 ms per token,  2265.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.75 ms /    28 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10815.08 ms /    16 runs   (  675.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12310.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    15 runs   (    0.45 ms per token,  2226.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.64 ms /    32 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =    9496.77 ms /    14 runs   (  678.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11136.67 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    15 runs   (    0.45 ms per token,  2227.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.39 ms /    28 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9438.81 ms /    14 runs   (  674.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10891.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.78 ms /    27 runs   (    0.44 ms per token,  2292.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.00 ms /    33 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   17672.23 ms /    26 runs   (  679.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19410.73 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    25 runs   (    0.43 ms per token,  2306.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1682.55 ms /    34 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   16198.02 ms /    24 runs   (  674.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17957.51 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    21 runs   (    0.43 ms per token,  2319.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1538.19 ms /    30 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13490.33 ms /    20 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15093.29 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /    12 runs   (    0.45 ms per token,  2240.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1726.31 ms /    33 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    7424.01 ms /    11 runs   (  674.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9187.64 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      17.83 ms /    45 runs   (    0.40 ms per token,  2524.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1759.19 ms /    34 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   29788.33 ms /    44 runs   (  677.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31685.92 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    25 runs   (    0.43 ms per token,  2306.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1683.86 ms /    34 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   16080.12 ms /    24 runs   (  670.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17841.51 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     4 runs   (    0.43 ms per token,  2302.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1585.05 ms /    32 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1991.05 ms /     3 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    3588.24 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    10 runs   (    0.45 ms per token,  2198.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1739.24 ms /    33 tokens (   52.70 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6073.07 ms /     9 runs   (  674.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7842.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    25 runs   (    0.43 ms per token,  2325.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1806.04 ms /    36 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   16297.20 ms /    24 runs   (  679.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18181.61 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    20 runs   (    0.44 ms per token,  2291.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.30 ms /    26 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12942.58 ms /    19 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14322.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    20 runs   (    0.44 ms per token,  2269.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1714.54 ms /    34 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12827.38 ms /    19 runs   (  675.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14603.47 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.70 ms /    30 runs   (    0.46 ms per token,  2190.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1756.57 ms /    35 tokens (   50.19 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   19472.41 ms /    29 runs   (  671.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21327.35 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2281.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1576.06 ms /    31 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =    5435.65 ms /     8 runs   (  679.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7040.15 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      19.46 ms /    48 runs   (    0.41 ms per token,  2466.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1795.77 ms /    35 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   31502.01 ms /    47 runs   (  670.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33447.04 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.44 ms /    24 runs   (    0.43 ms per token,  2299.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1845.96 ms /    37 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   15268.21 ms /    23 runs   (  663.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17188.60 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    26 runs   (    0.43 ms per token,  2309.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1815.02 ms /    36 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   16950.31 ms /    25 runs   (  678.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18846.77 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    19 runs   (    0.44 ms per token,  2264.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1581.58 ms /    32 tokens (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12091.09 ms /    18 runs   (  671.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13731.71 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    21 runs   (    0.44 ms per token,  2287.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1799.71 ms /    33 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13460.60 ms /    20 runs   (  673.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15327.16 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    25 runs   (    0.44 ms per token,  2291.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.93 ms /    31 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   16301.60 ms /    24 runs   (  679.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17928.57 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.72 ms /    22 runs   (    0.44 ms per token,  2264.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1844.48 ms /    36 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   14090.53 ms /    21 runs   (  670.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16003.97 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    23 runs   (    0.44 ms per token,  2256.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1674.63 ms /    33 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14777.83 ms /    22 runs   (  671.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16523.78 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.39 ms /    22 runs   (    0.43 ms per token,  2343.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1815.03 ms /    35 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14116.87 ms /    21 runs   (  672.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16000.05 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    24 runs   (    0.42 ms per token,  2390.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.17 ms /    32 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   15448.42 ms /    23 runs   (  671.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17106.96 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    20 runs   (    0.44 ms per token,  2272.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1536.58 ms /    31 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12829.28 ms /    19 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14428.73 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    18 runs   (    0.44 ms per token,  2274.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.35 ms /    32 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11834.72 ms /    17 runs   (  696.16 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13483.10 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.85 ms /    25 runs   (    0.43 ms per token,  2303.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1832.38 ms /    36 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   16150.68 ms /    24 runs   (  672.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18060.33 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    23 runs   (    0.43 ms per token,  2350.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1800.24 ms /    35 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   14728.47 ms /    22 runs   (  669.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16599.72 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    15 runs   (    0.45 ms per token,  2239.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1597.43 ms /    32 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9484.29 ms /    14 runs   (  677.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11129.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    20 runs   (    0.43 ms per token,  2329.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1799.47 ms /    36 tokens (   49.99 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12644.68 ms /    19 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14505.75 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    25 runs   (    0.43 ms per token,  2299.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1779.51 ms /    36 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   16133.12 ms /    24 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17989.37 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    21 runs   (    0.44 ms per token,  2285.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.48 ms /    30 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13429.53 ms /    20 runs   (  671.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14996.54 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    27 runs   (    0.44 ms per token,  2290.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1833.55 ms /    36 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   17447.12 ms /    26 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19364.92 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    26 runs   (    0.47 ms per token,  2126.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2043.22 ms /    35 tokens (   58.38 ms per token,    17.13 tokens per second)\n",
      "llama_print_timings:        eval time =   16793.72 ms /    25 runs   (  671.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18918.58 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    21 runs   (    0.43 ms per token,  2346.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1768.06 ms /    35 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13498.55 ms /    20 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15331.39 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1702.90 ms /    34 tokens (   50.09 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5938.65 ms /     9 runs   (  659.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7673.68 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    21 runs   (    0.43 ms per token,  2324.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1735.04 ms /    35 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   13213.83 ms /    20 runs   (  660.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15014.36 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /     6 runs   (    0.45 ms per token,  2208.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1503.10 ms /    30 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =    3381.26 ms /     5 runs   (  676.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4903.34 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.80 ms /    23 runs   (    0.43 ms per token,  2345.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1953.04 ms /    35 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   14840.78 ms /    22 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16865.53 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.52 ms /    27 runs   (    0.43 ms per token,  2344.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1789.70 ms /    35 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   17533.66 ms /    26 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19407.23 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    20 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1825.54 ms /    35 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12570.06 ms /    19 runs   (  661.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14458.60 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    21 runs   (    0.44 ms per token,  2272.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1602.57 ms /    32 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   13420.62 ms /    20 runs   (  671.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15091.49 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    16 runs   (    0.46 ms per token,  2173.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1848.75 ms /    32 tokens (   57.77 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10131.41 ms /    15 runs   (  675.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12030.79 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    28 runs   (    0.43 ms per token,  2344.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1770.36 ms /    35 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   18244.82 ms /    27 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20101.37 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.99 ms /    23 runs   (    0.43 ms per token,  2303.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1552.74 ms /    31 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14809.56 ms /    22 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16433.56 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    20 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1719.67 ms /    34 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12818.91 ms /    19 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14600.54 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    28 runs   (    0.43 ms per token,  2326.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1690.91 ms /    34 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   18080.32 ms /    27 runs   (  669.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19858.06 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    21 runs   (    0.44 ms per token,  2259.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1669.74 ms /    33 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13399.61 ms /    20 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15134.22 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.40 ms /    23 runs   (    0.45 ms per token,  2211.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1745.25 ms /    34 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   14858.06 ms /    22 runs   (  675.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16677.14 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    16 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.85 ms /    35 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   10205.13 ms /    15 runs   (  680.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12041.39 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    14 runs   (    0.45 ms per token,  2245.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1714.11 ms /    33 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =    8884.03 ms /    13 runs   (  683.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10641.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2334.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1796.02 ms /    34 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6082.26 ms /     9 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7909.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    23 runs   (    0.47 ms per token,  2123.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1649.13 ms /    33 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   15054.27 ms /    22 runs   (  684.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16778.10 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    21 runs   (    0.43 ms per token,  2312.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1671.41 ms /    33 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   13487.73 ms /    20 runs   (  674.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15224.19 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    16 runs   (    0.44 ms per token,  2292.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1698.89 ms /    33 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10019.77 ms /    15 runs   (  667.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11767.69 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    22 runs   (    0.43 ms per token,  2340.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1889.72 ms /    37 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14051.73 ms /    21 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16011.58 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    16 runs   (    0.43 ms per token,  2309.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1699.24 ms /    33 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10015.49 ms /    15 runs   (  667.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11764.27 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.50 ms /    25 runs   (    0.42 ms per token,  2381.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.50 ms /    30 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   16276.33 ms /    24 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17869.64 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    20 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1594.64 ms /    32 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12795.27 ms /    19 runs   (  673.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14452.64 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    22 runs   (    0.43 ms per token,  2348.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1887.64 ms /    36 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13953.98 ms /    21 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15909.58 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    17 runs   (    0.43 ms per token,  2343.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1691.19 ms /    34 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10523.29 ms /    16 runs   (  657.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12266.77 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    20 runs   (    0.44 ms per token,  2273.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1748.48 ms /    34 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12665.12 ms /    19 runs   (  666.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14475.63 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      20.03 ms /    49 runs   (    0.41 ms per token,  2446.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1800.95 ms /    36 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   32216.67 ms /    48 runs   (  671.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34170.77 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    24 runs   (    0.42 ms per token,  2374.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1857.91 ms /    37 tokens (   50.21 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15458.35 ms /    23 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17391.46 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    14 runs   (    0.45 ms per token,  2225.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1699.21 ms /    33 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =    8740.77 ms /    13 runs   (  672.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10483.19 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.39 ms /    24 runs   (    0.43 ms per token,  2309.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1708.84 ms /    34 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   15589.95 ms /    23 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17375.40 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    30 runs   (    0.43 ms per token,  2343.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1828.29 ms /    36 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   19227.13 ms /    29 runs   (  663.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21150.32 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    22 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1936.36 ms /    33 tokens (   58.68 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   14211.87 ms /    21 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16216.59 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2310.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1796.99 ms /    36 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5371.86 ms /     8 runs   (  671.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7196.76 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    20 runs   (    0.43 ms per token,  2306.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1581.31 ms /    32 tokens (   49.42 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12778.88 ms /    19 runs   (  672.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14422.26 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.76 ms /    25 runs   (    0.43 ms per token,  2324.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.75 ms /    30 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   16097.55 ms /    24 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17701.04 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    28 runs   (    0.44 ms per token,  2295.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1705.39 ms /    33 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   18162.03 ms /    27 runs   (  672.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19956.42 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      23.49 ms /    56 runs   (    0.42 ms per token,  2384.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1760.37 ms /    35 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   37628.02 ms /    55 runs   (  684.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   39563.22 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.18 ms /    26 runs   (    0.43 ms per token,  2325.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1842.30 ms /    35 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   16974.47 ms /    25 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18897.54 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    21 runs   (    0.44 ms per token,  2264.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1746.20 ms /    33 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   13685.19 ms /    20 runs   (  684.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15497.32 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    23 runs   (    0.43 ms per token,  2332.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1754.28 ms /    34 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   14948.17 ms /    22 runs   (  679.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16774.24 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    17 runs   (    0.44 ms per token,  2284.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1704.73 ms /    34 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10273.82 ms /    16 runs   (  642.11 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   12030.33 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    25 runs   (    0.42 ms per token,  2399.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1794.03 ms /    35 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   16071.68 ms /    24 runs   (  669.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17942.86 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    12 runs   (    0.45 ms per token,  2232.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1870.80 ms /    37 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7491.73 ms /    11 runs   (  681.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9400.24 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    20 runs   (    0.44 ms per token,  2279.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1787.42 ms /    35 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12819.41 ms /    19 runs   (  674.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14668.70 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    22 runs   (    0.44 ms per token,  2278.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1733.89 ms /    34 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   14108.36 ms /    21 runs   (  671.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15909.60 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.20 ms /    26 runs   (    0.43 ms per token,  2321.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1850.24 ms /    37 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   16773.06 ms /    25 runs   (  670.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18704.34 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.74 ms /    25 runs   (    0.43 ms per token,  2327.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1755.18 ms /    33 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   16254.07 ms /    24 runs   (  677.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18086.44 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    28 runs   (    0.42 ms per token,  2374.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1705.43 ms /    34 tokens (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   17970.88 ms /    27 runs   (  665.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19762.86 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    28 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1739.40 ms /    34 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   17927.62 ms /    27 runs   (  663.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19753.49 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      19.34 ms /    48 runs   (    0.40 ms per token,  2482.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1759.21 ms /    33 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   31521.93 ms /    47 runs   (  670.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33432.41 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    19 runs   (    0.44 ms per token,  2271.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1534.15 ms /    31 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12146.13 ms /    18 runs   (  674.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13738.86 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    20 runs   (    0.44 ms per token,  2272.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1699.90 ms /    33 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   13013.82 ms /    19 runs   (  684.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14776.32 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2316.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1566.09 ms /    31 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2031.50 ms /     3 runs   (  677.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3610.05 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.82 ms /    25 runs   (    0.43 ms per token,  2311.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1786.40 ms /    35 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   16234.65 ms /    24 runs   (  676.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18099.03 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.97 ms /    26 runs   (    0.42 ms per token,  2369.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1702.02 ms /    33 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   16943.37 ms /    25 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18725.92 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.20 ms /    23 runs   (    0.44 ms per token,  2254.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1810.86 ms /    35 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   14873.82 ms /    22 runs   (  676.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16755.81 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    20 runs   (    0.44 ms per token,  2279.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.08 ms /    32 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12803.58 ms /    19 runs   (  673.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14449.11 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    19 runs   (    0.44 ms per token,  2270.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.77 ms /    27 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12177.87 ms /    18 runs   (  676.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13620.41 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    19 runs   (    0.44 ms per token,  2289.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2079.17 ms /    36 tokens (   57.75 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12143.20 ms /    18 runs   (  674.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14280.76 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    20 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1596.80 ms /    32 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12878.32 ms /    19 runs   (  677.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14535.77 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    18 runs   (    0.44 ms per token,  2265.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1860.33 ms /    37 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11464.30 ms /    17 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13380.95 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.19 ms /    26 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1796.54 ms /    36 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   16879.49 ms /    25 runs   (  675.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18757.46 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    18 runs   (    0.44 ms per token,  2265.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1679.21 ms /    33 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11464.55 ms /    17 runs   (  674.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13199.07 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.96 ms /    30 runs   (    0.43 ms per token,  2315.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1748.68 ms /    35 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   19253.28 ms /    29 runs   (  663.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21095.48 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    22 runs   (    0.43 ms per token,  2314.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.59 ms /    27 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   14056.25 ms /    21 runs   (  669.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15531.22 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      18.71 ms /    45 runs   (    0.42 ms per token,  2404.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1707.15 ms /    33 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   29933.14 ms /    44 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31780.91 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    20 runs   (    0.44 ms per token,  2274.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1577.75 ms /    32 tokens (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12585.96 ms /    19 runs   (  662.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14226.14 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    18 runs   (    0.43 ms per token,  2335.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1897.08 ms /    35 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11487.23 ms /    17 runs   (  675.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13439.17 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.75 ms /    20 runs   (    0.44 ms per token,  2284.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1788.25 ms /    34 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12899.55 ms /    19 runs   (  678.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14749.94 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /     9 runs   (    0.44 ms per token,  2297.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1677.18 ms /    33 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =    5427.06 ms /     8 runs   (  678.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7132.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    20 runs   (    0.43 ms per token,  2308.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1678.86 ms /    33 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   13095.69 ms /    19 runs   (  689.25 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14837.66 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    22 runs   (    0.44 ms per token,  2289.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.23 ms /    29 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   14164.77 ms /    21 runs   (  674.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15681.81 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    18 runs   (    0.43 ms per token,  2344.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1524.18 ms /    31 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11478.82 ms /    17 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13058.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.09 ms /    26 runs   (    0.43 ms per token,  2343.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1545.25 ms /    29 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   16758.74 ms /    25 runs   (  670.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18384.58 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    15 runs   (    0.45 ms per token,  2218.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1784.35 ms /    35 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =    9341.11 ms /    14 runs   (  667.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11172.66 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      19.23 ms /    47 runs   (    0.41 ms per token,  2444.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1789.68 ms /    34 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   30749.09 ms /    46 runs   (  668.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32684.83 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.30 ms /    26 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.09 ms /    31 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   16841.82 ms /    25 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18470.40 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    17 runs   (    0.43 ms per token,  2334.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1758.12 ms /    34 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10782.53 ms /    16 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12593.67 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    20 runs   (    0.45 ms per token,  2236.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1730.43 ms /    32 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12491.71 ms /    19 runs   (  657.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14285.32 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    19 runs   (    0.42 ms per token,  2375.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.40 ms /    31 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11999.87 ms /    18 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13593.30 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    20 runs   (    0.44 ms per token,  2267.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1710.11 ms /    32 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12910.97 ms /    19 runs   (  679.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14682.82 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    20 runs   (    0.45 ms per token,  2236.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1825.80 ms /    36 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12803.04 ms /    19 runs   (  673.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14691.26 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.39 ms /    24 runs   (    0.43 ms per token,  2310.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1709.66 ms /    34 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15598.20 ms /    23 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17382.17 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    21 runs   (    0.44 ms per token,  2285.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1544.21 ms /    31 tokens (   49.81 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13321.39 ms /    20 runs   (  666.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14930.41 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      19.50 ms /    48 runs   (    0.41 ms per token,  2461.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1743.90 ms /    35 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   31562.26 ms /    47 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33453.65 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    15 runs   (    0.45 ms per token,  2244.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1692.29 ms /    33 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =    9312.18 ms /    14 runs   (  665.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11051.19 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.58 ms /    22 runs   (    0.44 ms per token,  2295.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1656.48 ms /    33 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   14223.88 ms /    21 runs   (  677.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15948.84 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.20 ms /    31 runs   (    0.43 ms per token,  2349.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1757.24 ms /    34 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   20024.14 ms /    30 runs   (  667.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21878.02 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    21 runs   (    0.52 ms per token,  1917.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1713.72 ms /    34 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   13627.26 ms /    20 runs   (  681.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15418.11 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    18 runs   (    0.43 ms per token,  2332.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1536.25 ms /    29 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11472.37 ms /    17 runs   (  674.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13064.69 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.43 ms /    26 runs   (    0.44 ms per token,  2273.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1710.98 ms /    33 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   16673.61 ms /    25 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18466.04 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.69 ms /    24 runs   (    0.45 ms per token,  2244.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1671.96 ms /    33 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   15449.19 ms /    23 runs   (  671.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17196.03 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    23 runs   (    0.44 ms per token,  2274.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1718.57 ms /    34 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   15006.74 ms /    22 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16797.44 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    20 runs   (    0.43 ms per token,  2322.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1780.01 ms /    36 tokens (   49.44 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12874.93 ms /    19 runs   (  677.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14717.12 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    29 runs   (    0.43 ms per token,  2323.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2013.14 ms /    35 tokens (   57.52 ms per token,    17.39 tokens per second)\n",
      "llama_print_timings:        eval time =   18991.51 ms /    28 runs   (  678.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21095.29 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.23 ms /    27 runs   (    0.42 ms per token,  2404.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1884.84 ms /    37 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   17537.14 ms /    26 runs   (  674.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19506.13 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    24 runs   (    0.43 ms per token,  2304.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1702.56 ms /    34 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   15385.60 ms /    23 runs   (  668.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17161.92 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.03 ms /    23 runs   (    0.44 ms per token,  2293.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1790.19 ms /    35 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14850.89 ms /    22 runs   (  675.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16713.34 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    23 runs   (    0.44 ms per token,  2264.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1696.33 ms /    33 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   14750.52 ms /    22 runs   (  670.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16518.12 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    27 runs   (    0.44 ms per token,  2278.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1566.33 ms /    31 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   17378.99 ms /    26 runs   (  668.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19029.29 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    28 runs   (    0.43 ms per token,  2309.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.33 ms /    32 tokens (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   18095.72 ms /    27 runs   (  670.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19770.70 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    20 runs   (    0.42 ms per token,  2364.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1541.17 ms /    30 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12755.24 ms /    19 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14358.45 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    20 runs   (    0.44 ms per token,  2279.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1542.81 ms /    31 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12853.31 ms /    19 runs   (  676.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14457.88 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    19 runs   (    0.44 ms per token,  2280.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1609.85 ms /    32 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12104.12 ms /    18 runs   (  672.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13773.74 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.72 ms /    20 runs   (    0.44 ms per token,  2292.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1460.76 ms /    29 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12788.75 ms /    19 runs   (  673.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14311.89 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.24 ms /    24 runs   (    0.43 ms per token,  2344.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1873.15 ms /    37 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15292.49 ms /    23 runs   (  664.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17240.55 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    25 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1838.83 ms /    36 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   16384.15 ms /    24 runs   (  682.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18302.67 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2265.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1800.97 ms /    35 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =    5401.32 ms /     8 runs   (  675.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7230.19 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    27 runs   (    0.44 ms per token,  2296.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1820.77 ms /    37 tokens (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   17500.17 ms /    26 runs   (  673.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19405.64 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    25 runs   (    0.44 ms per token,  2268.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1586.30 ms /    31 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   16176.12 ms /    24 runs   (  674.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17840.22 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    16 runs   (    0.43 ms per token,  2331.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1713.50 ms /    34 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10103.46 ms /    15 runs   (  673.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11866.52 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.75 ms /    22 runs   (    0.44 ms per token,  2257.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1709.34 ms /    33 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   14080.40 ms /    21 runs   (  670.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15859.16 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    18 runs   (    0.44 ms per token,  2269.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1730.89 ms /    33 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11593.08 ms /    17 runs   (  681.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13380.04 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.53 ms /    22 runs   (    0.43 ms per token,  2308.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1722.68 ms /    34 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14048.30 ms /    21 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15838.68 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.71 ms /    27 runs   (    0.43 ms per token,  2305.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1854.57 ms /    36 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   17280.70 ms /    26 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19219.62 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      21.20 ms /    52 runs   (    0.41 ms per token,  2453.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1972.57 ms /    39 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   34529.12 ms /    51 runs   (  677.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   36665.72 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.93 ms /    55 runs   (    0.42 ms per token,  2399.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1790.61 ms /    35 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   36785.29 ms /    54 runs   (  681.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38749.61 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    30 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1876.76 ms /    36 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   18929.47 ms /    29 runs   (  652.74 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   20900.25 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.15 ms /    53 runs   (    0.42 ms per token,  2392.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1975.91 ms /    40 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   34787.31 ms /    52 runs   (  668.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   36929.24 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.34 ms /    27 runs   (    0.42 ms per token,  2380.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1994.20 ms /    40 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   17610.02 ms /    26 runs   (  677.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19687.92 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.32 ms /    33 runs   (    0.40 ms per token,  2477.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1819.11 ms /    37 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   21905.02 ms /    32 runs   (  684.53 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23827.08 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.49 ms /    24 runs   (    0.44 ms per token,  2287.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1918.50 ms /    37 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   15340.85 ms /    23 runs   (  666.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17334.98 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      25.30 ms /    61 runs   (    0.41 ms per token,  2410.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1890.37 ms /    38 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   40730.24 ms /    60 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   42816.23 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    26 runs   (    0.46 ms per token,  2171.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1984.24 ms /    40 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   17038.51 ms /    25 runs   (  681.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19108.70 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    24 runs   (    0.43 ms per token,  2303.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2089.46 ms /    41 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   15418.92 ms /    23 runs   (  670.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17584.20 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      24.85 ms /    60 runs   (    0.41 ms per token,  2414.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2009.78 ms /    40 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   40248.11 ms /    59 runs   (  682.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   42447.09 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    22 runs   (    0.44 ms per token,  2276.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2288.73 ms /    40 tokens (   57.22 ms per token,    17.48 tokens per second)\n",
      "llama_print_timings:        eval time =   14292.35 ms /    21 runs   (  680.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16651.65 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.88 ms /    21 runs   (    0.42 ms per token,  2363.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1974.64 ms /    39 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13492.65 ms /    20 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15531.76 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      29.82 ms /    75 runs   (    0.40 ms per token,  2514.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1995.60 ms /    40 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   50919.14 ms /    74 runs   (  688.10 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   53151.46 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.34 ms /    24 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2012.01 ms /    39 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   15561.34 ms /    23 runs   (  676.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17647.85 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    26 runs   (    0.43 ms per token,  2351.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1875.29 ms /    38 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   16898.49 ms /    25 runs   (  675.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18854.47 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      21.00 ms /    50 runs   (    0.42 ms per token,  2380.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1774.87 ms /    35 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   33508.15 ms /    49 runs   (  683.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   35440.50 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.08 ms /    23 runs   (    0.44 ms per token,  2282.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1771.40 ms /    35 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   14960.11 ms /    22 runs   (  680.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16803.15 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.50 ms /    26 runs   (    0.44 ms per token,  2260.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.84 ms /    33 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   16913.32 ms /    25 runs   (  676.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18649.73 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      21.51 ms /    52 runs   (    0.41 ms per token,  2417.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2216.28 ms /    39 tokens (   56.83 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   34950.29 ms /    51 runs   (  685.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   37332.22 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.24 ms /    26 runs   (    0.43 ms per token,  2312.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1988.29 ms /    38 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   16827.42 ms /    25 runs   (  673.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18897.33 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    25 runs   (    0.42 ms per token,  2378.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1951.92 ms /    38 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   16168.02 ms /    24 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18198.55 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.78 ms /    25 runs   (    0.43 ms per token,  2319.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1896.08 ms /    38 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   16321.94 ms /    24 runs   (  680.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18297.04 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    23 runs   (    0.44 ms per token,  2297.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1897.23 ms /    38 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   14852.19 ms /    22 runs   (  675.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16820.99 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.94 ms /    25 runs   (    0.44 ms per token,  2285.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1962.73 ms /    36 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   16296.65 ms /    24 runs   (  679.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18337.97 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.70 ms /    25 runs   (    0.43 ms per token,  2336.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1900.36 ms /    38 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   16354.66 ms /    24 runs   (  681.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18333.47 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.60 ms /    32 runs   (    0.42 ms per token,  2353.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2035.28 ms /    40 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   21097.05 ms /    31 runs   (  680.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23231.84 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    23 runs   (    0.42 ms per token,  2355.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.79 ms /    36 tokens (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   14676.30 ms /    22 runs   (  667.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16515.59 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    26 runs   (    0.42 ms per token,  2357.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1861.82 ms /    37 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   16679.75 ms /    25 runs   (  667.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18622.58 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    19 runs   (    0.43 ms per token,  2341.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1947.77 ms /    39 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11969.78 ms /    18 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13976.96 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.51 ms /    27 runs   (    0.43 ms per token,  2346.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1923.61 ms /    38 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   17314.12 ms /    26 runs   (  665.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19322.03 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.84 ms /    23 runs   (    0.43 ms per token,  2337.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1772.96 ms /    35 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14567.95 ms /    22 runs   (  662.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16412.40 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.50 ms /    24 runs   (    0.44 ms per token,  2285.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2010.19 ms /    39 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   15705.05 ms /    23 runs   (  682.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17790.80 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    10 runs   (    0.46 ms per token,  2172.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1968.59 ms /    39 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =    6107.06 ms /     9 runs   (  678.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8107.32 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      18.66 ms /    45 runs   (    0.41 ms per token,  2411.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1538.22 ms /    31 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   29712.65 ms /    44 runs   (  675.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31391.63 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      25.27 ms /    63 runs   (    0.40 ms per token,  2492.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1859.34 ms /    37 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   42321.37 ms /    62 runs   (  682.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   44379.17 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      25.94 ms /    63 runs   (    0.41 ms per token,  2428.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2007.63 ms /    40 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   41756.34 ms /    62 runs   (  673.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   43964.07 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      24.95 ms /    61 runs   (    0.41 ms per token,  2445.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1973.66 ms /    38 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   40898.19 ms /    60 runs   (  681.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   43064.81 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    21 runs   (    0.42 ms per token,  2404.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1673.82 ms /    33 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   13456.34 ms /    20 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15195.63 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.36 ms /    26 runs   (    0.44 ms per token,  2288.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1816.26 ms /    36 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   16996.14 ms /    25 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18895.71 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    21 runs   (    0.42 ms per token,  2378.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1949.53 ms /    39 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13443.40 ms /    20 runs   (  672.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15458.06 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      24.77 ms /    60 runs   (    0.41 ms per token,  2422.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1720.61 ms /    34 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   39854.04 ms /    59 runs   (  675.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41763.42 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.67 ms /    25 runs   (    0.43 ms per token,  2342.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1950.44 ms /    39 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   16035.58 ms /    24 runs   (  668.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18064.65 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.36 ms /    26 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1774.87 ms /    35 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   16921.98 ms /    25 runs   (  676.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18778.07 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.72 ms /    25 runs   (    0.43 ms per token,  2332.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2056.63 ms /    40 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   16298.27 ms /    24 runs   (  679.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18432.63 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.35 ms /    24 runs   (    0.43 ms per token,  2317.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1757.49 ms /    35 tokens (   50.21 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15585.40 ms /    23 runs   (  677.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17418.11 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    28 runs   (    0.43 ms per token,  2325.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1917.69 ms /    38 tokens (   50.47 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   18272.57 ms /    27 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20278.80 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    24 runs   (    0.42 ms per token,  2370.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1958.81 ms /    40 tokens (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =   15570.80 ms /    23 runs   (  676.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17604.38 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.07 ms /    55 runs   (    0.40 ms per token,  2492.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1740.18 ms /    34 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   36834.93 ms /    54 runs   (  682.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38747.30 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.07 ms /    25 runs   (    0.44 ms per token,  2258.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2001.38 ms /    39 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   16282.08 ms /    24 runs   (  678.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18364.03 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    26 runs   (    0.42 ms per token,  2358.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1840.19 ms /    37 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   16861.20 ms /    25 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18782.81 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.06 ms /    23 runs   (    0.44 ms per token,  2287.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1591.14 ms /    32 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   14771.53 ms /    22 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16435.54 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    29 runs   (    0.42 ms per token,  2356.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1759.08 ms /    35 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18789.15 ms /    28 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20638.98 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.60 ms /    56 runs   (    0.40 ms per token,  2477.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.26 ms /    38 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   37286.15 ms /    55 runs   (  677.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39375.61 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2320.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1915.23 ms /    38 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10411.83 ms /    15 runs   (  694.12 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12376.88 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.49 ms /    55 runs   (    0.41 ms per token,  2445.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2034.28 ms /    40 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   36665.36 ms /    54 runs   (  678.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38873.61 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.30 ms /    27 runs   (    0.42 ms per token,  2388.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.92 ms /    37 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   17677.02 ms /    26 runs   (  679.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19674.84 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      14.67 ms /    31 runs   (    0.47 ms per token,  2112.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1882.35 ms /    38 tokens (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   20319.90 ms /    30 runs   (  677.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22305.10 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      27.04 ms /    66 runs   (    0.41 ms per token,  2441.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1847.51 ms /    35 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   43808.24 ms /    65 runs   (  673.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   45864.05 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.31 ms /    27 runs   (    0.42 ms per token,  2387.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.06 ms /    36 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   17309.74 ms /    26 runs   (  665.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19178.89 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.67 ms /    24 runs   (    0.44 ms per token,  2249.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1958.42 ms /    39 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15423.72 ms /    23 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17458.58 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      23.87 ms /    57 runs   (    0.42 ms per token,  2388.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1957.32 ms /    40 tokens (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   37550.65 ms /    56 runs   (  670.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39687.32 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      23.51 ms /    55 runs   (    0.43 ms per token,  2339.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1873.71 ms /    38 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   36756.51 ms /    54 runs   (  680.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38810.73 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    24 runs   (    0.42 ms per token,  2363.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1954.81 ms /    33 tokens (   59.24 ms per token,    16.88 tokens per second)\n",
      "llama_print_timings:        eval time =   15456.49 ms /    23 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17486.28 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.30 ms /    32 runs   (    0.42 ms per token,  2405.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2028.29 ms /    40 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   21187.60 ms /    31 runs   (  683.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23316.55 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.53 ms /    24 runs   (    0.44 ms per token,  2279.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1878.49 ms /    38 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   15546.44 ms /    23 runs   (  675.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17499.64 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     5 runs   (    0.44 ms per token,  2287.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1871.67 ms /    37 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2753.73 ms /     4 runs   (  688.43 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    4641.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    24 runs   (    0.42 ms per token,  2355.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1863.20 ms /    38 tokens (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   15349.75 ms /    23 runs   (  667.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17289.02 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.40 ms /    29 runs   (    0.43 ms per token,  2338.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1928.56 ms /    38 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   18575.34 ms /    28 runs   (  663.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20594.41 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    22 runs   (    0.43 ms per token,  2334.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1897.61 ms /    38 tokens (   49.94 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   14242.22 ms /    21 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16209.58 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.06 ms /    23 runs   (    0.44 ms per token,  2286.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1851.22 ms /    37 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14823.92 ms /    22 runs   (  673.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16748.22 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      25.48 ms /    61 runs   (    0.42 ms per token,  2394.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2039.60 ms /    41 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   40829.80 ms /    60 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   43063.22 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.40 ms /    24 runs   (    0.43 ms per token,  2306.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1956.75 ms /    40 tokens (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   15682.53 ms /    23 runs   (  681.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17714.72 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      21.70 ms /    52 runs   (    0.42 ms per token,  2396.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1808.75 ms /    34 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   34607.07 ms /    51 runs   (  678.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   36578.94 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    18 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1949.79 ms /    39 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11490.95 ms /    17 runs   (  675.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13496.28 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.05 ms /    30 runs   (    0.43 ms per token,  2299.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1716.93 ms /    34 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19539.15 ms /    29 runs   (  673.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21350.49 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    11 runs   (    0.46 ms per token,  2175.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.45 ms /    33 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =    6807.21 ms /    10 runs   (  680.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8509.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      25.28 ms /    61 runs   (    0.41 ms per token,  2413.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1843.26 ms /    36 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   40965.81 ms /    60 runs   (  682.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   42999.59 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      20.64 ms /    52 runs   (    0.40 ms per token,  2519.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1970.60 ms /    39 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   34097.91 ms /    51 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36230.66 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    31 runs   (    0.43 ms per token,  2344.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1883.76 ms /    38 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   20201.60 ms /    30 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22182.07 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.98 ms /    23 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1999.21 ms /    39 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   14732.19 ms /    22 runs   (  669.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16803.21 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      20.77 ms /    51 runs   (    0.41 ms per token,  2454.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1873.90 ms /    38 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   33714.62 ms /    50 runs   (  674.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35750.42 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      12.97 ms /    32 runs   (    0.41 ms per token,  2466.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1747.08 ms /    35 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   20880.15 ms /    31 runs   (  673.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22727.48 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    23 runs   (    0.42 ms per token,  2355.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1734.62 ms /    34 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   14491.64 ms /    22 runs   (  658.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16297.82 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.63 ms /    25 runs   (    0.43 ms per token,  2351.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1866.53 ms /    36 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   16340.59 ms /    24 runs   (  680.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18285.14 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    24 runs   (    0.42 ms per token,  2358.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1857.81 ms /    37 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   15566.76 ms /    23 runs   (  676.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17499.21 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      32.68 ms /    79 runs   (    0.41 ms per token,  2417.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1973.06 ms /    39 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   52844.37 ms /    78 runs   (  677.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   55068.93 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    24 runs   (    0.43 ms per token,  2305.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2108.93 ms /    41 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   15420.47 ms /    23 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17604.37 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    25 runs   (    0.44 ms per token,  2292.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1661.10 ms /    33 tokens (   50.34 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   16178.03 ms /    24 runs   (  674.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17918.01 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.31 ms /    26 runs   (    0.44 ms per token,  2297.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1942.30 ms /    39 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   16895.20 ms /    25 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18919.06 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.40 ms /    27 runs   (    0.42 ms per token,  2369.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1895.59 ms /    38 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   17602.41 ms /    26 runs   (  677.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19582.77 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    21 runs   (    0.43 ms per token,  2323.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1826.62 ms /    37 tokens (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13263.90 ms /    20 runs   (  663.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15155.97 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      14.58 ms /    34 runs   (    0.43 ms per token,  2331.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2024.54 ms /    40 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   22321.19 ms /    33 runs   (  676.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24452.08 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      17.77 ms /    43 runs   (    0.41 ms per token,  2420.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1872.62 ms /    38 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   28544.22 ms /    42 runs   (  679.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30551.57 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    21 runs   (    0.43 ms per token,  2300.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1833.19 ms /    36 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   13609.21 ms /    20 runs   (  680.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15509.56 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.16 ms /    26 runs   (    0.43 ms per token,  2329.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.62 ms /    33 tokens (   49.84 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   16897.14 ms /    25 runs   (  675.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18623.28 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    21 runs   (    0.43 ms per token,  2327.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1835.61 ms /    36 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   13413.45 ms /    20 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15316.03 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      17.86 ms /    43 runs   (    0.42 ms per token,  2407.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1724.57 ms /    34 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   28302.43 ms /    42 runs   (  673.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30162.79 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.59 ms /    27 runs   (    0.43 ms per token,  2330.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1832.17 ms /    37 tokens (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   17675.44 ms /    26 runs   (  679.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19592.70 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.57 ms /    25 runs   (    0.42 ms per token,  2365.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1929.15 ms /    38 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   16294.68 ms /    24 runs   (  678.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18301.72 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.29 ms /    24 runs   (    0.43 ms per token,  2333.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2058.60 ms /    40 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   15532.50 ms /    23 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17665.81 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    24 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1894.38 ms /    37 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   15471.78 ms /    23 runs   (  672.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17440.31 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    22 runs   (    0.43 ms per token,  2348.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2107.14 ms /    38 tokens (   55.45 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   14275.16 ms /    21 runs   (  679.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16452.11 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    27 runs   (    0.44 ms per token,  2291.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1917.60 ms /    38 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   17617.29 ms /    26 runs   (  677.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19621.90 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    26 runs   (    0.41 ms per token,  2419.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1960.58 ms /    39 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16993.06 ms /    25 runs   (  679.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19035.48 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    26 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1810.13 ms /    36 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   17020.30 ms /    25 runs   (  680.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18911.10 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      23.84 ms /    58 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1898.11 ms /    37 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   39004.50 ms /    57 runs   (  684.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   41083.17 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      26.34 ms /    64 runs   (    0.41 ms per token,  2429.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1944.26 ms /    38 tokens (   51.16 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   42945.78 ms /    63 runs   (  681.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45091.75 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      21.34 ms /    51 runs   (    0.42 ms per token,  2389.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1891.64 ms /    38 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   34207.65 ms /    50 runs   (  684.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   36259.40 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    25 runs   (    0.44 ms per token,  2298.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2354.64 ms /    41 tokens (   57.43 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:        eval time =   16088.65 ms /    24 runs   (  670.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18522.20 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    22 runs   (    0.43 ms per token,  2346.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1971.19 ms /    38 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14194.44 ms /    21 runs   (  675.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16234.59 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    23 runs   (    0.42 ms per token,  2363.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1821.95 ms /    37 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   14992.48 ms /    22 runs   (  681.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16885.47 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.74 ms /    23 runs   (    0.42 ms per token,  2361.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1822.11 ms /    36 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   14995.36 ms /    22 runs   (  681.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16889.07 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.82 ms /    55 runs   (    0.41 ms per token,  2410.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1996.89 ms /    40 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   36881.35 ms /    54 runs   (  682.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   39050.46 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      14.71 ms /    35 runs   (    0.42 ms per token,  2380.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2049.98 ms /    40 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   23241.49 ms /    34 runs   (  683.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   25402.43 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.40 ms /    24 runs   (    0.43 ms per token,  2307.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1984.25 ms /    36 tokens (   55.12 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   15651.03 ms /    23 runs   (  680.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17710.70 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.70 ms /    25 runs   (    0.43 ms per token,  2336.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1910.53 ms /    38 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16201.05 ms /    24 runs   (  675.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18189.47 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    24 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1994.71 ms /    40 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   15537.78 ms /    23 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17606.91 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    23 runs   (    0.42 ms per token,  2372.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1963.86 ms /    39 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14910.25 ms /    22 runs   (  677.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16945.04 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    25 runs   (    0.43 ms per token,  2320.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2138.23 ms /    38 tokens (   56.27 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =   16227.93 ms /    24 runs   (  676.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18444.70 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    23 runs   (    0.43 ms per token,  2329.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1877.19 ms /    38 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   14715.61 ms /    22 runs   (  668.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16665.02 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      21.89 ms /    54 runs   (    0.41 ms per token,  2466.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1887.48 ms /    38 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   36140.52 ms /    53 runs   (  681.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38197.15 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.29 ms /    24 runs   (    0.43 ms per token,  2333.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1791.29 ms /    35 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   15596.09 ms /    23 runs   (  678.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17461.75 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.49 ms /    27 runs   (    0.43 ms per token,  2350.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1744.82 ms /    35 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   17603.33 ms /    26 runs   (  677.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19432.22 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    25 runs   (    0.44 ms per token,  2280.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1738.30 ms /    34 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16182.76 ms /    24 runs   (  674.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17998.62 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.32 ms /    56 runs   (    0.40 ms per token,  2508.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1987.00 ms /    40 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   37040.42 ms /    55 runs   (  673.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39202.61 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    20 runs   (    0.43 ms per token,  2321.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1736.61 ms /    34 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12624.19 ms /    19 runs   (  664.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14423.11 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    22 runs   (    0.43 ms per token,  2348.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1917.75 ms /    39 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   14197.25 ms /    21 runs   (  676.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16184.26 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      20.84 ms /    51 runs   (    0.41 ms per token,  2447.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1800.70 ms /    34 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   34136.55 ms /    50 runs   (  682.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   36096.77 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      24.93 ms /    61 runs   (    0.41 ms per token,  2446.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1851.24 ms /    37 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   40869.27 ms /    60 runs   (  681.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   42911.94 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    18 runs   (    0.42 ms per token,  2356.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.05 ms /    27 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11456.27 ms /    17 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12952.93 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.74 ms /    55 runs   (    0.41 ms per token,  2418.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1936.23 ms /    38 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   36929.94 ms /    54 runs   (  683.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   39040.04 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      19.91 ms /    47 runs   (    0.42 ms per token,  2360.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1702.34 ms /    33 tokens (   51.59 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   31265.81 ms /    46 runs   (  679.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   33117.58 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.72 ms /    25 runs   (    0.43 ms per token,  2331.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1970.46 ms /    40 tokens (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   16268.94 ms /    24 runs   (  677.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18317.77 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    23 runs   (    0.43 ms per token,  2317.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1960.24 ms /    38 tokens (   51.59 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   14580.70 ms /    22 runs   (  662.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16612.66 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      22.88 ms /    56 runs   (    0.41 ms per token,  2448.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1808.91 ms /    36 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   37523.44 ms /    55 runs   (  682.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   39508.27 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    23 runs   (    0.43 ms per token,  2317.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1848.18 ms /    37 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   14800.33 ms /    22 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16720.62 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    24 runs   (    0.43 ms per token,  2316.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2063.39 ms /    36 tokens (   57.32 ms per token,    17.45 tokens per second)\n",
      "llama_print_timings:        eval time =   15517.67 ms /    23 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17656.07 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.93 ms /    26 runs   (    0.42 ms per token,  2378.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1846.70 ms /    37 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   16980.81 ms /    25 runs   (  679.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18908.00 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      24.16 ms /    60 runs   (    0.40 ms per token,  2483.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1871.71 ms /    37 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   40019.38 ms /    59 runs   (  678.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   42079.60 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      11.12 ms /    26 runs   (    0.43 ms per token,  2338.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1969.60 ms /    40 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   16714.75 ms /    25 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18765.97 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    22 runs   (    0.43 ms per token,  2325.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1682.40 ms /    33 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   14150.15 ms /    21 runs   (  673.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15901.06 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    20 runs   (    0.42 ms per token,  2362.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1809.66 ms /    36 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12772.71 ms /    19 runs   (  672.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14645.02 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      21.31 ms /    53 runs   (    0.40 ms per token,  2486.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1973.24 ms /    40 tokens (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   35076.73 ms /    52 runs   (  674.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   37216.82 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    25 runs   (    0.43 ms per token,  2300.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2018.67 ms /    40 tokens (   50.47 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   16327.06 ms /    24 runs   (  680.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18423.84 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      24.43 ms /    60 runs   (    0.41 ms per token,  2456.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1777.32 ms /    36 tokens (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   39845.01 ms /    59 runs   (  675.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41811.36 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      25.14 ms /    62 runs   (    0.41 ms per token,  2466.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1813.96 ms /    36 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   41349.11 ms /    61 runs   (  677.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   43358.47 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    20 runs   (    0.43 ms per token,  2316.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2101.21 ms /    37 tokens (   56.79 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12661.78 ms /    19 runs   (  666.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14825.10 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    32 runs   (    0.44 ms per token,  2291.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1661.06 ms /    33 tokens (   50.34 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   21002.34 ms /    31 runs   (  677.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22764.60 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3624.45 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    25 runs   (    0.42 ms per token,  2408.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2384.26 ms /    41 tokens (   58.15 ms per token,    17.20 tokens per second)\n",
      "llama_print_timings:        eval time =   16144.22 ms /    24 runs   (  672.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18606.15 ms /    65 tokens\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#run for list_size_3_pos first column of datafram df\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(f\"Completed {i} rows\")\n",
    "        \n",
    "    try:\n",
    "        #prompt is f\"Find the minimum number in the list [2, 0, 4, 5]\"\n",
    "        prompt= f\"{df.iloc[i, 0]} + {df.iloc[i, 1]} = ?\"\n",
    "\n",
    "\n",
    "        prompt_template=f'''SYSTEM: You are a math assistant.I will ask you some addition questions. Please answer in word format. Numbers can be in digit or word format. For example, if I ask you 'three + 2 = ?', you should answer 'answer=five'. Do not include any other information in your answer.\n",
    "        \n",
    "        USER: {prompt}\n",
    "                \n",
    "        ASSISTANT:'''\n",
    "        \n",
    "        response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                    repeat_penalty=1.2, top_k=150,\n",
    "                    echo=False)\n",
    "        \n",
    "        with open('numertion_int_addn_wndp_dw_ow.txt', 'a') as f:\n",
    "            answer=response[\"choices\"][0][\"text\"]\n",
    "            f.write(f\"{df.iloc[i, 0]} + {df.iloc[i, 1]} = {answer} \\n\")\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        #write in min_output.txt'\n",
    "        with open('numertion_int_addn_wndp_dw_ow.txt', 'a') as f:\n",
    "            f.write(f\"{df.iloc[i, 0]} + {df.iloc[i, 1]} = Error \\n\")\n",
    "            \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viveksdmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
