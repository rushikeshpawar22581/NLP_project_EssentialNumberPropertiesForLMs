{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required libraries\n",
    "# %pip install transformers\n",
    "# %pip install torchtext\n",
    "# %pip install sentencepiece\n",
    "# %pip install datasets\n",
    "# %pip install torchmetrics\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# #huggiface download\n",
    "# %pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the model llama 2 13b chat gguf\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is gguf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf\n"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "#print toal path\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.36 GiB (5.51 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  8555.93 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   400.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    85.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '16'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt= f'''2 / 3 = ?'''\n",
    "\n",
    "prompt_template=f'''SYSTEM: You are a math assistant.I will ask you some division questions. Please answer upto 12 digits after decimal point.For example, if I ask you '0.9 / 0.1 = ?', you should answer 'answer=9.000000000000'. Do not include any other information in your answer.\n",
    "\n",
    "USER: {prompt}\n",
    "        \n",
    "ASSISTANT:'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.65 ms /    34 runs   (    0.40 ms per token,  2490.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4800.76 ms /    99 tokens (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_print_timings:        eval time =   22777.71 ms /    33 runs   (  690.23 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27671.08 ms /   132 tokens\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/3 = 0.6666666666667 (answer upto 12 digits after decimal point)\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file in data folder\n",
    "with open('division_dataset.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>-665059.0</td>\n",
       "      <td>-3132.0</td>\n",
       "      <td>212.3432</td>\n",
       "      <td>212.343231</td>\n",
       "      <td>212.343231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>-96240.0</td>\n",
       "      <td>409482.0</td>\n",
       "      <td>-0.2350</td>\n",
       "      <td>-0.235029</td>\n",
       "      <td>-0.235029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>409482.0</td>\n",
       "      <td>-96240.0</td>\n",
       "      <td>-4.2548</td>\n",
       "      <td>-4.254800</td>\n",
       "      <td>-4.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>-96240.0</td>\n",
       "      <td>-409482.0</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.235029</td>\n",
       "      <td>0.235029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>-409482.0</td>\n",
       "      <td>-96240.0</td>\n",
       "      <td>4.2548</td>\n",
       "      <td>4.254800</td>\n",
       "      <td>4.254800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2           3           4\n",
       "3427 -665059.0   -3132.0  212.3432  212.343231  212.343231\n",
       "3428  -96240.0  409482.0   -0.2350   -0.235029   -0.235029\n",
       "3429  409482.0  -96240.0   -4.2548   -4.254800   -4.254800\n",
       "3430  -96240.0 -409482.0    0.2350    0.235029    0.235029\n",
       "3431 -409482.0  -96240.0    4.2548    4.254800    4.254800"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data as pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "#last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1       2         3         4\n",
      "0  1.0  2.0  0.5000  0.500000  0.500000\n",
      "1  2.0  1.0  2.0000  2.000000  2.000000\n",
      "2  1.0  3.0  0.3333  0.333333  0.333333\n",
      "3  3.0  1.0  3.0000  3.000000  3.000000\n",
      "4  1.0  4.0  0.2500  0.250000  0.250000\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3432\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 / 1.0 = ?\n"
     ]
    }
   ],
   "source": [
    "prompt= f\"{df.iloc[1, 0]} / {df.iloc[1, 1]} = ?\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2632.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.91 ms /    26 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11411.22 ms /    17 runs   (  671.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12775.06 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    17 runs   (    0.43 ms per token,  2350.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.22 ms /    19 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10956.50 ms /    16 runs   (  684.78 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12029.29 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.71 ms /    19 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11575.44 ms /    17 runs   (  680.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12639.57 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2532.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.06 ms /    19 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10951.48 ms /    16 runs   (  684.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12016.95 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.38 ms /    19 tokens (   55.49 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11404.56 ms /    17 runs   (  670.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12504.86 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    17 runs   (    0.40 ms per token,  2495.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.62 ms /    19 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10731.59 ms /    16 runs   (  670.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11788.56 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2653.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.05 ms /    19 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11486.75 ms /    17 runs   (  675.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12528.60 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2487.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.41 ms /    19 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10811.15 ms /    16 runs   (  675.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11878.30 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2559.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     997.77 ms /    19 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11140.36 ms /    17 runs   (  655.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12185.46 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2526.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.85 ms /    19 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10676.62 ms /    16 runs   (  667.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11722.63 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2579.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.09 ms /    19 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12616.16 ms /    19 runs   (  664.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13686.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.48 ms /    19 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10746.60 ms /    16 runs   (  671.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11793.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2611.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.51 ms /    19 tokens (   55.55 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11355.75 ms /    17 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12458.92 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2521.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.86 ms /    19 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10968.03 ms /    16 runs   (  685.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12040.39 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    17 runs   (    0.41 ms per token,  2455.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.01 ms /    19 tokens (   55.21 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10915.69 ms /    16 runs   (  682.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12010.62 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    17 runs   (    0.41 ms per token,  2462.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.06 ms /    19 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10845.93 ms /    16 runs   (  677.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11914.62 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    17 runs   (    0.46 ms per token,  2175.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     981.87 ms /    19 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11187.62 ms /    16 runs   (  699.23 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12220.88 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    18 runs   (    0.43 ms per token,  2346.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.53 ms /    19 tokens (   69.50 ms per token,    14.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12143.57 ms /    17 runs   (  714.33 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   13516.71 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2498.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.21 ms /    19 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11257.07 ms /    16 runs   (  703.57 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   12354.73 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    17 runs   (    0.40 ms per token,  2507.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.16 ms /    19 tokens (   59.85 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11387.91 ms /    16 runs   (  711.74 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   12571.62 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2556.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.13 ms /    19 tokens (   64.27 ms per token,    15.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10911.75 ms /    16 runs   (  681.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12179.03 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    17 runs   (    0.41 ms per token,  2437.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.69 ms /    19 tokens (   55.19 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10886.07 ms /    16 runs   (  680.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11981.74 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.20 ms /    19 tokens (   58.64 ms per token,    17.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11641.63 ms /    17 runs   (  684.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12804.78 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    17 runs   (    0.41 ms per token,  2429.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.20 ms /    19 tokens (   57.38 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11003.98 ms /    16 runs   (  687.75 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12141.45 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2634.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.69 ms /    19 tokens (   57.51 ms per token,    17.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10611.13 ms /    16 runs   (  663.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11749.79 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    17 runs   (    0.42 ms per token,  2376.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.51 ms /    19 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10873.48 ms /    16 runs   (  679.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11928.20 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2599.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.27 ms /    19 tokens (   56.33 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11327.18 ms /    17 runs   (  666.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12445.66 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2630.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.24 ms /    19 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11221.96 ms /    16 runs   (  701.37 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12273.50 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2626.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1042.41 ms /    19 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10689.28 ms /    16 runs   (  668.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11777.29 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2667.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.59 ms /    19 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10777.23 ms /    16 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11833.63 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    17 runs   (    0.41 ms per token,  2435.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.89 ms /    19 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10779.16 ms /    16 runs   (  673.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11847.20 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    17 runs   (    0.37 ms per token,  2676.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.95 ms /    19 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10683.71 ms /    16 runs   (  667.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11768.75 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2534.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.16 ms /    19 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10758.01 ms /    16 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11790.24 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    18 runs   (    0.40 ms per token,  2499.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.44 ms /    19 tokens (   62.29 ms per token,    16.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11521.43 ms /    17 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12753.89 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2548.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.38 ms /    19 tokens (   55.02 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11452.13 ms /    16 runs   (  715.76 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   12543.74 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2529.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.94 ms /    19 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11320.52 ms /    16 runs   (  707.53 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   12394.88 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2554.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.16 ms /    19 tokens (   55.48 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11391.47 ms /    16 runs   (  711.97 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   12493.34 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    17 runs   (    0.45 ms per token,  2235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.08 ms /    19 tokens (   66.00 ms per token,    15.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11214.42 ms /    16 runs   (  700.90 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12522.03 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2558.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.69 ms /    19 tokens (   67.04 ms per token,    14.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11376.68 ms /    16 runs   (  711.04 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   12696.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.76 ms /    19 tokens (   56.67 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10857.57 ms /    16 runs   (  678.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11981.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.59 ms /    19 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10882.52 ms /    16 runs   (  680.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11969.11 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2635.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.46 ms /    19 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10804.33 ms /    16 runs   (  675.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11864.43 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2614.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.36 ms /    19 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11427.11 ms /    17 runs   (  672.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12474.39 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2671.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.72 ms /    19 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10881.30 ms /    16 runs   (  680.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11948.80 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2563.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.33 ms /    19 tokens (   51.96 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10762.85 ms /    16 runs   (  672.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11797.51 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2638.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.15 ms /    19 tokens (   55.53 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10729.72 ms /    16 runs   (  670.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11831.14 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    17 runs   (    0.40 ms per token,  2480.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.22 ms /    19 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10635.78 ms /    16 runs   (  664.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11682.35 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2647.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.05 ms /    19 tokens (   57.95 ms per token,    17.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10608.05 ms /    16 runs   (  663.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11755.29 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.33 ms /    19 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10790.67 ms /    16 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11852.90 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2627.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.19 ms /    19 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11304.70 ms /    17 runs   (  664.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12375.16 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2512.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.45 ms /    19 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10639.91 ms /    16 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11688.47 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2538.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.47 ms /    19 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10671.93 ms /    16 runs   (  667.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11726.31 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.62 ms /    19 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10900.37 ms /    16 runs   (  681.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11961.49 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2540.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.01 ms /    19 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10462.52 ms /    16 runs   (  653.91 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11495.88 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2685.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.94 ms /    19 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10545.75 ms /    16 runs   (  659.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11598.32 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    17 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.49 ms /    19 tokens (   60.66 ms per token,    16.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10790.87 ms /    16 runs   (  674.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11991.06 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    17 runs   (    0.45 ms per token,  2215.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.98 ms /    19 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10738.34 ms /    16 runs   (  671.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11797.84 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.10 ms /    19 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10601.48 ms /    16 runs   (  662.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11640.58 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    22 runs   (    0.39 ms per token,  2593.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.52 ms /    19 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   13931.40 ms /    21 runs   (  663.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15016.60 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.07 ms /    19 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10676.21 ms /    16 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11726.22 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2628.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.64 ms /    19 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10752.39 ms /    16 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11805.39 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2687.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.93 ms /    19 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10641.23 ms /    16 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11680.39 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    17 runs   (    0.41 ms per token,  2457.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     999.52 ms /    19 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10403.82 ms /    16 runs   (  650.24 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11450.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     994.42 ms /    19 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10813.21 ms /    16 runs   (  675.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11854.58 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.98 ms /    19 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10737.67 ms /    16 runs   (  671.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11803.39 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.73 ms /    19 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11442.85 ms /    17 runs   (  673.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12488.64 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.34 ms /    19 tokens (   56.97 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10765.49 ms /    16 runs   (  672.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11894.62 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2650.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     994.78 ms /    19 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11287.76 ms /    17 runs   (  663.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12331.29 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2670.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.12 ms /    19 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11359.54 ms /    17 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12404.26 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2593.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.68 ms /    19 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10853.22 ms /    16 runs   (  678.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11910.60 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.09 ms /    19 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10727.38 ms /    16 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11763.01 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2638.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.43 ms /    19 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10797.89 ms /    16 runs   (  674.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11848.25 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2604.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.94 ms /    19 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10715.82 ms /    16 runs   (  669.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11758.91 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.86 ms /    19 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11373.48 ms /    17 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12413.15 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.61 ms /    19 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12700.61 ms /    19 runs   (  668.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13760.59 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2569.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.08 ms /    19 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10585.39 ms /    16 runs   (  661.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11617.78 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2586.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.13 ms /    19 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10560.60 ms /    16 runs   (  660.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11590.41 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2614.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     980.48 ms /    19 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10736.03 ms /    16 runs   (  671.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11763.43 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2535.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.28 ms /    19 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   10872.23 ms /    16 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11894.23 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     985.10 ms /    19 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10760.75 ms /    16 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11792.86 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2556.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.09 ms /    19 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10809.25 ms /    16 runs   (  675.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11834.24 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.55 ms /    19 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11379.37 ms /    17 runs   (  669.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12418.35 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2689.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.59 ms /    19 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10788.00 ms /    16 runs   (  674.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11837.14 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    17 runs   (    0.38 ms per token,  2661.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.75 ms /    19 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10736.06 ms /    16 runs   (  671.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11794.42 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     981.48 ms /    19 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10834.72 ms /    16 runs   (  677.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11862.48 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.95 ms /    19 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10600.40 ms /    16 runs   (  662.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11637.70 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    17 runs   (    0.41 ms per token,  2445.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.99 ms /    19 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10719.04 ms /    16 runs   (  669.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11758.91 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    17 runs   (    0.40 ms per token,  2494.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.01 ms /    19 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10772.09 ms /    16 runs   (  673.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11823.27 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2621.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.97 ms /    19 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11393.69 ms /    17 runs   (  670.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12430.06 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    17 runs   (    0.37 ms per token,  2675.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.90 ms /    19 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10628.57 ms /    16 runs   (  664.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11682.32 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2588.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.99 ms /    19 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   12053.89 ms /    18 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13132.13 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    21 runs   (    0.38 ms per token,  2629.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.96 ms /    19 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13423.31 ms /    20 runs   (  671.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14478.09 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2670.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.84 ms /    19 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10609.87 ms /    16 runs   (  663.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11668.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2665.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.62 ms /    19 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11440.77 ms /    17 runs   (  672.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12526.57 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    17 runs   (    0.40 ms per token,  2473.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.29 ms /    19 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10711.82 ms /    16 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11754.58 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2682.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.01 ms /    19 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10604.27 ms /    16 runs   (  662.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11656.45 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     997.22 ms /    19 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10697.55 ms /    16 runs   (  668.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11740.73 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2606.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.74 ms /    19 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12680.55 ms /    19 runs   (  667.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13748.42 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2652.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     984.58 ms /    19 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10753.12 ms /    16 runs   (  672.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11784.90 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2610.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.19 ms /    19 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11402.23 ms /    17 runs   (  670.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12487.92 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2683.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.16 ms /    19 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10674.81 ms /    16 runs   (  667.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11723.23 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     984.21 ms /    19 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11320.87 ms /    17 runs   (  665.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12353.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.52 ms /    19 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10522.34 ms /    16 runs   (  657.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11583.40 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    22 runs   (    0.39 ms per token,  2545.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.44 ms /    19 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   13841.70 ms /    21 runs   (  659.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14903.33 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2689.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.71 ms /    19 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10564.11 ms /    16 runs   (  660.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11584.95 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2583.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.58 ms /    19 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12557.61 ms /    19 runs   (  660.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13604.76 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    21 runs   (    0.38 ms per token,  2647.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.57 ms /    19 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   13077.33 ms /    20 runs   (  653.87 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14118.57 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2615.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.44 ms /    19 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11878.22 ms /    18 runs   (  659.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12919.22 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2670.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.65 ms /    19 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11215.73 ms /    17 runs   (  659.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12292.17 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2608.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.98 ms /    19 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12486.18 ms /    19 runs   (  657.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13537.92 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    20 runs   (    0.37 ms per token,  2703.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     982.25 ms /    19 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12687.08 ms /    19 runs   (  667.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13723.89 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2590.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.71 ms /    19 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11291.58 ms /    17 runs   (  664.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12370.97 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2549.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.48 ms /    19 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10700.65 ms /    16 runs   (  668.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11777.26 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2675.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.27 ms /    19 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11209.59 ms /    17 runs   (  659.39 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12234.71 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2623.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     980.55 ms /    19 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10539.44 ms /    16 runs   (  658.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11566.95 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2683.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.75 ms /    19 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10567.01 ms /    16 runs   (  660.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11603.33 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2647.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.54 ms /    19 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10578.39 ms /    16 runs   (  661.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11614.07 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2644.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     984.88 ms /    19 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10547.67 ms /    16 runs   (  659.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11579.24 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.09 ms /    19 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10608.56 ms /    16 runs   (  663.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11650.04 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2689.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.13 ms /    19 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10630.74 ms /    16 runs   (  664.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11715.43 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2649.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     984.66 ms /    19 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10635.24 ms /    16 runs   (  664.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11666.49 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2640.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.63 ms /    19 tokens (   55.98 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10662.36 ms /    16 runs   (  666.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11774.84 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2648.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     994.27 ms /    19 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11223.81 ms /    17 runs   (  660.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12267.40 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    17 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.13 ms /    19 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10788.04 ms /    16 runs   (  674.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11828.57 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2613.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.86 ms /    19 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12739.64 ms /    19 runs   (  670.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13786.73 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2663.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.18 ms /    19 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11443.93 ms /    17 runs   (  673.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12491.98 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    17 runs   (    0.40 ms per token,  2497.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.73 ms /    19 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10615.01 ms /    16 runs   (  663.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11676.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2672.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.85 ms /    19 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10657.25 ms /    16 runs   (  666.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11700.73 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2498.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.34 ms /    14 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10599.78 ms /    16 runs   (  662.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11371.03 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    17 runs   (    0.40 ms per token,  2484.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.88 ms /    19 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10693.71 ms /    16 runs   (  668.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11741.24 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2689.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.96 ms /    19 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10628.80 ms /    16 runs   (  664.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11664.53 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    17 runs   (    0.41 ms per token,  2455.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.39 ms /    19 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10770.39 ms /    16 runs   (  673.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11820.87 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    17 runs   (    0.37 ms per token,  2695.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.44 ms /    19 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10653.14 ms /    16 runs   (  665.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11728.29 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2524.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.61 ms /    19 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10645.49 ms /    16 runs   (  665.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11679.86 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2618.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.40 ms /    19 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10692.28 ms /    16 runs   (  668.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11734.94 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    17 runs   (    0.41 ms per token,  2461.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.95 ms /    19 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10663.47 ms /    16 runs   (  666.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11750.14 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2634.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.49 ms /    19 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10661.60 ms /    16 runs   (  666.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11698.31 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2528.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.92 ms /    19 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10496.62 ms /    16 runs   (  656.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11520.35 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2609.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     985.66 ms /    19 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10504.63 ms /    16 runs   (  656.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11536.64 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2500.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.11 ms /    19 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10842.37 ms /    16 runs   (  677.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11891.06 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2603.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.29 ms /    19 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11279.54 ms /    17 runs   (  663.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12324.61 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    20 runs   (    0.38 ms per token,  2664.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.39 ms /    19 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12560.23 ms /    19 runs   (  661.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13592.82 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.89 ms /    19 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10649.36 ms /    16 runs   (  665.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11672.69 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    17 runs   (    0.41 ms per token,  2428.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.53 ms /    19 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10693.91 ms /    16 runs   (  668.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11734.47 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2649.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.27 ms /    19 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10656.15 ms /    16 runs   (  666.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11717.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2687.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.24 ms /    20 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10707.17 ms /    16 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11820.14 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2613.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.84 ms /    19 tokens (   52.04 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12009.97 ms /    18 runs   (  667.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13051.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.41 ms /    19 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11424.82 ms /    17 runs   (  672.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12481.84 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    19 runs   (    0.37 ms per token,  2680.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.14 ms /    19 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12050.73 ms /    18 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13094.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2628.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.15 ms /    20 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12010.41 ms /    18 runs   (  667.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13090.64 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    20 runs   (    0.37 ms per token,  2715.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.62 ms /    20 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12546.69 ms /    19 runs   (  660.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13649.77 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2699.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.26 ms /    19 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11265.68 ms /    17 runs   (  662.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12323.73 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2614.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.93 ms /    20 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11332.46 ms /    17 runs   (  666.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12415.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2621.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.19 ms /    20 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10496.76 ms /    16 runs   (  656.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11583.72 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    19 runs   (    0.40 ms per token,  2516.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.82 ms /    19 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12464.99 ms /    18 runs   (  692.50 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13523.64 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2587.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.76 ms /    19 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11301.06 ms /    17 runs   (  664.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12327.79 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2601.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.30 ms /    20 tokens (   51.96 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11215.78 ms /    17 runs   (  659.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12304.51 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2580.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.68 ms /    20 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10701.92 ms /    16 runs   (  668.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11810.57 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2572.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.55 ms /    19 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12040.10 ms /    18 runs   (  668.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13105.59 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2672.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.02 ms /    19 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11198.47 ms /    17 runs   (  658.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12249.93 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2692.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.08 ms /    19 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11261.51 ms /    17 runs   (  662.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12321.66 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2627.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.56 ms /    20 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11965.06 ms /    18 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13042.13 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2627.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.58 ms /    20 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11854.71 ms /    18 runs   (  658.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12977.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2631.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.31 ms /    19 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11291.72 ms /    17 runs   (  664.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12348.69 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2575.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.67 ms /    20 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12639.53 ms /    19 runs   (  665.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13736.03 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2680.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.38 ms /    20 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10732.92 ms /    16 runs   (  670.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11818.13 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    21 runs   (    0.38 ms per token,  2605.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     999.90 ms /    19 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13330.15 ms /    20 runs   (  666.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14387.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2655.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.68 ms /    19 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11837.68 ms /    18 runs   (  657.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12886.61 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    18 runs   (    0.44 ms per token,  2274.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.61 ms /    20 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11155.74 ms /    17 runs   (  656.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12263.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2688.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.24 ms /    20 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10652.40 ms /    16 runs   (  665.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11727.08 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2578.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.24 ms /    19 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11964.55 ms /    18 runs   (  664.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13005.62 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    18 runs   (    0.37 ms per token,  2705.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.01 ms /    19 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11289.66 ms /    17 runs   (  664.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12353.38 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    17 runs   (    0.37 ms per token,  2703.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.47 ms /    19 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10720.89 ms /    16 runs   (  670.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11784.19 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.01 ms /    20 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11222.40 ms /    17 runs   (  660.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12337.02 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2635.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.17 ms /    20 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11879.62 ms /    18 runs   (  659.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12985.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    19 runs   (    0.37 ms per token,  2684.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.65 ms /    19 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11879.59 ms /    18 runs   (  659.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12920.88 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2591.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.27 ms /    20 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11892.81 ms /    18 runs   (  660.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12975.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.64 ms /    20 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11230.23 ms /    17 runs   (  660.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12302.04 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2671.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.19 ms /    19 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11308.60 ms /    17 runs   (  665.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12345.32 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2615.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.96 ms /    19 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11921.50 ms /    18 runs   (  662.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13013.00 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2623.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.91 ms /    20 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11949.95 ms /    18 runs   (  663.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13055.29 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.22 ms /    20 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10714.37 ms /    16 runs   (  669.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11785.28 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2624.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.70 ms /    19 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11462.51 ms /    17 runs   (  674.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12528.01 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2643.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.09 ms /    19 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12067.61 ms /    18 runs   (  670.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13144.25 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.52 ms /    20 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11346.11 ms /    17 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12455.44 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    17 runs   (    0.38 ms per token,  2659.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.39 ms /    20 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10690.48 ms /    16 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11798.42 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    19 runs   (    0.38 ms per token,  2639.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.13 ms /    19 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11857.57 ms /    18 runs   (  658.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12937.96 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2663.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.01 ms /    19 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11389.18 ms /    17 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12416.00 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2655.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.17 ms /    19 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11373.64 ms /    17 runs   (  669.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12412.59 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    26 runs   (    0.41 ms per token,  2413.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.54 ms /    20 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   16442.81 ms /    25 runs   (  657.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17542.46 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    19 runs   (    0.37 ms per token,  2670.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.38 ms /    20 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11924.91 ms /    18 runs   (  662.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13012.80 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    19 runs   (    0.37 ms per token,  2681.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.48 ms /    19 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11911.54 ms /    18 runs   (  661.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12950.68 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2636.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.12 ms /    19 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11290.61 ms /    17 runs   (  664.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12338.65 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2563.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.84 ms /    20 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10643.56 ms /    16 runs   (  665.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11716.82 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2601.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.97 ms /    20 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12633.63 ms /    19 runs   (  664.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13717.50 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.31 ms /    19 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11282.99 ms /    17 runs   (  663.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12307.64 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2559.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     984.67 ms /    19 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11285.61 ms /    17 runs   (  663.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12320.49 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2647.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.85 ms /    20 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10721.97 ms /    16 runs   (  670.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11810.57 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.60 ms /    20 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12118.72 ms /    18 runs   (  673.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13198.90 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2655.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.55 ms /    19 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11410.57 ms /    17 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12468.09 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2619.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.42 ms /    19 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11433.83 ms /    17 runs   (  672.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12489.04 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.88 ms /    20 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10714.77 ms /    16 runs   (  669.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11792.10 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    19 runs   (    0.38 ms per token,  2647.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.71 ms /    20 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12267.53 ms /    18 runs   (  681.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13364.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2618.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.26 ms /    19 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11283.33 ms /    17 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12309.10 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.82 ms /   404 runs   (    0.28 ms per token,  3518.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.12 ms /    20 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =  273600.91 ms /   403 runs   (  678.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  275824.11 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2635.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.98 ms /    20 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10543.70 ms /    16 runs   (  658.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11611.64 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    19 runs   (    0.37 ms per token,  2675.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     981.73 ms /    19 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11994.85 ms /    18 runs   (  666.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13030.97 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2642.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.95 ms /    19 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12027.69 ms /    18 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13087.82 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2650.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.53 ms /    19 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10651.36 ms /    16 runs   (  665.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11690.08 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    21 runs   (    0.38 ms per token,  2656.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.17 ms /    20 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   13162.72 ms /    20 runs   (  658.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14286.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2666.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.57 ms /    20 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11291.22 ms /    17 runs   (  664.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12361.12 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    20 runs   (    0.42 ms per token,  2365.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.57 ms /    19 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12819.84 ms /    19 runs   (  674.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13856.70 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2597.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.48 ms /    19 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.86 ms /    16 runs   (  665.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11715.40 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2613.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.95 ms /    20 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11870.64 ms /    18 runs   (  659.48 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13001.42 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2622.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.89 ms /    20 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11941.11 ms /    18 runs   (  663.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13053.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.51 ms /    19 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11264.44 ms /    17 runs   (  662.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12315.43 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2659.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.79 ms /    19 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11269.40 ms /    17 runs   (  662.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12341.01 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2541.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.12 ms /    20 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10728.93 ms /    16 runs   (  670.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11847.30 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2660.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.49 ms /    20 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11350.35 ms /    17 runs   (  667.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12464.86 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.18 ms /    19 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11192.61 ms /    17 runs   (  658.39 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12235.88 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.47 ms /    20 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10490.01 ms /    16 runs   (  655.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11568.36 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    17 runs   (    0.45 ms per token,  2236.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.67 ms /    20 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10563.85 ms /    16 runs   (  660.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11657.42 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    19 runs   (    0.38 ms per token,  2645.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.90 ms /    19 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12025.91 ms /    18 runs   (  668.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13081.88 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2603.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.78 ms /    19 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12070.71 ms /    18 runs   (  670.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13117.67 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    17 runs   (    0.44 ms per token,  2282.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.92 ms /    19 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10657.99 ms /    16 runs   (  666.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11724.87 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2643.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.52 ms /    20 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10667.07 ms /    16 runs   (  666.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11759.98 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    19 runs   (    0.42 ms per token,  2381.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.81 ms /    20 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12014.22 ms /    18 runs   (  667.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13113.45 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2609.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     997.88 ms /    19 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11250.58 ms /    17 runs   (  661.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12300.04 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2581.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.38 ms /    19 tokens (   52.18 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11975.08 ms /    18 runs   (  665.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13019.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2647.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.59 ms /    20 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10664.29 ms /    16 runs   (  666.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11750.57 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2606.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1041.29 ms /    20 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12420.23 ms /    19 runs   (  653.70 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13518.38 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    18 runs   (    0.37 ms per token,  2695.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.94 ms /    19 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11040.00 ms /    17 runs   (  649.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12089.40 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.21 ms /    19 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11156.46 ms /    17 runs   (  656.26 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12225.27 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.69 ms /    20 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10733.42 ms /    16 runs   (  670.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11862.92 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2642.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.67 ms /    20 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12297.16 ms /    18 runs   (  683.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13378.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2591.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.73 ms /    19 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11527.60 ms /    17 runs   (  678.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12604.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2650.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.79 ms /    19 tokens (   55.04 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11443.80 ms /    17 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12540.81 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.62 ms /    20 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11214.82 ms /    17 runs   (  659.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12288.58 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    19 runs   (    0.37 ms per token,  2706.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.52 ms /    20 tokens (   52.18 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12130.37 ms /    18 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13227.03 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2633.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.13 ms /    19 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11456.31 ms /    17 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12481.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2663.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.04 ms /    20 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10715.32 ms /    16 runs   (  669.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11833.42 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2553.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.41 ms /    20 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10612.39 ms /    16 runs   (  663.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11698.26 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.37 ms per token,  2667.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.19 ms /    19 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11400.20 ms /    17 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12440.42 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2643.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.48 ms /    19 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12045.85 ms /    18 runs   (  669.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13094.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2645.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.53 ms /    19 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10464.91 ms /    16 runs   (  654.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11545.46 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.26 ms /    20 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11442.19 ms /    17 runs   (  673.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12529.90 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.25 ms /    20 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11410.81 ms /    17 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12494.81 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    19 runs   (    0.37 ms per token,  2677.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.48 ms /    19 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12049.02 ms /    18 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13110.36 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.81 ms /    20 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11074.41 ms /    16 runs   (  692.15 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12171.47 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2646.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.96 ms /    20 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11623.26 ms /    17 runs   (  683.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12708.71 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2635.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.33 ms /    19 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11456.98 ms /    17 runs   (  673.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12492.19 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.08 ms /    19 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11345.35 ms /    17 runs   (  667.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12404.82 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2671.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.86 ms /    19 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10696.67 ms /    16 runs   (  668.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11754.96 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.02 ms /    27 runs   (    0.37 ms per token,  2695.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.95 ms /    20 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   17498.94 ms /    26 runs   (  673.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18628.93 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    19 runs   (    0.38 ms per token,  2638.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.01 ms /    20 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11870.76 ms /    18 runs   (  659.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12989.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2552.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.38 ms /    19 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12034.04 ms /    18 runs   (  668.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13086.72 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    19 runs   (    0.41 ms per token,  2466.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.43 ms /    19 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12066.31 ms /    18 runs   (  670.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13146.16 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.56 ms /    20 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10602.83 ms /    16 runs   (  662.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11690.29 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    19 runs   (    0.38 ms per token,  2663.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.61 ms /    20 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12041.67 ms /    18 runs   (  668.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13132.14 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2616.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.39 ms /    19 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12333.06 ms /    18 runs   (  685.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13388.18 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    21 runs   (    0.39 ms per token,  2566.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.04 ms /    19 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13443.12 ms /    20 runs   (  672.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14514.07 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2586.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.23 ms /    20 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10938.29 ms /    16 runs   (  683.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12023.73 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    22 runs   (    0.39 ms per token,  2590.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1041.26 ms /    20 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   14252.93 ms /    21 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15357.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.96 ms /    19 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11408.13 ms /    17 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12482.49 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2614.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1046.73 ms /    20 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11503.10 ms /    17 runs   (  676.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12600.43 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2662.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.76 ms /    20 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10810.25 ms /    16 runs   (  675.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11919.53 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2655.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.89 ms /    19 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11900.61 ms /    18 runs   (  661.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12947.88 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2646.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.23 ms /    19 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11251.94 ms /    17 runs   (  661.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12314.45 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2681.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.73 ms /    19 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10560.02 ms /    16 runs   (  660.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11583.64 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2606.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.64 ms /    20 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11214.30 ms /    17 runs   (  659.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12326.56 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    19 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.50 ms /    20 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12021.78 ms /    18 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13101.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2578.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.07 ms /    19 tokens (   54.69 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11411.78 ms /    17 runs   (  671.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12502.15 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    19 runs   (    0.37 ms per token,  2719.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.58 ms /    20 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11941.06 ms /    18 runs   (  663.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13032.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2608.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.37 ms /    20 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11241.34 ms /    17 runs   (  661.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12344.23 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2653.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.57 ms /    19 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11262.87 ms /    17 runs   (  662.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12300.63 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    19 runs   (    0.37 ms per token,  2694.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.20 ms /    19 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11882.78 ms /    18 runs   (  660.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12910.17 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2656.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.67 ms /    19 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10520.56 ms /    16 runs   (  657.53 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11562.99 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2665.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.77 ms /    20 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11202.63 ms /    17 runs   (  658.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12292.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2607.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.24 ms /    20 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11809.15 ms /    18 runs   (  656.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12905.42 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2604.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.18 ms /    19 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11803.95 ms /    18 runs   (  655.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12836.67 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.83 ms /    26 runs   (    0.38 ms per token,  2645.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.87 ms /    20 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   16588.59 ms /    25 runs   (  663.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17715.24 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    17 runs   (    0.43 ms per token,  2320.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.56 ms /    20 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10728.69 ms /    16 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11811.46 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2584.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.97 ms /    19 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12049.51 ms /    18 runs   (  669.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13109.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2658.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     984.38 ms /    19 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11978.48 ms /    18 runs   (  665.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13016.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.12 ms /    19 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10623.71 ms /    16 runs   (  663.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11673.71 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.80 ms /    20 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10711.38 ms /    16 runs   (  669.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11793.76 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2612.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.20 ms /    20 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12228.81 ms /    18 runs   (  679.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13309.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2658.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     994.86 ms /    19 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12152.93 ms /    18 runs   (  675.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13202.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.90 ms /    19 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11335.97 ms /    17 runs   (  666.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12384.00 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.57 ms /    20 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11380.71 ms /    17 runs   (  669.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12464.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2649.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.11 ms /    20 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11477.49 ms /    17 runs   (  675.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12569.31 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2542.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.06 ms /    19 tokens (   55.00 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11949.23 ms /    18 runs   (  663.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13049.36 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2601.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.10 ms /    19 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12783.58 ms /    19 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13844.84 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2617.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.99 ms /    20 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10594.47 ms /    16 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11686.09 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.32 ms /    20 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13197.38 ms /    20 runs   (  659.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14307.46 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2535.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.20 ms /    19 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11948.96 ms /    18 runs   (  663.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12990.27 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2690.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.24 ms /    19 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11313.19 ms /    17 runs   (  665.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12351.92 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.30 ms /    20 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   10579.91 ms /    16 runs   (  661.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11649.14 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2648.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.27 ms /    20 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12011.93 ms /    18 runs   (  667.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13122.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2586.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.95 ms /    19 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11639.92 ms /    18 runs   (  646.66 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12728.31 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2655.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.19 ms /    19 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11914.80 ms /    18 runs   (  661.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12944.94 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2572.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.69 ms /    20 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11972.57 ms /    18 runs   (  665.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13085.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2655.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1042.09 ms /    20 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12011.94 ms /    18 runs   (  667.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13108.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2629.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.85 ms /    19 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12677.31 ms /    19 runs   (  667.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13724.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2600.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.39 ms /    20 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11955.85 ms /    18 runs   (  664.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13039.57 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    18 runs   (    0.43 ms per token,  2312.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.23 ms /    20 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11116.26 ms /    17 runs   (  653.90 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12212.88 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.02 ms /    19 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11362.80 ms /    17 runs   (  668.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12438.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.58 ms /    19 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12050.95 ms /    18 runs   (  669.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13093.75 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2588.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.04 ms /    19 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10570.24 ms /    16 runs   (  660.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11646.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2587.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.47 ms /    20 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13098.56 ms /    20 runs   (  654.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14223.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    18 runs   (    0.37 ms per token,  2677.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.84 ms /    20 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10912.71 ms /    17 runs   (  641.92 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   11999.31 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    20 runs   (    0.38 ms per token,  2640.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.29 ms /    19 tokens (   55.02 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12610.28 ms /    19 runs   (  663.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13711.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.67 ms /    20 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.76 ms /    16 runs   (  665.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11766.72 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2589.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.14 ms /    20 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10642.14 ms /    16 runs   (  665.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11721.13 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.42 ms /    19 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11581.71 ms /    17 runs   (  681.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12611.03 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2549.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.01 ms /    19 tokens (   62.58 ms per token,    15.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11847.27 ms /    18 runs   (  658.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13091.27 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    17 runs   (    0.45 ms per token,  2230.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.33 ms /    20 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10789.23 ms /    16 runs   (  674.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11876.17 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    19 runs   (    0.44 ms per token,  2251.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.79 ms /    20 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12120.01 ms /    18 runs   (  673.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13294.29 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2546.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.03 ms /    19 tokens (   55.74 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12177.29 ms /    18 runs   (  676.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13292.63 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2608.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.21 ms /    19 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12111.18 ms /    18 runs   (  672.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13184.14 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2586.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.33 ms /    20 tokens (   55.67 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11436.77 ms /    17 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12600.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2640.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.48 ms /    20 tokens (   57.57 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11239.85 ms /    17 runs   (  661.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12441.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.39 ms /    19 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11927.18 ms /    18 runs   (  662.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12988.87 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2644.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.21 ms /    19 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11270.30 ms /    17 runs   (  662.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12319.79 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2549.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.27 ms /    20 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12710.00 ms /    19 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13812.88 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.06 ms /    24 runs   (    0.38 ms per token,  2649.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.13 ms /    20 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   15376.56 ms /    23 runs   (  668.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16510.70 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    21 runs   (    0.39 ms per token,  2559.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.34 ms /    19 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13445.08 ms /    20 runs   (  672.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14499.45 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    25 runs   (    0.38 ms per token,  2643.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     982.96 ms /    19 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   15950.76 ms /    24 runs   (  664.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17005.63 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2610.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.39 ms /    19 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11487.34 ms /    17 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12537.12 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2634.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.54 ms /    20 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10793.69 ms /    16 runs   (  674.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11894.12 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2616.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.29 ms /    20 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11875.74 ms /    18 runs   (  659.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12961.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2559.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     980.52 ms /    19 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12201.84 ms /    18 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13236.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    19 runs   (    0.37 ms per token,  2695.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.86 ms /    20 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12168.09 ms /    18 runs   (  676.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13261.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2672.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.98 ms /    20 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10814.44 ms /    16 runs   (  675.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11939.59 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.63 ms /    19 tokens (   56.93 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11513.48 ms /    17 runs   (  677.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12647.19 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2579.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.33 ms /    19 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12647.52 ms /    18 runs   (  702.64 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   13698.72 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.96 ms /    19 tokens (   56.21 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11070.72 ms /    16 runs   (  691.92 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12188.32 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    20 runs   (    0.40 ms per token,  2504.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.67 ms /    20 tokens (   57.28 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   13128.37 ms /    19 runs   (  690.97 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14333.47 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    19 runs   (    0.41 ms per token,  2431.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.70 ms /    20 tokens (   69.58 ms per token,    14.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12940.77 ms /    18 runs   (  718.93 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   14391.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2555.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.63 ms /    19 tokens (   70.14 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13737.64 ms /    20 runs   (  686.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15132.23 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2515.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.38 ms /    19 tokens (   69.86 ms per token,    14.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11374.13 ms /    16 runs   (  710.88 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   12752.68 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2547.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.28 ms /    20 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11362.49 ms /    17 runs   (  668.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12476.27 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.71 ms /    20 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11272.70 ms /    17 runs   (  663.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12358.97 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.51 ms /    19 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12043.55 ms /    18 runs   (  669.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13107.82 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2653.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.71 ms /    19 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10630.06 ms /    16 runs   (  664.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11667.79 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    19 runs   (    0.41 ms per token,  2413.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.24 ms /    20 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12078.25 ms /    18 runs   (  671.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13191.52 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.28 ms /    20 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11545.69 ms /    17 runs   (  679.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12652.65 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2575.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.97 ms /    19 tokens (   56.68 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12467.56 ms /    19 runs   (  656.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13601.69 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2510.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.11 ms /    20 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10633.18 ms /    16 runs   (  664.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11717.29 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    21 runs   (    0.41 ms per token,  2442.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.36 ms /    20 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13564.76 ms /    20 runs   (  678.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14688.79 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2618.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.51 ms /    19 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11683.42 ms /    17 runs   (  687.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12765.22 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.55 ms /    22 runs   (    0.39 ms per token,  2573.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.55 ms /    19 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   14291.55 ms /    21 runs   (  680.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15369.66 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.71 ms /    19 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10817.27 ms /    16 runs   (  676.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11855.34 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.28 ms /    29 runs   (    0.39 ms per token,  2571.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.32 ms /    20 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   19404.66 ms /    28 runs   (  693.02 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20540.93 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    19 runs   (    0.44 ms per token,  2251.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.04 ms /    20 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12611.19 ms /    18 runs   (  700.62 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13719.94 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2595.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.16 ms /    19 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13436.94 ms /    20 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14508.82 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.26 ms /    24 runs   (    0.39 ms per token,  2591.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     982.77 ms /    19 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   15440.36 ms /    23 runs   (  671.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16493.04 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2618.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.50 ms /    20 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12666.58 ms /    19 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13772.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.58 ms /    25 runs   (    0.38 ms per token,  2610.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1046.17 ms /    20 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   15813.40 ms /    24 runs   (  658.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16931.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    21 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.45 ms /    19 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13225.24 ms /    20 runs   (  661.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14294.98 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2642.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.60 ms /    19 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11279.16 ms /    17 runs   (  663.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12325.65 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2548.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.52 ms /    20 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12516.37 ms /    19 runs   (  658.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13629.67 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2611.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.01 ms /    20 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11838.42 ms /    18 runs   (  657.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12932.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2595.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.76 ms /    19 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13373.60 ms /    20 runs   (  668.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14424.13 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2592.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     997.53 ms /    19 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11287.06 ms /    17 runs   (  663.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12337.29 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.22 ms /    28 runs   (    0.40 ms per token,  2494.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.80 ms /    20 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   18212.70 ms /    27 runs   (  674.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19333.27 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    21 runs   (    0.38 ms per token,  2656.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.26 ms /    20 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   13200.47 ms /    20 runs   (  660.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14301.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.01 ms /    28 runs   (    0.39 ms per token,  2542.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.61 ms /    19 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   18198.01 ms /    27 runs   (  674.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19269.24 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2621.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.78 ms /    20 tokens (   55.94 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10774.66 ms /    16 runs   (  673.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11942.53 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.05 ms /    20 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11345.15 ms /    17 runs   (  667.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12472.62 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2632.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.62 ms /    19 tokens (   54.66 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11576.38 ms /    17 runs   (  680.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12667.07 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2620.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.66 ms /    19 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12241.88 ms /    18 runs   (  680.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13306.27 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2530.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.30 ms /    19 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11109.64 ms /    16 runs   (  694.35 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12167.78 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2608.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.84 ms /    20 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11537.82 ms /    17 runs   (  678.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12649.46 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.18 ms /    20 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11811.97 ms /    17 runs   (  694.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12928.33 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2555.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.54 ms /    19 tokens (   55.55 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12141.76 ms /    18 runs   (  674.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13253.78 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2534.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.34 ms /    19 tokens (   57.97 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10756.52 ms /    16 runs   (  672.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11908.75 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.53 ms /    20 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11347.88 ms /    17 runs   (  667.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12463.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2521.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.62 ms /    20 tokens (   55.63 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11412.73 ms /    17 runs   (  671.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12578.78 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2539.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.88 ms /    19 tokens (   57.41 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12121.35 ms /    18 runs   (  673.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13269.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.97 ms /    20 tokens (   55.25 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10572.81 ms /    16 runs   (  660.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11727.24 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2525.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1046.91 ms /    20 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11219.01 ms /    16 runs   (  701.19 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12316.40 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.61 ms /    19 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11547.33 ms /    17 runs   (  679.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12636.75 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2602.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.78 ms /    19 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12000.39 ms /    18 runs   (  666.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13053.48 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2629.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.85 ms /    19 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10378.14 ms /    16 runs   (  648.63 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11440.76 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.99 ms /    27 runs   (    0.37 ms per token,  2703.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.63 ms /    20 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   17369.28 ms /    26 runs   (  668.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18472.62 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.84 ms /    20 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12029.33 ms /    18 runs   (  668.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13129.64 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2657.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.22 ms /    19 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11892.06 ms /    18 runs   (  660.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12951.82 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2580.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.45 ms /    20 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10721.92 ms /    16 runs   (  670.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11815.84 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.48 ms /    20 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11442.01 ms /    17 runs   (  673.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12564.67 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    19 runs   (    0.43 ms per token,  2301.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.46 ms /    19 tokens (   63.34 ms per token,    15.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12197.43 ms /    18 runs   (  677.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13461.22 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2641.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.17 ms /    19 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12160.98 ms /    18 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13213.18 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2600.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.46 ms /    19 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12678.86 ms /    19 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13726.65 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2609.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.45 ms /    20 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11410.14 ms /    17 runs   (  671.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12479.29 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    21 runs   (    0.39 ms per token,  2556.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.32 ms /    20 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13600.30 ms /    20 runs   (  680.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14695.23 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2623.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.55 ms /    19 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11972.17 ms /    18 runs   (  665.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13020.93 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2596.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.54 ms /    19 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10796.17 ms /    16 runs   (  674.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11844.44 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2625.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.71 ms /    20 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12046.98 ms /    18 runs   (  669.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13128.57 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2684.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.17 ms /    20 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11283.40 ms /    17 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12360.10 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    21 runs   (    0.38 ms per token,  2629.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.87 ms /    19 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   13240.60 ms /    20 runs   (  662.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14304.37 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2672.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1096.90 ms /    20 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11322.85 ms /    17 runs   (  666.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12471.20 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2593.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.04 ms /    20 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   10715.69 ms /    16 runs   (  669.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11846.94 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2527.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.57 ms /    19 tokens (   59.66 ms per token,    16.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12520.75 ms /    18 runs   (  695.60 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13710.60 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.21 ms /    19 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12694.50 ms /    18 runs   (  705.25 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   13767.80 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    19 runs   (    0.40 ms per token,  2502.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.43 ms /    20 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12608.75 ms /    18 runs   (  700.49 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13759.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1096.14 ms /    20 tokens (   54.81 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10970.89 ms /    16 runs   (  685.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12116.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2561.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.48 ms /    19 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12515.06 ms /    18 runs   (  695.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13615.47 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    19 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.64 ms /    19 tokens (   58.35 ms per token,    17.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12844.36 ms /    18 runs   (  713.58 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   14010.46 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2521.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.85 ms /    19 tokens (   69.89 ms per token,    14.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11107.84 ms /    16 runs   (  694.24 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12487.72 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      30.79 ms /    70 runs   (    0.44 ms per token,  2273.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.16 ms /    20 tokens (   61.26 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =   49405.04 ms /    69 runs   (  716.02 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   50855.66 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2588.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.52 ms /    20 tokens (   71.78 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11611.84 ms /    17 runs   (  683.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13102.36 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2564.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.35 ms /    19 tokens (   58.44 ms per token,    17.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12730.16 ms /    18 runs   (  707.23 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   13897.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    18 runs   (    0.40 ms per token,  2496.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.93 ms /    20 tokens (   59.15 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12171.63 ms /    17 runs   (  715.98 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   13408.65 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2610.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.68 ms /    20 tokens (   58.48 ms per token,    17.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11054.05 ms /    16 runs   (  690.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12274.66 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.66 ms /    19 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11608.19 ms /    17 runs   (  682.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12652.07 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    19 runs   (    0.38 ms per token,  2631.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.88 ms /    19 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12257.11 ms /    18 runs   (  680.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13321.04 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2548.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.45 ms /    20 tokens (   54.57 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12269.80 ms /    18 runs   (  681.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13417.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2633.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1087.28 ms /    20 tokens (   54.36 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12267.60 ms /    18 runs   (  681.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13410.68 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    20 runs   (    0.40 ms per token,  2510.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.61 ms /    19 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12936.90 ms /    19 runs   (  680.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14036.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2618.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.50 ms /    19 tokens (   59.82 ms per token,    16.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12328.00 ms /    18 runs   (  684.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13521.28 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2594.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.18 ms /    19 tokens (   55.90 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11091.54 ms /    16 runs   (  693.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12204.47 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    19 runs   (    0.42 ms per token,  2394.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.41 ms /    20 tokens (   56.27 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12533.69 ms /    18 runs   (  696.32 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13717.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    19 runs   (    0.40 ms per token,  2524.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.85 ms /    20 tokens (   59.14 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12440.14 ms /    18 runs   (  691.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13680.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    18 runs   (    0.43 ms per token,  2341.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.87 ms /    19 tokens (   55.68 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11577.14 ms /    17 runs   (  681.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12693.61 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2538.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.14 ms /    19 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11458.75 ms /    17 runs   (  674.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12540.81 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.34 ms /    20 tokens (   54.87 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11411.15 ms /    17 runs   (  671.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12560.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    28 runs   (    0.39 ms per token,  2558.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.57 ms /    20 tokens (   55.83 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   18264.84 ms /    27 runs   (  676.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19463.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    21 runs   (    0.39 ms per token,  2580.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.80 ms /    19 tokens (   57.36 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =   13872.10 ms /    20 runs   (  693.61 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15023.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2577.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.09 ms /    19 tokens (   56.48 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10752.36 ms /    16 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11874.92 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.41 ms /    20 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10452.06 ms /    16 runs   (  653.25 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11581.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    21 runs   (    0.39 ms per token,  2563.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1041.34 ms /    20 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13531.89 ms /    20 runs   (  676.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14634.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2624.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.40 ms /    19 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11316.21 ms /    17 runs   (  665.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12376.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2561.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.31 ms /    22 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10542.00 ms /    16 runs   (  658.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11732.35 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2596.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.00 ms /    21 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10678.15 ms /    16 runs   (  667.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11806.84 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2603.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.06 ms /    21 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11393.87 ms /    17 runs   (  670.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12607.23 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2603.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.86 ms /    21 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12129.94 ms /    18 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13254.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2645.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.11 ms /    21 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10724.76 ms /    16 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11853.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2573.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.20 ms /    21 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11445.50 ms /    17 runs   (  673.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12588.00 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2656.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.68 ms /    21 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10866.12 ms /    16 runs   (  679.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12016.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2609.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.57 ms /    21 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10758.50 ms /    16 runs   (  672.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11908.25 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.50 ms /    21 tokens (   55.64 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10701.93 ms /    16 runs   (  668.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11920.90 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2514.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.93 ms /    21 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11246.21 ms /    17 runs   (  661.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12403.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2504.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.39 ms /    21 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10618.14 ms /    16 runs   (  663.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11774.47 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    16 runs   (    0.40 ms per token,  2480.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.88 ms /    20 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10102.60 ms /    15 runs   (  673.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11181.32 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2591.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.53 ms /    21 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10906.70 ms /    16 runs   (  681.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12044.13 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2534.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.53 ms /    21 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10738.82 ms /    16 runs   (  671.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11917.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2601.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.26 ms /    21 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10612.97 ms /    16 runs   (  663.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11826.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2529.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.48 ms /    20 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10567.80 ms /    16 runs   (  660.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11667.65 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2548.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.77 ms /    21 tokens (   56.80 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11936.83 ms /    18 runs   (  663.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13185.36 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2641.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.98 ms /    21 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10726.15 ms /    16 runs   (  670.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11884.08 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    21 runs   (    0.39 ms per token,  2580.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.54 ms /    21 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   13503.82 ms /    20 runs   (  675.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14634.79 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2625.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.77 ms /    21 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12720.22 ms /    19 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13850.58 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2651.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.41 ms /    21 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10633.91 ms /    16 runs   (  664.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11750.85 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2566.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.30 ms /    21 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11375.28 ms /    17 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12524.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    20 runs   (    0.39 ms per token,  2558.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.15 ms /    21 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12691.64 ms /    19 runs   (  667.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13851.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2552.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.26 ms /    21 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11319.94 ms /    17 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12451.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2528.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.68 ms /    21 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10635.19 ms /    16 runs   (  664.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11779.48 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.77 ms /    21 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10649.81 ms /    16 runs   (  665.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11825.20 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2609.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.40 ms /    21 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11176.38 ms /    17 runs   (  657.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12328.67 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.87 ms /    21 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11283.85 ms /    17 runs   (  663.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12471.11 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2593.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.77 ms /    21 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10632.26 ms /    16 runs   (  664.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11806.40 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2618.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.57 ms /    21 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12660.83 ms /    19 runs   (  666.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13798.23 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    18 runs   (    0.40 ms per token,  2477.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.75 ms /    21 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11389.76 ms /    17 runs   (  669.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12508.21 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2584.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.78 ms /    21 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12805.52 ms /    19 runs   (  673.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13969.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2648.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.54 ms /    21 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11641.63 ms /    17 runs   (  684.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12780.35 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2607.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.85 ms /    21 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11419.03 ms /    17 runs   (  671.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12572.60 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2611.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.44 ms /    21 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11226.26 ms /    16 runs   (  701.64 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12399.40 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    17 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.89 ms /    21 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11023.80 ms /    16 runs   (  688.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12158.72 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    18 runs   (    0.40 ms per token,  2488.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.28 ms /    21 tokens (   61.73 ms per token,    16.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11987.80 ms /    17 runs   (  705.16 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   13339.09 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2526.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.51 ms /    21 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11642.29 ms /    16 runs   (  727.64 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =   12831.38 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2533.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.97 ms /    21 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12345.10 ms /    18 runs   (  685.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13517.15 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.03 ms /    21 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11272.32 ms /    17 runs   (  663.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12403.36 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    20 runs   (    0.42 ms per token,  2357.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.36 ms /    21 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12884.88 ms /    19 runs   (  678.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14048.46 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2606.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.64 ms /    20 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11709.97 ms /    17 runs   (  688.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12854.81 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2629.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.68 ms /    21 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10768.64 ms /    16 runs   (  673.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11909.96 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2614.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.70 ms /    21 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11282.38 ms /    17 runs   (  663.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12428.91 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2593.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.65 ms /    21 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11403.50 ms /    17 runs   (  670.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12574.48 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    19 runs   (    0.44 ms per token,  2270.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.31 ms /    21 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12299.81 ms /    18 runs   (  683.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13454.69 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    17 runs   (    0.45 ms per token,  2240.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.66 ms /    21 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11356.11 ms /    16 runs   (  709.76 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   12509.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    18 runs   (    0.41 ms per token,  2427.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.24 ms /    21 tokens (   54.63 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12258.20 ms /    17 runs   (  721.07 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   13461.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2645.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.73 ms /    21 tokens (   51.99 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10531.21 ms /    16 runs   (  658.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11672.66 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2591.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.70 ms /    20 tokens (   51.59 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12012.15 ms /    18 runs   (  667.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13100.40 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.11 ms /    21 tokens (   57.39 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10814.90 ms /    16 runs   (  675.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12069.64 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    19 runs   (    0.44 ms per token,  2247.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.94 ms /    21 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12723.96 ms /    18 runs   (  706.89 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   13878.65 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.03 ms /    21 tokens (   62.33 ms per token,    16.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11051.25 ms /    16 runs   (  690.70 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12409.80 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2535.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.85 ms /    21 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11582.98 ms /    17 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12723.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    17 runs   (    0.41 ms per token,  2443.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.90 ms /    20 tokens (   54.10 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10883.53 ms /    16 runs   (  680.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12016.65 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.66 ms /    21 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10564.09 ms /    16 runs   (  660.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11720.49 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2560.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.21 ms /    21 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12042.14 ms /    18 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13180.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2624.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.82 ms /    21 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10672.12 ms /    16 runs   (  667.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11817.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.58 ms /    21 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10648.92 ms /    16 runs   (  665.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11816.72 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2650.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.76 ms /    20 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11939.34 ms /    18 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13050.56 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2563.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.47 ms /    21 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10666.17 ms /    16 runs   (  666.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11805.85 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2608.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.69 ms /    21 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11113.52 ms /    17 runs   (  653.74 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12287.68 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.46 ms /    21 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11944.81 ms /    18 runs   (  663.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13105.04 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.99 ms /    21 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11457.09 ms /    17 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12639.89 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2689.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.67 ms /    21 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10919.47 ms /    16 runs   (  682.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12078.53 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2525.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.65 ms /    21 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11322.74 ms /    17 runs   (  666.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12505.48 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.83 ms /    21 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10496.07 ms /    16 runs   (  656.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11624.05 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2526.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.47 ms /    21 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12329.68 ms /    19 runs   (  648.93 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13450.28 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2689.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.94 ms /    21 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10981.40 ms /    17 runs   (  645.96 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12119.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2614.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.23 ms /    21 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11096.68 ms /    17 runs   (  652.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12215.45 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    17 runs   (    0.37 ms per token,  2695.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.59 ms /    21 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10564.63 ms /    16 runs   (  660.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11714.62 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2653.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.58 ms /    21 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10594.35 ms /    16 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11764.83 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2662.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.21 ms /    21 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10878.55 ms /    16 runs   (  679.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12001.66 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2621.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.53 ms /    21 tokens (   55.26 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10731.94 ms /    16 runs   (  670.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11941.36 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2617.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.17 ms /    21 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10705.08 ms /    16 runs   (  669.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11862.65 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2683.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.31 ms /    21 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11441.80 ms /    17 runs   (  673.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12576.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.39 ms per token,  2532.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.30 ms /    21 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11413.88 ms /    17 runs   (  671.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12584.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2576.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.50 ms /    21 tokens (   55.98 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12580.72 ms /    19 runs   (  662.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13813.86 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2586.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.70 ms /    21 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11553.05 ms /    17 runs   (  679.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12729.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    17 runs   (    0.44 ms per token,  2263.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.92 ms /    21 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10828.07 ms /    16 runs   (  676.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11953.66 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.28 ms /    21 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10782.51 ms /    16 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11938.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2573.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.85 ms /    21 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10839.40 ms /    16 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11997.81 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    17 runs   (    0.44 ms per token,  2260.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.31 ms /    21 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10803.68 ms /    16 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11946.02 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2561.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.80 ms /    21 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10573.80 ms /    16 runs   (  660.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11736.35 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    27 runs   (    0.39 ms per token,  2545.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.01 ms /    21 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   16998.73 ms /    26 runs   (  653.80 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   18167.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2604.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.00 ms /    21 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10580.99 ms /    16 runs   (  661.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11705.22 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2674.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1087.31 ms /    21 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10678.27 ms /    16 runs   (  667.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11814.74 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    17 runs   (    0.44 ms per token,  2282.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.46 ms /    21 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10584.04 ms /    16 runs   (  661.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11767.43 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2547.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.00 ms /    21 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10755.44 ms /    16 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11887.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2554.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.20 ms /    21 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10746.28 ms /    16 runs   (  671.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11902.25 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2567.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.67 ms /    21 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11461.26 ms /    17 runs   (  674.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12648.38 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2604.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.02 ms /    21 tokens (   52.29 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12074.92 ms /    18 runs   (  670.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13228.11 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    17 runs   (    0.41 ms per token,  2434.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.11 ms /    21 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.85 ms /    16 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11874.73 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2648.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.73 ms /    21 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11899.85 ms /    18 runs   (  661.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13030.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.51 ms /    21 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11221.17 ms /    17 runs   (  660.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12366.32 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.62 ms /    21 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10573.36 ms /    16 runs   (  660.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11708.88 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2579.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.77 ms /    21 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10817.49 ms /    16 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11932.74 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2527.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.41 ms /    21 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11323.26 ms /    17 runs   (  666.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12468.00 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2603.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1087.36 ms /    21 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10669.90 ms /    16 runs   (  666.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11805.50 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.95 ms /    21 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10612.83 ms /    16 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11755.95 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2579.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.28 ms /    20 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10619.71 ms /    16 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11700.09 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    17 runs   (    0.37 ms per token,  2694.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.09 ms /    20 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10481.68 ms /    16 runs   (  655.10 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11580.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2609.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.02 ms /    20 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10635.91 ms /    16 runs   (  664.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11712.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.93 ms /    20 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10391.39 ms /    16 runs   (  649.46 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11460.73 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2556.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.44 ms /    20 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10636.11 ms /    16 runs   (  664.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11714.74 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.82 ms /    20 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10969.86 ms /    16 runs   (  685.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12095.26 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.65 ms /    20 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11007.15 ms /    16 runs   (  687.95 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12115.38 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    18 runs   (    0.37 ms per token,  2676.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.20 ms /    20 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11234.91 ms /    17 runs   (  660.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12338.17 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    27 runs   (    0.39 ms per token,  2552.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.83 ms /    20 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   17581.22 ms /    26 runs   (  676.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18696.03 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    18 runs   (    0.41 ms per token,  2433.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.41 ms /    20 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11541.28 ms /    17 runs   (  678.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12636.29 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.29 ms /    20 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10558.86 ms /    16 runs   (  659.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11652.41 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2533.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.25 ms /    20 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11432.34 ms /    17 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12569.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    19 runs   (    0.40 ms per token,  2514.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.79 ms /    20 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12074.73 ms /    18 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13168.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2633.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.09 ms /    20 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10821.52 ms /    16 runs   (  676.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11896.88 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    18 runs   (    0.46 ms per token,  2188.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.79 ms /    20 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11372.10 ms /    17 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12506.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2679.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.24 ms /    20 tokens (   58.76 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10758.66 ms /    16 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11983.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2641.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.17 ms /    20 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10415.69 ms /    16 runs   (  650.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11486.69 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2649.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.14 ms /    20 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11337.23 ms /    17 runs   (  666.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12476.39 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    20 runs   (    0.39 ms per token,  2590.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.43 ms /    20 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12567.15 ms /    19 runs   (  661.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13678.16 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.63 ms /    20 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11316.61 ms /    17 runs   (  665.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12428.44 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    20 runs   (    0.38 ms per token,  2638.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.68 ms /    20 tokens (   55.68 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12799.33 ms /    19 runs   (  673.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13971.45 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2524.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.23 ms /    20 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10621.57 ms /    16 runs   (  663.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11705.43 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2598.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.41 ms /    20 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12744.29 ms /    19 runs   (  670.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13856.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.90 ms /    20 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11404.86 ms /    17 runs   (  670.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12496.76 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    27 runs   (    0.39 ms per token,  2545.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.71 ms /    20 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   17352.57 ms /    26 runs   (  667.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18488.81 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.11 ms /    19 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11551.20 ms /    17 runs   (  679.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12635.63 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2543.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.06 ms /    20 tokens (   58.35 ms per token,    17.14 tokens per second)\n",
      "llama_print_timings:        eval time =   13585.48 ms /    19 runs   (  715.03 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   14813.23 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.10 ms /    20 tokens (   54.51 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12307.94 ms /    17 runs   (  724.00 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   13451.82 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2540.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.18 ms /    20 tokens (   54.96 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11862.33 ms /    17 runs   (  697.78 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13016.49 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2584.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.55 ms /    20 tokens (   56.23 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10648.18 ms /    16 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11823.46 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2516.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.32 ms /    20 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10817.96 ms /    16 runs   (  676.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11947.41 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2601.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.82 ms /    20 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11373.48 ms /    17 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12483.85 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    17 runs   (    0.41 ms per token,  2447.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.64 ms /    19 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11078.25 ms /    16 runs   (  692.39 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12137.97 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.77 ms /    20 tokens (   56.84 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10793.69 ms /    16 runs   (  674.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11978.97 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2532.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.88 ms /    19 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10545.41 ms /    16 runs   (  659.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11599.95 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    17 runs   (    0.45 ms per token,  2244.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.35 ms /    20 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11143.86 ms /    16 runs   (  696.49 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12288.86 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.59 ms /    20 tokens (   60.13 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11450.80 ms /    17 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12705.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    17 runs   (    0.45 ms per token,  2203.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.27 ms /    20 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10883.34 ms /    16 runs   (  680.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11973.62 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    28 runs   (    0.39 ms per token,  2583.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.17 ms /    20 tokens (   58.31 ms per token,    17.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18167.95 ms /    27 runs   (  672.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19416.68 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.29 ms /    20 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11050.62 ms /    16 runs   (  690.66 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12169.48 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    17 runs   (    0.40 ms per token,  2507.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.13 ms /    20 tokens (   53.81 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11030.23 ms /    16 runs   (  689.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12156.38 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2650.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.57 ms /    20 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10729.01 ms /    16 runs   (  670.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11810.41 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    17 runs   (    0.37 ms per token,  2678.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.27 ms /    20 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10767.95 ms /    16 runs   (  673.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11855.72 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2639.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.13 ms /    20 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11320.21 ms /    17 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12438.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2643.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.46 ms /    20 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10698.76 ms /    16 runs   (  668.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11803.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.10 ms /    20 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10984.28 ms /    16 runs   (  686.52 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12058.53 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.15 ms /    20 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10857.25 ms /    16 runs   (  678.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11983.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2610.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.71 ms /    20 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10753.63 ms /    16 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11840.46 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2579.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.33 ms /    20 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12068.24 ms /    18 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13157.73 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2541.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.66 ms /    20 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10912.09 ms /    16 runs   (  682.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12006.42 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    17 runs   (    0.42 ms per token,  2404.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1042.26 ms /    20 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10705.40 ms /    16 runs   (  669.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11796.84 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2597.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.59 ms /    20 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11531.09 ms /    17 runs   (  678.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12658.74 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2557.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.68 ms /    20 tokens (   56.28 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10852.16 ms /    16 runs   (  678.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12027.56 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2618.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1042.15 ms /    20 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11155.80 ms /    17 runs   (  656.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12250.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.77 ms /    20 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10782.05 ms /    16 runs   (  673.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11892.12 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.91 ms /    20 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11482.12 ms /    17 runs   (  675.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12649.85 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2596.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.13 ms /    20 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10845.09 ms /    16 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11947.53 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2611.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.13 ms /    20 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12586.84 ms /    19 runs   (  662.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13703.10 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    21 runs   (    0.38 ms per token,  2641.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.06 ms /    20 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   13466.88 ms /    20 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14555.41 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    18 runs   (    0.40 ms per token,  2480.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.12 ms /    19 tokens (   53.01 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11399.74 ms /    17 runs   (  670.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12460.39 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    28 runs   (    0.42 ms per token,  2384.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.21 ms /    20 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   17940.50 ms /    27 runs   (  664.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19059.49 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2634.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.41 ms /    20 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10694.18 ms /    16 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11789.65 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    19 runs   (    0.40 ms per token,  2493.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.26 ms /    19 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12746.49 ms /    18 runs   (  708.14 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   13797.25 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    18 runs   (    0.45 ms per token,  2214.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.41 ms /    20 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11645.89 ms /    17 runs   (  685.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12806.67 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2515.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.18 ms /    20 tokens (   57.26 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11611.83 ms /    17 runs   (  683.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12813.20 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    18 runs   (    0.40 ms per token,  2491.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.89 ms /    20 tokens (   57.19 ms per token,    17.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11627.08 ms /    17 runs   (  683.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12824.86 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2499.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.89 ms /    19 tokens (   67.10 ms per token,    14.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10955.19 ms /    16 runs   (  684.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12281.12 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.38 ms /    20 tokens (   71.97 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11838.58 ms /    17 runs   (  696.39 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13332.15 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.14 ms /    20 tokens (   57.76 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11375.43 ms /    17 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12585.03 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2599.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.47 ms /    20 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11612.58 ms /    17 runs   (  683.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12754.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2545.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.64 ms /    20 tokens (   55.18 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11768.06 ms /    17 runs   (  692.24 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12926.25 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.24 ms /    20 tokens (   55.16 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11171.00 ms /    16 runs   (  698.19 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12326.24 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    19 runs   (    0.44 ms per token,  2274.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.48 ms /    20 tokens (   62.72 ms per token,    15.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12230.58 ms /    18 runs   (  679.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13547.30 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.67 ms /    20 tokens (   52.23 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11303.11 ms /    16 runs   (  706.44 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   12398.03 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    21 runs   (    0.40 ms per token,  2524.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.65 ms /    20 tokens (   58.08 ms per token,    17.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13856.80 ms /    20 runs   (  692.84 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15081.60 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    18 runs   (    0.41 ms per token,  2442.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1096.16 ms /    20 tokens (   54.81 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11790.84 ms /    17 runs   (  693.58 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12942.24 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2551.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.70 ms /    19 tokens (   68.35 ms per token,    14.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10883.07 ms /    16 runs   (  680.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12232.41 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2535.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.70 ms /    20 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11880.50 ms /    17 runs   (  698.85 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13003.30 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2566.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.43 ms /    20 tokens (   56.07 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11994.99 ms /    17 runs   (  705.59 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   13170.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2514.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.87 ms /    20 tokens (   56.04 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11448.70 ms /    16 runs   (  715.54 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   12620.71 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2621.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.48 ms /    20 tokens (   57.52 ms per token,    17.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10881.34 ms /    16 runs   (  680.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12081.91 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1042.87 ms /    20 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10589.60 ms /    16 runs   (  661.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11681.70 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2551.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.17 ms /    20 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   13251.20 ms /    19 runs   (  697.43 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   14340.60 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    17 runs   (    0.41 ms per token,  2429.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.26 ms /    20 tokens (   55.16 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10975.82 ms /    16 runs   (  685.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12132.31 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    17 runs   (    0.42 ms per token,  2394.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.21 ms /    20 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10582.33 ms /    16 runs   (  661.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11689.62 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    17 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.12 ms /    20 tokens (   55.26 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10688.27 ms /    16 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11842.74 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    18 runs   (    0.40 ms per token,  2510.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.34 ms /    20 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11373.74 ms /    17 runs   (  669.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12468.53 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.16 ms /    20 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11334.16 ms /    17 runs   (  666.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12457.50 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2643.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.74 ms /    20 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10888.09 ms /    16 runs   (  680.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12027.01 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2651.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.80 ms /    20 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10568.88 ms /    16 runs   (  660.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11641.44 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    19 runs   (    0.37 ms per token,  2693.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.55 ms /    20 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11863.82 ms /    18 runs   (  659.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12948.42 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2658.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1001.51 ms /    19 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11435.34 ms /    17 runs   (  672.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12488.65 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2586.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.85 ms /    19 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10696.44 ms /    16 runs   (  668.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11719.94 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.87 ms /    20 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11388.45 ms /    17 runs   (  669.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12485.53 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2580.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.52 ms /    20 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12003.46 ms /    18 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13084.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.05 ms /    20 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10721.47 ms /    16 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11801.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2610.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.53 ms /    19 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11565.40 ms /    17 runs   (  680.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12593.92 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.41 ms /    20 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11436.66 ms /    17 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12550.79 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    17 runs   (    0.38 ms per token,  2662.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.03 ms /    20 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10845.44 ms /    16 runs   (  677.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11912.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2682.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.80 ms /    20 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11339.71 ms /    17 runs   (  667.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12409.58 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.74 ms /    21 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10729.51 ms /    16 runs   (  670.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11863.58 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.47 ms /    22 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10655.01 ms /    16 runs   (  665.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11817.56 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2633.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.07 ms /    21 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11371.87 ms /    17 runs   (  668.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12482.26 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2616.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.91 ms /    21 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11953.57 ms /    18 runs   (  664.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13111.24 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.24 ms /    22 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10774.09 ms /    16 runs   (  673.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11963.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    19 runs   (    0.38 ms per token,  2630.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.78 ms /    22 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12102.83 ms /    18 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13288.86 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2594.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.42 ms /    21 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12023.85 ms /    18 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13143.50 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    20 runs   (    0.39 ms per token,  2590.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.67 ms /    21 tokens (   53.98 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   12589.03 ms /    19 runs   (  662.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13779.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.07 ms /    22 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10524.75 ms /    16 runs   (  657.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11700.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.50 ms /    30 runs   (    0.38 ms per token,  2608.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.24 ms /    22 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   18922.49 ms /    29 runs   (  652.50 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   20173.44 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2681.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.49 ms /    21 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11259.01 ms /    17 runs   (  662.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12395.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    20 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.27 ms /    21 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12607.00 ms /    19 runs   (  663.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13727.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.80 ms /    21 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10675.63 ms /    16 runs   (  667.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11808.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    20 runs   (    0.41 ms per token,  2414.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.32 ms /    22 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12582.01 ms /    19 runs   (  662.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13781.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.47 ms /    22 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11278.81 ms /    17 runs   (  663.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12452.29 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2582.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.47 ms /    21 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11931.61 ms /    18 runs   (  662.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13048.33 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2665.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.89 ms /    21 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10563.93 ms /    16 runs   (  660.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11685.12 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.70 ms /    22 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10640.65 ms /    16 runs   (  665.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11804.35 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2641.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.24 ms /    22 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11859.76 ms /    18 runs   (  658.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13032.41 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    20 runs   (    0.38 ms per token,  2638.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.62 ms /    21 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12620.54 ms /    19 runs   (  664.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13797.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2640.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.33 ms /    21 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10562.15 ms /    16 runs   (  660.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11703.08 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2613.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.16 ms /    22 tokens (   51.83 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10609.22 ms /    16 runs   (  663.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11797.61 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.68 ms /    22 tokens (   51.99 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11404.39 ms /    17 runs   (  670.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12600.04 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2638.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.97 ms /    20 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11257.14 ms /    17 runs   (  662.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12357.96 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2578.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.05 ms /    21 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10677.79 ms /    16 runs   (  667.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11821.20 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.14 ms /    29 runs   (    0.38 ms per token,  2603.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.37 ms /    22 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   18585.31 ms /    28 runs   (  663.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19801.80 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2559.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.87 ms /    22 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11351.17 ms /    17 runs   (  667.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12515.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2606.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.20 ms /    21 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11985.70 ms /    18 runs   (  665.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13101.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2593.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.85 ms /    21 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12568.11 ms /    19 runs   (  661.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13696.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.01 ms /    28 runs   (    0.39 ms per token,  2543.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.30 ms /    22 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   17986.79 ms /    27 runs   (  666.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19205.80 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    18 runs   (    0.44 ms per token,  2256.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.02 ms /    22 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11287.51 ms /    17 runs   (  663.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12484.72 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2626.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.84 ms /    20 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11254.19 ms /    17 runs   (  662.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12359.04 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    15 runs   (    0.41 ms per token,  2467.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.72 ms /    22 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    9294.68 ms /    14 runs   (  663.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10476.42 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2630.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.80 ms /    22 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10629.47 ms /    16 runs   (  664.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11799.53 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2530.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.55 ms /    21 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10503.12 ms /    16 runs   (  656.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11645.13 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.34 ms /    21 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11090.93 ms /    17 runs   (  652.41 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12222.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.63 ms /    22 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10433.51 ms /    16 runs   (  652.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11590.69 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.85 ms /    22 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10491.37 ms /    16 runs   (  655.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11656.14 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2568.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.52 ms /    21 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   11796.84 ms /    18 runs   (  655.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12926.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2595.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.09 ms /    21 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12520.45 ms /    19 runs   (  658.97 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13647.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2640.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.49 ms /    22 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   10459.28 ms /    16 runs   (  653.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11631.53 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2561.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.94 ms /    22 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10417.81 ms /    16 runs   (  651.11 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11606.61 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.36 ms /    21 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11136.04 ms /    17 runs   (  655.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12263.58 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2610.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.59 ms /    21 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11306.11 ms /    17 runs   (  665.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12438.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.81 ms /    21 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10402.71 ms /    16 runs   (  650.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11578.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.06 ms /    22 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11678.63 ms /    18 runs   (  648.81 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12860.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2698.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.54 ms /    22 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11101.62 ms /    17 runs   (  653.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12275.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2547.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.48 ms /    21 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12063.33 ms /    18 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13190.94 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2584.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.09 ms /    21 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.86 ms /    16 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11873.05 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.59 ms /    22 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10580.93 ms /    16 runs   (  661.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11750.31 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2507.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.28 ms /    22 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12067.96 ms /    18 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13244.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2573.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.70 ms /    21 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12753.06 ms /    19 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13896.76 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2590.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.39 ms /    21 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10529.50 ms /    16 runs   (  658.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11654.74 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2592.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.86 ms /    22 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11257.87 ms /    17 runs   (  662.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12513.75 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2585.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.00 ms /    22 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12063.54 ms /    18 runs   (  670.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13240.28 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    21 runs   (    0.38 ms per token,  2609.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.51 ms /    21 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13317.23 ms /    20 runs   (  665.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14491.46 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.60 ms /    22 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11321.71 ms /    17 runs   (  665.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12528.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2572.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.31 ms /    22 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12078.90 ms /    18 runs   (  671.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13262.84 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    22 runs   (    0.38 ms per token,  2613.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.25 ms /    21 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   14160.10 ms /    21 runs   (  674.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15285.86 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.44 ms /    21 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12745.83 ms /    19 runs   (  670.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13875.91 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2634.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.46 ms /    21 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10808.46 ms /    16 runs   (  675.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11967.36 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    21 runs   (    0.39 ms per token,  2581.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.66 ms /    22 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   13294.54 ms /    20 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14475.90 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    20 runs   (    0.39 ms per token,  2538.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.14 ms /    22 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12613.57 ms /    19 runs   (  663.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13782.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    22 runs   (    0.39 ms per token,  2568.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1087.60 ms /    21 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   14127.34 ms /    21 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15276.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2573.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.70 ms /    22 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10570.72 ms /    16 runs   (  660.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11724.72 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.73 ms /    22 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11345.07 ms /    17 runs   (  667.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12506.85 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    19 runs   (    0.37 ms per token,  2686.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.39 ms /    21 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12235.77 ms /    18 runs   (  679.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13418.72 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2553.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.02 ms /    21 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12103.92 ms /    18 runs   (  672.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13248.37 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    21 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.47 ms /    21 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   13333.88 ms /    20 runs   (  666.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14459.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.12 ms /    22 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11442.18 ms /    17 runs   (  673.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12643.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    22 runs   (    0.39 ms per token,  2538.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.21 ms /    22 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   14412.04 ms /    21 runs   (  686.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15647.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    21 runs   (    0.39 ms per token,  2550.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.73 ms /    21 tokens (   55.99 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13466.97 ms /    20 runs   (  673.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14703.96 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    18 runs   (    0.40 ms per token,  2510.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.95 ms /    22 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   11385.48 ms /    17 runs   (  669.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12566.74 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2593.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.12 ms /    22 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12045.59 ms /    18 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13255.86 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.73 ms /    21 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12145.19 ms /    18 runs   (  674.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13297.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2587.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.95 ms /    21 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11995.93 ms /    18 runs   (  666.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13141.35 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    19 runs   (    0.40 ms per token,  2484.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.75 ms /    21 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11929.61 ms /    18 runs   (  662.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13077.78 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2561.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.59 ms /    22 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11140.57 ms /    17 runs   (  655.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12336.34 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2540.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.54 ms /    22 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11731.43 ms /    18 runs   (  651.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12909.97 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    21 runs   (    0.38 ms per token,  2639.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.74 ms /    21 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13087.68 ms /    20 runs   (  654.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14250.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2625.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.45 ms /    22 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10499.26 ms /    16 runs   (  656.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11672.46 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2669.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.19 ms /    22 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11301.03 ms /    17 runs   (  664.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12472.96 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    23 runs   (    0.39 ms per token,  2561.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.94 ms /    20 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   14549.57 ms /    22 runs   (  661.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15666.04 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    19 runs   (    0.39 ms per token,  2536.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.31 ms /    20 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11706.33 ms /    18 runs   (  650.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12796.90 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    31 runs   (    0.40 ms per token,  2507.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.34 ms /    22 tokens (   52.42 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   20114.29 ms /    30 runs   (  670.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21357.15 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.67 ms /    22 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11417.34 ms /    17 runs   (  671.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12624.54 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2568.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.23 ms /    21 tokens (   56.87 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11529.90 ms /    17 runs   (  678.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12777.97 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2507.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.24 ms /    21 tokens (   57.44 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12194.09 ms /    18 runs   (  677.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13457.20 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.40 ms per token,  2530.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.02 ms /    22 tokens (   58.27 ms per token,    17.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11614.19 ms /    17 runs   (  683.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12950.18 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.90 ms /    22 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10960.62 ms /    16 runs   (  685.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12190.92 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.01 ms /    23 runs   (    0.39 ms per token,  2553.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.45 ms /    21 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15102.13 ms /    22 runs   (  686.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16281.99 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.60 ms /    21 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11517.25 ms /    17 runs   (  677.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12696.95 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.42 ms /    22 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10753.08 ms /    16 runs   (  672.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11961.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.49 ms /    22 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10688.36 ms /    16 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11919.07 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    19 runs   (    0.40 ms per token,  2531.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.43 ms /    21 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12063.54 ms /    18 runs   (  670.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13237.37 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2600.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.40 ms /    21 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12396.03 ms /    18 runs   (  688.67 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13571.81 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2506.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.45 ms /    22 tokens (   57.11 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:        eval time =   13083.86 ms /    18 runs   (  726.88 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   14398.55 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    20 runs   (    0.40 ms per token,  2478.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.86 ms /    22 tokens (   59.22 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13077.46 ms /    19 runs   (  688.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14440.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.86 ms /    20 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11602.89 ms /    17 runs   (  682.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12721.13 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    18 runs   (    0.46 ms per token,  2191.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.48 ms /    20 tokens (   67.42 ms per token,    14.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11991.84 ms /    17 runs   (  705.40 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   13400.68 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2550.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.90 ms /    22 tokens (   61.13 ms per token,    16.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11103.94 ms /    16 runs   (  694.00 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12500.13 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    17 runs   (    0.41 ms per token,  2449.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.47 ms /    22 tokens (   59.39 ms per token,    16.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11190.45 ms /    16 runs   (  699.40 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12548.52 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2578.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.27 ms /    21 tokens (   57.35 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12427.68 ms /    18 runs   (  690.43 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13689.53 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     120.46 ms /   402 runs   (    0.30 ms per token,  3337.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.76 ms /    21 tokens (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =  276891.41 ms /   401 runs   (  690.50 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =  279337.69 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2568.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.19 ms /    22 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12048.18 ms /    18 runs   (  669.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13264.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2580.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.21 ms /    22 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10737.21 ms /    16 runs   (  671.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11911.52 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.45 ms /    24 runs   (    0.39 ms per token,  2538.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.33 ms /    21 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   15366.88 ms /    23 runs   (  668.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16517.26 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2524.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.18 ms /    21 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12695.80 ms /    19 runs   (  668.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13845.23 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2530.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.14 ms /    22 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10809.81 ms /    16 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11979.82 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    18 runs   (    0.42 ms per token,  2372.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.49 ms /    22 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11516.22 ms /    17 runs   (  677.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12690.54 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    18 runs   (    0.40 ms per token,  2480.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.58 ms /    21 tokens (   57.74 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11290.40 ms /    17 runs   (  664.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12558.31 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    23 runs   (    0.41 ms per token,  2445.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.93 ms /    21 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   15158.64 ms /    22 runs   (  689.03 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   16333.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    19 runs   (    0.40 ms per token,  2499.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.94 ms /    21 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12184.88 ms /    18 runs   (  676.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13323.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2541.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.41 ms /    22 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11797.28 ms /    17 runs   (  693.96 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13011.55 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2598.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1349.14 ms /    22 tokens (   61.32 ms per token,    16.31 tokens per second)\n",
      "llama_print_timings:        eval time =   13100.34 ms /    19 runs   (  689.49 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14508.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    19 runs   (    0.38 ms per token,  2637.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.32 ms /    21 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12004.89 ms /    18 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13195.83 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    17 runs   (    0.47 ms per token,  2139.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.08 ms /    21 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10834.03 ms /    16 runs   (  677.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12032.68 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    18 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.43 ms /    22 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11570.11 ms /    17 runs   (  680.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12760.22 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    21 runs   (    0.40 ms per token,  2515.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.37 ms /    22 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14016.07 ms /    20 runs   (  700.80 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   15240.03 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    20 runs   (    0.40 ms per token,  2491.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.34 ms /    20 tokens (   54.07 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13190.42 ms /    19 runs   (  694.23 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   14333.35 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.29 ms /    21 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10575.19 ms /    16 runs   (  660.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11755.88 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2564.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.09 ms /    22 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11061.71 ms /    17 runs   (  650.69 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12258.34 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    19 runs   (    0.40 ms per token,  2480.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.57 ms /    22 tokens (   54.94 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12306.98 ms /    18 runs   (  683.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13573.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2554.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.10 ms /    21 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12062.47 ms /    18 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13200.54 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      23.53 ms /    59 runs   (    0.40 ms per token,  2507.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.65 ms /    21 tokens (   55.17 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   40526.46 ms /    58 runs   (  698.73 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   41870.79 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2571.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.91 ms /    22 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11528.67 ms /    17 runs   (  678.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12748.63 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.61 ms /    34 runs   (    0.40 ms per token,  2497.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.88 ms /    22 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   22770.84 ms /    33 runs   (  690.03 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   24027.66 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    21 runs   (    0.40 ms per token,  2516.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.15 ms /    21 tokens (   55.48 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13734.82 ms /    20 runs   (  686.74 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14964.16 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2603.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.11 ms /    22 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10778.18 ms /    16 runs   (  673.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12002.86 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.08 ms /    38 runs   (    0.40 ms per token,  2520.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.93 ms /    22 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   25411.56 ms /    37 runs   (  686.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26675.93 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    18 runs   (    0.40 ms per token,  2498.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.78 ms /    21 tokens (   57.75 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12055.90 ms /    17 runs   (  709.17 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   13324.29 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    19 runs   (    0.40 ms per token,  2498.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.38 ms /    21 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12793.75 ms /    18 runs   (  710.76 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   13963.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    17 runs   (    0.41 ms per token,  2441.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.66 ms /    21 tokens (   69.94 ms per token,    14.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11224.52 ms /    16 runs   (  701.53 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12744.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.07 ms /    22 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11010.59 ms /    16 runs   (  688.16 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12223.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    18 runs   (    0.40 ms per token,  2511.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.61 ms /    22 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11262.42 ms /    17 runs   (  662.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12476.66 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    21 runs   (    0.40 ms per token,  2521.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.26 ms /    21 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13277.09 ms /    20 runs   (  663.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14475.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2517.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.65 ms /    21 tokens (   55.70 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10739.06 ms /    16 runs   (  671.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11959.18 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    18 runs   (    0.40 ms per token,  2495.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.88 ms /    22 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11759.05 ms /    17 runs   (  691.71 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12988.40 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.40 ms per token,  2530.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.14 ms /    22 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11278.74 ms /    17 runs   (  663.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12497.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2548.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.17 ms /    21 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12127.79 ms /    18 runs   (  673.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13282.62 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2511.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.39 ms /    21 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11211.18 ms /    16 runs   (  700.70 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12409.44 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.86 ms /    22 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11782.21 ms /    17 runs   (  693.07 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12996.03 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2576.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.00 ms /    22 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12240.81 ms /    18 runs   (  680.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13462.44 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2600.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.33 ms /    21 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12141.40 ms /    18 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13314.92 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2626.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.37 ms /    21 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10845.73 ms /    16 runs   (  677.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11997.66 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2562.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.98 ms /    22 tokens (   61.23 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11201.86 ms /    16 runs   (  700.12 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12601.26 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    18 runs   (    0.42 ms per token,  2386.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.71 ms /    22 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11774.53 ms /    17 runs   (  692.62 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12982.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2531.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.29 ms /    21 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12229.50 ms /    18 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13416.63 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2522.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.96 ms /    21 tokens (   55.00 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10738.35 ms /    16 runs   (  671.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11943.76 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.02 ms /    22 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11171.42 ms /    16 runs   (  698.21 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12390.23 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    19 runs   (    0.43 ms per token,  2332.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.34 ms /    22 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12305.20 ms /    18 runs   (  683.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13558.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    21 runs   (    0.40 ms per token,  2509.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.89 ms /    21 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13547.30 ms /    20 runs   (  677.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14709.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    31 runs   (    0.39 ms per token,  2589.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.52 ms /    22 tokens (   58.30 ms per token,    17.15 tokens per second)\n",
      "llama_print_timings:        eval time =   20725.65 ms /    30 runs   (  690.85 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   22100.23 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2487.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.57 ms /    22 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10905.13 ms /    16 runs   (  681.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12093.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    16 runs   (    0.40 ms per token,  2511.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.73 ms /    21 tokens (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10489.04 ms /    15 runs   (  699.27 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   11715.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.66 ms /    21 tokens (   57.56 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11105.49 ms /    17 runs   (  653.26 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12366.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    17 runs   (    0.41 ms per token,  2465.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.71 ms /    21 tokens (   53.18 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10936.51 ms /    16 runs   (  683.53 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12103.34 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    18 runs   (    0.41 ms per token,  2424.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.69 ms /    22 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11594.36 ms /    17 runs   (  682.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12839.18 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    20 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.74 ms /    22 tokens (   56.17 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12906.18 ms /    19 runs   (  679.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14202.95 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    18 runs   (    0.40 ms per token,  2492.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.05 ms /    21 tokens (   57.91 ms per token,    17.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11441.70 ms /    17 runs   (  673.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12711.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    19 runs   (    0.40 ms per token,  2509.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.29 ms /    22 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12278.87 ms /    18 runs   (  682.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13538.76 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2613.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.58 ms /    22 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10652.88 ms /    16 runs   (  665.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11863.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2561.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.60 ms /    21 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11345.80 ms /    17 runs   (  667.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12491.89 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2544.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.07 ms /    21 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12688.37 ms /    19 runs   (  667.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13851.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    17 runs   (    0.40 ms per token,  2492.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.33 ms /    22 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10761.50 ms /    16 runs   (  672.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11976.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2527.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.99 ms /    22 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10595.12 ms /    16 runs   (  662.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11785.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.11 ms /    21 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11280.65 ms /    17 runs   (  663.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12471.94 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2622.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.44 ms /    21 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11568.89 ms /    17 runs   (  680.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12730.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    20 runs   (    0.42 ms per token,  2373.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.36 ms /    22 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12686.75 ms /    19 runs   (  667.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13921.46 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2636.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.28 ms /    22 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10709.77 ms /    16 runs   (  669.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11887.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    19 runs   (    0.40 ms per token,  2531.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.47 ms /    21 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12135.24 ms /    18 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13304.47 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2588.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.60 ms /    21 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11627.70 ms /    17 runs   (  683.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12793.97 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2554.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.37 ms /    22 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10755.11 ms /    16 runs   (  672.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11957.23 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2649.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.56 ms /    22 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10700.07 ms /    16 runs   (  668.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11868.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2602.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.78 ms /    21 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12191.40 ms /    18 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13387.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.46 ms /    21 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11292.77 ms /    17 runs   (  664.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12485.12 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2571.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.83 ms /    21 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10398.51 ms /    16 runs   (  649.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11556.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.66 ms /    28 runs   (    0.38 ms per token,  2626.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.83 ms /    22 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   18463.78 ms /    27 runs   (  683.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19709.24 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2578.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.97 ms /    22 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12030.32 ms /    18 runs   (  668.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13278.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    21 runs   (    0.39 ms per token,  2552.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.99 ms /    21 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13739.46 ms /    20 runs   (  686.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14927.66 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    17 runs   (    0.41 ms per token,  2465.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.74 ms /    22 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10756.14 ms /    16 runs   (  672.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11966.83 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2540.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.71 ms /    22 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10630.34 ms /    16 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11870.94 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.19 ms /    21 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11139.74 ms /    17 runs   (  655.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12283.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    21 runs   (    0.39 ms per token,  2534.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.24 ms /    21 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   13454.70 ms /    20 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14653.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    17 runs   (    0.40 ms per token,  2474.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.99 ms /    22 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10716.94 ms /    16 runs   (  669.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11923.48 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2542.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.51 ms /    22 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11526.50 ms /    17 runs   (  678.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12719.85 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    19 runs   (    0.39 ms per token,  2536.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.06 ms /    21 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12106.64 ms /    18 runs   (  672.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13274.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2543.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.24 ms /    21 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12438.57 ms /    19 runs   (  654.66 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13569.66 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    17 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.99 ms /    22 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10955.12 ms /    16 runs   (  684.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12181.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    17 runs   (    0.41 ms per token,  2416.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.31 ms /    22 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10864.07 ms /    16 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12093.41 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    18 runs   (    0.40 ms per token,  2479.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.41 ms /    21 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11470.73 ms /    17 runs   (  674.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12666.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    18 runs   (    0.41 ms per token,  2437.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.28 ms /    21 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11512.56 ms /    17 runs   (  677.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12684.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2501.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.92 ms /    22 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10846.66 ms /    16 runs   (  677.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12065.56 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2534.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.08 ms /    22 tokens (   55.96 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10993.32 ms /    16 runs   (  687.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12275.24 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    18 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.81 ms /    21 tokens (   57.90 ms per token,    17.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11461.94 ms /    17 runs   (  674.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12731.43 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    21 runs   (    0.40 ms per token,  2511.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.06 ms /    21 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13674.31 ms /    20 runs   (  683.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14822.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.98 ms /    21 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10813.01 ms /    16 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12004.74 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2566.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.68 ms /    22 tokens (   55.30 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10641.27 ms /    16 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11909.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2578.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.12 ms /    22 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11982.63 ms /    18 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13187.19 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.35 ms /    21 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11597.93 ms /    17 runs   (  682.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12761.03 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.66 ms /    27 runs   (    0.43 ms per token,  2315.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.90 ms /    20 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   17908.77 ms /    26 runs   (  688.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   19070.40 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2623.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.92 ms /    21 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10828.18 ms /    16 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11990.36 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.47 ms /    23 runs   (    0.41 ms per token,  2427.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.10 ms /    21 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   14841.09 ms /    22 runs   (  674.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16056.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2621.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.36 ms /    20 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11362.58 ms /    17 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12468.22 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    28 runs   (    0.38 ms per token,  2638.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.34 ms /    21 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   18294.01 ms /    27 runs   (  677.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19453.03 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.04 ms /    21 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10903.43 ms /    16 runs   (  681.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12084.63 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.30 ms /    20 tokens (   54.66 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12847.06 ms /    19 runs   (  676.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13999.28 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2540.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.84 ms /    20 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11326.69 ms /    17 runs   (  666.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12431.25 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    17 runs   (    0.40 ms per token,  2506.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.00 ms /    20 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10679.82 ms /    16 runs   (  667.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11773.94 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2542.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.92 ms /    21 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10442.47 ms /    16 runs   (  652.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11617.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2563.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.83 ms /    21 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12485.46 ms /    19 runs   (  657.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13659.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2568.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.22 ms /    20 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11461.51 ms /    17 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12566.61 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.49 ms /    21 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11282.27 ms /    17 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12430.43 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.55 ms /    21 tokens (   52.45 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11505.47 ms /    17 runs   (  676.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12659.38 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    23 runs   (    0.39 ms per token,  2536.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.12 ms /    20 tokens (   68.56 ms per token,    14.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14797.13 ms /    22 runs   (  672.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16237.42 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.63 ms /    20 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12058.27 ms /    18 runs   (  669.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13192.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    21 runs   (    0.40 ms per token,  2528.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.50 ms /    20 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13434.18 ms /    20 runs   (  671.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14582.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    28 runs   (    0.39 ms per token,  2577.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.45 ms /    21 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17918.66 ms /    27 runs   (  663.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19109.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.91 ms /    22 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.11 ms /    21 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   14653.63 ms /    21 runs   (  697.79 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   15817.44 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2648.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.73 ms /    20 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12048.63 ms /    18 runs   (  669.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13217.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      17.88 ms /    44 runs   (    0.41 ms per token,  2460.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.71 ms /    20 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   30133.10 ms /    43 runs   (  700.77 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   31347.84 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    18 runs   (    0.41 ms per token,  2455.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.20 ms /    21 tokens (   68.53 ms per token,    14.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11369.73 ms /    17 runs   (  668.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12865.87 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2553.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1096.59 ms /    21 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   13450.73 ms /    20 runs   (  672.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14609.98 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.23 ms /    20 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12163.67 ms /    18 runs   (  675.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13281.92 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2550.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.81 ms /    21 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12939.87 ms /    19 runs   (  681.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14100.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2653.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1096.55 ms /    21 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10893.14 ms /    16 runs   (  680.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12040.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     138.37 ms /   403 runs   (    0.34 ms per token,  2912.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.56 ms /    20 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =  275055.89 ms /   402 runs   (  684.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =  277401.63 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.40 ms per token,  2530.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.27 ms /    20 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11293.32 ms /    17 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12391.38 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    20 runs   (    0.39 ms per token,  2592.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.94 ms /    21 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12786.18 ms /    19 runs   (  672.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13964.65 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2638.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.31 ms /    21 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10593.05 ms /    16 runs   (  662.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11748.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2641.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.91 ms /    20 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11875.18 ms /    18 runs   (  659.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12981.94 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.41 ms /    20 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11240.69 ms /    17 runs   (  661.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12350.58 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.40 ms per token,  2530.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.69 ms /    20 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11402.42 ms /    17 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12503.22 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.05 ms /    28 runs   (    0.39 ms per token,  2534.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.30 ms /    21 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   18154.00 ms /    27 runs   (  672.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19316.52 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2597.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.50 ms /    21 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12029.02 ms /    18 runs   (  668.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13164.10 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.18 ms /    20 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11864.43 ms /    18 runs   (  659.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12953.39 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    19 runs   (    0.45 ms per token,  2244.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.35 ms /    21 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11934.56 ms /    18 runs   (  663.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13060.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2570.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.98 ms /    21 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11274.16 ms /    17 runs   (  663.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12388.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2622.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.44 ms /    20 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11851.95 ms /    18 runs   (  658.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12974.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2576.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.03 ms /    20 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11717.34 ms /    18 runs   (  650.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12798.35 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    21 runs   (    0.40 ms per token,  2489.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.98 ms /    21 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   13203.07 ms /    20 runs   (  660.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14323.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2579.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.56 ms /    21 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10486.47 ms /    16 runs   (  655.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11617.05 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    21 runs   (    0.38 ms per token,  2603.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.53 ms /    20 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   13406.71 ms /    20 runs   (  670.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14485.19 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.46 ms /    20 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10982.92 ms /    17 runs   (  646.05 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12057.10 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2580.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.62 ms /    20 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12246.53 ms /    19 runs   (  644.55 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   13377.00 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.52 ms /    21 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11060.76 ms /    17 runs   (  650.63 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12195.03 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2596.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.13 ms /    21 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11871.10 ms /    18 runs   (  659.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13018.34 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2605.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.45 ms /    20 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   11706.14 ms /    18 runs   (  650.34 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12784.32 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.28 ms /    30 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.88 ms /    21 tokens (   52.76 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19069.89 ms /    29 runs   (  657.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20264.39 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.17 ms /    21 tokens (   52.87 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11337.82 ms /    17 runs   (  666.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12500.06 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     116.92 ms /   403 runs   (    0.29 ms per token,  3446.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.19 ms /    19 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =  265961.44 ms /   402 runs   (  661.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =  268174.29 ms /   421 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.21 ms /    19 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11718.05 ms /    18 runs   (  651.00 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12813.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.54 ms /    20 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11362.97 ms /    17 runs   (  668.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12475.85 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.30 ms /    21 tokens (   56.01 ms per token,    17.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11494.81 ms /    17 runs   (  676.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12724.32 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2564.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.02 ms /    21 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12125.08 ms /    18 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13272.08 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2658.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.23 ms /    20 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12010.16 ms /    18 runs   (  667.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13122.37 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2580.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.44 ms /    21 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12569.89 ms /    19 runs   (  661.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13723.27 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    29 runs   (    0.39 ms per token,  2573.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.48 ms /    21 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   18718.27 ms /    28 runs   (  668.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19867.30 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2546.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.70 ms /    20 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13171.92 ms /    20 runs   (  658.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14261.56 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.64 ms /    35 runs   (    0.39 ms per token,  2565.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.19 ms /    20 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   22407.63 ms /    34 runs   (  659.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23530.90 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2596.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.92 ms /    20 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   13265.27 ms /    20 runs   (  663.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14351.87 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.71 ms /    21 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11358.79 ms /    17 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12489.65 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    22 runs   (    0.38 ms per token,  2659.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.26 ms /    21 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   13711.91 ms /    21 runs   (  652.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14910.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2587.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.85 ms /    20 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12339.97 ms /    19 runs   (  649.47 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13452.75 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    19 runs   (    0.42 ms per token,  2382.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.89 ms /    19 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11929.94 ms /    18 runs   (  662.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12977.53 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    17 runs   (    0.37 ms per token,  2715.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.68 ms /    21 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10682.79 ms /    16 runs   (  667.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11800.85 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    20 runs   (    0.43 ms per token,  2330.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.82 ms /    21 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12548.21 ms /    19 runs   (  660.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13672.91 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2586.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.18 ms /    20 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11223.16 ms /    17 runs   (  660.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12330.87 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2608.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     971.50 ms /    19 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11249.73 ms /    17 runs   (  661.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12272.64 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2609.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.16 ms /    21 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10383.98 ms /    16 runs   (  649.00 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11508.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.40 ms per token,  2531.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.88 ms /    21 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11372.29 ms /    17 runs   (  668.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12502.52 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.93 ms /    20 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11407.31 ms /    17 runs   (  671.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12509.66 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    21 runs   (    0.39 ms per token,  2572.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.33 ms /    21 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   13304.86 ms /    20 runs   (  665.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14454.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.35 ms /    21 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10657.87 ms /    16 runs   (  666.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11787.90 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2637.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.55 ms /    20 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11855.27 ms /    18 runs   (  658.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12929.65 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2565.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.14 ms /    20 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11941.57 ms /    18 runs   (  663.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13042.07 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2562.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.43 ms /    20 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11346.72 ms /    17 runs   (  667.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12479.50 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.61 ms /    21 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10546.59 ms /    16 runs   (  659.16 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11702.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.69 ms /    28 runs   (    0.38 ms per token,  2618.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.97 ms /    21 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   17967.17 ms /    27 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19160.59 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2650.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.95 ms /    20 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11237.34 ms /    17 runs   (  661.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12326.28 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2516.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.37 ms /    20 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10670.98 ms /    16 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11767.14 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2547.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.44 ms /    21 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10617.65 ms /    16 runs   (  663.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11760.72 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    22 runs   (    0.40 ms per token,  2502.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.12 ms /    21 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14005.82 ms /    21 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15142.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2561.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.52 ms /    20 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11808.79 ms /    18 runs   (  656.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12881.90 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.65 ms /    20 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12547.17 ms /    19 runs   (  660.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13641.84 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2567.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.02 ms /    21 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11216.76 ms /    17 runs   (  659.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12342.02 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    21 runs   (    0.38 ms per token,  2642.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.70 ms /    21 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   13033.37 ms /    20 runs   (  651.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14154.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2622.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.84 ms /    20 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11857.29 ms /    18 runs   (  658.74 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12961.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2605.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.74 ms /    21 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11791.20 ms /    18 runs   (  655.07 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12910.79 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    17 runs   (    0.41 ms per token,  2459.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.27 ms /    21 tokens (   54.16 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10601.77 ms /    16 runs   (  662.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11787.41 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    20 runs   (    0.40 ms per token,  2531.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.71 ms /    20 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12485.12 ms /    19 runs   (  657.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13572.62 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2560.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.69 ms /    20 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11347.17 ms /    17 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12464.93 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2622.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.84 ms /    20 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11270.03 ms /    17 runs   (  662.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12360.12 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    15 runs   (    0.39 ms per token,  2560.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.77 ms /    21 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =    9084.29 ms /    14 runs   (  648.88 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   10195.83 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    21 runs   (    0.39 ms per token,  2593.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.25 ms /    21 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13355.97 ms /    20 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14528.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.72 ms /    20 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11920.25 ms /    18 runs   (  662.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13026.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    29 runs   (    0.38 ms per token,  2631.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.78 ms /    21 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   18605.88 ms /    28 runs   (  664.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19803.65 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2556.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.79 ms /    21 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10582.05 ms /    16 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11701.17 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    19 runs   (    0.43 ms per token,  2305.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.23 ms /    20 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11932.65 ms /    18 runs   (  662.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13025.11 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2595.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.29 ms /    20 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11336.31 ms /    17 runs   (  666.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12440.81 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    19 runs   (    0.37 ms per token,  2668.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.05 ms /    21 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12023.22 ms /    18 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13177.84 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2567.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.46 ms /    21 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11577.06 ms /    17 runs   (  681.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12698.16 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    22 runs   (    0.39 ms per token,  2559.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.63 ms /    20 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14270.22 ms /    21 runs   (  679.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15395.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2585.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.50 ms /    20 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   13319.87 ms /    20 runs   (  665.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14488.10 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2523.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.70 ms /    21 tokens (   57.84 ms per token,    17.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11376.18 ms /    17 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12644.42 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2569.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.64 ms /    21 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11471.58 ms /    17 runs   (  674.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12642.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2545.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.01 ms /    20 tokens (   61.30 ms per token,    16.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12052.95 ms /    18 runs   (  669.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13335.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2603.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.16 ms /    20 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12006.40 ms /    18 runs   (  667.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13137.22 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    21 runs   (    0.39 ms per token,  2559.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.45 ms /    20 tokens (   57.57 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   13784.37 ms /    20 runs   (  689.22 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14997.84 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    16 runs   (    0.40 ms per token,  2491.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.13 ms /    21 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10763.64 ms /    15 runs   (  717.58 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   11949.64 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2603.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.74 ms /    21 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13160.45 ms /    19 runs   (  692.66 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   14322.77 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2578.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.69 ms /    20 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12033.84 ms /    18 runs   (  668.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13152.01 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    18 runs   (    0.40 ms per token,  2516.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.52 ms /    20 tokens (   55.73 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11536.18 ms /    17 runs   (  678.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12704.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    19 runs   (    0.40 ms per token,  2497.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.59 ms /    21 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12267.49 ms /    18 runs   (  681.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13390.26 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.56 ms /    30 runs   (    0.39 ms per token,  2595.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.13 ms /    21 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   19481.08 ms /    29 runs   (  671.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20672.94 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    21 runs   (    0.39 ms per token,  2592.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.40 ms /    20 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13355.38 ms /    20 runs   (  667.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14496.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.67 ms /    25 runs   (    0.39 ms per token,  2584.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.68 ms /    20 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16308.67 ms /    24 runs   (  679.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17405.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2612.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.41 ms /    21 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12797.39 ms /    19 runs   (  673.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13930.16 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    22 runs   (    0.38 ms per token,  2611.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.72 ms /    21 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14168.12 ms /    21 runs   (  674.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15310.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    21 runs   (    0.38 ms per token,  2609.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.94 ms /    19 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   13382.55 ms /    20 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14446.45 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.38 ms /    20 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11275.09 ms /    17 runs   (  663.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12367.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    17 runs   (    0.41 ms per token,  2439.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.46 ms /    21 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10607.57 ms /    16 runs   (  662.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11738.83 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2567.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.91 ms /    21 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11996.79 ms /    18 runs   (  666.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13127.94 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    18 runs   (    0.44 ms per token,  2255.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.80 ms /    20 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11464.35 ms /    17 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12578.06 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    21 runs   (    0.41 ms per token,  2462.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.70 ms /    19 tokens (   56.56 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   13635.90 ms /    20 runs   (  681.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14773.48 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.93 ms /    21 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11287.04 ms /    17 runs   (  663.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12463.79 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2568.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.92 ms /    21 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12064.40 ms /    18 runs   (  670.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13238.77 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    19 runs   (    0.42 ms per token,  2370.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.00 ms /    20 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12196.56 ms /    18 runs   (  677.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13332.45 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    16 runs   (    0.39 ms per token,  2544.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.89 ms /    20 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10050.98 ms /    15 runs   (  670.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11160.54 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.95 ms /    21 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11335.49 ms /    17 runs   (  666.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12451.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    19 runs   (    0.40 ms per token,  2503.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.37 ms /    21 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12223.72 ms /    18 runs   (  679.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13346.46 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2580.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.31 ms /    20 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12675.82 ms /    19 runs   (  667.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13772.23 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.55 ms /    21 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12453.76 ms /    18 runs   (  691.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13667.75 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    18 runs   (    0.45 ms per token,  2225.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.08 ms /    21 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11844.09 ms /    17 runs   (  696.71 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13048.77 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.07 ms /    20 tokens (   56.65 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13048.04 ms /    19 runs   (  686.74 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14240.53 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    19 runs   (    0.40 ms per token,  2524.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.31 ms /    20 tokens (   55.42 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12442.52 ms /    18 runs   (  691.25 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13607.90 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2608.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.48 ms /    20 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11405.98 ms /    17 runs   (  670.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12552.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2601.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.10 ms /    21 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11604.64 ms /    17 runs   (  682.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12751.98 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2601.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.29 ms /    21 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11856.67 ms /    18 runs   (  658.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13001.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.05 ms /    20 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11926.46 ms /    18 runs   (  662.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13034.28 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2520.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.58 ms /    21 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10840.69 ms /    16 runs   (  677.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12015.83 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.69 ms /    21 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11037.67 ms /    16 runs   (  689.85 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12222.11 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.50 ms /    20 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12150.55 ms /    18 runs   (  675.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13266.39 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    20 runs   (    0.39 ms per token,  2557.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.07 ms /    20 tokens (   55.20 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12723.72 ms /    19 runs   (  669.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13887.90 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2573.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.22 ms /    20 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11990.08 ms /    18 runs   (  666.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13098.76 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2538.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.58 ms /    21 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11003.83 ms /    16 runs   (  687.74 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12173.39 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2532.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.03 ms /    21 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12188.38 ms /    18 runs   (  677.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13336.92 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.39 ms /    20 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11486.03 ms /    17 runs   (  675.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12567.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    18 runs   (    0.40 ms per token,  2498.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.83 ms /    20 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11662.52 ms /    17 runs   (  686.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12818.06 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.04 ms /    21 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11543.81 ms /    17 runs   (  679.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12696.16 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    19 runs   (    0.44 ms per token,  2269.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.21 ms /    21 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12155.35 ms /    18 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13354.39 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2563.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.67 ms /    20 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12030.77 ms /    18 runs   (  668.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13118.24 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2540.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.03 ms /    19 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11444.16 ms /    17 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12500.21 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    18 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.27 ms /    21 tokens (   56.39 ms per token,    17.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11385.85 ms /    17 runs   (  669.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12623.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2627.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.98 ms /    21 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12304.67 ms /    18 runs   (  683.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13434.64 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2556.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.09 ms /    20 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12058.09 ms /    18 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13170.99 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2569.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.89 ms /    20 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11191.07 ms /    17 runs   (  658.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12294.04 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2513.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.16 ms /    21 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11245.93 ms /    17 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12370.31 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2627.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.62 ms /    21 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12171.25 ms /    18 runs   (  676.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13294.42 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2578.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1046.64 ms /    20 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11395.21 ms /    17 runs   (  670.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12495.89 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2594.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.88 ms /    20 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   10743.35 ms /    16 runs   (  671.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11820.79 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.72 ms /    21 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11524.49 ms /    17 runs   (  677.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12739.80 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2631.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.81 ms /    21 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11282.23 ms /    17 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12487.60 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2614.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.89 ms /    20 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11639.73 ms /    17 runs   (  684.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12737.53 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.91 ms /    29 runs   (    0.41 ms per token,  2435.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.41 ms /    20 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   18876.99 ms /    28 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20049.17 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2498.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.33 ms /    21 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11025.95 ms /    16 runs   (  689.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12177.08 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    21 runs   (    0.39 ms per token,  2573.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.90 ms /    21 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13640.98 ms /    20 runs   (  682.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14820.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2535.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.89 ms /    20 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11691.40 ms /    17 runs   (  687.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12798.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2670.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.05 ms /    20 tokens (   55.50 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10616.91 ms /    16 runs   (  663.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11776.70 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.58 ms /    21 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10990.91 ms /    16 runs   (  686.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12159.78 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2673.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.99 ms /    21 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11325.12 ms /    17 runs   (  666.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12443.01 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    22 runs   (    0.38 ms per token,  2649.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.49 ms /    20 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   14450.33 ms /    21 runs   (  688.11 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15565.57 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    28 runs   (    0.42 ms per token,  2388.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.75 ms /    21 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   18256.89 ms /    27 runs   (  676.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19433.90 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2571.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.16 ms /    21 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11319.97 ms /    17 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12479.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2535.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.08 ms /    20 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11531.37 ms /    17 runs   (  678.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12632.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    19 runs   (    0.40 ms per token,  2485.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.44 ms /    20 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12393.19 ms /    18 runs   (  688.51 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13532.16 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.43 ms /    21 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10857.78 ms /    16 runs   (  678.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12018.51 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    17 runs   (    0.40 ms per token,  2486.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.78 ms /    21 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10940.74 ms /    16 runs   (  683.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12122.56 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2564.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.19 ms /    20 tokens (   56.01 ms per token,    17.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11894.93 ms /    17 runs   (  699.70 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13068.73 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2567.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.14 ms /    20 tokens (   52.51 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11565.97 ms /    17 runs   (  680.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12669.40 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2552.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.50 ms /    20 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12186.23 ms /    18 runs   (  677.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13323.55 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.77 ms /    21 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11666.92 ms /    17 runs   (  686.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12865.56 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    20 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.99 ms /    21 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12857.73 ms /    19 runs   (  676.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14040.72 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    19 runs   (    0.41 ms per token,  2463.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.58 ms /    19 tokens (   57.40 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12249.78 ms /    18 runs   (  680.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13397.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    18 runs   (    0.47 ms per token,  2115.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.94 ms /    19 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12243.88 ms /    17 runs   (  720.23 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   13293.74 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2548.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.94 ms /    21 tokens (   56.85 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =   13487.26 ms /    19 runs   (  709.86 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   14741.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.66 ms /    24 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.04 ms /    21 tokens (   56.48 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:        eval time =   16358.33 ms /    23 runs   (  711.23 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   17622.85 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2584.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.91 ms /    20 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13082.92 ms /    19 runs   (  688.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14232.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    19 runs   (    0.40 ms per token,  2504.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.12 ms /    20 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12263.55 ms /    18 runs   (  681.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13355.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2490.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.25 ms /    21 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11329.76 ms /    16 runs   (  708.11 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   12522.37 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2569.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.91 ms /    21 tokens (   57.57 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12002.45 ms /    18 runs   (  666.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13268.28 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.25 ms /    20 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11516.33 ms /    17 runs   (  677.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12643.43 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2545.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.53 ms /    19 tokens (   60.45 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =   13579.21 ms /    20 runs   (  678.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14789.89 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2622.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.34 ms /    21 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11701.29 ms /    17 runs   (  688.31 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12901.11 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    22 runs   (    0.39 ms per token,  2558.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.42 ms /    21 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   14090.94 ms /    21 runs   (  671.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15277.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2591.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.02 ms /    20 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11795.16 ms /    18 runs   (  655.29 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12890.14 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.75 ms /    20 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11128.59 ms /    17 runs   (  654.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12202.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2627.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.05 ms /    21 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11179.98 ms /    17 runs   (  657.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12291.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2689.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.82 ms /    21 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11275.42 ms /    17 runs   (  663.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12392.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2598.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.46 ms /    20 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12081.89 ms /    18 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13175.45 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    17 runs   (    0.40 ms per token,  2495.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.11 ms /    24 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10729.64 ms /    16 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11981.79 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2618.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.34 ms /    23 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10734.20 ms /    16 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11958.66 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.20 ms /    22 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10645.47 ms /    16 runs   (  665.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11833.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2578.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.98 ms /    23 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12582.63 ms /    19 runs   (  662.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13825.55 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.11 ms /    23 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11952.56 ms /    18 runs   (  664.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13177.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.34 ms /    23 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12127.40 ms /    18 runs   (  673.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13337.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2606.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.68 ms /    23 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12571.04 ms /    19 runs   (  661.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13801.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2594.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.10 ms /    22 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10719.70 ms /    16 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11891.72 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.72 ms /    22 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10679.31 ms /    16 runs   (  667.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11907.29 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.05 ms /    23 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11194.49 ms /    17 runs   (  658.50 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12434.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.59 ms /    23 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11231.57 ms /    17 runs   (  660.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12448.40 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.74 ms /    23 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12053.85 ms /    18 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13356.81 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2592.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.37 ms /    23 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10567.14 ms /    16 runs   (  660.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11781.83 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    18 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.86 ms /    23 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11444.93 ms /    17 runs   (  673.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12685.37 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2621.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.44 ms /    23 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10596.73 ms /    16 runs   (  662.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11832.09 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2655.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.42 ms /    23 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10528.15 ms /    16 runs   (  658.01 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11745.22 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2530.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.33 ms /    23 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10537.39 ms /    16 runs   (  658.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11779.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2550.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.58 ms /    23 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10553.13 ms /    16 runs   (  659.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11780.32 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.76 ms /    23 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11214.63 ms /    17 runs   (  659.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12429.00 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2597.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.81 ms /    23 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11291.30 ms /    17 runs   (  664.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12509.88 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2602.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.33 ms /    23 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11979.12 ms /    18 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13200.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2562.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.51 ms /    23 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10734.21 ms /    16 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11949.09 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2538.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.69 ms /    23 tokens (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10875.03 ms /    16 runs   (  679.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12078.73 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.80 ms /    23 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10645.67 ms /    16 runs   (  665.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11872.79 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2636.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.85 ms /    23 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10561.78 ms /    16 runs   (  660.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11791.48 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    14 runs   (    0.39 ms per token,  2581.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.75 ms /    23 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8574.81 ms /    13 runs   (  659.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9775.12 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2572.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.08 ms /    23 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12660.57 ms /    19 runs   (  666.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13962.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.54 ms /    23 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10703.49 ms /    16 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11917.24 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2573.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.74 ms /    23 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10517.95 ms /    16 runs   (  657.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11727.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.45 ms /    23 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10497.80 ms /    16 runs   (  656.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11705.70 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    17 runs   (    0.36 ms per token,  2751.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.94 ms /    23 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10811.72 ms /    16 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12049.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.27 ms /    17 runs   (    0.37 ms per token,  2710.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.40 ms /    23 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10697.51 ms /    16 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11912.98 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.68 ms /    23 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10557.09 ms /    16 runs   (  659.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11796.91 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2546.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.47 ms /    22 tokens (   55.11 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12210.15 ms /    18 runs   (  678.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13479.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.82 ms /    23 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10824.79 ms /    16 runs   (  676.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12136.02 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.56 ms /    23 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12670.01 ms /    19 runs   (  666.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13949.61 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2542.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.54 ms /    23 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10509.01 ms /    16 runs   (  656.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11730.67 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2609.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1180.58 ms /    23 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   10421.08 ms /    16 runs   (  651.32 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11650.59 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2616.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.47 ms /    23 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10600.11 ms /    16 runs   (  662.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11803.70 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2605.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.79 ms /    23 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10630.90 ms /    16 runs   (  664.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11888.38 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.56 ms /    23 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10775.82 ms /    16 runs   (  673.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11979.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    18 runs   (    0.43 ms per token,  2336.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.58 ms /    22 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11225.99 ms /    17 runs   (  660.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12410.77 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2588.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.25 ms /    23 tokens (   58.62 ms per token,    17.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11291.76 ms /    17 runs   (  664.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12692.42 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.28 ms /    23 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10938.94 ms /    16 runs   (  683.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12151.24 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.82 ms /    23 tokens (   59.21 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10910.42 ms /    16 runs   (  681.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12322.35 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    17 runs   (    0.48 ms per token,  2103.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.62 ms /    23 tokens (   56.77 ms per token,    17.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11388.27 ms /    16 runs   (  711.77 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   12752.04 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.18 ms /    23 tokens (   55.14 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10816.17 ms /    16 runs   (  676.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12134.78 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    18 runs   (    0.40 ms per token,  2506.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.57 ms /    23 tokens (   54.76 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11923.19 ms /    17 runs   (  701.36 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13235.97 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    17 runs   (    0.48 ms per token,  2084.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.60 ms /    23 tokens (   65.94 ms per token,    15.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12203.16 ms /    16 runs   (  762.70 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =   13781.40 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    17 runs   (    0.41 ms per token,  2421.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.14 ms /    23 tokens (   68.61 ms per token,    14.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12110.71 ms /    16 runs   (  756.92 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =   13741.78 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2501.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.33 ms /    23 tokens (   56.71 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11193.99 ms /    16 runs   (  699.62 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12553.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2523.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.74 ms /    23 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11446.15 ms /    17 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12696.40 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.67 ms /    23 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10676.41 ms /    16 runs   (  667.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11909.58 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    18 runs   (    0.45 ms per token,  2202.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.06 ms /    23 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11551.60 ms /    17 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12800.89 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    17 runs   (    0.40 ms per token,  2479.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.52 ms /    23 tokens (   54.54 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11130.43 ms /    16 runs   (  695.65 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12437.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2609.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.63 ms /    23 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10814.89 ms /    16 runs   (  675.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12086.46 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2547.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1233.75 ms /    23 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12066.91 ms /    18 runs   (  670.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13356.86 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.12 ms /    23 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10812.30 ms /    16 runs   (  675.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12082.23 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    17 runs   (    0.42 ms per token,  2401.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.64 ms /    23 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11253.12 ms /    16 runs   (  703.32 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   12508.22 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2490.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.51 ms /    23 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10959.09 ms /    16 runs   (  684.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12201.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    17 runs   (    0.44 ms per token,  2261.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.92 ms /    23 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10508.91 ms /    16 runs   (  656.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11758.50 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    15 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.91 ms /    23 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    9242.92 ms /    14 runs   (  660.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10541.16 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    19 runs   (    0.42 ms per token,  2370.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.51 ms /    23 tokens (   57.54 ms per token,    17.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12201.40 ms /    18 runs   (  677.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13587.16 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    17 runs   (    0.43 ms per token,  2312.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.50 ms /    23 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11062.84 ms /    16 runs   (  691.43 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12319.63 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.16 ms /    23 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10764.47 ms /    16 runs   (  672.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11992.77 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    19 runs   (    0.42 ms per token,  2393.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.21 ms /    23 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12362.26 ms /    18 runs   (  686.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13631.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2596.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.76 ms /    23 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11224.01 ms /    16 runs   (  701.50 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12495.25 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.82 ms /    23 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11000.59 ms /    16 runs   (  687.54 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12263.43 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2515.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.84 ms /    23 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11083.34 ms /    16 runs   (  692.71 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12378.32 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    19 runs   (    0.40 ms per token,  2485.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.96 ms /    23 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12281.81 ms /    18 runs   (  682.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13539.76 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    20 runs   (    0.40 ms per token,  2477.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.89 ms /    22 tokens (   51.59 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   13019.04 ms /    19 runs   (  685.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14213.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.34 ms /    23 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11465.46 ms /    17 runs   (  674.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12689.78 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    17 runs   (    0.41 ms per token,  2458.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.31 ms /    23 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10931.70 ms /    16 runs   (  683.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12184.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    33 runs   (    0.40 ms per token,  2475.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.44 ms /    23 tokens (   60.45 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =   21589.74 ms /    32 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23081.16 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    17 runs   (    0.44 ms per token,  2261.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.04 ms /    23 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10886.81 ms /    16 runs   (  680.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12151.68 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    19 runs   (    0.43 ms per token,  2313.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.62 ms /    23 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12422.54 ms /    18 runs   (  690.14 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13650.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.22 ms /    23 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11417.05 ms /    17 runs   (  671.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12665.92 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    17 runs   (    0.41 ms per token,  2413.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.04 ms /    23 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11075.23 ms /    16 runs   (  692.20 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12309.13 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2529.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.67 ms /    23 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10800.21 ms /    16 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12074.82 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2519.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.85 ms /    23 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10703.15 ms /    16 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11990.07 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.36 ms /    23 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11194.11 ms /    16 runs   (  699.63 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12450.42 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.14 ms /    22 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12674.13 ms /    18 runs   (  704.12 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   13912.49 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2551.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.00 ms /    23 tokens (   54.78 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12488.93 ms /    18 runs   (  693.83 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13805.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    17 runs   (    0.40 ms per token,  2486.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.18 ms /    23 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10904.22 ms /    16 runs   (  681.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12171.10 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2544.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.02 ms /    23 tokens (   54.87 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12344.97 ms /    18 runs   (  685.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13662.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2516.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.54 ms /    23 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10901.02 ms /    16 runs   (  681.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12173.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2580.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.08 ms /    23 tokens (   54.48 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11757.75 ms /    17 runs   (  691.63 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13063.68 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2563.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.84 ms /    23 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12079.98 ms /    18 runs   (  671.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13384.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2569.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.41 ms /    23 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12007.42 ms /    18 runs   (  667.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13281.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.51 ms /    23 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10656.57 ms /    16 runs   (  666.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11884.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.01 ms /    23 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10879.27 ms /    16 runs   (  679.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12116.33 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2599.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.45 ms /    23 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   13109.50 ms /    19 runs   (  689.97 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14350.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2598.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.29 ms /    23 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12696.12 ms /    19 runs   (  668.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13925.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.91 ms /    23 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10710.28 ms /    16 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11972.64 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2571.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.97 ms /    23 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10954.59 ms /    16 runs   (  684.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12221.64 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2526.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.20 ms /    22 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   12654.68 ms /    19 runs   (  666.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13843.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2579.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.77 ms /    22 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10845.59 ms /    16 runs   (  677.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12075.47 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.45 ms /    23 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10557.41 ms /    16 runs   (  659.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11781.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.19 ms /    22 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10604.28 ms /    16 runs   (  662.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11794.45 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2543.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.05 ms /    23 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10553.68 ms /    16 runs   (  659.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11782.70 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    21 runs   (    0.39 ms per token,  2556.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.87 ms /    22 tokens (   51.59 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   13642.59 ms /    20 runs   (  682.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14839.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2665.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.45 ms /    22 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11376.60 ms /    17 runs   (  669.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12566.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2573.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.17 ms /    22 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12459.58 ms /    19 runs   (  655.77 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13628.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2563.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.61 ms /    21 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11279.05 ms /    17 runs   (  663.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12406.52 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.74 ms /    22 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10752.32 ms /    16 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11918.31 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2627.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.14 ms /    22 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12710.14 ms /    19 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13914.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.80 ms /    22 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11486.11 ms /    17 runs   (  675.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12713.54 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2655.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.42 ms /    21 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11424.36 ms /    17 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12541.91 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    21 runs   (    0.42 ms per token,  2359.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.18 ms /    20 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13326.62 ms /    20 runs   (  666.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14417.47 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2622.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.80 ms /    21 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11320.21 ms /    17 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12440.87 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2550.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.22 ms /    22 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12696.43 ms /    19 runs   (  668.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13870.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.24 ms /    22 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12741.06 ms /    19 runs   (  670.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13938.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.92 ms /    22 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10575.11 ms /    16 runs   (  660.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11751.70 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.39 ms per token,  2533.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.52 ms /    22 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11344.66 ms /    17 runs   (  667.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12524.00 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2585.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.22 ms /    22 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10518.39 ms /    16 runs   (  657.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11678.70 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2617.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.23 ms /    22 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10599.18 ms /    16 runs   (  662.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11766.02 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2591.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.36 ms /    22 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11230.48 ms /    17 runs   (  660.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12412.17 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2598.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.72 ms /    22 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12710.60 ms /    19 runs   (  668.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13927.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.62 ms /    22 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10745.90 ms /    16 runs   (  671.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11940.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2652.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.02 ms /    21 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10765.94 ms /    16 runs   (  672.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11905.44 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2559.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.10 ms /    21 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11126.34 ms /    17 runs   (  654.49 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12256.95 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2656.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.70 ms /    21 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11315.19 ms /    17 runs   (  665.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12467.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2586.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.10 ms /    22 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11684.07 ms /    18 runs   (  649.12 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12853.13 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2623.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.18 ms /    22 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10522.10 ms /    16 runs   (  657.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11720.71 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.27 ms /    22 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10928.81 ms /    16 runs   (  683.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12095.58 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.38 ms /    22 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12762.61 ms /    19 runs   (  671.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14023.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    19 runs   (    0.44 ms per token,  2261.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.46 ms /    22 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11976.55 ms /    18 runs   (  665.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13153.46 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.39 ms per token,  2597.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.01 ms /    21 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12656.70 ms /    19 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13776.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.09 ms /    38 runs   (    0.40 ms per token,  2519.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.87 ms /    22 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   24935.18 ms /    37 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26167.81 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.49 ms /    22 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11128.88 ms /    17 runs   (  654.64 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12320.02 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.45 ms /    22 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10600.11 ms /    16 runs   (  662.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11826.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2628.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.90 ms /    22 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10623.63 ms /    16 runs   (  663.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11793.59 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2581.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.97 ms /    22 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10732.96 ms /    16 runs   (  670.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11945.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.24 ms /    22 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10616.21 ms /    16 runs   (  663.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11782.01 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    18 runs   (    0.40 ms per token,  2499.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.04 ms /    22 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11376.10 ms /    17 runs   (  669.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12541.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2520.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.04 ms /    22 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11519.57 ms /    17 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12678.87 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2563.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.09 ms /    22 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10764.49 ms /    16 runs   (  672.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11955.86 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.57 ms /    22 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11417.76 ms /    17 runs   (  671.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12604.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2545.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.60 ms /    22 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11161.58 ms /    17 runs   (  656.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12348.70 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2593.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.37 ms /    22 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11113.81 ms /    17 runs   (  653.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12292.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    23 runs   (    0.39 ms per token,  2560.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.59 ms /    21 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14628.85 ms /    22 runs   (  664.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15770.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.65 ms /    21 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11926.74 ms /    18 runs   (  662.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13066.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2537.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.24 ms /    22 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11192.38 ms /    17 runs   (  658.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12358.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2590.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.73 ms /    22 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11261.93 ms /    17 runs   (  662.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12450.99 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2591.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.01 ms /    22 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10802.44 ms /    16 runs   (  675.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11967.36 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2546.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.28 ms /    22 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10581.24 ms /    16 runs   (  661.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11746.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2638.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.63 ms /    22 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10559.44 ms /    16 runs   (  659.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11719.03 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    13 runs   (    0.40 ms per token,  2517.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.94 ms /    22 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    7987.83 ms /    12 runs   (  665.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9177.16 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2536.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.54 ms /    22 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10706.77 ms /    16 runs   (  669.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11906.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2621.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.02 ms /    22 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11351.15 ms /    17 runs   (  667.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12540.51 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    19 runs   (    0.37 ms per token,  2684.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.87 ms /    22 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12195.82 ms /    18 runs   (  677.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13388.11 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.30 ms /    22 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11405.05 ms /    17 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12586.34 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.02 ms /    22 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12104.48 ms /    18 runs   (  672.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13272.84 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.39 ms per token,  2532.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.48 ms /    22 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11215.84 ms /    17 runs   (  659.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12394.95 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2594.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.06 ms /    22 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10529.11 ms /    16 runs   (  658.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11699.59 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.27 ms /    22 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10599.70 ms /    16 runs   (  662.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11766.52 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2517.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.45 ms /    22 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10550.99 ms /    16 runs   (  659.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11716.53 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2542.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.97 ms /    22 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11312.45 ms /    17 runs   (  665.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12488.66 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    19 runs   (    0.41 ms per token,  2414.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.86 ms /    22 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12260.59 ms /    18 runs   (  681.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13445.04 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2639.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.31 ms /    22 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10791.90 ms /    16 runs   (  674.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11950.13 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2629.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.39 ms /    22 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10844.33 ms /    16 runs   (  677.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12015.95 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.74 ms /    22 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12700.08 ms /    19 runs   (  668.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13876.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2601.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.98 ms /    22 tokens (   50.54 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10731.20 ms /    16 runs   (  670.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11891.81 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.79 ms /    22 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10632.23 ms /    16 runs   (  664.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11793.97 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2640.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.13 ms /    22 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11415.57 ms /    17 runs   (  671.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12589.89 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2633.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.49 ms /    22 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11370.55 ms /    17 runs   (  668.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12559.99 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.22 ms /    22 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11192.37 ms /    17 runs   (  658.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12372.96 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    18 runs   (    0.46 ms per token,  2162.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.70 ms /    22 tokens (   56.17 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12527.14 ms /    17 runs   (  736.89 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =   13826.47 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    17 runs   (    0.41 ms per token,  2413.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.95 ms /    22 tokens (   60.50 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11079.88 ms /    16 runs   (  692.49 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12462.09 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2562.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.88 ms /    22 tokens (   57.99 ms per token,    17.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11546.14 ms /    17 runs   (  679.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12875.64 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2550.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.06 ms /    22 tokens (   56.96 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11348.42 ms /    16 runs   (  709.28 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   12652.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    20 runs   (    0.39 ms per token,  2532.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.27 ms /    22 tokens (   62.24 ms per token,    16.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13289.74 ms /    19 runs   (  699.46 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   14719.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    18 runs   (    0.47 ms per token,  2128.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.25 ms /    22 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11932.96 ms /    17 runs   (  701.94 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   13180.93 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2552.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.51 ms /    22 tokens (   60.80 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12635.74 ms /    18 runs   (  701.99 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   14029.38 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2529.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.52 ms /    22 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11788.40 ms /    17 runs   (  693.44 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13032.63 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2567.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.94 ms /    22 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12288.63 ms /    18 runs   (  682.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13550.48 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2566.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.19 ms /    21 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10669.80 ms /    16 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11876.86 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    18 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.32 ms /    21 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11449.95 ms /    17 runs   (  673.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12598.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2670.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.84 ms /    22 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11501.69 ms /    17 runs   (  676.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12720.91 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2549.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.54 ms /    21 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   11430.81 ms /    17 runs   (  672.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12558.26 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2634.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.64 ms /    22 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11937.79 ms /    18 runs   (  663.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13123.36 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    17 runs   (    0.41 ms per token,  2460.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.32 ms /    21 tokens (   55.06 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10892.05 ms /    16 runs   (  680.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12101.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    20 runs   (    0.39 ms per token,  2539.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.33 ms /    22 tokens (   55.38 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12767.44 ms /    19 runs   (  671.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14044.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    17 runs   (    0.41 ms per token,  2448.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.91 ms /    22 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10868.93 ms /    16 runs   (  679.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12051.37 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2564.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.92 ms /    22 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11518.41 ms /    17 runs   (  677.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12709.59 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2639.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.23 ms /    22 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10906.19 ms /    16 runs   (  681.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12074.79 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2636.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.92 ms /    22 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10659.07 ms /    16 runs   (  666.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11865.61 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    20 runs   (    0.41 ms per token,  2415.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.93 ms /    22 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   12524.21 ms /    19 runs   (  659.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13775.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2549.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.98 ms /    22 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12070.20 ms /    18 runs   (  670.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13235.03 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2592.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.06 ms /    22 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11625.93 ms /    17 runs   (  683.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12804.40 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    17 runs   (    0.44 ms per token,  2251.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.53 ms /    21 tokens (   52.45 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11177.47 ms /    16 runs   (  698.59 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12333.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2623.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.01 ms /    20 tokens (   55.45 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12195.28 ms /    18 runs   (  677.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13360.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.93 ms /    22 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10767.87 ms /    16 runs   (  672.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11943.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    17 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.65 ms /    22 tokens (   56.89 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10869.58 ms /    16 runs   (  679.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12176.77 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2582.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.78 ms /    22 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11531.01 ms /    17 runs   (  678.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12702.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2569.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.53 ms /    21 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10825.03 ms /    16 runs   (  676.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11957.61 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2611.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.09 ms /    20 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10683.27 ms /    16 runs   (  667.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11802.51 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.84 ms /    20 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11273.16 ms /    17 runs   (  663.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12364.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2580.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.65 ms /    22 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10787.10 ms /    16 runs   (  674.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11957.22 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2572.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.82 ms /    22 tokens (   55.99 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12573.43 ms /    19 runs   (  661.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13864.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.61 ms /    24 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10841.79 ms /    16 runs   (  677.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12112.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2562.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.90 ms /    24 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10598.55 ms /    16 runs   (  662.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11852.46 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.59 ms /    24 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11392.77 ms /    17 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12640.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2586.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.02 ms /    23 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12008.15 ms /    18 runs   (  667.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13220.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2515.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.11 ms /    22 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11243.03 ms /    17 runs   (  661.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12416.83 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2486.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.79 ms /    24 tokens (   55.91 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12807.95 ms /    19 runs   (  674.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14208.85 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2563.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.60 ms /    24 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12044.41 ms /    18 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13302.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    22 runs   (    0.40 ms per token,  2500.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.77 ms /    23 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14137.02 ms /    21 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15443.50 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    17 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.25 ms /    24 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10722.32 ms /    16 runs   (  670.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11976.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.86 ms /    24 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10629.94 ms /    16 runs   (  664.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11895.08 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.43 ms /    23 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11191.05 ms /    17 runs   (  658.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12428.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    18 runs   (    0.45 ms per token,  2234.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.34 ms /    23 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11466.03 ms /    17 runs   (  674.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12681.45 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.67 ms /    24 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11423.86 ms /    17 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12703.08 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2605.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.34 ms /    24 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10722.25 ms /    16 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12001.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2540.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.92 ms /    22 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12047.60 ms /    18 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13215.95 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2585.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.28 ms /    22 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11963.88 ms /    18 runs   (  664.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13166.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    22 runs   (    0.39 ms per token,  2549.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.37 ms /    24 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   14076.48 ms /    21 runs   (  670.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15352.00 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    18 runs   (    0.41 ms per token,  2460.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.80 ms /    24 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11426.17 ms /    17 runs   (  672.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12699.61 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2526.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.19 ms /    23 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12911.77 ms /    19 runs   (  679.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14161.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.03 ms /    23 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12199.16 ms /    18 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13435.98 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.11 ms /    24 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12236.07 ms /    18 runs   (  679.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13546.13 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2596.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1233.99 ms /    24 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12195.82 ms /    18 runs   (  677.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13485.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2562.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.04 ms /    23 tokens (   52.78 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12789.25 ms /    19 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14061.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    21 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.57 ms /    23 tokens (   61.72 ms per token,    16.20 tokens per second)\n",
      "llama_print_timings:        eval time =   13443.22 ms /    20 runs   (  672.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14925.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.81 ms /    23 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10760.44 ms /    16 runs   (  672.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11973.16 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2598.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.21 ms /    24 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12701.27 ms /    19 runs   (  668.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13964.87 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.60 ms /    24 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12066.41 ms /    18 runs   (  670.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13316.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    21 runs   (    0.39 ms per token,  2557.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.19 ms /    23 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   13455.39 ms /    20 runs   (  672.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14682.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.08 ms /    24 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11174.90 ms /    17 runs   (  657.35 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12437.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2552.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.08 ms /    24 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11512.26 ms /    17 runs   (  677.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12781.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2526.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.76 ms /    23 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11341.43 ms /    17 runs   (  667.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12586.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2545.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.44 ms /    23 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11414.95 ms /    17 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12626.54 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2536.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.61 ms /    24 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10415.38 ms /    16 runs   (  650.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11724.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    18 runs   (    0.40 ms per token,  2486.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.87 ms /    24 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11343.36 ms /    17 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12593.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2543.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.57 ms /    23 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11401.35 ms /    17 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12617.54 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.02 ms /    23 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12215.51 ms /    18 runs   (  678.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13427.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.86 ms /    23 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11787.50 ms /    18 runs   (  654.86 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12993.82 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2579.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.13 ms /    24 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10698.68 ms /    16 runs   (  668.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11962.93 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    28 runs   (    0.39 ms per token,  2569.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.66 ms /    24 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   18131.49 ms /    27 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19416.57 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    21 runs   (    0.39 ms per token,  2558.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.10 ms /    23 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   13166.89 ms /    20 runs   (  658.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14402.79 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    17 runs   (    0.40 ms per token,  2494.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.44 ms /    23 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11051.12 ms /    16 runs   (  690.69 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12270.40 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.88 ms /    24 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10629.07 ms /    16 runs   (  664.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11883.68 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2627.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.65 ms /    24 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11290.36 ms /    17 runs   (  664.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12553.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.23 ms /    23 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12636.45 ms /    19 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13846.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    36 runs   (    0.39 ms per token,  2533.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.43 ms /    23 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   23141.34 ms /    35 runs   (  661.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24441.00 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2546.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.32 ms /    24 tokens (   50.01 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12672.27 ms /    19 runs   (  666.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13931.93 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    20 runs   (    0.39 ms per token,  2566.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.17 ms /    24 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12633.89 ms /    19 runs   (  664.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13918.19 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    20 runs   (    0.40 ms per token,  2500.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.03 ms /    23 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12756.45 ms /    19 runs   (  671.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14001.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.47 ms /    23 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10674.64 ms /    16 runs   (  667.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11884.14 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    19 runs   (    0.40 ms per token,  2501.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.30 ms /    24 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12137.07 ms /    18 runs   (  674.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13387.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2584.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.27 ms /    24 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11288.88 ms /    17 runs   (  664.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12540.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2539.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.94 ms /    23 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11679.13 ms /    18 runs   (  648.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12892.61 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2584.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.89 ms /    24 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12565.28 ms /    19 runs   (  661.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13837.82 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.83 ms /    24 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10562.38 ms /    16 runs   (  660.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11841.34 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.33 ms /    29 runs   (    0.39 ms per token,  2559.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.65 ms /    23 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   18669.01 ms /    28 runs   (  666.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19910.49 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    22 runs   (    0.39 ms per token,  2595.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.32 ms /    23 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13996.00 ms /    21 runs   (  666.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15252.94 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.68 ms /    24 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10760.39 ms /    16 runs   (  672.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12010.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2529.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.58 ms /    24 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10686.18 ms /    16 runs   (  667.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11939.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    18 runs   (    0.45 ms per token,  2238.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.59 ms /    23 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11194.31 ms /    17 runs   (  658.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12425.14 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2542.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.38 ms /    23 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11935.97 ms /    18 runs   (  663.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13162.99 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2589.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.21 ms /    24 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10760.13 ms /    16 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12014.30 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1227.53 ms /    24 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10712.49 ms /    16 runs   (  669.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11988.60 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    20 runs   (    0.38 ms per token,  2664.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.94 ms /    23 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12870.70 ms /    19 runs   (  677.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14120.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2685.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.29 ms /    23 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11340.88 ms /    17 runs   (  667.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12540.02 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2510.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.81 ms /    23 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10586.34 ms /    16 runs   (  661.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11787.89 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    17 runs   (    0.44 ms per token,  2293.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.87 ms /    24 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10929.07 ms /    16 runs   (  683.07 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12222.79 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2593.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1227.65 ms /    24 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11973.32 ms /    18 runs   (  665.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13256.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    19 runs   (    0.39 ms per token,  2537.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.82 ms /    22 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11907.46 ms /    18 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13074.87 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    18 runs   (    0.40 ms per token,  2501.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.71 ms /    24 tokens (   50.11 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11002.75 ms /    17 runs   (  647.22 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12257.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2586.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.25 ms /    24 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12603.85 ms /    19 runs   (  663.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13875.77 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    19 runs   (    0.40 ms per token,  2523.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.67 ms /    23 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11885.11 ms /    18 runs   (  660.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13107.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    21 runs   (    0.41 ms per token,  2467.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.87 ms /    23 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   13280.54 ms /    20 runs   (  664.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14498.67 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2575.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.95 ms /    23 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10563.77 ms /    16 runs   (  660.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11803.90 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2526.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.16 ms /    24 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10243.78 ms /    16 runs   (  640.24 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   11488.19 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.12 ms /    24 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11119.32 ms /    17 runs   (  654.08 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12384.28 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    19 runs   (    0.40 ms per token,  2511.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.62 ms /    23 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11828.28 ms /    18 runs   (  657.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13037.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    20 runs   (    0.40 ms per token,  2527.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.70 ms /    23 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12528.51 ms /    19 runs   (  659.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13781.69 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2593.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.78 ms /    24 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10666.09 ms /    16 runs   (  666.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11955.28 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.62 ms /    24 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11200.58 ms /    17 runs   (  658.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12451.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2571.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.11 ms /    23 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12558.85 ms /    19 runs   (  660.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13775.24 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       4.66 ms /    12 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.61 ms /    23 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =    7269.78 ms /    11 runs   (  660.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8474.28 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2582.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.82 ms /    24 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12543.15 ms /    19 runs   (  660.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13825.12 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2588.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.42 ms /    24 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12567.62 ms /    19 runs   (  661.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13828.02 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    21 runs   (    0.39 ms per token,  2559.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.25 ms /    22 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13294.30 ms /    20 runs   (  664.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14508.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2553.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.14 ms /    23 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11168.19 ms /    17 runs   (  656.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12398.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2529.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.30 ms /    24 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10698.08 ms /    16 runs   (  668.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11974.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2555.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.88 ms /    24 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12638.18 ms /    19 runs   (  665.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13915.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2568.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.96 ms /    23 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11954.12 ms /    18 runs   (  664.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13180.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    28 runs   (    0.45 ms per token,  2202.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.49 ms /    23 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   17967.50 ms /    27 runs   (  665.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19219.87 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2580.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.21 ms /    24 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10488.41 ms /    16 runs   (  655.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11779.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.91 ms /    24 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10778.22 ms /    16 runs   (  673.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12080.05 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2581.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.08 ms /    23 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11331.41 ms /    17 runs   (  666.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12538.59 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    17 runs   (    0.40 ms per token,  2478.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.96 ms /    24 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10439.60 ms /    16 runs   (  652.48 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11709.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2605.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.56 ms /    24 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12546.36 ms /    19 runs   (  660.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13795.37 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2651.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.39 ms /    23 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11262.02 ms /    17 runs   (  662.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12493.72 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2588.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.96 ms /    23 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12549.92 ms /    19 runs   (  660.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13830.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2561.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.56 ms /    23 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10234.01 ms /    16 runs   (  639.63 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   11436.57 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2579.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.41 ms /    24 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12588.76 ms /    19 runs   (  662.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13843.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.25 ms /    24 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11069.05 ms /    17 runs   (  651.12 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12331.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2580.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.12 ms /    23 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11109.64 ms /    17 runs   (  653.51 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12355.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.35 ms /    23 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10465.93 ms /    16 runs   (  654.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11712.59 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    18 runs   (    0.45 ms per token,  2213.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1562.54 ms /    24 tokens (   65.11 ms per token,    15.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11708.25 ms /    17 runs   (  688.72 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13330.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2581.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.29 ms /    24 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11446.81 ms /    17 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12803.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    22 runs   (    0.39 ms per token,  2550.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.32 ms /    23 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   13817.28 ms /    21 runs   (  657.97 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15123.31 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.40 ms /    23 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10684.20 ms /    16 runs   (  667.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11902.13 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    20 runs   (    0.40 ms per token,  2522.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.79 ms /    24 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12975.33 ms /    19 runs   (  682.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14237.15 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    21 runs   (    0.41 ms per token,  2449.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.30 ms /    24 tokens (   55.64 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   13507.43 ms /    20 runs   (  675.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14907.15 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    23 runs   (    0.39 ms per token,  2533.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.07 ms /    23 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14831.95 ms /    22 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16074.24 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2547.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.46 ms /    23 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10833.89 ms /    16 runs   (  677.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12124.49 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.64 ms /    24 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10684.87 ms /    16 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12016.03 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    19 runs   (    0.40 ms per token,  2514.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.86 ms /    24 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12103.17 ms /    18 runs   (  672.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13402.83 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.38 ms /    23 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11407.71 ms /    17 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12656.76 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2520.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1233.26 ms /    24 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10814.75 ms /    16 runs   (  675.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12097.93 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.51 ms /    24 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10865.33 ms /    16 runs   (  679.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12134.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2534.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.07 ms /    23 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11581.02 ms /    17 runs   (  681.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12831.22 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2515.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.82 ms /    23 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11253.03 ms /    17 runs   (  661.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12477.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2629.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.39 ms /    23 tokens (   52.23 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10798.52 ms /    16 runs   (  674.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12048.98 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2490.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.87 ms /    24 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10393.30 ms /    16 runs   (  649.58 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11650.60 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.55 ms /    24 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11410.56 ms /    17 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12686.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2562.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.31 ms /    23 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11551.97 ms /    17 runs   (  679.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12778.30 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.48 ms /    23 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10772.84 ms /    16 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12005.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    19 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.13 ms /    24 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12024.48 ms /    18 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13278.05 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2531.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.53 ms /    24 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12186.55 ms /    18 runs   (  677.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13448.28 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    16 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.24 ms /    23 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10145.88 ms /    15 runs   (  676.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11398.38 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2599.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.27 ms /    23 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12996.54 ms /    19 runs   (  684.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14230.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2549.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.94 ms /    24 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10779.60 ms /    16 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12043.64 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    18 runs   (    0.41 ms per token,  2463.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.19 ms /    24 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11640.86 ms /    17 runs   (  684.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12953.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2543.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.48 ms /    23 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11444.13 ms /    17 runs   (  673.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12703.74 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    17 runs   (    0.46 ms per token,  2186.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.40 ms /    23 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10789.93 ms /    16 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12104.38 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    17 runs   (    0.41 ms per token,  2458.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.83 ms /    24 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11014.40 ms /    16 runs   (  688.40 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12264.41 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    21 runs   (    0.41 ms per token,  2458.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.14 ms /    24 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13633.01 ms /    20 runs   (  681.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14998.50 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2551.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.48 ms /    23 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12341.58 ms /    18 runs   (  685.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13564.84 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    18 runs   (    0.41 ms per token,  2461.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.09 ms /    23 tokens (   55.57 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11430.43 ms /    17 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12763.04 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     131.48 ms /   400 runs   (    0.33 ms per token,  3042.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.49 ms /    24 tokens (   50.65 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =  272063.84 ms /   399 runs   (  681.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  274522.10 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    18 runs   (    0.43 ms per token,  2310.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.66 ms /    24 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11616.98 ms /    17 runs   (  683.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12882.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    19 runs   (    0.40 ms per token,  2509.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.70 ms /    23 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12112.11 ms /    18 runs   (  672.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13340.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2571.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.70 ms /    23 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10723.50 ms /    16 runs   (  670.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11924.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    17 runs   (    0.40 ms per token,  2507.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.51 ms /    24 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10766.32 ms /    16 runs   (  672.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12025.28 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.78 ms /    24 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11416.03 ms /    17 runs   (  671.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12673.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.55 ms /    23 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10979.14 ms /    17 runs   (  645.83 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12200.66 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2546.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.39 ms /    24 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12569.36 ms /    19 runs   (  661.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13860.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2555.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.58 ms /    24 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10557.44 ms /    16 runs   (  659.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11817.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2565.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.94 ms /    23 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12784.02 ms /    19 runs   (  672.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14029.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2522.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.18 ms /    23 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11344.51 ms /    17 runs   (  667.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12580.92 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.21 ms /    23 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10716.74 ms /    16 runs   (  669.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11925.16 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.09 ms /    24 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10895.31 ms /    16 runs   (  680.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12162.95 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2529.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.36 ms /    24 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11360.44 ms /    17 runs   (  668.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12622.89 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    21 runs   (    0.39 ms per token,  2533.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.83 ms /    23 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   13579.46 ms /    20 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14820.88 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    17 runs   (    0.40 ms per token,  2475.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.68 ms /    24 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10636.51 ms /    16 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11946.76 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.14 ms /    24 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12606.46 ms /    19 runs   (  663.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13903.24 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    20 runs   (    0.39 ms per token,  2535.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.46 ms /    23 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12740.93 ms /    19 runs   (  670.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13971.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.68 ms /    23 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11156.90 ms /    17 runs   (  656.29 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12384.06 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2621.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.19 ms /    23 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11264.59 ms /    17 runs   (  662.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12485.33 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2621.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.30 ms /    24 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10542.02 ms /    16 runs   (  658.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11799.43 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    20 runs   (    0.40 ms per token,  2521.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.41 ms /    24 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12769.13 ms /    19 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14027.67 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.22 ms /    23 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12464.74 ms /    19 runs   (  656.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13675.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2550.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.98 ms /    23 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10585.73 ms /    16 runs   (  661.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11796.90 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2536.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.33 ms /    24 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10550.30 ms /    16 runs   (  659.39 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11846.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.82 ms /    24 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   12071.76 ms /    18 runs   (  670.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13356.86 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2568.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.68 ms /    23 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11977.30 ms /    18 runs   (  665.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13208.25 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2623.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.94 ms /    24 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11953.18 ms /    18 runs   (  664.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13208.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2608.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.79 ms /    24 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12232.71 ms /    19 runs   (  643.83 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   13506.31 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    21 runs   (    0.41 ms per token,  2459.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.73 ms /    22 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   13415.12 ms /    20 runs   (  670.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14619.03 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.98 ms /    22 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11320.59 ms /    17 runs   (  665.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12481.24 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.16 ms /    23 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11384.27 ms /    17 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12594.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2537.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.90 ms /    24 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11295.65 ms /    17 runs   (  664.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12585.13 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2588.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.07 ms /    24 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11923.83 ms /    18 runs   (  662.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13193.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2563.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.82 ms /    23 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12777.30 ms /    19 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14031.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2548.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.54 ms /    23 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12068.13 ms /    18 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13280.61 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2512.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.82 ms /    24 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10626.98 ms /    16 runs   (  664.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11882.18 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    21 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.70 ms /    24 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   13136.26 ms /    20 runs   (  656.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14399.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    21 runs   (    0.40 ms per token,  2527.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.87 ms /    23 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   13209.83 ms /    20 runs   (  660.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14439.53 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    20 runs   (    0.39 ms per token,  2556.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.17 ms /    23 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12616.83 ms /    19 runs   (  664.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13843.49 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2562.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.74 ms /    24 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10503.67 ms /    16 runs   (  656.48 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11764.19 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2574.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.16 ms /    24 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11822.90 ms /    18 runs   (  656.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13081.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2545.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.31 ms /    23 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12480.20 ms /    19 runs   (  656.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13696.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2521.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.32 ms /    24 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11179.58 ms /    17 runs   (  657.62 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12439.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2556.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.35 ms /    24 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10464.49 ms /    16 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11710.82 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    19 runs   (    0.40 ms per token,  2482.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.77 ms /    23 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11910.09 ms /    18 runs   (  661.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13124.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.06 ms /    23 runs   (    0.44 ms per token,  2285.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.17 ms /    23 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14601.02 ms /    22 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15852.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    18 runs   (    0.43 ms per token,  2318.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.60 ms /    24 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11723.73 ms /    17 runs   (  689.63 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13017.01 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2585.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.80 ms /    24 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10908.52 ms /    16 runs   (  681.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12264.65 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2547.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.60 ms /    23 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12164.60 ms /    18 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13452.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.16 ms /    23 runs   (    0.40 ms per token,  2509.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.45 ms /    23 tokens (   56.11 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =   14831.82 ms /    22 runs   (  674.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16191.70 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    20 runs   (    0.41 ms per token,  2414.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.51 ms /    24 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12759.81 ms /    19 runs   (  671.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14045.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    17 runs   (    0.41 ms per token,  2446.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.56 ms /    24 tokens (   55.81 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10887.61 ms /    16 runs   (  680.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12276.95 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2550.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.84 ms /    23 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11580.07 ms /    17 runs   (  681.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12800.01 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    19 runs   (    0.40 ms per token,  2474.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.60 ms /    23 tokens (   56.94 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12103.47 ms /    18 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13470.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2511.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.74 ms /    23 tokens (   55.64 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10944.91 ms /    16 runs   (  684.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12275.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    20 runs   (    0.40 ms per token,  2501.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.32 ms /    24 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   13055.45 ms /    19 runs   (  687.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14401.47 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    18 runs   (    0.40 ms per token,  2502.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.52 ms /    24 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11653.09 ms /    17 runs   (  685.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12962.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    19 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.80 ms /    22 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12281.24 ms /    18 runs   (  682.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13519.92 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2526.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.53 ms /    24 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12300.85 ms /    18 runs   (  683.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13596.70 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     124.02 ms /   400 runs   (    0.31 ms per token,  3225.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.94 ms /    24 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =  273705.59 ms /   399 runs   (  685.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =  276206.93 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2544.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.04 ms /    23 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13754.67 ms /    20 runs   (  687.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15010.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    18 runs   (    0.40 ms per token,  2516.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.43 ms /    23 tokens (   52.45 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11742.30 ms /    17 runs   (  690.72 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13002.91 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2559.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.66 ms /    22 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11563.19 ms /    17 runs   (  680.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12790.87 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    17 runs   (    0.44 ms per token,  2248.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.15 ms /    24 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10865.54 ms /    16 runs   (  679.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12206.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2536.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.65 ms /    24 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11221.07 ms /    17 runs   (  660.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12509.78 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.27 ms /    23 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11395.74 ms /    17 runs   (  670.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12694.22 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    19 runs   (    0.41 ms per token,  2455.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.51 ms /    23 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12297.49 ms /    18 runs   (  683.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13573.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2636.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.91 ms /    23 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11515.35 ms /    17 runs   (  677.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12755.39 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2552.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.73 ms /    22 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12984.62 ms /    19 runs   (  683.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14206.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    20 runs   (    0.41 ms per token,  2463.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.59 ms /    22 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12647.67 ms /    19 runs   (  665.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13860.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    20 runs   (    0.40 ms per token,  2506.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.62 ms /    22 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12952.07 ms /    19 runs   (  681.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14174.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2504.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.58 ms /    23 tokens (   55.16 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10810.49 ms /    16 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12129.68 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2609.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.13 ms /    23 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11967.94 ms /    18 runs   (  664.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13247.32 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    21 runs   (    0.39 ms per token,  2566.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.28 ms /    21 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13396.48 ms /    20 runs   (  669.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14560.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    21 runs   (    0.40 ms per token,  2471.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.08 ms /    22 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   13410.49 ms /    20 runs   (  670.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14613.43 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2632.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.79 ms /    23 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11121.32 ms /    17 runs   (  654.20 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12334.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.85 ms /    23 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11540.39 ms /    17 runs   (  678.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12776.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2591.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.37 ms /    22 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11985.81 ms /    18 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13233.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.92 ms /    23 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   13507.34 ms /    20 runs   (  675.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14737.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2626.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.89 ms /    23 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11256.69 ms /    17 runs   (  662.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12481.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1087.78 ms /    21 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12722.31 ms /    19 runs   (  669.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13869.00 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2611.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1087.10 ms /    21 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12779.19 ms /    19 runs   (  672.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13924.66 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    21 runs   (    0.39 ms per token,  2588.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.56 ms /    22 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   13189.34 ms /    20 runs   (  659.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14374.24 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2589.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.32 ms /    22 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11480.08 ms /    17 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12665.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2562.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.92 ms /    21 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12277.69 ms /    18 runs   (  682.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13420.75 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2603.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.21 ms /    21 tokens (   55.06 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12081.69 ms /    18 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13293.84 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    20 runs   (    0.40 ms per token,  2481.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.77 ms /    23 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12788.33 ms /    19 runs   (  673.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14036.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    17 runs   (    0.40 ms per token,  2497.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.07 ms /    23 tokens (   54.79 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10765.26 ms /    16 runs   (  672.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12075.99 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    23 runs   (    0.39 ms per token,  2534.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.94 ms /    22 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   15104.24 ms /    22 runs   (  686.56 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16390.38 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2525.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.40 ms /    22 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12114.83 ms /    18 runs   (  673.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13316.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    16 runs   (    0.41 ms per token,  2446.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.46 ms /    23 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10114.49 ms /    15 runs   (  674.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11394.47 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    18 runs   (    0.40 ms per token,  2508.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.51 ms /    23 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11627.59 ms /    17 runs   (  683.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12866.01 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    22 runs   (    0.39 ms per token,  2535.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.11 ms /    22 tokens (   54.69 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   14235.82 ms /    21 runs   (  677.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15504.60 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    19 runs   (    0.40 ms per token,  2509.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.61 ms /    22 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12340.66 ms /    18 runs   (  685.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13542.34 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    17 runs   (    0.40 ms per token,  2477.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.65 ms /    22 tokens (   56.21 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11391.76 ms /    16 runs   (  711.98 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   12679.79 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    17 runs   (    0.44 ms per token,  2256.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.27 ms /    23 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11201.25 ms /    16 runs   (  700.08 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12466.18 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    19 runs   (    0.41 ms per token,  2430.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1227.90 ms /    23 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12851.77 ms /    18 runs   (  713.99 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   14138.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2551.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.85 ms /    22 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11711.48 ms /    17 runs   (  688.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12933.89 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    20 runs   (    0.44 ms per token,  2271.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.19 ms /    23 tokens (   66.75 ms per token,    14.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13360.52 ms /    19 runs   (  703.19 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   14961.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    20 runs   (    0.42 ms per token,  2355.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.69 ms /    23 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13359.01 ms /    19 runs   (  703.11 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   14629.85 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2544.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.82 ms /    22 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   13819.20 ms /    20 runs   (  690.96 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15025.19 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    19 runs   (    0.40 ms per token,  2479.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.03 ms /    22 tokens (   59.82 ms per token,    16.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12489.44 ms /    18 runs   (  693.86 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13863.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    18 runs   (    0.40 ms per token,  2493.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.91 ms /    22 tokens (   56.41 ms per token,    17.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11533.38 ms /    17 runs   (  678.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12828.68 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2505.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.94 ms /    23 tokens (   59.17 ms per token,    16.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12263.88 ms /    18 runs   (  681.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13681.15 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2559.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.18 ms /    23 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12183.95 ms /    18 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13426.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.08 ms /    21 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11381.11 ms /    17 runs   (  669.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12542.43 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.23 ms /    23 runs   (    0.40 ms per token,  2490.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.13 ms /    21 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   15013.40 ms /    22 runs   (  682.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16171.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    18 runs   (    0.44 ms per token,  2263.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.99 ms /    22 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11874.90 ms /    17 runs   (  698.52 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13151.25 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    20 runs   (    0.40 ms per token,  2518.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.58 ms /    22 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12852.01 ms /    19 runs   (  676.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14085.03 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    19 runs   (    0.43 ms per token,  2319.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.17 ms /    21 tokens (   57.44 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12132.89 ms /    18 runs   (  674.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13401.11 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    20 runs   (    0.40 ms per token,  2493.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.90 ms /    22 tokens (   54.04 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13147.86 ms /    19 runs   (  691.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14397.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2543.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.88 ms /    23 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12987.65 ms /    19 runs   (  683.56 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14214.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    18 runs   (    0.40 ms per token,  2502.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.21 ms /    23 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11467.09 ms /    17 runs   (  674.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12735.11 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    21 runs   (    0.41 ms per token,  2454.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.87 ms /    22 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   13299.26 ms /    20 runs   (  664.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14491.36 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    23 runs   (    0.40 ms per token,  2489.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1180.25 ms /    22 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   15017.36 ms /    22 runs   (  682.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16267.48 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    18 runs   (    0.45 ms per token,  2222.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.19 ms /    23 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11462.77 ms /    17 runs   (  674.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12701.06 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    22 runs   (    0.39 ms per token,  2563.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.39 ms /    23 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14418.12 ms /    21 runs   (  686.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15721.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    21 runs   (    0.40 ms per token,  2525.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.79 ms /    22 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   13861.26 ms /    20 runs   (  693.06 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15126.11 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.65 ms /    22 runs   (    0.39 ms per token,  2541.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.77 ms /    23 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   14138.38 ms /    21 runs   (  673.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15399.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    20 runs   (    0.46 ms per token,  2177.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.33 ms /    23 tokens (   60.14 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12982.47 ms /    19 runs   (  683.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14434.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    19 runs   (    0.40 ms per token,  2508.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.40 ms /    21 tokens (   55.11 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12291.23 ms /    18 runs   (  682.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13505.97 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    21 runs   (    0.39 ms per token,  2560.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.87 ms /    21 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   13600.05 ms /    20 runs   (  680.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14772.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     162.23 ms /   401 runs   (    0.40 ms per token,  2471.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.54 ms /    23 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =  272476.53 ms /   400 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  274955.66 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.86 ms /    35 runs   (    0.40 ms per token,  2524.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.68 ms /    23 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   23188.55 ms /    34 runs   (  682.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24459.31 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    22 runs   (    0.40 ms per token,  2530.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.43 ms /    22 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14322.67 ms /    21 runs   (  682.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15543.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2579.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.69 ms /    22 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12439.52 ms /    18 runs   (  691.08 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13618.28 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2512.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.72 ms /    23 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11424.43 ms /    17 runs   (  672.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12701.43 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2500.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.73 ms /    23 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10711.71 ms /    16 runs   (  669.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11956.01 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    19 runs   (    0.41 ms per token,  2423.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.88 ms /    22 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11825.33 ms /    18 runs   (  656.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13044.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    18 runs   (    0.40 ms per token,  2495.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.10 ms /    22 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11916.59 ms /    17 runs   (  700.98 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13101.93 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    19 runs   (    0.43 ms per token,  2346.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.29 ms /    23 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13514.84 ms /    18 runs   (  750.82 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =   14782.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2540.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.39 ms /    23 tokens (   56.76 ms per token,    17.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10626.54 ms /    16 runs   (  664.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11983.03 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    22 runs   (    0.39 ms per token,  2545.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.05 ms /    22 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14120.99 ms /    21 runs   (  672.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15308.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    18 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.19 ms /    22 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11504.89 ms /    17 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12689.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    18 runs   (    0.40 ms per token,  2471.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.85 ms /    23 tokens (   57.17 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =   11599.82 ms /    17 runs   (  682.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12968.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.28 ms /    23 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11761.94 ms /    17 runs   (  691.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13028.10 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    19 runs   (    0.40 ms per token,  2497.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.93 ms /    22 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11960.53 ms /    18 runs   (  664.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13179.91 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.92 ms /    22 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11758.59 ms /    18 runs   (  653.25 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12948.41 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    21 runs   (    0.39 ms per token,  2565.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.45 ms /    22 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12950.18 ms /    20 runs   (  647.51 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   14126.67 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.12 ms /    28 runs   (    0.40 ms per token,  2518.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.76 ms /    23 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   18350.09 ms /    27 runs   (  679.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19606.65 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     120.21 ms /   401 runs   (    0.30 ms per token,  3335.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.09 ms /    23 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =  270977.04 ms /   400 runs   (  677.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  273403.75 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2560.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.33 ms /    22 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12125.28 ms /    18 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13370.03 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /     4 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.60 ms /    23 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2088.90 ms /     3 runs   (  696.30 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    3272.15 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.23 ms /    23 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11300.46 ms /    17 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12527.56 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    20 runs   (    0.39 ms per token,  2540.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.35 ms /    22 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12715.06 ms /    19 runs   (  669.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13893.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.77 ms /    22 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12145.78 ms /    18 runs   (  674.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13313.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    34 runs   (    0.39 ms per token,  2567.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.63 ms /    22 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   22239.61 ms /    33 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23456.85 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2562.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.61 ms /    22 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12032.19 ms /    18 runs   (  668.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13195.56 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    21 runs   (    0.39 ms per token,  2559.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.29 ms /    21 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13355.02 ms /    20 runs   (  667.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14518.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    23 runs   (    0.40 ms per token,  2513.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.38 ms /    21 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14493.11 ms /    22 runs   (  658.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15639.20 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2617.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.01 ms /    22 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10564.17 ms /    16 runs   (  660.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11738.36 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2553.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.37 ms /    23 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11316.47 ms /    17 runs   (  665.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12522.16 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    22 runs   (    0.41 ms per token,  2460.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.05 ms /    23 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14258.39 ms /    21 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15529.38 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    19 runs   (    0.40 ms per token,  2485.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.49 ms /    22 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12138.14 ms /    18 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13357.19 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.27 ms /    22 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11845.09 ms /    18 runs   (  658.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13067.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2515.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.33 ms /    23 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10284.21 ms /    16 runs   (  642.76 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   11507.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2532.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.86 ms /    23 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11694.56 ms /    18 runs   (  649.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12912.26 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.21 ms /    22 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11345.24 ms /    17 runs   (  667.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12519.30 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.29 ms /    23 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10488.55 ms /    16 runs   (  655.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11725.26 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.67 ms /    23 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10680.51 ms /    16 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11906.32 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2594.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.97 ms /    22 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11943.27 ms /    18 runs   (  663.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13117.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2578.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.40 ms /    22 tokens (   51.75 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11268.94 ms /    17 runs   (  662.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12458.95 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    31 runs   (    0.39 ms per token,  2567.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.58 ms /    22 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20206.88 ms /    30 runs   (  673.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21413.18 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2577.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.61 ms /    23 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11333.67 ms /    17 runs   (  666.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12556.59 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2588.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.79 ms /    23 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11904.91 ms /    18 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13116.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.71 ms /    22 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11970.34 ms /    18 runs   (  665.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13155.66 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2569.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.74 ms /    23 tokens (   56.99 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12142.32 ms /    18 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13509.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    18 runs   (    0.37 ms per token,  2677.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.03 ms /    23 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11413.56 ms /    17 runs   (  671.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12632.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    20 runs   (    0.39 ms per token,  2568.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.33 ms /    22 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12793.03 ms /    19 runs   (  673.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13974.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.39 ms per token,  2596.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.07 ms /    22 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12714.33 ms /    19 runs   (  669.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13924.84 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.53 ms /    23 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10726.20 ms /    16 runs   (  670.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11976.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2551.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.34 ms /    23 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11427.78 ms /    17 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12662.21 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      14.09 ms /    36 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1132.61 ms /    22 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   23519.61 ms /    35 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24759.88 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2575.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.72 ms /    22 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12576.02 ms /    19 runs   (  661.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13759.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2531.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.88 ms /    23 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.28 ms /    16 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11889.98 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    19 runs   (    0.40 ms per token,  2524.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.00 ms /    23 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12057.04 ms /    18 runs   (  669.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13279.87 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    19 runs   (    0.45 ms per token,  2239.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.88 ms /    22 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12129.49 ms /    18 runs   (  673.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13373.37 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2573.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.75 ms /    22 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11293.37 ms /    17 runs   (  664.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12509.35 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    22 runs   (    0.39 ms per token,  2569.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.01 ms /    23 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13955.03 ms /    21 runs   (  664.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15176.01 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.02 ms /    23 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11242.39 ms /    17 runs   (  661.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12453.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2553.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.03 ms /    22 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   13343.18 ms /    20 runs   (  667.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14511.10 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    21 runs   (    0.39 ms per token,  2578.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.71 ms /    22 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   13321.03 ms /    20 runs   (  666.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14502.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    30 runs   (    0.38 ms per token,  2666.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.85 ms /    23 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19179.95 ms /    29 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20440.66 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2642.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.78 ms /    23 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10508.88 ms /    16 runs   (  656.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11726.92 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    21 runs   (    0.40 ms per token,  2519.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.54 ms /    22 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   13108.21 ms /    20 runs   (  655.41 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14286.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.01 ms /    22 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11412.63 ms /    17 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12587.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.93 ms /    29 runs   (    0.38 ms per token,  2653.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.93 ms /    23 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   18636.93 ms /    28 runs   (  665.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19889.26 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2592.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.18 ms /    23 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12719.56 ms /    19 runs   (  669.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13962.80 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2552.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.75 ms /    22 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11232.01 ms /    17 runs   (  660.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12430.07 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    21 runs   (    0.39 ms per token,  2577.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.27 ms /    22 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   13300.35 ms /    20 runs   (  665.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14488.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2538.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.07 ms /    22 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10754.58 ms /    16 runs   (  672.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11977.90 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2549.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.49 ms /    23 tokens (   50.06 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10435.85 ms /    16 runs   (  652.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11636.77 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2540.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.65 ms /    23 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10919.23 ms /    17 runs   (  642.31 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   12125.16 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2524.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.01 ms /    22 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11353.67 ms /    17 runs   (  667.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12522.45 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2488.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.50 ms /    23 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10761.95 ms /    16 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11982.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.89 ms /    23 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11126.97 ms /    17 runs   (  654.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12378.04 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    20 runs   (    0.40 ms per token,  2521.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.04 ms /    22 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12269.00 ms /    19 runs   (  645.74 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   13474.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2627.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.80 ms /    22 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11709.04 ms /    18 runs   (  650.50 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12879.41 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2538.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.13 ms /    23 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11127.47 ms /    17 runs   (  654.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12376.44 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    18 runs   (    0.43 ms per token,  2326.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.81 ms /    23 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11331.66 ms /    17 runs   (  666.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12570.21 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2626.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.76 ms /    22 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13417.04 ms /    20 runs   (  670.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14607.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    19 runs   (    0.37 ms per token,  2673.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.66 ms /    22 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11979.61 ms /    18 runs   (  665.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13151.73 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     159.78 ms /   401 runs   (    0.40 ms per token,  2509.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.58 ms /    22 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =  270150.74 ms /   400 runs   (  675.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  272558.44 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    17 runs   (    0.44 ms per token,  2292.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.88 ms /    23 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10604.72 ms /    16 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11815.34 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2572.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.94 ms /    23 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12640.84 ms /    19 runs   (  665.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13857.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2607.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.44 ms /    22 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12096.54 ms /    18 runs   (  672.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13290.58 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2573.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.51 ms /    22 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10558.33 ms /    16 runs   (  659.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11733.41 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    21 runs   (    0.41 ms per token,  2462.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.79 ms /    23 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13722.79 ms /    20 runs   (  686.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14974.40 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    21 runs   (    0.40 ms per token,  2512.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.53 ms /    23 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   13883.34 ms /    20 runs   (  694.17 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15194.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    22 runs   (    0.39 ms per token,  2554.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.74 ms /    22 tokens (   55.26 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   13893.87 ms /    21 runs   (  661.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15174.05 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2673.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.10 ms /    22 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11130.01 ms /    17 runs   (  654.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12372.67 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    23 runs   (    0.40 ms per token,  2519.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.92 ms /    23 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   14729.84 ms /    22 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15985.45 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.33 ms /    23 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12206.91 ms /    18 runs   (  678.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13486.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    22 runs   (    0.40 ms per token,  2491.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.58 ms /    22 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   13939.99 ms /    21 runs   (  663.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15134.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    26 runs   (    0.38 ms per token,  2630.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.55 ms /    23 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17140.01 ms /    25 runs   (  685.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18392.79 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2532.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.08 ms /    23 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12152.11 ms /    18 runs   (  675.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13455.49 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2570.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.51 ms /    22 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11333.44 ms /    17 runs   (  666.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12565.82 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    20 runs   (    0.40 ms per token,  2510.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.31 ms /    22 tokens (   57.60 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12857.63 ms /    19 runs   (  676.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14185.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    21 runs   (    0.40 ms per token,  2479.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.35 ms /    21 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13327.06 ms /    20 runs   (  666.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14509.03 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    28 runs   (    0.43 ms per token,  2312.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.80 ms /    22 tokens (   51.85 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   18155.73 ms /    27 runs   (  672.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19387.66 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    23 runs   (    0.40 ms per token,  2496.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.63 ms /    22 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   15062.57 ms /    22 runs   (  684.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16278.40 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    20 runs   (    0.40 ms per token,  2483.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.59 ms /    21 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12757.06 ms /    19 runs   (  671.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13925.44 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2488.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.56 ms /    23 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12556.66 ms /    19 runs   (  660.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13803.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2536.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.27 ms /    23 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11384.06 ms /    17 runs   (  669.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12652.57 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    19 runs   (    0.37 ms per token,  2691.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.27 ms /    21 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11899.41 ms /    18 runs   (  661.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13086.65 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2566.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.92 ms /    21 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11946.04 ms /    18 runs   (  663.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13074.08 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2561.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.63 ms /    23 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11795.65 ms /    18 runs   (  655.31 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13118.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2578.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.82 ms /    23 tokens (   50.77 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.73 ms /    16 runs   (  671.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11960.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2615.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.81 ms /    21 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11961.02 ms /    18 runs   (  664.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13118.54 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2585.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.59 ms /    21 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11290.94 ms /    17 runs   (  664.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12441.60 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    20 runs   (    0.40 ms per token,  2521.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.23 ms /    23 tokens (   55.66 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12781.95 ms /    19 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14121.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2519.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.67 ms /    23 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10992.95 ms /    16 runs   (  687.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12298.94 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    19 runs   (    0.41 ms per token,  2452.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.84 ms /    22 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12224.59 ms /    18 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13504.77 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    18 runs   (    0.40 ms per token,  2509.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.10 ms /    22 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11434.34 ms /    17 runs   (  672.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12710.69 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    21 runs   (    0.42 ms per token,  2372.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.15 ms /    23 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   13307.46 ms /    20 runs   (  665.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14621.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2628.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.78 ms /    23 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10826.57 ms /    16 runs   (  676.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12142.67 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    21 runs   (    0.40 ms per token,  2502.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.87 ms /    22 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   13514.04 ms /    20 runs   (  675.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14760.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2562.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.61 ms /    22 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11650.50 ms /    17 runs   (  685.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12852.87 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.56 ms /    28 runs   (    0.41 ms per token,  2422.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.71 ms /    22 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   18108.71 ms /    27 runs   (  670.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19339.21 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    31 runs   (    0.45 ms per token,  2243.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1233.33 ms /    23 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   20874.44 ms /    30 runs   (  695.81 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   22207.40 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2525.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.09 ms /    23 tokens (   55.79 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12399.76 ms /    18 runs   (  688.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13739.42 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    18 runs   (    0.41 ms per token,  2468.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.49 ms /    22 tokens (   65.75 ms per token,    15.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11289.17 ms /    17 runs   (  664.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12793.51 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    20 runs   (    0.40 ms per token,  2516.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.39 ms /    23 tokens (   59.50 ms per token,    16.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12272.42 ms /    19 runs   (  645.92 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   13701.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.69 ms /    23 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10998.17 ms /    16 runs   (  687.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12270.50 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2535.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.37 ms /    22 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11957.41 ms /    18 runs   (  664.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13178.16 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.16 ms /    22 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11421.18 ms /    17 runs   (  671.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12604.02 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    21 runs   (    0.38 ms per token,  2645.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.32 ms /    22 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13522.43 ms /    20 runs   (  676.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14795.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2607.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.01 ms /    22 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11342.43 ms /    17 runs   (  667.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12605.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.47 ms /    20 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10465.89 ms /    16 runs   (  654.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11544.29 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2606.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.86 ms /    20 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12490.01 ms /    19 runs   (  657.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13594.16 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.70 ms /    23 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11047.89 ms /    17 runs   (  649.88 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12262.48 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2577.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.13 ms /    23 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10683.32 ms /    16 runs   (  667.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11902.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    19 runs   (    0.40 ms per token,  2528.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1132.88 ms /    22 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12101.38 ms /    18 runs   (  672.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13290.10 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.82 ms /    22 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11281.19 ms /    17 runs   (  663.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12499.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    21 runs   (    0.41 ms per token,  2464.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.03 ms /    22 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   13460.32 ms /    20 runs   (  673.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14640.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2619.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.71 ms /    23 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10608.26 ms /    16 runs   (  663.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11843.61 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    23 runs   (    0.38 ms per token,  2624.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.01 ms /    23 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   15013.55 ms /    22 runs   (  682.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16270.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.96 ms /    21 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11420.78 ms /    17 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12554.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    31 runs   (    0.40 ms per token,  2502.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.57 ms /    20 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   20210.33 ms /    30 runs   (  673.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21331.65 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.75 ms /    22 tokens (   51.22 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11198.36 ms /    17 runs   (  658.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12379.08 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    22 runs   (    0.39 ms per token,  2575.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.59 ms /    22 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   14006.33 ms /    21 runs   (  666.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15189.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2614.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.67 ms /    20 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11989.30 ms /    18 runs   (  666.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13094.56 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.20 ms /    22 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11936.61 ms /    18 runs   (  663.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13137.74 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2536.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.40 ms /    23 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10702.20 ms /    16 runs   (  668.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11923.54 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    20 runs   (    0.40 ms per token,  2470.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.78 ms /    23 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12732.92 ms /    19 runs   (  670.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13969.79 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.88 ms /    22 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11416.10 ms /    17 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12644.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2583.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.81 ms /    26 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10706.33 ms /    16 runs   (  669.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12054.35 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2552.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.21 ms /    25 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11436.69 ms /    17 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12744.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2614.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.38 ms /    25 tokens (   50.14 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12769.33 ms /    19 runs   (  672.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14080.18 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2591.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.79 ms /    25 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10557.88 ms /    16 runs   (  659.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11854.46 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    17 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.54 ms /    25 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10634.46 ms /    16 runs   (  664.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11978.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2623.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.62 ms /    25 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10676.18 ms /    16 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12053.96 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2640.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.64 ms /    25 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11450.82 ms /    17 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12751.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2593.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.42 ms /    24 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10760.75 ms /    16 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12019.47 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2636.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.18 ms /    25 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10679.88 ms /    16 runs   (  667.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12013.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2568.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.86 ms /    25 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11189.44 ms /    17 runs   (  658.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12489.90 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    17 runs   (    0.44 ms per token,  2281.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.96 ms /    25 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10653.87 ms /    16 runs   (  665.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11973.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    20 runs   (    0.38 ms per token,  2620.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.74 ms /    25 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12869.70 ms /    19 runs   (  677.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14219.82 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.14 ms /    25 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11321.49 ms /    17 runs   (  665.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12624.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.51 ms /    25 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10620.53 ms /    16 runs   (  663.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11918.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2585.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.24 ms /    25 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12746.34 ms /    19 runs   (  670.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14077.71 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.29 ms /    25 tokens (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11230.17 ms /    17 runs   (  660.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12520.99 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2501.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.10 ms /    25 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10731.74 ms /    16 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12100.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.27 ms /    25 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11255.20 ms /    17 runs   (  662.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12564.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2572.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.47 ms /    25 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10723.98 ms /    16 runs   (  670.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12059.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2643.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.89 ms /    25 tokens (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10580.54 ms /    16 runs   (  661.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11872.30 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2561.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.46 ms /    25 tokens (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10766.11 ms /    16 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12058.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.18 ms /    25 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10796.12 ms /    16 runs   (  674.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12105.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    28 runs   (    0.39 ms per token,  2586.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.50 ms /    25 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   18165.36 ms /    27 runs   (  672.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19497.39 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.73 ms /    25 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10700.55 ms /    16 runs   (  668.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12020.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.46 ms /    25 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10799.20 ms /    16 runs   (  674.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12094.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2589.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.57 ms /    25 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10818.24 ms /    16 runs   (  676.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12128.49 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2539.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.44 ms /    25 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12300.69 ms /    18 runs   (  683.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13616.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.81 ms /    25 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12104.14 ms /    18 runs   (  672.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13439.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    18 runs   (    0.44 ms per token,  2278.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.05 ms /    25 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11535.20 ms /    17 runs   (  678.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12876.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2621.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.50 ms /    25 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10930.92 ms /    16 runs   (  683.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12254.05 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2629.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.99 ms /    25 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12882.22 ms /    19 runs   (  678.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14196.97 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2643.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.89 ms /    25 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10766.91 ms /    16 runs   (  672.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12092.25 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2647.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.12 ms /    25 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10584.46 ms /    16 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11887.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2610.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.53 ms /    24 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11373.15 ms /    17 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12632.07 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2566.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.10 ms /    25 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10841.60 ms /    16 runs   (  677.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12156.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2594.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.33 ms /    25 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11991.27 ms /    18 runs   (  666.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13294.89 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.82 ms /    24 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11420.03 ms /    17 runs   (  671.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12669.55 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.01 ms /    25 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10595.79 ms /    16 runs   (  662.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11917.15 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2619.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.74 ms /    25 tokens (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12021.01 ms /    18 runs   (  667.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13316.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2623.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.47 ms /    25 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11441.31 ms /    17 runs   (  673.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12754.49 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.02 ms /    25 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10695.59 ms /    16 runs   (  668.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12008.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2610.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.91 ms /    25 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11221.64 ms /    17 runs   (  660.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12553.04 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     130.07 ms /   398 runs   (    0.33 ms per token,  3059.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.73 ms /    25 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =  269925.09 ms /   397 runs   (  679.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  272410.06 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2627.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.69 ms /    25 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11489.00 ms /    17 runs   (  675.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12806.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.13 ms /    25 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10792.85 ms /    16 runs   (  674.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12091.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.46 ms /    24 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10626.49 ms /    16 runs   (  664.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11878.97 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2526.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.59 ms /    25 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10663.28 ms /    16 runs   (  666.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12004.89 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2581.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.90 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10421.92 ms /    16 runs   (  651.37 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11721.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2569.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.88 ms /    25 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10476.01 ms /    16 runs   (  654.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11795.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    17 runs   (    0.37 ms per token,  2730.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.10 ms /    25 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10611.50 ms /    16 runs   (  663.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11902.81 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.44 ms /    25 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10733.83 ms /    16 runs   (  670.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12058.66 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.89 ms /    25 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10646.77 ms /    16 runs   (  665.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11977.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2656.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.51 ms /    25 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11434.63 ms /    17 runs   (  672.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12744.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2642.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1227.92 ms /    24 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11376.80 ms /    17 runs   (  669.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12657.16 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2581.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.24 ms /    25 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11342.44 ms /    17 runs   (  667.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12657.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2562.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.91 ms /    25 tokens (   49.84 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10703.22 ms /    16 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11998.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2656.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.91 ms /    25 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10745.24 ms /    16 runs   (  671.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12107.04 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2609.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.97 ms /    24 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12580.08 ms /    19 runs   (  662.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13849.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.86 ms /    25 tokens (   49.59 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11376.04 ms /    17 runs   (  669.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12668.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.76 ms /    25 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10713.40 ms /    16 runs   (  669.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12021.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    16 runs   (    0.38 ms per token,  2619.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.22 ms /    25 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =    9943.53 ms /    15 runs   (  662.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11252.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.30 ms /    25 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10720.24 ms /    16 runs   (  670.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12017.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2560.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.81 ms /    25 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10728.87 ms /    16 runs   (  670.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12070.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2643.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.48 ms /    25 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10565.20 ms /    16 runs   (  660.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11886.38 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2518.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.54 ms /    25 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10552.72 ms /    16 runs   (  659.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11851.76 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.02 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10546.99 ms /    16 runs   (  659.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11846.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2626.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.72 ms /    25 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10691.18 ms /    16 runs   (  668.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11996.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.64 ms /    25 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10603.09 ms /    16 runs   (  662.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11910.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2610.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.78 ms /    25 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10676.17 ms /    16 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12002.10 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2524.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.53 ms /    25 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10792.40 ms /    16 runs   (  674.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12120.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2573.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.44 ms /    25 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12206.17 ms /    18 runs   (  678.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13508.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2623.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.53 ms /    25 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10535.92 ms /    16 runs   (  658.50 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11842.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.79 ms /    25 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11265.74 ms /    17 runs   (  662.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12700.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2658.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.85 ms /    24 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10734.14 ms /    16 runs   (  670.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11984.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.75 ms /    25 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10678.34 ms /    16 runs   (  667.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11976.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.14 ms /    25 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10625.93 ms /    16 runs   (  664.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11937.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.31 ms /    25 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10534.77 ms /    16 runs   (  658.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11841.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.18 ms /    25 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11095.86 ms /    17 runs   (  652.70 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12477.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2635.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.88 ms /    24 tokens (   50.29 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11401.68 ms /    17 runs   (  670.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12662.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.61 ms /    25 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11415.07 ms /    17 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12720.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2550.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.92 ms /    24 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10718.02 ms /    16 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11972.93 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.05 ms /    25 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11342.91 ms /    17 runs   (  667.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12650.78 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2608.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.76 ms /    25 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9213.59 ms /    14 runs   (  658.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   10516.00 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    17 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.78 ms /    25 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10630.22 ms /    16 runs   (  664.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11936.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2527.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.32 ms /    25 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10661.01 ms /    16 runs   (  666.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11950.26 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2675.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.11 ms /    25 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.60 ms /    16 runs   (  665.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11952.08 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2636.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.24 ms /    25 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12927.35 ms /    19 runs   (  680.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14239.67 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.04 ms /    25 tokens (   54.72 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10863.25 ms /    16 runs   (  678.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12281.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2655.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.03 ms /    25 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10642.10 ms /    16 runs   (  665.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11956.79 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2623.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.22 ms /    25 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12957.82 ms /    19 runs   (  681.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14256.14 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.97 ms /    25 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10709.27 ms /    16 runs   (  669.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12029.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2607.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.04 ms /    24 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10667.51 ms /    16 runs   (  666.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11931.19 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.10 ms /    25 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12748.79 ms /    19 runs   (  670.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14063.72 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2558.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.11 ms /    24 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12086.70 ms /    18 runs   (  671.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13373.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.81 ms /    25 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10743.63 ms /    16 runs   (  671.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12042.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2617.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.44 ms /    25 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10702.64 ms /    16 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12017.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2552.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.31 ms /    25 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11400.98 ms /    17 runs   (  670.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12698.49 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.89 ms /    25 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10728.87 ms /    16 runs   (  670.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12017.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2589.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.64 ms /    25 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10647.79 ms /    16 runs   (  665.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11967.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.45 ms /    25 tokens (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11411.45 ms /    17 runs   (  671.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12707.36 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2569.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.53 ms /    24 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10706.08 ms /    16 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11954.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.17 ms /    24 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11505.71 ms /    17 runs   (  676.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12756.17 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2569.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.27 ms /    24 tokens (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10786.43 ms /    16 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12033.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.50 ms /    24 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10635.45 ms /    16 runs   (  664.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11898.16 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.39 ms per token,  2533.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.89 ms /    24 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11255.80 ms /    17 runs   (  662.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12507.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2589.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.45 ms /    24 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10664.99 ms /    16 runs   (  666.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11925.72 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2548.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.52 ms /    24 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10473.82 ms /    16 runs   (  654.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11791.99 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2617.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.87 ms /    24 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12753.35 ms /    19 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14018.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2653.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.84 ms /    24 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10605.84 ms /    16 runs   (  662.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11864.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2642.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.53 ms /    24 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11362.74 ms /    17 runs   (  668.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12639.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2591.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.08 ms /    23 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12178.89 ms /    18 runs   (  676.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13402.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    19 runs   (    0.40 ms per token,  2484.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.18 ms /    23 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12107.78 ms /    18 runs   (  672.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13336.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.49 ms /    24 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11280.20 ms /    17 runs   (  663.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12532.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.92 ms /    24 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11497.62 ms /    17 runs   (  676.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12804.55 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2579.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.63 ms /    24 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10749.56 ms /    16 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12021.83 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2591.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.43 ms /    24 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11953.79 ms /    18 runs   (  664.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13254.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2558.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.35 ms /    23 tokens (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10667.82 ms /    16 runs   (  666.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11880.32 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.15 ms /    24 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12015.58 ms /    18 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13290.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2555.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.87 ms /    24 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12721.42 ms /    19 runs   (  669.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13979.03 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2636.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.03 ms /    22 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11106.93 ms /    17 runs   (  653.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12317.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2631.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.48 ms /    22 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11260.88 ms /    17 runs   (  662.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12428.84 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2591.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.46 ms /    22 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10669.92 ms /    16 runs   (  666.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11828.66 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    18 runs   (    0.44 ms per token,  2266.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.26 ms /    24 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11321.10 ms /    17 runs   (  665.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12598.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.76 ms /    24 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10740.54 ms /    16 runs   (  671.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11989.58 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2556.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.49 ms /    24 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10687.67 ms /    16 runs   (  667.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11937.88 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.02 ms /    24 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11717.48 ms /    18 runs   (  650.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13053.78 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2597.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.48 ms /    24 tokens (   50.19 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10572.43 ms /    16 runs   (  660.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11827.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2606.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.02 ms /    24 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11995.66 ms /    18 runs   (  666.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13272.67 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2609.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.59 ms /    24 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11333.18 ms /    17 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12595.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.38 ms /    24 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10485.51 ms /    16 runs   (  655.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11731.73 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2514.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.04 ms /    24 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10416.60 ms /    16 runs   (  651.04 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11668.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2597.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.69 ms /    24 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11930.61 ms /    18 runs   (  662.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13212.19 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.22 ms /    23 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10717.24 ms /    16 runs   (  669.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11962.05 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    19 runs   (    0.37 ms per token,  2690.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.11 ms /    23 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11954.82 ms /    18 runs   (  664.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13180.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    21 runs   (    0.38 ms per token,  2622.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.75 ms /    24 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13479.74 ms /    20 runs   (  673.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14747.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.96 ms /    24 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11290.57 ms /    17 runs   (  664.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12549.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    13 runs   (    0.39 ms per token,  2579.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.91 ms /    24 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7996.36 ms /    12 runs   (  666.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9244.97 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2558.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.62 ms /    24 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11886.27 ms /    18 runs   (  660.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13154.05 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.50 ms /    24 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10579.95 ms /    16 runs   (  661.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11846.56 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.83 ms /    24 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10621.27 ms /    16 runs   (  663.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11876.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2684.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.56 ms /    24 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10721.03 ms /    16 runs   (  670.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11986.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2604.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.98 ms /    24 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11993.25 ms /    18 runs   (  666.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13251.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    29 runs   (    0.39 ms per token,  2575.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.58 ms /    24 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   18761.99 ms /    28 runs   (  670.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20067.37 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.69 ms /    24 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12672.72 ms /    19 runs   (  666.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13952.20 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2595.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.65 ms /    24 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11411.43 ms /    17 runs   (  671.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12669.30 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2616.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.11 ms /    24 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10649.84 ms /    16 runs   (  665.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11936.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2636.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.74 ms /    24 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10684.02 ms /    16 runs   (  667.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11974.33 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.94 ms /    24 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10459.98 ms /    16 runs   (  653.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11732.27 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.42 ms /    24 tokens (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10514.60 ms /    16 runs   (  657.16 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11765.76 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2650.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.52 ms /    24 tokens (   50.06 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10720.02 ms /    16 runs   (  670.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11970.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2613.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.17 ms /    23 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10610.59 ms /    16 runs   (  663.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11821.47 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.74 ms /    23 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11136.94 ms /    17 runs   (  655.11 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12357.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     118.92 ms /   400 runs   (    0.30 ms per token,  3363.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.30 ms /    23 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =  270018.66 ms /   399 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  272397.70 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.34 ms /    23 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11291.61 ms /    17 runs   (  664.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12512.35 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.85 ms /    24 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10696.43 ms /    16 runs   (  668.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11943.72 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.86 ms /    24 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10714.11 ms /    16 runs   (  669.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11959.39 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2639.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.05 ms /    23 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10580.78 ms /    16 runs   (  661.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11802.92 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.08 ms /    24 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10611.33 ms /    16 runs   (  663.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11873.49 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.77 ms /    23 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10644.37 ms /    16 runs   (  665.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11848.08 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.66 ms /    23 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11297.05 ms /    17 runs   (  664.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12500.21 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.68 ms /    24 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11167.54 ms /    17 runs   (  656.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12443.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.87 ms /    14 runs   (    0.42 ms per token,  2384.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.28 ms /    24 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8794.62 ms /    13 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10057.11 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.41 ms /    23 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10817.90 ms /    16 runs   (  676.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12047.36 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    20 runs   (    0.43 ms per token,  2325.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.02 ms /    24 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12765.14 ms /    19 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14044.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2625.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.14 ms /    24 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10734.28 ms /    16 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12001.48 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2617.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.93 ms /    24 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10484.45 ms /    16 runs   (  655.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11743.45 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.55 ms /    24 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10793.79 ms /    16 runs   (  674.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12055.77 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2561.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.06 ms /    24 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11315.20 ms /    17 runs   (  665.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12576.43 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2599.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.47 ms /    24 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12857.50 ms /    19 runs   (  676.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14123.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2578.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.50 ms /    24 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11289.06 ms /    17 runs   (  664.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12545.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    17 runs   (    0.38 ms per token,  2661.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.33 ms /    23 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10701.49 ms /    16 runs   (  668.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11911.47 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2635.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.41 ms /    24 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11434.61 ms /    17 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12684.07 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2628.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.77 ms /    24 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11824.35 ms /    18 runs   (  656.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13080.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.75 ms /    24 tokens (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11299.28 ms /    17 runs   (  664.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12556.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2575.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.39 ms /    24 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12368.01 ms /    19 runs   (  650.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13625.82 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2614.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.57 ms /    24 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10572.02 ms /    16 runs   (  660.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11842.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2657.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.21 ms /    24 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   10573.83 ms /    16 runs   (  660.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11847.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.89 ms /    24 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11220.62 ms /    17 runs   (  660.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12468.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2574.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.97 ms /    24 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   10850.10 ms /    16 runs   (  678.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12131.72 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2635.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.95 ms /    24 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10602.18 ms /    16 runs   (  662.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11857.82 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2635.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.27 ms /    24 tokens (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11261.07 ms /    17 runs   (  662.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12510.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    18 runs   (    0.45 ms per token,  2230.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.82 ms /    24 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11307.62 ms /    17 runs   (  665.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12563.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2573.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.75 ms /    24 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10779.68 ms /    16 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12038.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2593.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.79 ms /    24 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10661.90 ms /    16 runs   (  666.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11961.48 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2611.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.06 ms /    23 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11438.18 ms /    17 runs   (  672.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12657.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2550.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.39 ms /    24 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13012.70 ms /    19 runs   (  684.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14277.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.97 ms /    24 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11352.88 ms /    17 runs   (  667.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12655.78 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2546.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.38 ms /    24 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11878.53 ms /    18 runs   (  659.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13133.00 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2596.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.88 ms /    24 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12054.05 ms /    18 runs   (  669.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13319.27 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2630.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.06 ms /    24 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10724.56 ms /    16 runs   (  670.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11972.07 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2588.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.23 ms /    24 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12188.26 ms /    18 runs   (  677.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13449.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2636.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.78 ms /    24 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11267.36 ms /    17 runs   (  662.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12516.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2579.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.74 ms /    23 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12650.25 ms /    19 runs   (  665.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13881.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2568.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.99 ms /    24 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11347.09 ms /    17 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12636.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    31 runs   (    0.38 ms per token,  2635.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.07 ms /    23 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19969.21 ms /    30 runs   (  665.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21242.95 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2582.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.55 ms /    23 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11400.38 ms /    17 runs   (  670.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12610.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2626.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.13 ms /    24 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10668.90 ms /    16 runs   (  666.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11933.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2622.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.19 ms /    24 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10662.62 ms /    16 runs   (  666.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11930.21 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2580.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.45 ms /    24 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10610.21 ms /    16 runs   (  663.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11876.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    17 runs   (    0.38 ms per token,  2662.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.18 ms /    24 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.80 ms /    16 runs   (  671.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11993.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.21 ms /    26 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10736.78 ms /    16 runs   (  671.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12072.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.56 ms /    26 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10926.58 ms /    16 runs   (  682.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12262.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    21 runs   (    0.38 ms per token,  2600.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.77 ms /    26 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   13307.30 ms /    20 runs   (  665.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14664.23 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2613.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.95 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12097.07 ms /    18 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13402.64 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2579.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.95 ms /    26 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12722.47 ms /    19 runs   (  669.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14194.43 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2525.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.33 ms /    26 tokens (   49.44 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11275.91 ms /    17 runs   (  663.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12613.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2583.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.05 ms /    25 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12081.32 ms /    18 runs   (  671.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13407.26 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.72 ms /    25 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11255.77 ms /    17 runs   (  662.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12615.16 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    17 runs   (    0.40 ms per token,  2482.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.05 ms /    25 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10886.08 ms /    16 runs   (  680.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12199.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2652.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.52 ms /    26 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10616.68 ms /    16 runs   (  663.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11965.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2655.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.40 ms /    26 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11907.59 ms /    18 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13264.89 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2644.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.11 ms /    25 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11325.63 ms /    17 runs   (  666.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12647.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.52 ms /    25 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10617.66 ms /    16 runs   (  663.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11934.17 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    17 runs   (    0.40 ms per token,  2482.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.14 ms /    26 tokens (   49.54 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10502.24 ms /    16 runs   (  656.39 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11840.83 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    19 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.45 ms /    26 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11896.30 ms /    18 runs   (  660.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13246.84 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.93 ms /    24 tokens (   50.29 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12044.56 ms /    18 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13306.80 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2542.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.71 ms /    26 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10688.82 ms /    16 runs   (  668.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12033.48 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    18 runs   (    0.40 ms per token,  2476.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.48 ms /    26 tokens (   49.86 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11473.39 ms /    17 runs   (  674.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12823.41 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2528.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.67 ms /    25 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12094.61 ms /    18 runs   (  671.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13433.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    20 runs   (    0.42 ms per token,  2407.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.96 ms /    25 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12602.90 ms /    19 runs   (  663.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13939.21 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.84 ms /    25 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10600.42 ms /    16 runs   (  662.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11916.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    21 runs   (    0.39 ms per token,  2588.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.21 ms /    26 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13342.94 ms /    20 runs   (  667.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14692.59 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    21 runs   (    0.39 ms per token,  2542.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.16 ms /    26 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13182.53 ms /    20 runs   (  659.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14555.25 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    22 runs   (    0.39 ms per token,  2578.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.26 ms /    25 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   14121.43 ms /    21 runs   (  672.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15445.21 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    20 runs   (    0.39 ms per token,  2556.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.72 ms /    25 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12950.70 ms /    19 runs   (  681.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14249.89 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.33 ms /    26 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11367.90 ms /    17 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12725.59 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    23 runs   (    0.39 ms per token,  2542.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.36 ms /    26 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14550.34 ms /    22 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15914.33 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.38 ms /    25 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11213.15 ms /    17 runs   (  659.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12507.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2544.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.20 ms /    25 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11401.57 ms /    17 runs   (  670.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12698.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2525.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.79 ms /    26 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12749.25 ms /    19 runs   (  671.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14091.79 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2591.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.30 ms /    26 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12002.59 ms /    18 runs   (  666.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13351.75 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2528.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.74 ms /    25 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11517.78 ms /    17 runs   (  677.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12849.08 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.13 ms /    28 runs   (    0.40 ms per token,  2516.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.28 ms /    26 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   18282.57 ms /    27 runs   (  677.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19669.76 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2560.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.28 ms /    26 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11978.54 ms /    18 runs   (  665.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13341.76 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    21 runs   (    0.39 ms per token,  2549.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.84 ms /    25 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13301.47 ms /    20 runs   (  665.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14611.55 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    19 runs   (    0.41 ms per token,  2467.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.34 ms /    25 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11877.61 ms /    18 runs   (  659.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13188.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2514.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.74 ms /    25 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10593.53 ms /    16 runs   (  662.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11893.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    22 runs   (    0.39 ms per token,  2567.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.72 ms /    26 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   14057.55 ms /    21 runs   (  669.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15419.19 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2588.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.29 ms /    26 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11180.68 ms /    17 runs   (  657.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12545.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    21 runs   (    0.39 ms per token,  2532.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.44 ms /    25 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   13400.17 ms /    20 runs   (  670.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14715.53 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2597.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.16 ms /    26 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11466.11 ms /    17 runs   (  674.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12817.42 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    17 runs   (    0.45 ms per token,  2227.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.66 ms /    26 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10530.11 ms /    16 runs   (  658.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11871.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    19 runs   (    0.40 ms per token,  2522.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.38 ms /    25 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12061.39 ms /    18 runs   (  670.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13375.25 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.17 ms /    25 tokens (   50.09 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11197.80 ms /    17 runs   (  658.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12503.47 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.94 ms /    25 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10730.91 ms /    16 runs   (  670.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12019.04 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2591.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.00 ms /    26 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11388.08 ms /    17 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12767.40 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2571.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.02 ms /    26 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12881.18 ms /    19 runs   (  677.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14243.71 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2567.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.70 ms /    25 tokens (   49.79 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12074.03 ms /    18 runs   (  670.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13374.07 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2626.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.90 ms /    26 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11203.00 ms /    17 runs   (  659.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12588.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.50 ms /    26 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10630.89 ms /    16 runs   (  664.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11980.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    19 runs   (    0.44 ms per token,  2279.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.69 ms /    25 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11998.74 ms /    18 runs   (  666.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13318.91 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.06 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11332.53 ms /    17 runs   (  666.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12635.29 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2605.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.34 ms /    25 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10605.28 ms /    16 runs   (  662.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11905.61 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2574.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.38 ms /    26 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10685.20 ms /    16 runs   (  667.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12034.43 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2559.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.77 ms /    26 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12733.58 ms /    19 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14107.94 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2594.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.72 ms /    25 tokens (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11835.02 ms /    18 runs   (  657.50 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13134.87 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2608.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.34 ms /    26 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11768.55 ms /    18 runs   (  653.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13138.52 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.86 ms /    26 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10380.04 ms /    16 runs   (  648.75 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11729.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2554.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.79 ms /    25 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13308.91 ms /    20 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14611.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    22 runs   (    0.39 ms per token,  2569.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.66 ms /    25 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14240.93 ms /    21 runs   (  678.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15583.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2586.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.11 ms /    26 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12569.16 ms /    19 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13922.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.86 ms /    26 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10734.31 ms /    16 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12076.81 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     140.32 ms /   398 runs   (    0.35 ms per token,  2836.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.83 ms /    25 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =  268362.20 ms /   397 runs   (  675.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270909.77 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.83 ms /    25 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11170.75 ms /    17 runs   (  657.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12491.92 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2611.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.36 ms /    25 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12820.41 ms /    19 runs   (  674.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14116.71 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2544.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.10 ms /    26 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11180.94 ms /    17 runs   (  657.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12543.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2624.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.27 ms /    26 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11293.63 ms /    17 runs   (  664.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12640.90 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2625.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.22 ms /    24 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   13257.71 ms /    20 runs   (  662.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14538.28 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2667.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.90 ms /    25 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10597.44 ms /    16 runs   (  662.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11889.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.56 ms /    26 tokens (   50.14 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11945.62 ms /    18 runs   (  663.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13304.62 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2584.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.44 ms /    26 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11401.81 ms /    17 runs   (  670.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12752.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2625.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.14 ms /    25 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12827.35 ms /    19 runs   (  675.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14144.42 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2513.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.82 ms /    24 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11326.03 ms /    17 runs   (  666.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12610.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    22 runs   (    0.39 ms per token,  2536.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.12 ms /    26 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14149.21 ms /    21 runs   (  673.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15502.09 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2564.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.47 ms /    26 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12130.16 ms /    18 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13526.54 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.39 ms per token,  2532.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.49 ms /    25 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11369.21 ms /    17 runs   (  668.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12685.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    15 runs   (    0.39 ms per token,  2569.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.90 ms /    25 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =    9420.91 ms /    14 runs   (  672.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10712.87 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.36 ms /    26 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10778.78 ms /    16 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12114.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    21 runs   (    0.39 ms per token,  2590.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.43 ms /    26 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13213.22 ms /    20 runs   (  660.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14562.62 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.72 ms /    25 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11435.36 ms /    17 runs   (  672.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12745.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.38 ms /    26 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.96 ms /    16 runs   (  671.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12102.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2566.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.01 ms /    26 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11301.51 ms /    17 runs   (  664.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12638.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2591.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.61 ms /    25 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11204.73 ms /    17 runs   (  659.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12512.28 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    19 runs   (    0.44 ms per token,  2275.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.14 ms /    25 tokens (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12052.84 ms /    18 runs   (  669.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13361.43 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2571.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.56 ms /    26 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11517.64 ms /    17 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12944.32 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2633.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.00 ms /    26 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11177.88 ms /    17 runs   (  657.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12516.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    24 runs   (    0.38 ms per token,  2601.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.68 ms /    25 tokens (   49.99 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   15060.32 ms /    23 runs   (  654.80 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   16379.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.50 ms /    25 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11882.75 ms /    18 runs   (  660.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13208.58 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2600.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.73 ms /    26 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11086.12 ms /    17 runs   (  652.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12427.29 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2584.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.13 ms /    26 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12368.18 ms /    19 runs   (  650.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13748.70 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2597.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.83 ms /    24 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11965.93 ms /    18 runs   (  664.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13226.10 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2625.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.83 ms /    24 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11927.88 ms /    18 runs   (  662.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13234.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2566.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.42 ms /    26 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11700.19 ms /    18 runs   (  650.01 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13078.05 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2521.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.02 ms /    26 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10479.70 ms /    16 runs   (  654.98 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11826.53 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2612.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.82 ms /    25 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12346.93 ms /    19 runs   (  649.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13672.77 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.62 ms /    25 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11828.50 ms /    18 runs   (  657.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13132.16 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    20 runs   (    0.39 ms per token,  2558.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.85 ms /    26 tokens (   49.42 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12836.64 ms /    19 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14180.50 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.70 ms /    26 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10690.06 ms /    16 runs   (  668.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12056.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2589.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.17 ms /    25 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11157.53 ms /    17 runs   (  656.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12471.34 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    19 runs   (    0.38 ms per token,  2663.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.80 ms /    25 tokens (   49.59 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11779.04 ms /    18 runs   (  654.39 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13074.41 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    28 runs   (    0.39 ms per token,  2540.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.67 ms /    25 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   17806.68 ms /    27 runs   (  659.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19148.13 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2584.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.80 ms /    26 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12216.74 ms /    18 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13561.40 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2626.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.26 ms /    26 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11278.41 ms /    17 runs   (  663.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12704.05 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2619.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.83 ms /    25 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12182.49 ms /    18 runs   (  676.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13476.00 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.77 ms /    25 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11256.93 ms /    17 runs   (  662.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12549.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2592.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.06 ms /    26 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10647.18 ms /    16 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12006.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.35 ms /    26 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12090.62 ms /    18 runs   (  671.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13438.13 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.88 ms /    24 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11038.10 ms /    17 runs   (  649.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12313.07 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2586.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.05 ms /    26 tokens (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11235.14 ms /    17 runs   (  660.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12566.37 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2554.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.40 ms /    26 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10698.71 ms /    16 runs   (  668.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12060.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2592.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.69 ms /    25 tokens (   49.79 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11837.53 ms /    18 runs   (  657.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13137.60 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    20 runs   (    0.39 ms per token,  2590.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.74 ms /    25 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12631.01 ms /    19 runs   (  664.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13940.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2618.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.33 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12499.76 ms /    19 runs   (  657.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13833.74 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2634.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.16 ms /    26 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11208.75 ms /    17 runs   (  659.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12617.67 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2563.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.10 ms /    26 tokens (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11450.55 ms /    17 runs   (  673.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12789.33 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     116.02 ms /   398 runs   (    0.29 ms per token,  3430.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.80 ms /    24 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =  267642.76 ms /   397 runs   (  674.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270062.20 ms /   421 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.63 ms /    25 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11257.38 ms /    17 runs   (  662.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12554.30 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.21 ms /    26 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11352.34 ms /    17 runs   (  667.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12691.32 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    18 runs   (    0.41 ms per token,  2456.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.27 ms /    26 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11133.81 ms /    17 runs   (  654.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12477.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2592.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.60 ms /    25 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12161.93 ms /    18 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13484.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2565.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.87 ms /    26 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10736.41 ms /    16 runs   (  671.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12089.69 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2566.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.10 ms /    26 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11278.63 ms /    17 runs   (  663.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12620.64 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    21 runs   (    0.40 ms per token,  2527.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.67 ms /    25 tokens (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13270.97 ms /    20 runs   (  663.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14568.86 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2556.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.71 ms /    25 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11967.46 ms /    18 runs   (  664.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13261.20 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2574.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.64 ms /    26 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10720.88 ms /    16 runs   (  670.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12065.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2574.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.50 ms /    26 tokens (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10651.45 ms /    16 runs   (  665.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11990.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2616.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.47 ms /    25 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12739.94 ms /    19 runs   (  670.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14060.34 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.61 ms /    25 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11440.85 ms /    17 runs   (  672.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12764.42 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2573.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.76 ms /    25 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10765.57 ms /    16 runs   (  672.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12057.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.70 ms /    26 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11069.26 ms /    17 runs   (  651.13 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12419.05 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    21 runs   (    0.40 ms per token,  2523.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.40 ms /    26 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12943.24 ms /    20 runs   (  647.16 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   14288.91 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.82 ms /    25 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10928.68 ms /    17 runs   (  642.86 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   12237.61 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.22 ms /    25 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12368.37 ms /    19 runs   (  650.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13686.68 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    17 runs   (    0.40 ms per token,  2508.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.59 ms /    26 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10598.74 ms /    16 runs   (  662.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11978.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2566.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.16 ms /    26 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11556.93 ms /    18 runs   (  642.05 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   12898.16 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.52 ms /    25 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11030.21 ms /    17 runs   (  648.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12338.03 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.30 ms /    25 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10633.03 ms /    16 runs   (  664.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11970.32 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.27 ms /    26 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10468.20 ms /    16 runs   (  654.26 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11805.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    18 runs   (    0.44 ms per token,  2284.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.48 ms /    26 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11415.60 ms /    17 runs   (  671.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12782.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2631.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.21 ms /    25 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11187.17 ms /    17 runs   (  658.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12502.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2551.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.43 ms /    26 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11243.58 ms /    17 runs   (  661.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12584.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2597.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.39 ms /    26 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10691.38 ms /    16 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12039.47 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.73 ms /    25 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11176.66 ms /    17 runs   (  657.45 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12488.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2563.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.12 ms /    25 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12070.15 ms /    18 runs   (  670.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13468.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2588.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.44 ms /    26 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11872.62 ms /    18 runs   (  659.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13214.71 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2554.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.34 ms /    26 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12576.95 ms /    19 runs   (  661.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13956.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2584.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.16 ms /    24 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11449.20 ms /    17 runs   (  673.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12712.03 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    20 runs   (    0.39 ms per token,  2537.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.66 ms /    24 tokens (   49.99 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12736.38 ms /    19 runs   (  670.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13994.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2558.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.31 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10543.16 ms /    16 runs   (  658.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11868.10 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2594.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.11 ms /    26 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10752.42 ms /    16 runs   (  672.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12123.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2540.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.02 ms /    26 tokens (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11978.97 ms /    18 runs   (  665.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13329.58 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2592.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.02 ms /    25 tokens (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11400.10 ms /    17 runs   (  670.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12706.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2546.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.58 ms /    25 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10678.90 ms /    16 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12040.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.80 ms /    30 runs   (    0.39 ms per token,  2541.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.82 ms /    26 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19597.58 ms /    29 runs   (  675.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20991.84 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2546.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.37 ms /    26 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11880.18 ms /    18 runs   (  660.01 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13289.96 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2618.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.93 ms /    25 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10994.32 ms /    17 runs   (  646.72 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12297.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2626.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.74 ms /    24 tokens (   49.86 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11358.60 ms /    17 runs   (  668.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12607.57 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2533.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.36 ms /    26 tokens (   50.01 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11485.32 ms /    17 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12838.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2581.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.05 ms /    26 tokens (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12766.61 ms /    19 runs   (  671.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14117.70 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2611.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.01 ms /    25 tokens (   49.84 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12792.02 ms /    19 runs   (  673.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14095.56 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2563.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.18 ms /    26 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11160.13 ms /    17 runs   (  656.48 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12514.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.17 ms /    26 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11172.33 ms /    17 runs   (  657.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12514.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2537.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.71 ms /    25 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11288.79 ms /    17 runs   (  664.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12590.38 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.06 ms /    25 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11494.80 ms /    17 runs   (  676.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12794.84 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.83 ms /    26 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10822.65 ms /    16 runs   (  676.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12160.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2570.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.87 ms /    26 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10670.31 ms /    16 runs   (  666.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12017.28 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    21 runs   (    0.39 ms per token,  2568.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.21 ms /    25 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13161.92 ms /    20 runs   (  658.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14465.98 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.25 ms /    25 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11351.41 ms /    17 runs   (  667.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12650.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    15 runs   (    0.40 ms per token,  2523.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.54 ms /    25 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =    9237.33 ms /    14 runs   (  659.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   10551.35 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2574.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.80 ms /    26 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11810.99 ms /    18 runs   (  656.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13160.48 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2525.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.95 ms /    26 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12123.19 ms /    18 runs   (  673.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13468.52 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2658.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.11 ms /    25 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11267.68 ms /    17 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12583.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.80 ms /    26 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12662.16 ms /    19 runs   (  666.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14071.35 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2560.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.58 ms /    26 tokens (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10543.00 ms /    16 runs   (  658.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11887.53 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    19 runs   (    0.44 ms per token,  2295.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.20 ms /    25 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12206.41 ms /    18 runs   (  678.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13512.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.51 ms /    25 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11598.42 ms /    17 runs   (  682.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12892.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2596.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.34 ms /    25 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10604.87 ms /    16 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11922.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.27 ms /    26 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10555.35 ms /    16 runs   (  659.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11890.48 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2578.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.40 ms /    26 tokens (   49.59 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11425.89 ms /    17 runs   (  672.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12767.99 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2573.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.94 ms /    25 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11521.56 ms /    17 runs   (  677.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12901.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2574.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.07 ms /    25 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12218.48 ms /    18 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13539.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2579.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.54 ms /    26 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12649.19 ms /    19 runs   (  665.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14037.09 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    22 runs   (    0.38 ms per token,  2610.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.26 ms /    26 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   13935.19 ms /    21 runs   (  663.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15318.19 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.89 ms /    24 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11875.68 ms /    18 runs   (  659.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13144.37 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2616.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.01 ms /    25 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10629.97 ms /    16 runs   (  664.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11997.99 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    21 runs   (    0.37 ms per token,  2713.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.21 ms /    26 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13398.49 ms /    20 runs   (  669.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14745.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2663.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.84 ms /    26 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11350.67 ms /    17 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12714.01 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1227.62 ms /    24 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   13310.35 ms /    20 runs   (  665.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14599.86 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2541.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.65 ms /    26 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10538.58 ms /    16 runs   (  658.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11891.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.26 ms /    26 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10686.86 ms /    16 runs   (  667.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12022.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    21 runs   (    0.39 ms per token,  2559.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.34 ms /    25 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   13502.78 ms /    20 runs   (  675.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14802.32 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.01 ms /    25 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11269.96 ms /    17 runs   (  662.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12576.03 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.44 ms /    25 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10939.56 ms /    16 runs   (  683.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12261.58 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2538.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.76 ms /    26 tokens (   49.84 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10878.38 ms /    16 runs   (  679.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12222.83 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2546.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.17 ms /    26 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12649.83 ms /    19 runs   (  665.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14012.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2548.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.06 ms /    25 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11343.04 ms /    17 runs   (  667.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12650.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2550.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.17 ms /    26 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10667.85 ms /    16 runs   (  666.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12071.03 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2522.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.13 ms /    26 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11705.05 ms /    17 runs   (  688.53 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13056.41 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.40 ms per token,  2531.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.53 ms /    25 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11484.28 ms /    17 runs   (  675.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12782.70 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2533.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.09 ms /    25 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12089.46 ms /    18 runs   (  671.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13414.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2559.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.79 ms /    25 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11438.95 ms /    17 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12738.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2543.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.37 ms /    25 tokens (   50.77 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11362.44 ms /    17 runs   (  668.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12684.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.62 ms /    24 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11602.09 ms /    17 runs   (  682.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12875.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2598.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.93 ms /    24 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12095.39 ms /    18 runs   (  671.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13384.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.21 ms /    24 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11195.45 ms /    17 runs   (  658.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12467.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.89 ms /    25 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10633.12 ms /    16 runs   (  664.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11958.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2579.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.14 ms /    25 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12103.12 ms /    18 runs   (  672.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13408.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2603.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.41 ms /    24 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11243.07 ms /    17 runs   (  661.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12568.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2579.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.16 ms /    24 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11070.09 ms /    17 runs   (  651.18 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12360.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2654.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.85 ms /    25 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10547.92 ms /    16 runs   (  659.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11876.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2549.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.16 ms /    25 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11756.62 ms /    18 runs   (  653.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13060.86 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2616.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.35 ms /    24 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11731.14 ms /    18 runs   (  651.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12998.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2570.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.05 ms /    24 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10591.51 ms /    16 runs   (  661.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11913.03 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    18 runs   (    0.44 ms per token,  2250.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.71 ms /    25 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11288.24 ms /    17 runs   (  664.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12593.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2581.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.54 ms /    25 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11347.12 ms /    17 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12648.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    22 runs   (    0.39 ms per token,  2552.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.66 ms /    24 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   13934.02 ms /    21 runs   (  663.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15225.07 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    16 runs   (    0.39 ms per token,  2562.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.31 ms /    25 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10014.43 ms /    15 runs   (  667.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11314.82 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.68 ms /    25 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11474.47 ms /    17 runs   (  674.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12791.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2605.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.79 ms /    24 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12056.31 ms /    18 runs   (  669.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13313.86 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2581.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.65 ms /    24 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11958.95 ms /    18 runs   (  664.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13215.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    17 runs   (    0.43 ms per token,  2330.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.55 ms /    25 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10658.61 ms /    16 runs   (  666.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11990.49 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2563.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.14 ms /    25 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12010.90 ms /    18 runs   (  667.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13309.67 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2603.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.53 ms /    23 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11935.50 ms /    18 runs   (  663.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13167.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2541.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.47 ms /    23 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11967.48 ms /    18 runs   (  664.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13193.13 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2586.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.95 ms /    24 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11319.68 ms /    17 runs   (  665.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12595.30 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2566.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.56 ms /    25 tokens (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11734.64 ms /    18 runs   (  651.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13041.12 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    21 runs   (    0.38 ms per token,  2620.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.05 ms /    25 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   13297.31 ms /    20 runs   (  664.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14696.42 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    21 runs   (    0.39 ms per token,  2590.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.35 ms /    24 tokens (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12998.92 ms /    20 runs   (  649.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   14261.02 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    19 runs   (    0.40 ms per token,  2508.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.38 ms /    25 tokens (   49.81 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11999.83 ms /    18 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13300.57 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2592.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.04 ms /    25 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11505.33 ms /    17 runs   (  676.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12828.44 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2582.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.31 ms /    24 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11070.32 ms /    17 runs   (  651.20 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12346.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2565.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.99 ms /    24 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11958.97 ms /    18 runs   (  664.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13224.19 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    20 runs   (    0.39 ms per token,  2540.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.87 ms /    23 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12717.77 ms /    19 runs   (  669.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13934.55 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2536.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.85 ms /    25 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11226.60 ms /    17 runs   (  660.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12545.34 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    19 runs   (    0.40 ms per token,  2516.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.29 ms /    25 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11847.68 ms /    18 runs   (  658.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13155.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    26 runs   (    0.39 ms per token,  2560.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.99 ms /    24 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   16620.51 ms /    25 runs   (  664.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17985.56 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2605.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.58 ms /    25 tokens (   49.86 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10549.27 ms /    16 runs   (  659.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11844.86 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2583.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.47 ms /    25 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12576.73 ms /    19 runs   (  661.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13895.95 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    21 runs   (    0.39 ms per token,  2562.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.80 ms /    22 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   13256.50 ms /    20 runs   (  662.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14441.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.81 ms /    22 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11933.62 ms /    18 runs   (  662.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13155.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2528.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.42 ms /    24 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10608.51 ms /    16 runs   (  663.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11855.86 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2611.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.96 ms /    24 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11491.56 ms /    17 runs   (  675.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12745.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2613.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.53 ms /    22 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12846.61 ms /    19 runs   (  676.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14029.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2579.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.93 ms /    22 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12077.27 ms /    18 runs   (  670.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13273.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2514.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.50 ms /    25 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11124.47 ms /    17 runs   (  654.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12417.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2605.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.49 ms /    25 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11907.73 ms /    18 runs   (  661.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13231.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    20 runs   (    0.40 ms per token,  2493.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.65 ms /    24 tokens (   49.74 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12606.23 ms /    19 runs   (  663.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13858.26 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    18 runs   (    0.42 ms per token,  2381.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.21 ms /    24 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11163.16 ms /    17 runs   (  656.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12443.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2546.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.88 ms /    24 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13184.15 ms /    20 runs   (  659.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14441.40 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    18 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.68 ms /    25 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11184.90 ms /    17 runs   (  657.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12502.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    25 runs   (    0.39 ms per token,  2556.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.78 ms /    25 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15790.28 ms /    24 runs   (  657.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17112.76 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2554.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.08 ms /    24 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11872.39 ms /    18 runs   (  659.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13151.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2541.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.68 ms /    25 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11386.56 ms /    17 runs   (  669.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12686.00 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    19 runs   (    0.40 ms per token,  2520.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.63 ms /    25 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12056.97 ms /    18 runs   (  669.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13399.23 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.79 ms /    24 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11112.96 ms /    17 runs   (  653.70 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12395.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.41 ms /    24 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12632.26 ms /    19 runs   (  664.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13904.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2560.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.49 ms /    24 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10838.06 ms /    16 runs   (  677.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12117.52 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2583.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.76 ms /    25 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10499.32 ms /    16 runs   (  656.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11787.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    21 runs   (    0.39 ms per token,  2584.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.13 ms /    25 tokens (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13265.45 ms /    20 runs   (  663.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14574.49 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2595.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.78 ms /    24 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11245.98 ms /    17 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12524.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2548.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.13 ms /    25 tokens (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11271.32 ms /    17 runs   (  663.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12571.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2550.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.96 ms /    25 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12048.91 ms /    18 runs   (  669.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13377.56 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    21 runs   (    0.38 ms per token,  2605.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.97 ms /    24 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   13267.55 ms /    20 runs   (  663.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14530.19 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    21 runs   (    0.40 ms per token,  2514.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.61 ms /    24 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13150.86 ms /    20 runs   (  657.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14428.93 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2629.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.91 ms /    24 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11234.47 ms /    17 runs   (  660.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12511.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2602.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.02 ms /    24 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12001.43 ms /    18 runs   (  666.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13258.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    19 runs   (    0.37 ms per token,  2679.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.45 ms /    23 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12057.83 ms /    18 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13308.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    32 runs   (    0.39 ms per token,  2586.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.09 ms /    23 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20856.54 ms /    31 runs   (  672.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22108.27 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.91 ms /    23 runs   (    0.39 ms per token,  2581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.06 ms /    25 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14608.07 ms /    22 runs   (  664.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15951.20 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2563.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.11 ms /    25 tokens (   51.96 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11409.23 ms /    17 runs   (  671.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12760.47 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    22 runs   (    0.38 ms per token,  2608.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.92 ms /    24 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14166.99 ms /    21 runs   (  674.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15449.54 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    21 runs   (    0.39 ms per token,  2580.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.43 ms /    24 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   13447.76 ms /    20 runs   (  672.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14721.70 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2541.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.40 ms /    24 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10624.76 ms /    16 runs   (  664.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11890.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2578.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.80 ms /    25 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12006.90 ms /    18 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13304.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2688.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.75 ms /    25 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11573.93 ms /    17 runs   (  680.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12875.27 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     124.25 ms /   399 runs   (    0.31 ms per token,  3211.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.90 ms /    24 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =  266493.24 ms /   398 runs   (  669.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =  268916.86 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2553.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1227.24 ms /    24 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12846.87 ms /    19 runs   (  676.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14132.86 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.34 ms /    25 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10758.16 ms /    16 runs   (  672.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12074.10 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.39 ms /    27 runs   (    0.38 ms per token,  2597.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.36 ms /    25 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17709.32 ms /    26 runs   (  681.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19041.00 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2553.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.64 ms /    24 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12385.91 ms /    18 runs   (  688.11 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13661.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.41 ms /    25 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10771.06 ms /    16 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12066.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.62 ms /    25 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11313.05 ms /    17 runs   (  665.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12644.44 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    28 runs   (    0.38 ms per token,  2614.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.79 ms /    24 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   17982.52 ms /    27 runs   (  666.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19325.29 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.01 ms /    24 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   13328.68 ms /    20 runs   (  666.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14593.31 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     126.48 ms /   399 runs   (    0.32 ms per token,  3154.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.68 ms /    24 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =  268396.63 ms /   398 runs   (  674.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270853.66 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.32 ms /    25 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11435.43 ms /    17 runs   (  672.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12785.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2586.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.72 ms /    25 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11460.54 ms /    17 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12786.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2555.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.69 ms /    24 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13238.83 ms /    20 runs   (  661.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14512.31 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    23 runs   (    0.39 ms per token,  2565.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.56 ms /    25 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   14551.23 ms /    22 runs   (  661.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15867.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     140.95 ms /   399 runs   (    0.35 ms per token,  2830.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.80 ms /    25 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =  268871.21 ms /   398 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  271402.56 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2618.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.45 ms /    24 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12008.63 ms /    18 runs   (  667.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13276.55 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.56 ms /    24 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11299.92 ms /    17 runs   (  664.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12553.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    21 runs   (    0.39 ms per token,  2547.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.00 ms /    24 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   13117.07 ms /    20 runs   (  655.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14414.90 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     115.52 ms /   399 runs   (    0.29 ms per token,  3453.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.56 ms /    25 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =  268040.84 ms /   398 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270486.39 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2584.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.28 ms /    25 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11294.96 ms /    17 runs   (  664.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12615.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    18 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.40 ms /    24 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11492.50 ms /    17 runs   (  676.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12755.66 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2628.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.38 ms /    24 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10454.90 ms /    16 runs   (  653.43 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11706.05 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2556.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.04 ms /    25 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10661.94 ms /    16 runs   (  666.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11974.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2552.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.11 ms /    25 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11440.58 ms /    17 runs   (  672.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12759.10 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    19 runs   (    0.37 ms per token,  2669.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.58 ms /    24 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12264.59 ms /    18 runs   (  681.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13519.39 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2555.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.89 ms /    23 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10743.88 ms /    16 runs   (  671.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12042.65 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2589.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.73 ms /    24 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11404.35 ms /    17 runs   (  670.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12695.49 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    24 runs   (    0.39 ms per token,  2563.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.29 ms /    24 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   15839.41 ms /    23 runs   (  688.67 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   17139.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    21 runs   (    0.40 ms per token,  2510.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.31 ms /    23 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   13596.87 ms /    20 runs   (  679.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14836.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    19 runs   (    0.40 ms per token,  2513.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1714.78 ms /    24 tokens (   71.45 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12056.73 ms /    18 runs   (  669.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13828.38 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2561.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.90 ms /    24 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11353.51 ms /    17 runs   (  667.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12651.79 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.53 ms /    24 runs   (    0.40 ms per token,  2519.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.30 ms /    23 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   15634.30 ms /    23 runs   (  679.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16920.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2417.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.43 ms /    23 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12675.74 ms /    18 runs   (  704.21 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   13908.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2578.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.50 ms /    24 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11059.75 ms /    16 runs   (  691.23 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12353.52 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    17 runs   (    0.45 ms per token,  2200.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.06 ms /    25 tokens (   56.68 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10897.77 ms /    16 runs   (  681.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12368.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    18 runs   (    0.46 ms per token,  2178.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.13 ms /    25 tokens (   55.77 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11749.46 ms /    17 runs   (  691.14 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13204.53 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2521.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.85 ms /    24 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11490.65 ms /    17 runs   (  675.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12832.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    17 runs   (    0.41 ms per token,  2413.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.92 ms /    23 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10982.83 ms /    16 runs   (  686.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12261.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    17 runs   (    0.40 ms per token,  2475.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.01 ms /    25 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10707.25 ms /    16 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12033.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2561.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.74 ms /    25 tokens (   56.35 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11620.38 ms /    17 runs   (  683.55 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13082.58 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    18 runs   (    0.40 ms per token,  2504.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.83 ms /    24 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11290.31 ms /    17 runs   (  664.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12665.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    21 runs   (    0.41 ms per token,  2452.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.80 ms /    23 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   13696.76 ms /    20 runs   (  684.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15015.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2548.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.13 ms /    24 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11960.80 ms /    18 runs   (  664.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13220.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2595.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.21 ms /    24 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   13336.42 ms /    20 runs   (  666.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14622.27 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2550.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.53 ms /    23 tokens (   50.54 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12576.33 ms /    19 runs   (  661.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13797.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2581.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.95 ms /    25 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11162.06 ms /    17 runs   (  656.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12485.34 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2598.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.39 ms /    25 tokens (   50.34 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11889.81 ms /    18 runs   (  660.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13202.91 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2532.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.00 ms /    24 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12048.37 ms /    18 runs   (  669.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13350.84 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2618.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.43 ms /    24 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12705.29 ms /    19 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13982.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2568.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.93 ms /    23 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10552.28 ms /    16 runs   (  659.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11758.59 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2547.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.06 ms /    25 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12683.13 ms /    19 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14000.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2588.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.20 ms /    25 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11245.82 ms /    17 runs   (  661.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12583.92 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    19 runs   (    0.40 ms per token,  2496.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.13 ms /    24 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11918.74 ms /    18 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13194.78 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2577.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.85 ms /    24 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10571.79 ms /    16 runs   (  660.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11862.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.01 ms /    25 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10694.04 ms /    16 runs   (  668.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11990.38 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    22 runs   (    0.40 ms per token,  2520.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.68 ms /    25 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13993.86 ms /    21 runs   (  666.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15305.23 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    20 runs   (    0.41 ms per token,  2412.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.05 ms /    24 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12699.82 ms /    19 runs   (  668.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13997.82 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    16 runs   (    0.40 ms per token,  2504.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.62 ms /    25 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10007.78 ms /    15 runs   (  667.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11298.60 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.59 ms /    25 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11102.22 ms /    17 runs   (  653.07 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12398.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.15 ms /    24 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11739.77 ms /    17 runs   (  690.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13004.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    20 runs   (    0.39 ms per token,  2535.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.13 ms /    24 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12611.20 ms /    19 runs   (  663.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13884.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2562.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.38 ms /    25 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10791.84 ms /    16 runs   (  674.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12142.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2588.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.63 ms /    25 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11133.72 ms /    17 runs   (  654.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12432.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    25 runs   (    0.39 ms per token,  2533.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.37 ms /    24 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   16363.60 ms /    24 runs   (  681.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17679.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2567.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.19 ms /    24 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12186.80 ms /    18 runs   (  677.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13465.17 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.05 ms /    25 tokens (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11371.04 ms /    17 runs   (  668.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12676.55 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2632.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.64 ms /    25 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10710.17 ms /    16 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12001.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2689.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.92 ms /    24 tokens (   50.29 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11399.17 ms /    17 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12657.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2581.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.86 ms /    24 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11365.97 ms /    17 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12615.79 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    19 runs   (    0.44 ms per token,  2281.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.81 ms /    24 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12253.42 ms /    18 runs   (  680.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13532.05 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2553.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.87 ms /    25 tokens (   56.51 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12571.69 ms /    19 runs   (  661.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14043.15 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.94 ms /    26 runs   (    0.38 ms per token,  2615.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.18 ms /    25 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   16564.22 ms /    25 runs   (  662.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17897.86 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    20 runs   (    0.40 ms per token,  2518.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.64 ms /    24 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12704.95 ms /    19 runs   (  668.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14002.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    17 runs   (    0.42 ms per token,  2402.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.24 ms /    25 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10920.79 ms /    16 runs   (  682.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12292.95 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.06 ms /    25 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11077.23 ms /    17 runs   (  651.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12467.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    18 runs   (    0.40 ms per token,  2485.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.06 ms /    24 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11327.72 ms /    17 runs   (  666.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12621.98 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    22 runs   (    0.40 ms per token,  2505.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.18 ms /    24 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   13986.50 ms /    21 runs   (  666.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15352.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2541.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.62 ms /    25 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10625.59 ms /    16 runs   (  664.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11936.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2563.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.45 ms /    25 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12011.76 ms /    18 runs   (  667.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13322.64 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.02 ms /    27 runs   (    0.37 ms per token,  2694.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.02 ms /    24 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   17227.46 ms /    26 runs   (  662.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18531.47 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     115.24 ms /   399 runs   (    0.29 ms per token,  3462.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.36 ms /    24 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =  268730.49 ms /   398 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  271159.80 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2531.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.46 ms /    25 tokens (   55.02 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10759.67 ms /    16 runs   (  672.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12187.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2524.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.63 ms /    25 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11436.74 ms /    17 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12762.17 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2583.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.14 ms /    24 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12730.59 ms /    19 runs   (  670.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14003.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.36 ms /    24 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11385.59 ms /    17 runs   (  669.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12684.25 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    21 runs   (    0.40 ms per token,  2505.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.51 ms /    25 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13493.22 ms /    20 runs   (  674.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14815.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2632.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.40 ms /    25 tokens (   55.78 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11196.26 ms /    17 runs   (  658.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12642.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    20 runs   (    0.38 ms per token,  2638.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.69 ms /    24 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12506.09 ms /    19 runs   (  658.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13777.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2596.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.84 ms /    24 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11998.57 ms /    18 runs   (  666.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13248.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.29 ms /    25 tokens (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12456.11 ms /    19 runs   (  655.58 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13756.86 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2532.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.37 ms /    25 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10935.71 ms /    16 runs   (  683.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12233.17 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2601.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.82 ms /    24 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11262.65 ms /    17 runs   (  662.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12521.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2624.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.73 ms /    24 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12024.55 ms /    18 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13277.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2521.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.62 ms /    25 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11404.20 ms /    17 runs   (  670.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12738.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2546.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.07 ms /    25 tokens (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12690.24 ms /    19 runs   (  667.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13989.33 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2592.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.37 ms /    24 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12220.03 ms /    18 runs   (  678.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13537.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.73 ms /    24 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11400.91 ms /    17 runs   (  670.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12668.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    32 runs   (    0.39 ms per token,  2582.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.90 ms /    25 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   20708.01 ms /    31 runs   (  668.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22060.08 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2523.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.69 ms /    25 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10777.07 ms /    16 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12070.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2555.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.53 ms /    24 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12173.80 ms /    18 runs   (  676.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13452.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2572.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.60 ms /    24 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12085.64 ms /    18 runs   (  671.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13340.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    19 runs   (    0.40 ms per token,  2496.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.99 ms /    24 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12010.66 ms /    18 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13288.16 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2589.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.19 ms /    25 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10460.93 ms /    16 runs   (  653.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11763.13 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2596.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.66 ms /    25 tokens (   50.47 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12002.10 ms /    18 runs   (  666.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13319.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.04 ms /    24 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10956.54 ms /    17 runs   (  644.50 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12233.23 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    21 runs   (    0.40 ms per token,  2472.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.33 ms /    25 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13504.75 ms /    20 runs   (  675.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14849.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2543.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.96 ms /    25 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12205.39 ms /    18 runs   (  678.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13576.53 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    22 runs   (    0.39 ms per token,  2536.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.28 ms /    24 tokens (   54.93 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   14206.77 ms /    21 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15591.93 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    20 runs   (    0.40 ms per token,  2507.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.81 ms /    24 tokens (   55.12 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12866.50 ms /    19 runs   (  677.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14248.54 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    17 runs   (    0.41 ms per token,  2462.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.60 ms /    25 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10627.45 ms /    16 runs   (  664.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11956.32 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    18 runs   (    0.43 ms per token,  2351.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.86 ms /    25 tokens (   50.31 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11732.21 ms /    17 runs   (  690.13 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13046.00 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     116.20 ms /   399 runs   (    0.29 ms per token,  3433.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.80 ms /    24 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =  271389.25 ms /   398 runs   (  681.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  273857.69 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    20 runs   (    0.44 ms per token,  2292.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.50 ms /    24 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12737.54 ms /    19 runs   (  670.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14045.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2644.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.36 ms /    23 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10816.94 ms /    16 runs   (  676.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12028.63 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2542.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.44 ms /    24 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11409.92 ms /    17 runs   (  671.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12663.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2586.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.29 ms /    24 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11346.25 ms /    17 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12620.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2609.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.41 ms /    23 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11968.95 ms /    18 runs   (  664.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13241.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    18 runs   (    0.40 ms per token,  2473.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.20 ms /    24 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11733.55 ms /    17 runs   (  690.21 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13128.22 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    17 runs   (    0.40 ms per token,  2481.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.70 ms /    25 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10711.44 ms /    16 runs   (  669.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12078.99 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2505.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.10 ms /    25 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11976.55 ms /    18 runs   (  665.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13344.85 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    18 runs   (    0.40 ms per token,  2504.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.18 ms /    24 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11680.58 ms /    17 runs   (  687.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12938.55 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.34 ms /    29 runs   (    0.39 ms per token,  2558.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.16 ms /    25 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   18979.69 ms /    28 runs   (  677.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20353.37 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    17 runs   (    0.40 ms per token,  2476.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.43 ms /    25 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10653.82 ms /    16 runs   (  665.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12013.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     116.98 ms /   399 runs   (    0.29 ms per token,  3410.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.71 ms /    24 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =  271844.23 ms /   398 runs   (  683.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =  274359.73 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2537.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.74 ms /    24 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11387.90 ms /    17 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12677.05 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     116.07 ms /   396 runs   (    0.29 ms per token,  3411.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.27 ms /    28 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =  270153.21 ms /   395 runs   (  683.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =  272884.74 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2547.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.07 ms /    27 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10710.86 ms /    16 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12124.20 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2607.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.24 ms /    27 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12259.23 ms /    18 runs   (  681.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13712.90 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2600.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1480.06 ms /    27 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11435.15 ms /    17 runs   (  672.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12968.15 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2604.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.54 ms /    26 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12301.12 ms /    18 runs   (  683.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13678.58 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2544.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.77 ms /    27 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11272.48 ms /    17 runs   (  663.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12710.99 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.08 ms /    27 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11430.90 ms /    17 runs   (  672.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12886.30 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2582.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.90 ms /    26 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11378.24 ms /    17 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12745.13 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2559.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.26 ms /    27 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11764.30 ms /    17 runs   (  692.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13219.00 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.94 ms /    27 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10811.43 ms /    16 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12225.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2637.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.88 ms /    27 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11159.14 ms /    16 runs   (  697.45 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12570.47 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1307.98 ms /    26 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10920.61 ms /    16 runs   (  682.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12279.43 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2564.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.89 ms /    27 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12308.21 ms /    18 runs   (  683.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13793.64 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    16 runs   (    0.39 ms per token,  2565.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.16 ms /    27 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10633.65 ms /    15 runs   (  708.91 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   12146.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.41 ms /    26 tokens (   55.75 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10711.88 ms /    16 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12212.35 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    17 runs   (    0.40 ms per token,  2475.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.65 ms /    27 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10795.82 ms /    16 runs   (  674.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12216.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    29 runs   (    0.39 ms per token,  2573.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.89 ms /    27 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   19179.72 ms /    28 runs   (  684.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20678.56 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.16 ms /    27 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11993.77 ms /    18 runs   (  666.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13424.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.18 ms /    27 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12105.68 ms /    18 runs   (  672.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13518.69 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2640.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.90 ms /    27 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10675.46 ms /    16 runs   (  667.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12115.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.46 ms /    27 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12023.99 ms /    18 runs   (  668.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13476.26 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    19 runs   (    0.40 ms per token,  2492.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1349.72 ms /    27 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12179.63 ms /    18 runs   (  676.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13586.44 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2613.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.72 ms /    27 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10587.64 ms /    16 runs   (  661.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12018.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.73 ms /    27 tokens (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11244.40 ms /    17 runs   (  661.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12639.29 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.89 ms /    27 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10662.55 ms /    16 runs   (  666.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12130.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2608.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.76 ms /    27 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12110.99 ms /    18 runs   (  672.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13527.25 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2635.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.23 ms /    27 tokens (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10661.38 ms /    16 runs   (  666.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12065.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.26 ms /    27 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11359.58 ms /    17 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12764.67 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2640.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.31 ms /    27 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10772.73 ms /    16 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12184.99 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2581.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.19 ms /    27 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11567.79 ms /    18 runs   (  642.65 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   12972.38 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2579.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.27 ms /    26 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11350.56 ms /    17 runs   (  667.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12692.06 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2543.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.06 ms /    27 tokens (   49.59 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10912.28 ms /    16 runs   (  682.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12302.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2573.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.12 ms /    27 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12904.06 ms /    19 runs   (  679.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14329.45 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2581.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.60 ms /    27 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12040.30 ms /    18 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13528.54 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2586.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1349.54 ms /    27 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10631.70 ms /    16 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12030.77 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.68 ms /    27 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10669.43 ms /    16 runs   (  666.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12079.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.25 ms /    27 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10963.88 ms /    17 runs   (  644.93 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12375.04 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2609.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.99 ms /    27 tokens (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11841.15 ms /    18 runs   (  657.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13237.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2607.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.27 ms /    27 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11283.65 ms /    17 runs   (  663.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12687.89 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2585.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.38 ms /    27 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10635.74 ms /    16 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12023.29 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2565.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.58 ms /    27 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10806.37 ms /    16 runs   (  675.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12195.85 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.03 ms /    26 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10777.56 ms /    16 runs   (  673.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12141.81 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.27 ms /    16 runs   (    0.39 ms per token,  2550.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.62 ms /    27 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10123.45 ms /    15 runs   (  674.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11558.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.52 ms /    27 tokens (   58.69 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11326.69 ms /    17 runs   (  666.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12963.76 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2629.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.82 ms /    27 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12746.17 ms /    19 runs   (  670.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14152.79 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2574.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.86 ms /    27 tokens (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10885.97 ms /    16 runs   (  680.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12266.99 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.11 ms /    27 tokens (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11366.90 ms /    17 runs   (  668.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12749.94 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2583.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.99 ms /    27 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10787.32 ms /    16 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12178.41 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2488.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.94 ms /    27 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10651.16 ms /    16 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12049.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2594.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.54 ms /    27 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10635.94 ms /    16 runs   (  664.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12015.33 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.31 ms /    27 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11661.54 ms /    17 runs   (  685.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13086.54 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.50 ms /    27 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12237.44 ms /    18 runs   (  679.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13664.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2642.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.81 ms /    27 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =    7256.24 ms /    11 runs   (  659.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8654.53 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    19 runs   (    0.40 ms per token,  2503.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.92 ms /    27 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12051.25 ms /    18 runs   (  669.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13455.35 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.34 ms /    29 runs   (    0.39 ms per token,  2558.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.32 ms /    27 tokens (   51.83 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   18994.83 ms /    28 runs   (  678.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20479.74 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    20 runs   (    0.40 ms per token,  2494.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.76 ms /    27 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12925.73 ms /    19 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14378.83 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.80 ms /    27 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11461.52 ms /    17 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12979.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     125.41 ms /   396 runs   (    0.32 ms per token,  3157.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.00 ms /    27 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =  269310.08 ms /   395 runs   (  681.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  271905.58 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    19 runs   (    0.41 ms per token,  2448.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.65 ms /    27 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11954.13 ms /    18 runs   (  664.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13347.69 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.44 ms /    27 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10737.09 ms /    16 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12122.53 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2633.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.50 ms /    27 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10621.71 ms /    16 runs   (  663.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12034.25 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2665.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.59 ms /    27 tokens (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10796.03 ms /    16 runs   (  674.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12180.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2573.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.19 ms /    27 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11299.79 ms /    17 runs   (  664.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12680.78 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2662.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.40 ms /    27 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10657.75 ms /    16 runs   (  666.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12072.13 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2656.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.03 ms /    27 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12070.77 ms /    18 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13475.66 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.37 ms per token,  2667.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.34 ms /    27 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11359.54 ms /    17 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12743.84 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2633.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.99 ms /    27 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12419.92 ms /    18 runs   (  690.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13822.16 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    20 runs   (    0.40 ms per token,  2482.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.24 ms /    27 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12922.93 ms /    19 runs   (  680.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14343.00 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.57 ms /    27 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11445.59 ms /    17 runs   (  673.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12846.02 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2596.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1349.30 ms /    27 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10885.80 ms /    16 runs   (  680.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12284.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2635.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.32 ms /    27 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10619.68 ms /    16 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12011.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2650.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.99 ms /    27 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12079.28 ms /    18 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13477.95 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2630.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.35 ms /    27 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.92 ms /    16 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12128.18 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    16 runs   (    0.38 ms per token,  2603.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.74 ms /    27 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10054.77 ms /    15 runs   (  670.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11431.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.22 ms /    27 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11381.26 ms /    17 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12777.20 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2634.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.89 ms /    27 tokens (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10513.27 ms /    16 runs   (  657.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11890.48 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2615.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.92 ms /    27 tokens (   49.74 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12037.04 ms /    18 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13436.39 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.72 ms /    27 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12133.77 ms /    18 runs   (  674.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13586.44 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.99 ms /    27 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10750.10 ms /    16 runs   (  671.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12181.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2575.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.56 ms /    27 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12866.25 ms /    19 runs   (  677.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14255.51 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.07 ms /    27 tokens (   49.22 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12243.16 ms /    18 runs   (  680.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13627.76 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2610.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.65 ms /    27 tokens (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10559.84 ms /    16 runs   (  659.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11934.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2625.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.64 ms /    27 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10493.51 ms /    16 runs   (  655.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11870.04 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.19 ms /    27 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10913.79 ms /    16 runs   (  682.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12301.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    16 runs   (    0.39 ms per token,  2562.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.88 ms /    27 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10051.28 ms /    15 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11491.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2612.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.76 ms /    27 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11969.90 ms /    18 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13440.27 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2538.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.30 ms /    27 tokens (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12152.44 ms /    18 runs   (  675.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13546.87 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    19 runs   (    0.40 ms per token,  2503.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.44 ms /    27 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12202.24 ms /    18 runs   (  677.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13616.11 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2578.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.82 ms /    27 tokens (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11935.81 ms /    18 runs   (  663.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13321.75 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    28 runs   (    0.39 ms per token,  2579.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.16 ms /    27 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   18294.42 ms /    27 runs   (  677.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19738.67 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2561.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.59 ms /    27 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10828.16 ms /    16 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12263.77 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2560.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.75 ms /    27 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11107.35 ms /    17 runs   (  653.37 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12511.37 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2613.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.68 ms /    27 tokens (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10605.40 ms /    16 runs   (  662.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11984.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.01 ms /    27 tokens (   50.19 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10921.56 ms /    16 runs   (  682.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12326.16 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2576.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.24 ms /    26 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12169.02 ms /    18 runs   (  676.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13540.38 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2547.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.94 ms /    27 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11887.85 ms /    18 runs   (  660.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13320.79 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2584.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.47 ms /    27 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11644.37 ms /    17 runs   (  684.96 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13035.60 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2609.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.20 ms /    27 tokens (   49.79 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10694.00 ms /    16 runs   (  668.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12087.73 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.76 ms /    27 tokens (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12758.30 ms /    19 runs   (  671.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14160.43 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    18 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.21 ms /    27 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11628.27 ms /    17 runs   (  684.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13079.08 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2527.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.62 ms /    25 tokens (   50.26 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10985.79 ms /    16 runs   (  686.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12293.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    18 runs   (    0.40 ms per token,  2479.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.63 ms /    25 tokens (   50.19 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11846.26 ms /    17 runs   (  696.84 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13154.03 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2607.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.14 ms /    26 tokens (   54.04 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11479.09 ms /    17 runs   (  675.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12936.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.19 ms /    26 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11471.06 ms /    17 runs   (  674.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12850.14 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.76 ms /    25 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11235.04 ms /    17 runs   (  660.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12541.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2625.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.31 ms /    24 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12110.21 ms /    18 runs   (  672.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13372.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.67 ms /    24 runs   (    0.40 ms per token,  2483.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.26 ms /    26 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   15107.32 ms /    23 runs   (  656.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16511.55 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.06 ms /    26 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11263.75 ms /    17 runs   (  662.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12603.73 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2629.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.93 ms /    26 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10493.97 ms /    16 runs   (  655.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11837.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2594.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.76 ms /    26 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10541.01 ms /    16 runs   (  658.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11911.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2581.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.37 ms /    26 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12078.63 ms /    18 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13436.00 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2503.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.85 ms /    26 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10920.46 ms /    16 runs   (  682.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12311.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2588.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.22 ms /    25 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11979.02 ms /    18 runs   (  665.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13293.94 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2614.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.69 ms /    25 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12181.34 ms /    18 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13483.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2557.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.45 ms /    26 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12035.36 ms /    18 runs   (  668.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13418.32 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    18 runs   (    0.41 ms per token,  2467.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.38 ms /    26 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11468.39 ms /    17 runs   (  674.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12838.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.25 ms /    26 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10594.41 ms /    16 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11938.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2593.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.36 ms /    26 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11251.47 ms /    17 runs   (  661.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12646.17 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2549.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.10 ms /    26 tokens (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11309.94 ms /    17 runs   (  665.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12649.11 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2504.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.60 ms /    26 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11084.45 ms /    16 runs   (  692.78 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12449.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    17 runs   (    0.41 ms per token,  2414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.15 ms /    26 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10445.09 ms /    16 runs   (  652.82 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11786.61 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2596.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.98 ms /    25 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11480.78 ms /    17 runs   (  675.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12785.39 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2528.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.80 ms /    26 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11343.06 ms /    17 runs   (  667.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12696.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2558.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.76 ms /    26 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12055.57 ms /    18 runs   (  669.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13433.02 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    17 runs   (    0.40 ms per token,  2484.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.46 ms /    26 tokens (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10746.21 ms /    16 runs   (  671.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12086.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2592.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.63 ms /    26 tokens (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11318.02 ms /    17 runs   (  665.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12664.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2556.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.05 ms /    26 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11979.62 ms /    18 runs   (  665.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13360.13 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2537.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.57 ms /    26 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10645.49 ms /    16 runs   (  665.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12023.08 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.68 ms /    26 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10678.68 ms /    16 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12031.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2582.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.50 ms /    26 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12202.25 ms /    18 runs   (  677.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13573.29 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2609.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.41 ms /    25 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10905.76 ms /    16 runs   (  681.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12237.30 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    14 runs   (    0.38 ms per token,  2641.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.47 ms /    26 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =    8659.18 ms /    13 runs   (  666.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10000.88 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2561.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.90 ms /    26 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11213.22 ms /    17 runs   (  659.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12581.08 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.32 ms /    26 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11294.10 ms /    17 runs   (  664.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12673.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2608.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.96 ms /    26 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11244.76 ms /    17 runs   (  661.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12597.27 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2639.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.47 ms /    25 tokens (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11400.86 ms /    17 runs   (  670.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12694.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2655.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.07 ms /    26 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11364.23 ms /    17 runs   (  668.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12736.58 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    20 runs   (    0.38 ms per token,  2654.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.44 ms /    25 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12794.74 ms /    19 runs   (  673.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14096.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2575.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.12 ms /    25 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12821.16 ms /    19 runs   (  674.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14160.90 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2624.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.36 ms /    26 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11366.81 ms /    17 runs   (  668.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12724.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2617.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.71 ms /    25 tokens (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11999.83 ms /    18 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13299.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.39 ms /    26 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10705.20 ms /    16 runs   (  669.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12050.69 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.30 ms /    26 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11450.98 ms /    17 runs   (  673.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12787.37 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.18 ms /    26 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11366.82 ms /    17 runs   (  668.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12730.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2618.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.84 ms /    26 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12624.37 ms /    19 runs   (  664.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13975.24 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    19 runs   (    0.38 ms per token,  2646.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.71 ms /    26 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11782.30 ms /    18 runs   (  654.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13137.44 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    20 runs   (    0.38 ms per token,  2660.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.38 ms /    26 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12445.90 ms /    19 runs   (  655.05 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13802.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.82 ms /    25 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10475.79 ms /    16 runs   (  654.74 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11798.01 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    17 runs   (    0.41 ms per token,  2432.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.30 ms /    26 tokens (   52.70 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10572.66 ms /    16 runs   (  660.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11996.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2629.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.86 ms /    26 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12150.82 ms /    18 runs   (  675.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13492.72 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2599.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.50 ms /    25 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10673.59 ms /    16 runs   (  667.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11983.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2609.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.34 ms /    24 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10701.45 ms /    16 runs   (  668.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11966.00 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2548.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.02 ms /    26 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12695.97 ms /    19 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14069.53 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2592.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.59 ms /    26 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11883.82 ms /    18 runs   (  660.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13251.11 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2550.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.80 ms /    25 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11248.27 ms /    17 runs   (  661.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12543.00 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.02 ms /    26 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10672.27 ms /    16 runs   (  667.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12029.29 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    24 runs   (    0.39 ms per token,  2563.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.99 ms /    26 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   15302.34 ms /    23 runs   (  665.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16694.52 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2581.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.06 ms /    26 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10997.35 ms /    17 runs   (  646.90 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12359.11 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2532.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.28 ms /    26 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11858.62 ms /    18 runs   (  658.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13228.65 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.94 ms /    25 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12058.79 ms /    18 runs   (  669.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13389.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.03 ms /    26 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12700.27 ms /    20 runs   (  635.01 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =   14057.96 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.41 ms /    26 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12012.84 ms /    18 runs   (  667.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13380.67 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2557.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.69 ms /    26 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10370.39 ms /    16 runs   (  648.15 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11705.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.07 ms /    26 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11123.97 ms /    17 runs   (  654.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12508.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2561.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.74 ms /    25 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10435.82 ms /    16 runs   (  652.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11735.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    20 runs   (    0.38 ms per token,  2631.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.86 ms /    26 tokens (   49.84 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12376.14 ms /    19 runs   (  651.38 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13729.57 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    21 runs   (    0.38 ms per token,  2618.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.06 ms /    26 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13242.17 ms /    20 runs   (  662.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14615.38 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2616.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.78 ms /    25 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10877.63 ms /    16 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12169.42 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2594.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.63 ms /    25 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11657.74 ms /    18 runs   (  647.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12985.25 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2593.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.90 ms /    25 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11251.09 ms /    17 runs   (  661.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12613.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2547.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.07 ms /    26 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10506.94 ms /    16 runs   (  656.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11869.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2619.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.34 ms /    26 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10577.57 ms /    16 runs   (  661.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11949.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2611.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.12 ms /    26 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10747.28 ms /    16 runs   (  671.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12087.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2626.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.23 ms /    26 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10614.82 ms /    16 runs   (  663.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11981.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2543.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.81 ms /    26 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11082.84 ms /    17 runs   (  651.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12422.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.01 ms /    26 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10299.40 ms /    16 runs   (  643.71 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   11669.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    20 runs   (    0.39 ms per token,  2592.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.35 ms /    25 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12227.38 ms /    19 runs   (  643.55 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   13540.85 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2623.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.84 ms /    25 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =    9095.25 ms /    14 runs   (  649.66 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   10389.68 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2588.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.46 ms /    26 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11159.35 ms /    17 runs   (  656.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12529.70 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2557.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.63 ms /    26 tokens (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10418.67 ms /    16 runs   (  651.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11759.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2596.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.14 ms /    26 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11443.26 ms /    18 runs   (  635.74 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =   12813.93 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.58 ms /    26 tokens (   54.60 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11133.82 ms /    17 runs   (  654.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12606.31 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2597.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.79 ms /    25 tokens (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10653.84 ms /    16 runs   (  665.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11948.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2597.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.57 ms /    26 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10395.57 ms /    16 runs   (  649.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11731.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.95 ms /    26 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10658.46 ms /    16 runs   (  666.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11992.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.82 ms /    26 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11379.65 ms /    17 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12721.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    21 runs   (    0.39 ms per token,  2535.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.56 ms /    26 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   13117.28 ms /    20 runs   (  655.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14492.74 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.23 ms /    26 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11298.92 ms /    17 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12676.58 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2639.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.84 ms /    26 tokens (   49.84 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10600.77 ms /    16 runs   (  662.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11947.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2611.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.96 ms /    26 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11318.73 ms /    17 runs   (  665.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12682.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2502.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.38 ms /    26 tokens (   51.75 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10873.08 ms /    16 runs   (  679.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12268.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2589.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.27 ms /    26 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10779.56 ms /    16 runs   (  673.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12128.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2542.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.16 ms /    26 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11307.54 ms /    17 runs   (  665.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12672.04 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.99 ms /    26 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10547.09 ms /    16 runs   (  659.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11901.34 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2592.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.07 ms /    25 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10448.29 ms /    16 runs   (  653.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11753.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.14 ms /    26 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10599.31 ms /    16 runs   (  662.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11985.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.37 ms /    26 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11127.56 ms /    17 runs   (  654.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12479.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.52 ms /    26 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11300.94 ms /    17 runs   (  664.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12665.20 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2574.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.53 ms /    26 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12156.15 ms /    18 runs   (  675.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13514.32 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.55 ms /    26 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11366.37 ms /    17 runs   (  668.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12731.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.55 ms /   396 runs   (    0.29 ms per token,  3457.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.89 ms /    27 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =  266900.89 ms /   395 runs   (  675.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  269481.51 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    18 runs   (    0.41 ms per token,  2414.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.17 ms /    28 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11481.52 ms /    17 runs   (  675.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12928.94 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.34 ms /   396 runs   (    0.29 ms per token,  3493.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.79 ms /    27 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =  267606.09 ms /   395 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270136.28 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.73 ms /    27 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12065.03 ms /    18 runs   (  670.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13454.91 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    17 runs   (    0.43 ms per token,  2331.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.96 ms /    27 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10765.44 ms /    16 runs   (  672.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12178.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2555.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.43 ms /    28 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10803.50 ms /    16 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12234.17 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.04 ms /    28 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11305.54 ms /    17 runs   (  665.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12761.76 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.57 ms /    27 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11401.95 ms /    17 runs   (  670.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12897.10 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2578.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.40 ms /    26 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12563.95 ms /    19 runs   (  661.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13945.60 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2569.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.12 ms /    28 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11961.35 ms /    18 runs   (  664.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13406.82 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2594.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.31 ms /    28 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11482.51 ms /    17 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12921.78 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    22 runs   (    0.40 ms per token,  2531.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.36 ms /    27 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   14069.33 ms /    21 runs   (  669.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15466.02 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2584.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.44 ms /    28 tokens (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10750.88 ms /    16 runs   (  671.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12170.79 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.57 ms /    28 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11250.49 ms /    17 runs   (  661.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12674.67 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2529.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.72 ms /    26 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11308.43 ms /    17 runs   (  665.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12673.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2588.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.96 ms /    26 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12099.95 ms /    18 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13463.19 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.61 ms /    28 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10604.44 ms /    16 runs   (  662.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12189.75 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2665.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.77 ms /    28 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10414.36 ms /    16 runs   (  650.90 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11851.76 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    19 runs   (    0.40 ms per token,  2530.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.61 ms /    27 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12137.99 ms /    18 runs   (  674.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13526.98 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.84 ms /    25 runs   (    0.39 ms per token,  2540.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.68 ms /    27 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   16358.14 ms /    24 runs   (  681.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17774.15 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2581.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.91 ms /    27 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10494.65 ms /    16 runs   (  655.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11896.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2591.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.99 ms /    28 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11135.40 ms /    17 runs   (  655.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12568.66 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2580.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.93 ms /    28 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11951.20 ms /    18 runs   (  663.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13414.43 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2553.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.78 ms /    26 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   13063.46 ms /    20 runs   (  653.17 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14419.60 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    17 runs   (    0.43 ms per token,  2337.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.70 ms /    28 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10928.92 ms /    16 runs   (  683.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12380.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.39 ms per token,  2596.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1531.04 ms /    28 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12508.32 ms /    19 runs   (  658.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14099.15 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    20 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.40 ms /    27 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12438.03 ms /    19 runs   (  654.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13838.71 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    22 runs   (    0.38 ms per token,  2629.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.57 ms /    27 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13977.93 ms /    21 runs   (  665.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15375.51 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.25 ms /    28 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10390.98 ms /    16 runs   (  649.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11830.96 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.19 ms /    28 tokens (   49.54 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11313.79 ms /    17 runs   (  665.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12753.78 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2577.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.41 ms /    27 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11348.85 ms /    17 runs   (  667.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12764.60 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2580.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.77 ms /    27 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11156.20 ms /    17 runs   (  656.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12549.96 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2577.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.72 ms /    27 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12300.54 ms /    19 runs   (  647.40 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13703.66 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2614.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.09 ms /    28 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11972.03 ms /    18 runs   (  665.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13419.64 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2543.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.61 ms /    28 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11111.81 ms /    17 runs   (  653.64 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12624.39 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2636.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.36 ms /    27 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10902.36 ms /    17 runs   (  641.32 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   12320.98 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2608.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.24 ms /    27 tokens (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11082.44 ms /    17 runs   (  651.91 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12464.59 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2579.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.81 ms /    28 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12594.68 ms /    19 runs   (  662.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14032.58 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    20 runs   (    0.39 ms per token,  2567.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.24 ms /    28 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12667.08 ms /    19 runs   (  666.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14111.91 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2555.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.64 ms /    27 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12492.33 ms /    19 runs   (  657.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13889.03 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.38 ms /    27 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10378.00 ms /    16 runs   (  648.63 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11780.56 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     115.98 ms /   396 runs   (    0.29 ms per token,  3414.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.24 ms /    28 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =  268354.07 ms /   395 runs   (  679.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  270945.32 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.84 ms /    28 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11183.51 ms /    17 runs   (  657.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12621.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     116.45 ms /   396 runs   (    0.29 ms per token,  3400.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.69 ms /    27 tokens (   49.84 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =  266605.87 ms /   395 runs   (  674.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  269176.88 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.12 ms /    28 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10663.77 ms /    16 runs   (  666.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12092.84 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    19 runs   (    0.40 ms per token,  2517.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.77 ms /    28 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11939.37 ms /    18 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13379.14 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    20 runs   (    0.39 ms per token,  2591.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.68 ms /    27 tokens (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12394.53 ms /    19 runs   (  652.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13784.91 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2555.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.05 ms /    27 tokens (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12138.79 ms /    18 runs   (  674.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13531.06 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2629.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.18 ms /    28 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10724.63 ms /    16 runs   (  670.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12171.26 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2588.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.49 ms /    28 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12250.07 ms /    18 runs   (  680.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13708.15 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2586.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.27 ms /    27 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11707.98 ms /    17 runs   (  688.70 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13135.17 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    21 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.87 ms /    27 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13390.30 ms /    20 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14817.22 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.50 ms /    27 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11426.88 ms /    17 runs   (  672.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12822.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2597.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.65 ms /    28 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10667.89 ms /    16 runs   (  666.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12114.01 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2545.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.92 ms /    28 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11341.63 ms /    17 runs   (  667.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12795.45 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     123.62 ms /   396 runs   (    0.31 ms per token,  3203.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.11 ms /    27 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =  267738.78 ms /   395 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270303.47 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    17 runs   (    0.43 ms per token,  2351.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.09 ms /    28 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11088.13 ms /    16 runs   (  693.01 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12540.81 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2599.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.50 ms /    28 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11402.61 ms /    17 runs   (  670.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12869.10 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2588.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.44 ms /    27 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11400.95 ms /    17 runs   (  670.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12800.62 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.35 ms /    27 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11222.46 ms /    17 runs   (  660.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12691.11 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.16 ms /    28 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10457.40 ms /    16 runs   (  653.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11905.44 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2585.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.52 ms /    28 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10659.77 ms /    16 runs   (  666.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12104.46 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2585.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.23 ms /    27 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12209.47 ms /    18 runs   (  678.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13606.25 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.97 ms /    27 tokens (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11989.89 ms /    18 runs   (  666.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13392.50 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2560.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.93 ms /    27 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12116.43 ms /    18 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13523.78 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2607.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.34 ms /    28 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12676.97 ms /    19 runs   (  667.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14175.57 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    19 runs   (    0.42 ms per token,  2381.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.67 ms /    28 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12145.77 ms /    18 runs   (  674.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13608.67 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2586.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.85 ms /    27 tokens (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12645.73 ms /    19 runs   (  665.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14034.37 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2554.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.10 ms /    27 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10683.70 ms /    16 runs   (  667.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12076.12 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2520.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.39 ms /    28 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10945.38 ms /    16 runs   (  684.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12438.53 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.45 ms /    28 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11536.72 ms /    17 runs   (  678.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13028.60 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    23 runs   (    0.38 ms per token,  2620.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1364.32 ms /    27 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   14817.35 ms /    22 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16249.03 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    22 runs   (    0.40 ms per token,  2503.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.51 ms /    28 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   14422.57 ms /    21 runs   (  686.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15870.85 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2605.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.53 ms /    28 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12591.74 ms /    19 runs   (  662.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14063.55 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2607.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.52 ms /    27 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12016.34 ms /    18 runs   (  667.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13416.07 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.31 ms /    27 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11593.56 ms /    17 runs   (  681.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12981.89 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2594.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.51 ms /    28 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11961.71 ms /    18 runs   (  664.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13429.55 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    18 runs   (    0.45 ms per token,  2206.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.06 ms /    28 tokens (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11272.52 ms /    17 runs   (  663.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12706.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    19 runs   (    0.40 ms per token,  2499.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.32 ms /    27 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12348.94 ms /    18 runs   (  686.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13800.61 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.61 ms /    27 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11319.12 ms /    17 runs   (  665.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12720.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.34 ms /    28 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11243.10 ms /    17 runs   (  661.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12703.85 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    21 runs   (    0.39 ms per token,  2580.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.83 ms /    28 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13534.83 ms /    20 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15007.24 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2565.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1871.25 ms /    26 tokens (   71.97 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12197.63 ms /    18 runs   (  677.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14124.82 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2622.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.82 ms /    26 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12175.56 ms /    18 runs   (  676.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13567.31 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    22 runs   (    0.39 ms per token,  2579.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.04 ms /    28 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   13988.11 ms /    21 runs   (  666.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15430.17 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.24 ms /    28 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11171.53 ms /    17 runs   (  657.15 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12602.20 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.79 ms /    27 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11223.23 ms /    17 runs   (  660.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12643.90 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2549.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.69 ms /    27 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12556.23 ms /    19 runs   (  660.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13963.70 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.75 ms /    28 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10563.47 ms /    16 runs   (  660.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11989.75 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.24 ms /    28 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10499.51 ms /    16 runs   (  656.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11941.40 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2601.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.21 ms /    27 tokens (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11371.97 ms /    17 runs   (  668.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12750.50 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2570.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.33 ms /    27 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11995.26 ms /    18 runs   (  666.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13389.55 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2585.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1349.23 ms /    27 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10685.10 ms /    16 runs   (  667.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12085.04 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2527.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.59 ms /    28 tokens (   49.74 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10547.43 ms /    16 runs   (  659.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11990.36 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2546.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.52 ms /    28 tokens (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12017.92 ms /    18 runs   (  667.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13449.94 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    22 runs   (    0.38 ms per token,  2625.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.10 ms /    27 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   13906.31 ms /    21 runs   (  662.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15328.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2571.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.84 ms /    27 tokens (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10721.62 ms /    16 runs   (  670.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12113.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2557.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.30 ms /    28 tokens (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10717.48 ms /    16 runs   (  669.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12143.83 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    21 runs   (    0.39 ms per token,  2562.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.56 ms /    28 tokens (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   13517.25 ms /    20 runs   (  675.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14974.08 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2552.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.01 ms /    27 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12984.03 ms /    19 runs   (  683.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14387.63 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2546.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.43 ms /    28 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12835.99 ms /    19 runs   (  675.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14278.17 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    17 runs   (    0.40 ms per token,  2493.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.78 ms /    28 tokens (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10754.94 ms /    16 runs   (  672.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12185.44 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2617.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.49 ms /    27 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11907.89 ms /    18 runs   (  661.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13317.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    18 runs   (    0.41 ms per token,  2441.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.83 ms /    27 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11216.33 ms /    17 runs   (  659.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12629.50 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.15 ms /    29 runs   (    0.38 ms per token,  2599.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.88 ms /    28 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   18885.62 ms /    28 runs   (  674.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20356.54 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2539.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.94 ms /    28 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10491.04 ms /    16 runs   (  655.69 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11931.05 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    23 runs   (    0.39 ms per token,  2574.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.69 ms /    27 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   14820.94 ms /    22 runs   (  673.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16251.74 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2599.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.64 ms /    27 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11436.94 ms /    17 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12821.12 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      22.26 ms /    55 runs   (    0.40 ms per token,  2471.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.06 ms /    27 tokens (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   36457.40 ms /    54 runs   (  675.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   37955.94 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2565.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.19 ms /    28 tokens (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12553.39 ms /    19 runs   (  660.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13987.93 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2584.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.20 ms /    28 tokens (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12218.54 ms /    18 runs   (  678.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13654.97 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.27 ms /   396 runs   (    0.29 ms per token,  3465.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.93 ms /    27 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =  266059.31 ms /   395 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268630.23 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2561.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.15 ms /    27 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12136.87 ms /    18 runs   (  674.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13528.87 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.62 ms /    28 tokens (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11419.07 ms /    17 runs   (  671.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12851.27 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2586.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.65 ms /    28 tokens (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   13242.76 ms /    20 runs   (  662.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14683.46 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2610.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.64 ms /    27 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12832.27 ms /    19 runs   (  675.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14229.48 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2550.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.04 ms /    28 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12124.62 ms /    18 runs   (  673.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13573.84 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    17 runs   (    0.40 ms per token,  2528.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.28 ms /    28 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10608.97 ms /    16 runs   (  663.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12057.20 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    30 runs   (    0.42 ms per token,  2402.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.26 ms /    27 tokens (   49.94 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19190.10 ms /    29 runs   (  661.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20632.50 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2567.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.10 ms /    27 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12076.01 ms /    18 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13470.31 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.88 ms /    23 runs   (    0.39 ms per token,  2590.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.67 ms /    28 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   14930.19 ms /    22 runs   (  678.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16397.99 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    17 runs   (    0.40 ms per token,  2484.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.04 ms /    28 tokens (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10712.25 ms /    16 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12139.98 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.69 ms /    27 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12110.82 ms /    18 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13528.00 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    20 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.80 ms /    27 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12803.20 ms /    19 runs   (  673.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14207.90 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.47 ms /    29 runs   (    0.40 ms per token,  2528.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.42 ms /    28 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   18791.64 ms /    28 runs   (  671.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20271.55 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    17 runs   (    0.40 ms per token,  2508.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.88 ms /    28 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10560.88 ms /    16 runs   (  660.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11997.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2523.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.70 ms /    27 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12734.76 ms /    19 runs   (  670.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14133.74 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2520.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.67 ms /    27 tokens (   49.91 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11545.20 ms /    17 runs   (  679.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12945.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.67 ms /    27 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10915.82 ms /    16 runs   (  682.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12295.93 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.08 ms /    28 tokens (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11446.03 ms /    17 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12884.75 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    20 runs   (    0.38 ms per token,  2620.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.60 ms /    28 tokens (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12829.28 ms /    19 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14274.10 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2702.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.62 ms /    27 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11170.79 ms /    17 runs   (  657.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12561.41 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    17 runs   (    0.45 ms per token,  2223.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.47 ms /    27 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10743.03 ms /    16 runs   (  671.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12141.51 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2578.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.36 ms /    28 tokens (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10822.27 ms /    16 runs   (  676.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12253.15 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.20 ms /    28 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12613.27 ms /    19 runs   (  663.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14132.83 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.80 ms /    27 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11248.46 ms /    17 runs   (  661.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12637.17 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    19 runs   (    0.40 ms per token,  2500.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.57 ms /    27 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11920.43 ms /    18 runs   (  662.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13310.48 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.33 ms /    28 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10722.96 ms /    16 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12166.78 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.89 ms /    28 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12951.36 ms /    19 runs   (  681.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14390.34 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    21 runs   (    0.38 ms per token,  2604.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.47 ms /    27 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13463.76 ms /    20 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14856.10 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.76 ms /    27 tokens (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12134.48 ms /    18 runs   (  674.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13534.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    20 runs   (    0.44 ms per token,  2261.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.95 ms /    28 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12240.62 ms /    19 runs   (  644.24 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   13687.98 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2557.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.69 ms /    28 tokens (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11122.82 ms /    17 runs   (  654.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12551.74 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2604.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.27 ms /    27 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   12401.13 ms /    19 runs   (  652.69 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13833.23 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.18 ms /    28 tokens (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12103.18 ms /    19 runs   (  637.01 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =   13544.13 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.01 ms /    16 runs   (    0.38 ms per token,  2660.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.15 ms /    28 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =    9783.46 ms /    15 runs   (  652.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11216.61 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    20 runs   (    0.39 ms per token,  2565.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.23 ms /    27 tokens (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12773.37 ms /    19 runs   (  672.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14155.67 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2618.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.13 ms /    27 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12581.16 ms /    19 runs   (  662.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13991.37 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.86 ms /    27 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10781.38 ms /    16 runs   (  673.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12219.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2536.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.28 ms /    28 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11220.80 ms /    17 runs   (  660.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12671.09 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2585.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.36 ms /    28 tokens (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12002.71 ms /    18 runs   (  666.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13435.75 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.77 ms /    27 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11588.35 ms /    18 runs   (  643.80 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12977.55 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1522.41 ms /    28 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10629.49 ms /    16 runs   (  664.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12201.48 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    19 runs   (    0.40 ms per token,  2520.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.93 ms /    28 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12024.74 ms /    18 runs   (  668.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13512.30 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2582.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.03 ms /    27 tokens (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11130.71 ms /    17 runs   (  654.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12514.09 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2610.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.11 ms /    27 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11270.93 ms /    17 runs   (  663.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12652.70 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    19 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.50 ms /    28 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12036.44 ms /    18 runs   (  668.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13505.01 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2610.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.84 ms /    28 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11886.68 ms /    18 runs   (  660.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13324.10 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    21 runs   (    0.39 ms per token,  2566.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.34 ms /    27 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13212.79 ms /    20 runs   (  660.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14625.43 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.15 ms /    27 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11359.85 ms /    17 runs   (  668.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12759.05 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    19 runs   (    0.40 ms per token,  2513.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.59 ms /    27 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12168.52 ms /    18 runs   (  676.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13581.21 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     129.25 ms /   396 runs   (    0.33 ms per token,  3063.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.73 ms /    28 tokens (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_print_timings:        eval time =  266733.37 ms /   395 runs   (  675.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  269332.91 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2616.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.79 ms /    28 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12759.60 ms /    19 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14205.28 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2628.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.89 ms /    27 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11460.52 ms /    17 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12847.06 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2581.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.05 ms /    28 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10634.57 ms /    16 runs   (  664.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12105.46 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2579.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.50 ms /    28 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11010.03 ms /    17 runs   (  647.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12489.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    23 runs   (    0.39 ms per token,  2570.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.66 ms /    27 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   14449.83 ms /    22 runs   (  656.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15872.90 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    21 runs   (    0.39 ms per token,  2564.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.08 ms /    27 tokens (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13351.17 ms /    20 runs   (  667.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14748.34 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.57 ms /    27 tokens (   49.84 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11395.66 ms /    17 runs   (  670.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12794.34 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     4 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.30 ms /    28 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1990.87 ms /     3 runs   (  663.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    3413.37 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    19 runs   (    0.45 ms per token,  2239.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.58 ms /    28 tokens (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11744.64 ms /    18 runs   (  652.48 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13184.70 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    24 runs   (    0.40 ms per token,  2512.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.87 ms /    27 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   15331.91 ms /    23 runs   (  666.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16743.63 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2543.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.78 ms /    27 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10790.35 ms /    16 runs   (  674.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12204.14 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.42 ms /    28 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11366.56 ms /    17 runs   (  668.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12817.32 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    21 runs   (    0.39 ms per token,  2565.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.95 ms /    28 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13293.73 ms /    20 runs   (  664.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14768.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     133.61 ms /   329 runs   (    0.41 ms per token,  2462.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.63 ms /    27 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =  221543.95 ms /   328 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  223948.35 ms /   355 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2514.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.80 ms /    28 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11644.50 ms /    17 runs   (  684.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13114.75 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.72 ms /   396 runs   (    0.29 ms per token,  3482.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.24 ms /    28 tokens (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =  267617.88 ms /   395 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270210.26 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2547.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.97 ms /    27 tokens (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12547.03 ms /    19 runs   (  660.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13937.63 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.00 ms /    23 runs   (    0.39 ms per token,  2554.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.45 ms /    27 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   15350.87 ms /    22 runs   (  697.77 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   16776.02 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2553.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.10 ms /    27 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10630.08 ms /    16 runs   (  664.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12048.63 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.34 ms /    28 tokens (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10498.12 ms /    16 runs   (  656.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11930.54 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2547.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.04 ms /    28 tokens (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11391.47 ms /    17 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12817.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2555.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.35 ms /    27 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11679.71 ms /    18 runs   (  648.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13076.89 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.29 ms /    28 tokens (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11918.71 ms /    18 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13348.60 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.62 ms /    28 tokens (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10957.86 ms /    17 runs   (  644.58 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12383.60 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      48.99 ms /   121 runs   (    0.40 ms per token,  2469.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.88 ms /    27 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   79399.41 ms /   120 runs   (  661.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   81115.26 ms /   147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2581.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.52 ms /    27 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11839.32 ms /    18 runs   (  657.74 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13250.34 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2554.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.83 ms /    28 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11916.07 ms /    18 runs   (  662.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13349.77 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2593.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.41 ms /    28 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10610.25 ms /    16 runs   (  663.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12047.26 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    19 runs   (    0.44 ms per token,  2287.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.28 ms /    27 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11880.44 ms /    18 runs   (  660.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13278.65 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.40 ms /    27 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11141.06 ms /    17 runs   (  655.36 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12526.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2563.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.57 ms /    27 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11304.82 ms /    17 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12708.18 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    17 runs   (    0.37 ms per token,  2678.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.92 ms /    28 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10680.63 ms /    16 runs   (  667.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12128.02 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2549.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.08 ms /    28 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12693.72 ms /    19 runs   (  668.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14145.78 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2529.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.53 ms /    27 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11030.54 ms /    17 runs   (  648.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12425.74 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.21 ms /   396 runs   (    0.29 ms per token,  3467.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.42 ms /    28 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =  267200.03 ms /   395 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  269806.89 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2573.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.91 ms /    28 tokens (   49.18 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11818.58 ms /    18 runs   (  656.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13250.09 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2555.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.12 ms /    27 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13236.37 ms /    20 runs   (  661.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14633.24 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    20 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.25 ms /    27 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12730.07 ms /    19 runs   (  670.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14131.45 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     115.24 ms /   398 runs   (    0.29 ms per token,  3453.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.18 ms /    26 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =  270233.52 ms /   397 runs   (  680.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  272807.17 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2551.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.71 ms /    26 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11277.21 ms /    17 runs   (  663.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12645.95 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    22 runs   (    0.40 ms per token,  2519.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.12 ms /    25 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13805.77 ms /    21 runs   (  657.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15117.26 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.81 ms /    25 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12128.31 ms /    18 runs   (  673.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13502.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    21 runs   (    0.39 ms per token,  2572.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.07 ms /    27 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13134.36 ms /    20 runs   (  656.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14532.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.65 ms /    27 tokens (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12011.26 ms /    18 runs   (  667.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13396.90 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     116.40 ms /   397 runs   (    0.29 ms per token,  3410.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.28 ms /    26 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =  268827.63 ms /   396 runs   (  678.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  271338.39 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2586.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.13 ms /    26 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12445.84 ms /    19 runs   (  655.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13801.17 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    19 runs   (    0.40 ms per token,  2528.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.24 ms /    25 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12067.90 ms /    18 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13372.48 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.55 ms /    26 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10662.69 ms /    16 runs   (  666.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12005.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2573.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.97 ms /    26 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11399.01 ms /    17 runs   (  670.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12752.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2547.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.97 ms /    24 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11970.04 ms /    18 runs   (  665.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13227.16 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.63 ms /    35 runs   (    0.39 ms per token,  2568.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.15 ms /    27 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   22762.88 ms /    34 runs   (  669.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24210.86 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    21 runs   (    0.39 ms per token,  2565.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.50 ms /    27 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   13380.37 ms /    20 runs   (  669.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14773.95 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2594.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.64 ms /    26 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13410.13 ms /    20 runs   (  670.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14789.00 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2563.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.75 ms /    26 tokens (   49.64 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12520.78 ms /    19 runs   (  658.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13869.32 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1349.02 ms /    27 tokens (   49.96 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12445.94 ms /    19 runs   (  655.05 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13853.52 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2547.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.04 ms /    27 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12754.43 ms /    19 runs   (  671.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14188.25 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.17 ms /    26 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11397.70 ms /    17 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12739.16 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2660.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.58 ms /    26 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11115.26 ms /    17 runs   (  653.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12461.17 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    18 runs   (    0.40 ms per token,  2481.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.54 ms /    26 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11436.75 ms /    17 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12835.82 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.49 ms /    27 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12034.99 ms /    18 runs   (  668.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13448.82 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.27 ms /    27 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11981.72 ms /    18 runs   (  665.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13369.77 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    19 runs   (    0.40 ms per token,  2519.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.75 ms /    26 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   11999.58 ms /    18 runs   (  666.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13389.07 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2592.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.08 ms /    26 tokens (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12640.04 ms /    19 runs   (  665.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13989.25 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2578.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.06 ms /    26 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10613.11 ms /    16 runs   (  663.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11949.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    23 runs   (    0.40 ms per token,  2522.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.30 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14434.23 ms /    22 runs   (  656.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15777.62 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    18 runs   (    0.45 ms per token,  2242.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.89 ms /    25 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11356.96 ms /    17 runs   (  668.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12659.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.12 ms /    27 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   12051.00 ms /    18 runs   (  669.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13490.82 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.39 ms per token,  2532.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1467.35 ms /    27 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11410.38 ms /    17 runs   (  671.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12931.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    19 runs   (    0.40 ms per token,  2519.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.01 ms /    26 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12086.43 ms /    18 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13455.11 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2653.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.95 ms /    26 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12279.95 ms /    18 runs   (  682.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13629.32 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2572.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.73 ms /    27 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10692.45 ms /    16 runs   (  668.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12164.88 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2562.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.20 ms /    27 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12075.99 ms /    18 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13487.99 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2563.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.00 ms /    26 tokens (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12571.33 ms /    19 runs   (  661.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13921.96 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2592.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.95 ms /    26 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11949.14 ms /    18 runs   (  663.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13317.19 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2525.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.76 ms /    26 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11409.37 ms /    17 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12754.14 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    18 runs   (    0.40 ms per token,  2507.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.84 ms /    27 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11432.58 ms /    17 runs   (  672.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12828.12 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2507.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.51 ms /    27 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11893.89 ms /    18 runs   (  660.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13308.76 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.21 ms /    26 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11313.08 ms /    17 runs   (  665.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12651.51 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.45 ms /    27 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10274.46 ms /    16 runs   (  642.15 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   11656.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2550.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.14 ms /    27 tokens (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10610.44 ms /    16 runs   (  663.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11990.16 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    25 runs   (    0.39 ms per token,  2586.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.78 ms /    25 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   16081.68 ms /    24 runs   (  670.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17396.84 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.43 ms /    25 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11387.73 ms /    17 runs   (  669.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12716.37 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2547.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.41 ms /    27 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11213.94 ms /    17 runs   (  659.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12619.05 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2505.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.08 ms /    27 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11907.23 ms /    18 runs   (  661.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13425.21 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.06 ms /    23 runs   (    0.39 ms per token,  2539.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.76 ms /    26 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   14892.34 ms /    22 runs   (  676.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16264.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2597.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.91 ms /    26 tokens (   51.53 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   13344.86 ms /    20 runs   (  667.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14746.51 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.26 ms /    27 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10466.12 ms /    16 runs   (  654.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11849.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2581.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.54 ms /    27 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11876.95 ms /    18 runs   (  659.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13298.41 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.75 ms /    26 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11249.03 ms /    17 runs   (  661.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12699.62 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2551.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.73 ms /    26 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12034.96 ms /    18 runs   (  668.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13389.56 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2635.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.58 ms /    26 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11453.59 ms /    17 runs   (  673.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12818.88 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2579.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.02 ms /    27 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11233.95 ms /    17 runs   (  660.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12639.93 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    21 runs   (    0.38 ms per token,  2608.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.01 ms /    27 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13491.60 ms /    20 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14903.77 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2593.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.76 ms /    26 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11373.17 ms /    17 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12744.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.36 ms /    29 runs   (    0.39 ms per token,  2552.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.38 ms /    26 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   18771.85 ms /    28 runs   (  670.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20186.82 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2591.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.82 ms /    27 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11276.32 ms /    17 runs   (  663.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12682.89 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    21 runs   (    0.39 ms per token,  2565.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.07 ms /    27 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13179.98 ms /    20 runs   (  659.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14584.53 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2548.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.13 ms /    26 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12660.25 ms /    19 runs   (  666.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14003.78 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.97 ms /    25 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11543.60 ms /    17 runs   (  679.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12844.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2589.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.34 ms /    27 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11520.01 ms /    17 runs   (  677.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12947.34 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2600.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.69 ms /    27 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12642.31 ms /    19 runs   (  665.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14048.95 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2579.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.60 ms /    26 tokens (   53.18 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12731.44 ms /    19 runs   (  670.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14172.38 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     128.81 ms /   397 runs   (    0.32 ms per token,  3081.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.01 ms /    26 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =  267499.16 ms /   396 runs   (  675.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270033.52 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2561.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.83 ms /    27 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11526.28 ms /    17 runs   (  678.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12926.41 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    21 runs   (    0.38 ms per token,  2617.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.94 ms /    27 tokens (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   13428.59 ms /    20 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14823.13 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2570.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.49 ms /    26 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12117.94 ms /    18 runs   (  673.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13491.66 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     119.17 ms /   397 runs   (    0.30 ms per token,  3331.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.74 ms /    27 tokens (   49.84 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =  267897.44 ms /   396 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  270458.98 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.34 ms /    27 tokens (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11482.49 ms /    17 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12860.40 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    32 runs   (    0.38 ms per token,  2613.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.24 ms /    25 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   20494.42 ms /    31 runs   (  661.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21856.55 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2613.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.64 ms /    25 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11809.47 ms /    18 runs   (  656.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13129.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2553.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.66 ms /    27 tokens (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11406.97 ms /    17 runs   (  671.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12791.55 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2629.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.73 ms /    27 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11361.44 ms /    17 runs   (  668.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12744.95 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2605.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.86 ms /    25 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12112.13 ms /    18 runs   (  672.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13441.00 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2552.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.34 ms /    25 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11429.52 ms /    17 runs   (  672.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12750.17 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2617.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.39 ms /    27 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10555.64 ms /    16 runs   (  659.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11951.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2545.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.18 ms /    27 tokens (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11486.67 ms /    17 runs   (  675.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12866.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     115.80 ms /   397 runs   (    0.29 ms per token,  3428.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.37 ms /    26 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =  268635.60 ms /   396 runs   (  678.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  271237.27 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    23 runs   (    0.40 ms per token,  2498.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.75 ms /    26 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   14803.37 ms /    22 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16177.82 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.83 ms /    27 tokens (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10689.09 ms /    16 runs   (  668.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12068.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2546.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.10 ms /    27 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12155.23 ms /    18 runs   (  675.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13599.54 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    19 runs   (    0.40 ms per token,  2501.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.11 ms /    26 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11834.00 ms /    18 runs   (  657.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13192.61 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2542.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.83 ms /    26 tokens (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12071.09 ms /    18 runs   (  670.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13409.59 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2534.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.45 ms /    26 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11305.86 ms /    17 runs   (  665.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12654.85 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.33 ms /    27 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11365.13 ms /    17 runs   (  668.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12766.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.55 ms /    27 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11403.12 ms /    17 runs   (  670.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12813.52 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.40 ms /    26 tokens (   49.52 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11986.60 ms /    18 runs   (  665.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13328.23 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2516.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.46 ms /    27 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10471.04 ms /    16 runs   (  654.44 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11890.41 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2579.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.43 ms /    27 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12015.25 ms /    18 runs   (  667.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13429.87 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.80 ms /    26 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11383.94 ms /    17 runs   (  669.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12735.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.73 ms /   397 runs   (    0.29 ms per token,  3460.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.05 ms /    26 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =  269986.37 ms /   396 runs   (  681.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  272511.50 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    22 runs   (    0.39 ms per token,  2553.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.69 ms /    26 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13999.95 ms /    21 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15407.88 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.40 ms /    27 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10627.33 ms /    16 runs   (  664.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12027.91 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2545.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.75 ms /    27 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11334.71 ms /    17 runs   (  666.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12761.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2632.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.58 ms /    25 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10782.18 ms /    16 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12091.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    22 runs   (    0.39 ms per token,  2564.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.60 ms /    26 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   14144.06 ms /    21 runs   (  673.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15507.43 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2545.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.41 ms /    27 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12082.73 ms /    18 runs   (  671.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13532.64 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.03 ms /    26 runs   (    0.39 ms per token,  2593.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.98 ms /    27 tokens (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   16670.67 ms /    25 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18080.07 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    19 runs   (    0.44 ms per token,  2264.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.66 ms /    26 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11817.23 ms /    18 runs   (  656.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13181.31 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2632.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.94 ms /    26 tokens (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11332.51 ms /    17 runs   (  666.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12669.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.67 ms /    26 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10774.21 ms /    16 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12135.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    19 runs   (    0.44 ms per token,  2277.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.34 ms /    24 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12166.48 ms /    18 runs   (  675.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13536.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2519.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.55 ms /    24 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11296.43 ms /    17 runs   (  664.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12561.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    20 runs   (    0.40 ms per token,  2513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.03 ms /    27 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12720.57 ms /    19 runs   (  669.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14151.68 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    17 runs   (    0.44 ms per token,  2295.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.02 ms /    27 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10499.01 ms /    16 runs   (  656.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11882.54 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    17 runs   (    0.44 ms per token,  2266.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.05 ms /    26 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10762.14 ms /    16 runs   (  672.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12103.67 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    22 runs   (    0.39 ms per token,  2583.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.84 ms /    26 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14177.38 ms /    21 runs   (  675.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15570.48 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2546.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.09 ms /    27 tokens (   50.11 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11810.78 ms /    18 runs   (  656.15 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13219.47 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2628.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.90 ms /    27 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11319.19 ms /    17 runs   (  665.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12703.12 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    19 runs   (    0.38 ms per token,  2639.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.13 ms /    26 tokens (   50.24 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12083.97 ms /    18 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13445.06 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.27 ms /    26 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10749.23 ms /    16 runs   (  671.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12115.90 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2540.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.71 ms /    27 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11358.48 ms /    17 runs   (  668.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12770.17 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    18 runs   (    0.40 ms per token,  2507.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.96 ms /    27 tokens (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11327.72 ms /    17 runs   (  666.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12707.47 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2541.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.40 ms /    26 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12193.83 ms /    18 runs   (  677.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13545.95 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    20 runs   (    0.44 ms per token,  2266.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.51 ms /    26 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12797.82 ms /    19 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14164.55 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2562.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.79 ms /    27 tokens (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.74 ms /    16 runs   (  665.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12035.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    21 runs   (    0.39 ms per token,  2549.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.41 ms /    27 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   13310.12 ms /    20 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14740.24 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2589.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.93 ms /    25 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11389.75 ms /    17 runs   (  669.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12684.44 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.42 ms /    25 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11950.45 ms /    18 runs   (  663.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13272.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     157.85 ms /   397 runs   (    0.40 ms per token,  2515.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.46 ms /    26 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =  267317.25 ms /   396 runs   (  675.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  269856.89 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2613.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.21 ms /    27 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12524.26 ms /    19 runs   (  659.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13916.84 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.33 ms /    27 tokens (   49.49 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10743.88 ms /    16 runs   (  671.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12130.03 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2593.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.57 ms /    26 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12788.45 ms /    19 runs   (  673.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14209.79 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2532.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.78 ms /    26 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10631.28 ms /    16 runs   (  664.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11974.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.20 ms /    27 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10631.12 ms /    16 runs   (  664.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12030.70 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2596.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.93 ms /    27 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11407.99 ms /    17 runs   (  671.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12834.64 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    17 runs   (    0.41 ms per token,  2457.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.32 ms /    26 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10734.00 ms /    16 runs   (  670.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12095.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.54 ms /    24 runs   (    0.40 ms per token,  2514.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.00 ms /    27 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   15471.56 ms /    23 runs   (  672.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16876.83 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.34 ms /    27 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11368.86 ms /    17 runs   (  668.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12818.53 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2594.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.25 ms /    26 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11061.25 ms /    17 runs   (  650.66 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12397.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2598.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.86 ms /    26 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11795.11 ms /    18 runs   (  655.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13144.85 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.99 ms /    23 runs   (    0.39 ms per token,  2558.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.19 ms /    26 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   14928.15 ms /    22 runs   (  678.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16279.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    17 runs   (    0.39 ms per token,  2543.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.98 ms /    27 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10735.91 ms /    16 runs   (  670.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12141.56 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.78 ms /    27 tokens (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12004.80 ms /    18 runs   (  666.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13385.37 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2568.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.62 ms /    25 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11389.99 ms /    17 runs   (  670.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12703.12 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.31 ms /    26 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13395.84 ms /    20 runs   (  669.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14745.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    21 runs   (    0.38 ms per token,  2598.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.53 ms /    26 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   13475.44 ms /    20 runs   (  673.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14864.14 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2609.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.65 ms /    25 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11577.86 ms /    17 runs   (  681.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12899.67 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    19 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.93 ms /    25 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12215.60 ms /    18 runs   (  678.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13541.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2549.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.60 ms /    27 tokens (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11152.95 ms /    17 runs   (  656.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12537.61 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2581.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.20 ms /    27 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10790.68 ms /    16 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12174.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2571.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.32 ms /    26 tokens (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11348.24 ms /    17 runs   (  667.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12692.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2549.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.73 ms /    26 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11013.53 ms /    17 runs   (  647.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12349.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2578.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.08 ms /    27 tokens (   50.11 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10468.93 ms /    16 runs   (  654.31 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11870.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2621.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.29 ms /    27 tokens (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10992.69 ms /    17 runs   (  646.63 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12374.76 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    31 runs   (    0.38 ms per token,  2608.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.89 ms /    26 tokens (   49.42 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20096.77 ms /    30 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21471.61 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1349.48 ms /    26 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11125.73 ms /    17 runs   (  654.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12526.70 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2565.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.94 ms /    27 tokens (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12797.74 ms /    19 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14183.80 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2590.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.38 ms /    27 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10819.05 ms /    16 runs   (  676.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12202.02 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.88 ms /    26 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12064.77 ms /    18 runs   (  670.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13412.85 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2567.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.29 ms /    26 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11921.40 ms /    18 runs   (  662.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13261.74 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    23 runs   (    0.40 ms per token,  2525.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.19 ms /    25 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14524.89 ms /    22 runs   (  660.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15860.77 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2555.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.03 ms /    26 tokens (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12168.38 ms /    18 runs   (  676.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13503.50 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.01 ms /    23 runs   (    0.39 ms per token,  2554.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.40 ms /    26 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   14674.20 ms /    22 runs   (  667.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16029.45 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2625.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.52 ms /    25 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10563.52 ms /    16 runs   (  660.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11991.10 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.56 ms /    27 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10466.30 ms /    16 runs   (  654.14 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11866.19 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    20 runs   (    0.39 ms per token,  2535.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.73 ms /    27 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12823.64 ms /    19 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14225.14 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    21 runs   (    0.39 ms per token,  2543.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.27 ms /    26 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   13279.25 ms /    20 runs   (  663.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14678.94 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      21.03 ms /    54 runs   (    0.39 ms per token,  2568.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.76 ms /    26 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   35658.51 ms /    53 runs   (  672.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37122.90 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2568.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.08 ms /    27 tokens (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11881.33 ms /    18 runs   (  660.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13271.27 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2526.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.76 ms /    27 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   12638.41 ms /    19 runs   (  665.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14055.93 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    22 runs   (    0.40 ms per token,  2529.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.92 ms /    26 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   13954.67 ms /    21 runs   (  664.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15365.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    21 runs   (    0.39 ms per token,  2566.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.48 ms /    26 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13709.46 ms /    20 runs   (  685.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15074.11 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2666.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.71 ms /    25 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   10710.62 ms /    16 runs   (  669.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12036.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2560.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.08 ms /    27 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12179.64 ms /    18 runs   (  676.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13624.07 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2619.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.21 ms /    27 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12138.04 ms /    18 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13530.26 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2545.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.72 ms /    26 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12560.19 ms /    19 runs   (  661.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13910.92 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.52 ms /    27 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10491.70 ms /    16 runs   (  655.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11906.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2540.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.23 ms /    27 tokens (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11947.97 ms /    18 runs   (  663.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13330.34 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2537.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.50 ms /    26 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11259.43 ms /    17 runs   (  662.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12623.89 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2568.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.42 ms /    26 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11879.10 ms /    18 runs   (  659.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13257.02 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.51 ms /    26 tokens (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10625.89 ms /    16 runs   (  664.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11962.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      13.47 ms /    32 runs   (    0.42 ms per token,  2375.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.92 ms /    27 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   20985.86 ms /    31 runs   (  676.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22445.63 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    23 runs   (    0.40 ms per token,  2515.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.93 ms /    27 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   15124.06 ms /    22 runs   (  687.46 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   16563.66 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2619.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.81 ms /    26 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12136.39 ms /    18 runs   (  674.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13479.92 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2636.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.74 ms /    27 tokens (   49.18 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10811.02 ms /    16 runs   (  675.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12187.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2582.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.26 ms /    27 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11361.17 ms /    17 runs   (  668.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12766.53 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.20 ms /    26 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11446.67 ms /    17 runs   (  673.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12797.93 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2641.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.12 ms /    26 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11366.61 ms /    17 runs   (  668.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12715.05 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2544.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.03 ms /    26 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10770.03 ms /    16 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12113.69 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2527.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.11 ms /    27 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10518.56 ms /    16 runs   (  657.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11910.64 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.82 ms /    27 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11922.65 ms /    18 runs   (  662.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13318.01 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.21 ms /    26 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11259.49 ms /    17 runs   (  662.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12634.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2586.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.86 ms /    27 tokens (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10565.78 ms /    16 runs   (  660.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11959.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2510.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.09 ms /    27 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10598.05 ms /    16 runs   (  662.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11994.04 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2567.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.31 ms /    26 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11771.75 ms /    18 runs   (  653.99 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13132.68 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2604.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.80 ms /    26 tokens (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10566.04 ms /    16 runs   (  660.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11907.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    21 runs   (    0.39 ms per token,  2542.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.67 ms /    25 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   13427.39 ms /    20 runs   (  671.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14742.05 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2537.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.97 ms /    27 tokens (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11431.51 ms /    17 runs   (  672.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12816.29 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    21 runs   (    0.39 ms per token,  2570.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.89 ms /    27 tokens (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   13352.44 ms /    20 runs   (  667.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14741.36 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    20 runs   (    0.44 ms per token,  2274.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.82 ms /    26 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12896.77 ms /    19 runs   (  678.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14269.76 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    16 runs   (    0.39 ms per token,  2571.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.24 ms /    27 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10190.49 ms /    15 runs   (  679.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11565.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.44 ms /    27 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12107.01 ms /    18 runs   (  672.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13495.48 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.23 ms /    21 runs   (    0.44 ms per token,  2274.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.01 ms /    26 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13372.92 ms /    20 runs   (  668.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14739.77 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.24 ms /    26 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11331.22 ms /    17 runs   (  666.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12672.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    21 runs   (    0.39 ms per token,  2575.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.29 ms /    26 tokens (   51.16 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   13516.09 ms /    20 runs   (  675.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14907.01 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    19 runs   (    0.45 ms per token,  2203.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.21 ms /    27 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12106.50 ms /    18 runs   (  672.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13520.53 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2637.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.85 ms /    27 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11328.65 ms /    17 runs   (  666.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12712.71 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.17 ms /    29 runs   (    0.39 ms per token,  2596.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.45 ms /    26 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   18681.07 ms /    28 runs   (  667.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20126.74 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2655.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.25 ms /    30 tokens (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10451.03 ms /    16 runs   (  653.19 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11973.54 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    20 runs   (    0.43 ms per token,  2303.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.80 ms /    29 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12864.60 ms /    19 runs   (  677.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14364.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.35 ms /    29 runs   (    0.39 ms per token,  2556.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.38 ms /    29 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   18906.04 ms /    28 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20424.53 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2605.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.79 ms /    29 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12757.09 ms /    19 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14246.43 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2551.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.05 ms /    29 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10489.65 ms /    16 runs   (  655.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11989.67 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    19 runs   (    0.38 ms per token,  2640.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.65 ms /    29 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12003.48 ms /    18 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13480.45 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      18.41 ms /    43 runs   (    0.43 ms per token,  2335.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.33 ms /    29 tokens (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   27768.12 ms /    42 runs   (  661.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29329.74 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2613.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.00 ms /    29 tokens (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12451.08 ms /    19 runs   (  655.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13930.94 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2601.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.90 ms /    29 tokens (   48.65 ms per token,    20.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10526.60 ms /    16 runs   (  657.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11986.13 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2613.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.77 ms /    29 tokens (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12418.74 ms /    19 runs   (  653.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13904.88 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2608.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.73 ms /    29 tokens (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12424.73 ms /    19 runs   (  653.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13904.39 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2553.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.70 ms /    29 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10551.30 ms /    16 runs   (  659.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12051.26 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.69 ms /    29 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11899.52 ms /    18 runs   (  661.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13411.53 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2649.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1675.14 ms /    29 tokens (   57.76 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12072.83 ms /    18 runs   (  670.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13803.00 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2570.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.37 ms /    29 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10612.06 ms /    16 runs   (  663.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12091.57 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2622.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.42 ms /    29 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10758.23 ms /    16 runs   (  672.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12244.72 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2682.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.32 ms /    28 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10715.18 ms /    16 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12151.11 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2613.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.43 ms /    29 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10658.44 ms /    16 runs   (  666.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12139.54 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2567.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.93 ms /    29 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10747.82 ms /    16 runs   (  671.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12250.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2588.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.47 ms /    28 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10606.54 ms /    16 runs   (  662.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12037.37 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2537.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.08 ms /    28 tokens (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10620.79 ms /    16 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12047.53 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2663.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.71 ms /    29 tokens (   48.89 ms per token,    20.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10537.50 ms /    16 runs   (  658.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12004.58 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2586.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1454.43 ms /    29 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12801.68 ms /    19 runs   (  673.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14315.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2592.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.25 ms /    29 tokens (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10858.28 ms /    16 runs   (  678.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12328.86 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.70 ms /    29 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12163.41 ms /    18 runs   (  675.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13654.15 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2599.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.05 ms /    29 tokens (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10437.06 ms /    16 runs   (  652.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11906.86 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.26 ms /    29 tokens (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11339.83 ms /    17 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12825.12 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2604.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.03 ms /    29 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10815.77 ms /    16 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12294.55 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2623.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.08 ms /    29 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12004.28 ms /    18 runs   (  666.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13494.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2565.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.50 ms /    29 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11984.43 ms /    18 runs   (  665.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13467.21 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.90 ms /    29 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10657.85 ms /    16 runs   (  666.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12142.27 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2581.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.29 ms /    29 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10740.53 ms /    16 runs   (  671.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12219.72 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2622.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.83 ms /    29 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10774.90 ms /    16 runs   (  673.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12336.31 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2580.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.08 ms /    29 tokens (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10693.73 ms /    16 runs   (  668.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12165.32 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2617.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.62 ms /    29 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12641.18 ms /    19 runs   (  665.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14140.24 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2597.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.41 ms /    29 tokens (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10901.43 ms /    16 runs   (  681.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12383.05 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.67 ms /   394 runs   (    0.29 ms per token,  3466.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.75 ms /    29 tokens (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =  265112.86 ms /   393 runs   (  674.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  267738.37 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2602.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.81 ms /    29 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12592.45 ms /    19 runs   (  662.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14100.21 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2626.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.34 ms /    29 tokens (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12107.11 ms /    18 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13601.42 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.78 ms /    29 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10724.59 ms /    16 runs   (  670.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12217.20 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2634.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.07 ms /    29 tokens (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10542.68 ms /    16 runs   (  658.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12033.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.48 ms /    29 tokens (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10729.01 ms /    16 runs   (  670.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12202.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2633.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.47 ms /    29 tokens (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12804.57 ms /    19 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14280.77 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.71 ms /    29 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12670.29 ms /    19 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14170.42 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2607.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.02 ms /    29 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10573.66 ms /    16 runs   (  660.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12053.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.38 ms /    29 tokens (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_print_timings:        eval time =   13010.21 ms /    19 runs   (  684.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14484.49 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2487.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.37 ms /    29 tokens (   49.32 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12667.67 ms /    19 runs   (  666.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14157.17 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2621.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.97 ms /    29 tokens (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12104.47 ms /    18 runs   (  672.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13582.90 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    20 runs   (    0.39 ms per token,  2534.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.45 ms /    29 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12729.54 ms /    19 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14214.72 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2626.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1517.53 ms /    29 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12533.41 ms /    19 runs   (  659.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14108.63 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2604.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.22 ms /    29 tokens (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10660.46 ms /    16 runs   (  666.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12149.53 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    20 runs   (    0.42 ms per token,  2355.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.97 ms /    29 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12629.97 ms /    19 runs   (  664.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14124.32 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2618.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.58 ms /    29 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12026.24 ms /    18 runs   (  668.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13527.36 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2573.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.51 ms /    28 tokens (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10545.30 ms /    16 runs   (  659.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11971.92 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2580.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.70 ms /    29 tokens (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11289.76 ms /    17 runs   (  664.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12766.80 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    19 runs   (    0.38 ms per token,  2630.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1469.44 ms /    29 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11964.07 ms /    18 runs   (  664.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13488.82 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.92 ms /   394 runs   (    0.29 ms per token,  3458.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.17 ms /    29 tokens (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =  265319.56 ms /   393 runs   (  675.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  267950.29 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2635.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.66 ms /    29 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10731.00 ms /    16 runs   (  670.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12222.33 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2603.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.14 ms /    29 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12008.64 ms /    18 runs   (  667.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13499.92 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2599.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.92 ms /    29 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10665.11 ms /    16 runs   (  666.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12144.67 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    17 runs   (    0.38 ms per token,  2660.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.04 ms /    29 tokens (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10679.24 ms /    16 runs   (  667.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12151.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2619.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.91 ms /    29 tokens (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10782.51 ms /    16 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12250.99 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2642.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.41 ms /    29 tokens (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10477.80 ms /    16 runs   (  654.86 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11993.97 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.48 ms /    29 tokens (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10446.70 ms /    16 runs   (  652.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11915.43 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2623.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.75 ms /    29 tokens (   49.44 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10492.23 ms /    16 runs   (  655.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11975.16 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    23 runs   (    0.43 ms per token,  2336.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.00 ms /    29 tokens (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   14625.83 ms /    22 runs   (  664.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16134.80 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    19 runs   (    0.44 ms per token,  2295.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.60 ms /    29 tokens (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12114.05 ms /    18 runs   (  673.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13604.48 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2615.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.61 ms /    29 tokens (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12093.40 ms /    18 runs   (  671.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13567.73 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2617.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.42 ms /    29 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12598.00 ms /    19 runs   (  663.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14083.56 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.21 ms /    29 tokens (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10466.83 ms /    16 runs   (  654.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11945.06 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2598.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.31 ms /    29 tokens (   49.49 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10691.27 ms /    16 runs   (  668.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12176.64 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2569.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1487.23 ms /    28 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10856.53 ms /    16 runs   (  678.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12395.77 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.06 ms /   394 runs   (    0.29 ms per token,  3454.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.85 ms /    29 tokens (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =  262040.48 ms /   393 runs   (  666.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =  264656.47 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2564.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.56 ms /    29 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12885.05 ms /    19 runs   (  678.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14387.78 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    17 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.90 ms /    29 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10780.61 ms /    16 runs   (  673.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12268.43 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.81 ms /    29 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10673.99 ms /    16 runs   (  667.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12155.83 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2589.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.89 ms /    29 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11392.61 ms /    17 runs   (  670.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12895.20 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2559.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.82 ms /    29 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10653.53 ms /    16 runs   (  665.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12138.31 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.00 ms /    28 tokens (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10283.30 ms /    16 runs   (  642.71 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   11706.16 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2618.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.49 ms /    29 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10721.88 ms /    16 runs   (  670.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12256.53 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.26 ms /    29 tokens (   51.22 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.90 ms /    16 runs   (  665.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12189.65 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.46 ms /    28 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10728.92 ms /    16 runs   (  670.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12184.29 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2591.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.00 ms /    29 tokens (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10564.79 ms /    16 runs   (  660.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12058.09 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2617.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.76 ms /    29 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11867.06 ms /    18 runs   (  659.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13353.83 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2609.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.45 ms /    29 tokens (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11893.69 ms /    18 runs   (  660.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13366.75 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.73 ms /    29 tokens (   48.89 ms per token,    20.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11438.58 ms /    17 runs   (  672.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12908.89 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2590.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.21 ms /    29 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12193.85 ms /    18 runs   (  677.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13684.02 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    17 runs   (    0.37 ms per token,  2717.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.63 ms /    29 tokens (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10647.07 ms /    16 runs   (  665.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12126.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    17 runs   (    0.45 ms per token,  2233.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.27 ms /    29 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10557.65 ms /    16 runs   (  659.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12056.58 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.34 ms /    29 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10727.42 ms /    16 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12219.86 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.54 ms /    29 tokens (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12781.38 ms /    19 runs   (  672.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14259.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2572.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.37 ms /    29 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10629.90 ms /    16 runs   (  664.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12126.02 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    19 runs   (    0.38 ms per token,  2638.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.80 ms /    29 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12139.50 ms /    18 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13641.07 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2602.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.30 ms /    29 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10829.67 ms /    16 runs   (  676.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12332.09 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2625.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.18 ms /    29 tokens (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12787.15 ms /    19 runs   (  673.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14271.59 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2653.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.39 ms /    29 tokens (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12072.15 ms /    18 runs   (  670.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13550.61 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2626.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.82 ms /    29 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12091.34 ms /    18 runs   (  671.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13625.62 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.41 ms /    29 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10779.06 ms /    16 runs   (  673.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12260.77 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2593.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.38 ms /    29 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10672.78 ms /    16 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12185.44 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.63 ms /    29 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10724.80 ms /    16 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12297.09 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    17 runs   (    0.42 ms per token,  2397.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.53 ms /    28 tokens (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10684.78 ms /    16 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12114.15 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2664.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.17 ms /    28 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11367.51 ms /    17 runs   (  668.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12811.12 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2539.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.68 ms /    28 tokens (   49.35 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11806.34 ms /    18 runs   (  655.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13243.42 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2527.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.94 ms /    28 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11954.23 ms /    18 runs   (  664.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13501.35 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2616.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.34 ms /    28 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12092.20 ms /    18 runs   (  671.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13550.84 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2565.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.39 ms /    28 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10694.26 ms /    16 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12167.83 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2526.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.35 ms /    28 tokens (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12065.67 ms /    18 runs   (  670.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13503.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    17 runs   (    0.40 ms per token,  2526.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.34 ms /    28 tokens (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10863.24 ms /    16 runs   (  678.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12288.82 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      22.53 ms /    56 runs   (    0.40 ms per token,  2485.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.06 ms /    28 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   37291.84 ms /    55 runs   (  678.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38914.56 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.82 ms /    28 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11519.52 ms /    17 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12983.94 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.68 ms /    28 tokens (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11414.99 ms /    17 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12841.49 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.23 ms /    28 tokens (   49.62 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10587.90 ms /    16 runs   (  661.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12026.44 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2664.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.08 ms /    28 tokens (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10642.74 ms /    16 runs   (  665.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12071.28 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2664.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.91 ms /    28 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11347.61 ms /    17 runs   (  667.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12833.97 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2558.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.45 ms /    28 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10751.65 ms /    16 runs   (  671.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12186.72 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.99 ms /    28 tokens (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11381.45 ms /    17 runs   (  669.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12808.43 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2586.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.54 ms /    28 tokens (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10759.87 ms /    16 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12185.08 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2641.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.41 ms /    27 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11088.18 ms /    17 runs   (  652.25 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12475.81 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2504.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.77 ms /    28 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10753.06 ms /    16 runs   (  672.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12186.07 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2660.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.91 ms /    28 tokens (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11354.33 ms /    17 runs   (  667.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12795.39 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2513.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1529.79 ms /    28 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11024.31 ms /    16 runs   (  689.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12603.81 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2656.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.19 ms /    28 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11461.00 ms /    17 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12922.65 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2543.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.88 ms /    27 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11959.90 ms /    18 runs   (  664.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13366.79 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    20 runs   (    0.37 ms per token,  2668.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.46 ms /    28 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12777.48 ms /    19 runs   (  672.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14236.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    20 runs   (    0.40 ms per token,  2490.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.01 ms /    27 tokens (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12677.90 ms /    19 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14070.53 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2585.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.83 ms /    27 tokens (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11424.50 ms /    17 runs   (  672.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12807.09 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2560.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.34 ms /    26 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11987.75 ms /    18 runs   (  665.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13335.55 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    20 runs   (    0.44 ms per token,  2270.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.73 ms /    27 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12703.56 ms /    19 runs   (  668.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14127.47 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2593.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.14 ms /    28 tokens (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11961.37 ms /    18 runs   (  664.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13392.12 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    19 runs   (    0.38 ms per token,  2639.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.13 ms /    28 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12106.87 ms /    18 runs   (  672.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13565.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2626.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.23 ms /    28 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12245.89 ms /    18 runs   (  680.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13686.19 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2604.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.08 ms /    28 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11977.49 ms /    18 runs   (  665.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13437.87 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    21 runs   (    0.38 ms per token,  2610.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.25 ms /    28 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13396.92 ms /    20 runs   (  669.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14843.34 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2605.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.66 ms /    28 tokens (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11396.12 ms /    17 runs   (  670.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12833.64 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2643.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.85 ms /    28 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12146.33 ms /    18 runs   (  674.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13598.00 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2569.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.23 ms /    28 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10743.24 ms /    16 runs   (  671.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12172.18 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2577.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.15 ms /    27 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10724.84 ms /    16 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12128.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.49 ms /   396 runs   (    0.29 ms per token,  3489.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.74 ms /    27 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =  266469.13 ms /   395 runs   (  674.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  269005.36 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.67 ms /    28 tokens (   50.24 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10861.99 ms /    16 runs   (  678.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12318.62 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2575.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.17 ms /    28 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10872.38 ms /    16 runs   (  679.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12315.85 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.46 ms /    27 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12644.75 ms /    19 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14033.78 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2566.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.63 ms /    28 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12044.16 ms /    18 runs   (  669.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13481.23 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.13 ms /    28 tokens (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10725.38 ms /    16 runs   (  670.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12150.49 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2585.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.89 ms /    28 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10842.40 ms /    16 runs   (  677.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12309.04 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.67 ms /    28 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11519.83 ms /    17 runs   (  677.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12945.11 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2556.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.83 ms /    28 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10628.66 ms /    16 runs   (  664.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12086.40 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    21 runs   (    0.40 ms per token,  2513.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.78 ms /    28 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13551.71 ms /    20 runs   (  677.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15025.20 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2574.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.34 ms /    28 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11994.49 ms /    18 runs   (  666.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13427.05 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2611.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.44 ms /    28 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10595.07 ms /    16 runs   (  662.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12026.75 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2640.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.25 ms /    28 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10679.60 ms /    16 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12129.37 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2628.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.06 ms /    28 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11989.94 ms /    18 runs   (  666.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13440.43 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1324.78 ms /    27 tokens (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10625.12 ms /    16 runs   (  664.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11999.94 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.54 ms /    28 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10492.73 ms /    16 runs   (  655.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11948.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2663.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.28 ms /    27 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11347.28 ms /    17 runs   (  667.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12745.72 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.90 ms /    28 tokens (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11863.27 ms /    18 runs   (  659.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13292.05 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2571.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.75 ms /    28 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10368.12 ms /    16 runs   (  648.01 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11830.18 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2593.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.99 ms /    28 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12142.53 ms /    18 runs   (  674.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13611.38 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2675.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.59 ms /    28 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10844.53 ms /    16 runs   (  677.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12305.74 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2573.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.23 ms /    27 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12241.55 ms /    18 runs   (  680.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13677.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2535.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.62 ms /    27 tokens (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12059.07 ms /    18 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13466.83 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1532.77 ms /    28 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10546.16 ms /    16 runs   (  659.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12128.10 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    21 runs   (    0.38 ms per token,  2641.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.59 ms /    28 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   13431.11 ms /    20 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14917.69 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.51 ms /    26 tokens (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10629.19 ms /    16 runs   (  664.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11969.37 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2659.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.15 ms /    28 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12144.67 ms /    18 runs   (  674.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13611.73 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    17 runs   (    0.44 ms per token,  2262.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.96 ms /    27 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10801.07 ms /    16 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12231.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2703.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.33 ms /    27 tokens (   50.09 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11420.72 ms /    17 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12825.72 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.20 ms /    28 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11301.27 ms /    17 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12748.94 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    17 runs   (    0.44 ms per token,  2278.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.64 ms /    28 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10612.50 ms /    16 runs   (  663.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12051.17 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2570.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.05 ms /    27 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11187.98 ms /    17 runs   (  658.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12602.35 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.97 ms /   395 runs   (    0.29 ms per token,  3465.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.94 ms /    28 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =  267419.68 ms /   394 runs   (  678.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  270024.92 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2633.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.77 ms /    28 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12873.88 ms /    19 runs   (  677.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14312.40 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2669.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.07 ms /    27 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10636.70 ms /    16 runs   (  664.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12034.70 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    21 runs   (    0.38 ms per token,  2644.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.35 ms /    28 tokens (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   13444.86 ms /    20 runs   (  672.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14879.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2517.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.03 ms /    28 tokens (   49.79 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10939.21 ms /    16 runs   (  683.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12383.60 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    22 runs   (    0.40 ms per token,  2492.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.47 ms /    28 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   14192.08 ms /    21 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15671.20 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2603.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.42 ms /    28 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12057.93 ms /    18 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13521.35 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2614.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.03 ms /    28 tokens (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10652.07 ms /    16 runs   (  665.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12083.54 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1529.58 ms /    27 tokens (   56.65 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11360.31 ms /    17 runs   (  668.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12941.98 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    19 runs   (    0.44 ms per token,  2275.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.46 ms /    28 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12173.49 ms /    18 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13618.39 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2555.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.28 ms /    28 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12188.20 ms /    18 runs   (  677.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13639.98 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2526.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.98 ms /    28 tokens (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12511.06 ms /    19 runs   (  658.48 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13946.18 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2640.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.53 ms /    28 tokens (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11190.15 ms /    17 runs   (  658.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12626.82 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2595.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.33 ms /    28 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10543.08 ms /    16 runs   (  658.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11991.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    19 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.52 ms /    28 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12007.84 ms /    18 runs   (  667.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13435.26 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.70 ms /    28 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11374.08 ms /    17 runs   (  669.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12867.77 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.05 ms /    28 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10774.41 ms /    16 runs   (  673.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12220.29 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.07 ms /    28 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12543.58 ms /    19 runs   (  660.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14001.25 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.01 ms /    28 tokens (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10879.34 ms /    16 runs   (  679.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12311.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2611.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.60 ms /    28 tokens (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10803.62 ms /    16 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12223.16 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2629.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.08 ms /    28 tokens (   49.32 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11201.36 ms /    17 runs   (  658.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12634.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2540.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.74 ms /    27 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12040.28 ms /    18 runs   (  668.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13471.10 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2600.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.46 ms /    28 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10741.34 ms /    16 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12196.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    18 runs   (    0.40 ms per token,  2516.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.50 ms /    28 tokens (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11312.59 ms /    17 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12748.46 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.38 ms /    28 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11953.95 ms /    18 runs   (  664.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13423.51 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.87 ms /    28 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11698.32 ms /    17 runs   (  688.14 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13144.72 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2553.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.47 ms /    28 tokens (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12257.38 ms /    18 runs   (  680.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13688.37 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2595.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.32 ms /    26 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12117.91 ms /    18 runs   (  673.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13497.58 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    20 runs   (    0.38 ms per token,  2621.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.43 ms /    27 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12580.86 ms /    19 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13993.94 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2625.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.33 ms /    28 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12046.65 ms /    18 runs   (  669.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13508.25 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2652.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.00 ms /    28 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10571.43 ms /    16 runs   (  660.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12003.41 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2554.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1767.94 ms /    30 tokens (   58.93 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10572.37 ms /    16 runs   (  660.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12390.75 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.25 ms /    30 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11163.48 ms /    17 runs   (  656.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12713.37 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2626.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.55 ms /    30 tokens (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11455.71 ms /    17 runs   (  673.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12969.37 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.57 ms /    29 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11222.24 ms /    17 runs   (  660.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12724.81 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.33 ms /    29 runs   (    0.39 ms per token,  2559.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1489.13 ms /    30 tokens (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18406.07 ms /    28 runs   (  657.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19980.63 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    18 runs   (    0.44 ms per token,  2282.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1460.93 ms /    30 tokens (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11293.36 ms /    17 runs   (  664.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12812.84 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.00 ms /    29 tokens (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11232.36 ms /    17 runs   (  660.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12708.78 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2547.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.95 ms /    29 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12615.65 ms /    19 runs   (  663.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14125.48 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      16.05 ms /    42 runs   (    0.38 ms per token,  2616.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.52 ms /    29 tokens (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   27552.47 ms /    41 runs   (  672.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29099.57 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2557.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.32 ms /    30 tokens (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11973.78 ms /    18 runs   (  665.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13492.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2594.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.95 ms /    30 tokens (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10439.13 ms /    16 runs   (  652.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11961.79 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2589.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.45 ms /    29 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12412.31 ms /    19 runs   (  653.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13908.08 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    17 runs   (    0.40 ms per token,  2509.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.52 ms /    30 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10663.46 ms /    16 runs   (  666.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12204.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    17 runs   (    0.39 ms per token,  2571.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.33 ms /    30 tokens (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10808.34 ms /    16 runs   (  675.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12330.68 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.76 ms /    39 runs   (    0.40 ms per token,  2473.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.25 ms /    29 tokens (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   25272.31 ms /    38 runs   (  665.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26828.20 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    21 runs   (    0.40 ms per token,  2524.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.64 ms /    29 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13303.20 ms /    20 runs   (  665.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14805.83 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2573.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.79 ms /    29 tokens (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12098.14 ms /    18 runs   (  672.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13576.31 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2586.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.49 ms /    30 tokens (   49.52 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10560.50 ms /    16 runs   (  660.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12095.75 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    19 runs   (    0.38 ms per token,  2630.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.28 ms /    30 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12080.54 ms /    18 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13628.67 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2562.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.88 ms /    29 tokens (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11371.81 ms /    17 runs   (  668.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12857.00 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    21 runs   (    0.39 ms per token,  2570.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.13 ms /    29 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   13411.07 ms /    20 runs   (  670.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14929.01 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2550.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.33 ms /    30 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11341.46 ms /    17 runs   (  667.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12879.07 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.52 ms /   394 runs   (    0.29 ms per token,  3470.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.58 ms /    30 tokens (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_print_timings:        eval time =  264872.89 ms /   393 runs   (  673.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  267523.55 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    18 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.12 ms /    29 tokens (   49.94 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11372.97 ms /    17 runs   (  669.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12873.70 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2555.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.39 ms /    30 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12711.28 ms /    19 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14285.52 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.57 ms /    30 tokens (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11981.09 ms /    18 runs   (  665.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13510.19 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2554.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.36 ms /    29 tokens (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   13440.70 ms /    20 runs   (  672.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14940.70 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.71 ms /    29 tokens (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11389.26 ms /    17 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12864.66 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    24 runs   (    0.39 ms per token,  2594.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.28 ms /    30 tokens (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   15440.95 ms /    23 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16983.77 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    19 runs   (    0.39 ms per token,  2557.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1488.71 ms /    30 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12108.98 ms /    18 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13653.17 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2545.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.69 ms /    29 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12549.71 ms /    19 runs   (  660.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14061.03 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.55 ms /    29 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11435.67 ms /    17 runs   (  672.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12959.43 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.50 ms /    41 runs   (    0.38 ms per token,  2644.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.47 ms /    28 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   26447.77 ms /    40 runs   (  661.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27973.62 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     126.99 ms /   394 runs   (    0.32 ms per token,  3102.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.05 ms /    30 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =  267129.20 ms /   393 runs   (  679.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  269818.67 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2609.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1467.73 ms /    30 tokens (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11510.85 ms /    17 runs   (  677.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13031.56 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      68.47 ms /   162 runs   (    0.42 ms per token,  2365.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.35 ms /    29 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =  108844.31 ms /   161 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  110773.49 ms /   190 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2560.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.01 ms /    29 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10751.93 ms /    16 runs   (  672.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12230.05 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2601.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.82 ms /    30 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10660.58 ms /    16 runs   (  666.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12232.96 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.05 ms /    30 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11423.85 ms /    17 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12959.39 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2595.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.89 ms /    28 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11461.69 ms /    17 runs   (  674.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12934.29 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    19 runs   (    0.45 ms per token,  2244.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1474.72 ms /    30 tokens (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12044.23 ms /    18 runs   (  669.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13581.39 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2605.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.59 ms /    30 tokens (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10474.75 ms /    16 runs   (  654.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11986.99 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2593.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.82 ms /    29 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12620.22 ms /    19 runs   (  664.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14114.49 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2585.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.51 ms /    29 tokens (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11662.50 ms /    18 runs   (  647.92 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13135.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2562.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.71 ms /    30 tokens (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12357.53 ms /    19 runs   (  650.40 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13882.49 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    17 runs   (    0.40 ms per token,  2478.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.64 ms /    30 tokens (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10685.46 ms /    16 runs   (  667.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12218.64 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    21 runs   (    0.39 ms per token,  2583.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.95 ms /    29 tokens (   49.69 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13199.22 ms /    20 runs   (  659.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14701.05 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    22 runs   (    0.38 ms per token,  2607.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.52 ms /    29 tokens (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   13926.83 ms /    21 runs   (  663.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15409.09 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    19 runs   (    0.39 ms per token,  2537.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.18 ms /    30 tokens (   48.51 ms per token,    20.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11961.38 ms /    18 runs   (  664.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13472.76 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    17 runs   (    0.40 ms per token,  2487.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.67 ms /    30 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10588.86 ms /    16 runs   (  661.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12151.30 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2600.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.65 ms /    29 tokens (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11121.34 ms /    17 runs   (  654.20 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12610.29 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    23 runs   (    0.39 ms per token,  2564.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.18 ms /    29 tokens (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_print_timings:        eval time =   14547.82 ms /    22 runs   (  661.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16033.06 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      18.92 ms /    44 runs   (    0.43 ms per token,  2325.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.93 ms /    30 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   28983.66 ms /    43 runs   (  674.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30603.64 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2575.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1476.58 ms /    30 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12085.41 ms /    18 runs   (  671.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13616.70 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.49 ms /    29 tokens (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12658.19 ms /    19 runs   (  666.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14155.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2562.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.50 ms /    29 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11240.45 ms /    17 runs   (  661.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12748.81 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2621.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.01 ms /    29 tokens (   49.35 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11870.06 ms /    18 runs   (  659.45 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13356.32 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2545.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1504.98 ms /    30 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10594.17 ms /    16 runs   (  662.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12148.89 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2553.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1502.69 ms /    30 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   13211.23 ms /    20 runs   (  660.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14774.66 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2528.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.60 ms /    29 tokens (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11031.42 ms /    17 runs   (  648.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12498.58 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      17.22 ms /    45 runs   (    0.38 ms per token,  2613.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.08 ms /    29 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   28827.67 ms /    44 runs   (  655.17 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   30402.01 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.48 ms /    30 tokens (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10556.55 ms /    16 runs   (  659.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12065.52 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.62 ms /    41 runs   (    0.38 ms per token,  2625.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1474.62 ms /    30 tokens (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   26215.92 ms /    40 runs   (  655.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   27810.37 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.39 ms /    29 tokens (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11118.26 ms /    17 runs   (  654.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12590.54 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    21 runs   (    0.39 ms per token,  2577.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1533.02 ms /    30 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   13119.89 ms /    20 runs   (  655.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14714.46 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2609.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.97 ms /    30 tokens (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11687.14 ms /    18 runs   (  649.29 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13198.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.54 ms /    29 tokens (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11123.35 ms /    17 runs   (  654.31 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12591.52 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      16.55 ms /    41 runs   (    0.40 ms per token,  2477.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.90 ms /    29 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   26332.71 ms /    40 runs   (  658.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   27904.82 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.07 ms /    40 runs   (    0.38 ms per token,  2654.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.59 ms /    29 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   25517.98 ms /    39 runs   (  654.31 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   27074.86 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2585.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.38 ms /    30 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11911.66 ms /    18 runs   (  661.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13447.19 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.32 ms /    30 tokens (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11334.96 ms /    17 runs   (  666.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12845.85 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    18 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.04 ms /    29 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11161.99 ms /    17 runs   (  656.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12650.35 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     112.88 ms /   394 runs   (    0.29 ms per token,  3490.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.15 ms /    29 tokens (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_print_timings:        eval time =  264254.89 ms /   393 runs   (  672.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =  266856.09 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     127.28 ms /   394 runs   (    0.32 ms per token,  3095.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.61 ms /    30 tokens (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_print_timings:        eval time =  263370.99 ms /   393 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =  266040.65 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     112.47 ms /   394 runs   (    0.29 ms per token,  3503.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.55 ms /    30 tokens (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_print_timings:        eval time =  261355.50 ms /   393 runs   (  665.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =  264017.40 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    20 runs   (    0.40 ms per token,  2527.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.88 ms /    29 tokens (   49.20 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12793.94 ms /    19 runs   (  673.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14280.37 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2543.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.62 ms /    29 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12578.92 ms /    19 runs   (  662.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14095.42 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2585.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1545.76 ms /    30 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   13173.18 ms /    20 runs   (  658.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14781.23 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    18 runs   (    0.40 ms per token,  2489.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.23 ms /    30 tokens (   49.44 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11067.47 ms /    17 runs   (  651.03 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12606.66 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2581.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.24 ms /    29 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11336.98 ms /    17 runs   (  666.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12842.81 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    21 runs   (    0.40 ms per token,  2505.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1459.26 ms /    30 tokens (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_print_timings:        eval time =   13220.34 ms /    20 runs   (  661.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14742.17 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.56 ms /    41 runs   (    0.38 ms per token,  2634.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.38 ms /    30 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   26465.45 ms /    40 runs   (  661.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28072.56 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    23 runs   (    0.38 ms per token,  2619.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.66 ms /    29 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14658.28 ms /    22 runs   (  666.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16169.99 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.69 ms /    29 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11397.21 ms /    17 runs   (  670.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12902.34 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     124.73 ms /   394 runs   (    0.32 ms per token,  3158.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.26 ms /    29 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =  265680.67 ms /   393 runs   (  676.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268394.54 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2577.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1470.73 ms /    30 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12755.91 ms /    19 runs   (  671.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14285.46 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2616.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.26 ms /    30 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12024.65 ms /    18 runs   (  668.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13557.16 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    21 runs   (    0.48 ms per token,  2079.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.26 ms /    29 tokens (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_print_timings:        eval time =   13381.59 ms /    20 runs   (  669.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14869.09 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.80 ms /    29 tokens (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10620.09 ms /    16 runs   (  663.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12090.10 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2544.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.05 ms /    30 tokens (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12719.09 ms /    19 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14264.15 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     164.65 ms /   394 runs   (    0.42 ms per token,  2392.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.61 ms /    30 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =  264390.23 ms /   393 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =  267146.26 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.23 ms /   394 runs   (    0.29 ms per token,  3449.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.84 ms /    29 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =  267147.06 ms /   393 runs   (  679.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  269784.56 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    20 runs   (    0.38 ms per token,  2652.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.06 ms /    29 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12681.01 ms /    19 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14177.38 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    20 runs   (    0.40 ms per token,  2518.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.56 ms /    30 tokens (   49.79 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12971.25 ms /    19 runs   (  682.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14523.91 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    22 runs   (    0.39 ms per token,  2590.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.38 ms /    30 tokens (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14058.04 ms /    21 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15587.92 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    26 runs   (    0.42 ms per token,  2399.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.87 ms /    29 tokens (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_print_timings:        eval time =   16993.97 ms /    25 runs   (  679.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18491.13 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    21 runs   (    0.43 ms per token,  2322.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.58 ms /    29 tokens (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   13249.88 ms /    20 runs   (  662.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14735.39 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2626.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.72 ms /    30 tokens (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11234.62 ms /    17 runs   (  660.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12760.00 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    17 runs   (    0.38 ms per token,  2601.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.45 ms /    30 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10553.35 ms /    16 runs   (  659.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12119.84 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2591.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.65 ms /    29 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11848.98 ms /    18 runs   (  658.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13326.39 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1495.83 ms /    30 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10632.45 ms /    16 runs   (  664.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12177.31 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    15 runs   (    0.39 ms per token,  2534.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.98 ms /    30 tokens (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:        eval time =    9406.95 ms /    14 runs   (  671.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10916.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.24 ms /   394 runs   (    0.29 ms per token,  3448.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.36 ms /    29 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =  265524.05 ms /   393 runs   (  675.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268145.33 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    21 runs   (    0.39 ms per token,  2577.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.41 ms /    29 tokens (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_print_timings:        eval time =   13234.59 ms /    20 runs   (  661.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14714.14 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     137.14 ms /   394 runs   (    0.35 ms per token,  2872.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.19 ms /    30 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =  265002.97 ms /   393 runs   (  674.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  267705.96 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    19 runs   (    0.39 ms per token,  2581.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.76 ms /    30 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12206.46 ms /    18 runs   (  678.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13749.09 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2569.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.00 ms /    28 tokens (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12799.16 ms /    19 runs   (  673.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14226.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      17.72 ms /    44 runs   (    0.40 ms per token,  2482.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.20 ms /    28 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   29230.18 ms /    43 runs   (  679.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30764.69 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    19 runs   (    0.40 ms per token,  2500.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.48 ms /    30 tokens (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12186.01 ms /    18 runs   (  677.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13721.11 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2611.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1481.93 ms /    30 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12019.11 ms /    18 runs   (  667.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13555.92 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    19 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.62 ms /    29 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11980.96 ms /    18 runs   (  665.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13488.65 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2608.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.37 ms /    29 tokens (   48.84 ms per token,    20.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12087.99 ms /    18 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13560.31 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.87 ms /    29 tokens (   48.96 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11800.19 ms /    18 runs   (  655.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13275.80 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2579.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.36 ms /    30 tokens (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10554.77 ms /    16 runs   (  659.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12066.55 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    21 runs   (    0.39 ms per token,  2568.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.47 ms /    30 tokens (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13449.24 ms /    20 runs   (  672.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14976.22 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      51.12 ms /   125 runs   (    0.41 ms per token,  2445.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.33 ms /    29 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   83111.61 ms /   124 runs   (  670.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   84940.02 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      18.71 ms /    49 runs   (    0.38 ms per token,  2619.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.84 ms /    29 tokens (   49.62 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   32592.35 ms /    48 runs   (  679.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   34178.32 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2543.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.88 ms /    30 tokens (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12665.41 ms /    19 runs   (  666.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14204.10 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1489.44 ms /    30 tokens (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11608.64 ms /    17 runs   (  682.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13151.99 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.62 ms /   394 runs   (    0.29 ms per token,  3467.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.55 ms /    29 tokens (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =  267025.59 ms /   393 runs   (  679.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  269657.28 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      16.53 ms /    44 runs   (    0.38 ms per token,  2662.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.52 ms /    29 tokens (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   28993.91 ms /    43 runs   (  674.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30557.51 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1475.44 ms /    30 tokens (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10737.24 ms /    16 runs   (  671.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12261.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2582.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.10 ms /    30 tokens (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11431.78 ms /    17 runs   (  672.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12948.55 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    18 runs   (    0.42 ms per token,  2400.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.82 ms /    29 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11193.76 ms /    17 runs   (  658.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12686.20 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.05 ms /    30 tokens (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10536.16 ms /    16 runs   (  658.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12057.73 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2546.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.65 ms /    30 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11420.44 ms /    17 runs   (  671.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12964.57 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    21 runs   (    0.38 ms per token,  2619.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1599.26 ms /    29 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13449.73 ms /    20 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15111.11 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    18 runs   (    0.39 ms per token,  2550.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.54 ms /    29 tokens (   48.98 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11457.94 ms /    17 runs   (  674.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12931.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      16.93 ms /    44 runs   (    0.38 ms per token,  2598.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.75 ms /    29 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   28989.54 ms /    43 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30561.10 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    20 runs   (    0.40 ms per token,  2526.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.37 ms /    30 tokens (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12725.83 ms /    19 runs   (  669.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14241.74 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2560.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.27 ms /    30 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11362.66 ms /    17 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12940.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2573.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.40 ms /    29 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12144.87 ms /    18 runs   (  674.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13686.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2559.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.90 ms /    30 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12133.33 ms /    18 runs   (  674.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13689.01 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      17.63 ms /    46 runs   (    0.38 ms per token,  2609.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.75 ms /    30 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   30480.84 ms /    45 runs   (  677.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   32100.64 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      17.01 ms /    42 runs   (    0.41 ms per token,  2468.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.65 ms /    29 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   27690.94 ms /    41 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29270.65 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    19 runs   (    0.39 ms per token,  2533.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.06 ms /    29 tokens (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12069.39 ms /    18 runs   (  670.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13540.37 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    22 runs   (    0.39 ms per token,  2541.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.79 ms /    30 tokens (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   13911.82 ms /    21 runs   (  662.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15449.32 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     129.25 ms /   394 runs   (    0.33 ms per token,  3048.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.88 ms /    30 tokens (   48.96 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =  265998.10 ms /   393 runs   (  676.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268683.31 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     137.31 ms /   394 runs   (    0.35 ms per token,  2869.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.69 ms /    29 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =  264703.68 ms /   393 runs   (  673.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  267370.39 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    21 runs   (    0.39 ms per token,  2571.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1495.10 ms /    29 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   13274.59 ms /    20 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14831.94 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    18 runs   (    0.41 ms per token,  2457.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.50 ms /    29 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11321.10 ms /    17 runs   (  665.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12833.31 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2623.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1475.78 ms /    30 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12739.19 ms /    19 runs   (  670.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14273.30 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2603.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1475.90 ms /    30 tokens (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11178.99 ms /    17 runs   (  657.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12708.66 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2536.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.35 ms /    28 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11282.79 ms /    17 runs   (  663.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12721.75 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      16.34 ms /    43 runs   (    0.38 ms per token,  2631.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.66 ms /    29 tokens (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:        eval time =   28365.76 ms /    42 runs   (  675.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29910.62 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    20 runs   (    0.39 ms per token,  2544.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.17 ms /    30 tokens (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12784.06 ms /    19 runs   (  672.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14307.54 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      31.50 ms /    81 runs   (    0.39 ms per token,  2571.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1480.24 ms /    30 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   54362.67 ms /    80 runs   (  679.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   56082.72 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2524.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.59 ms /    29 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11279.60 ms /    17 runs   (  663.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12764.67 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    17 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1475.00 ms /    30 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10722.84 ms /    16 runs   (  670.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12247.01 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2613.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.39 ms /    30 tokens (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10761.84 ms /    16 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12284.84 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2559.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.98 ms /    29 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11453.44 ms /    17 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12931.90 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    21 runs   (    0.39 ms per token,  2591.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.13 ms /    29 tokens (   49.42 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   13394.81 ms /    20 runs   (  669.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14889.82 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    21 runs   (    0.39 ms per token,  2538.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.80 ms /    29 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13541.10 ms /    20 runs   (  677.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15047.98 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2521.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.25 ms /    30 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10537.62 ms /    16 runs   (  658.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12065.31 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2633.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.28 ms /    30 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11971.77 ms /    18 runs   (  665.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13511.58 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    22 runs   (    0.39 ms per token,  2558.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.06 ms /    29 tokens (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   14101.50 ms /    21 runs   (  671.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15589.88 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      16.52 ms /    44 runs   (    0.38 ms per token,  2663.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.88 ms /    28 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   28944.47 ms /    43 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30457.56 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    21 runs   (    0.39 ms per token,  2591.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1469.82 ms /    30 tokens (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   13431.72 ms /    20 runs   (  671.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14963.69 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.98 ms /    30 tokens (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11514.71 ms /    17 runs   (  677.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13046.56 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2579.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.88 ms /    29 tokens (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11431.10 ms /    17 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12902.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2584.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.80 ms /    29 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10786.59 ms /    16 runs   (  674.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12299.88 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2546.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.67 ms /    30 tokens (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10690.88 ms /    16 runs   (  668.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12218.65 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2618.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.24 ms /    30 tokens (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11421.93 ms /    17 runs   (  671.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12944.93 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2627.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.93 ms /    28 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11374.06 ms /    17 runs   (  669.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12811.48 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2585.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.23 ms /    29 tokens (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11873.13 ms /    18 runs   (  659.62 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13355.01 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    19 runs   (    0.39 ms per token,  2586.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.99 ms /    30 tokens (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11996.28 ms /    18 runs   (  666.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13514.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2611.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.43 ms /    30 tokens (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12501.48 ms /    19 runs   (  657.97 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14045.62 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    20 runs   (    0.39 ms per token,  2568.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.96 ms /    29 tokens (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12790.69 ms /    19 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14280.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.32 ms /    30 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10729.31 ms /    16 runs   (  670.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12257.71 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2578.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.22 ms /    30 tokens (   48.84 ms per token,    20.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11196.21 ms /    17 runs   (  658.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12713.60 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.37 ms /    29 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11543.96 ms /    17 runs   (  679.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13029.06 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    19 runs   (    0.38 ms per token,  2631.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.81 ms /    29 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12048.56 ms /    18 runs   (  669.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13538.60 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2604.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.41 ms /    30 tokens (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10746.96 ms /    16 runs   (  671.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12258.62 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2634.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1510.86 ms /    30 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10421.08 ms /    16 runs   (  651.32 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11982.29 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2601.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.89 ms /    29 tokens (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11378.72 ms /    17 runs   (  669.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12856.38 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    18 runs   (    0.40 ms per token,  2516.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.57 ms /    29 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11316.24 ms /    17 runs   (  665.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12814.67 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2581.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.79 ms /    30 tokens (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10585.07 ms /    16 runs   (  661.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12101.03 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.95 ms /    42 runs   (    0.38 ms per token,  2632.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.70 ms /    30 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   27363.46 ms /    41 runs   (  667.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28970.85 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      17.20 ms /    42 runs   (    0.41 ms per token,  2441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.76 ms /    29 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   26689.11 ms /    41 runs   (  650.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   28251.82 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     115.78 ms /   394 runs   (    0.29 ms per token,  3403.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.08 ms /    29 tokens (   49.18 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =  266018.31 ms /   393 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268652.63 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2546.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.85 ms /    30 tokens (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13210.76 ms /    20 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14752.76 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    20 runs   (    0.39 ms per token,  2537.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.38 ms /    30 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12830.69 ms /    19 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14397.63 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     156.21 ms /   394 runs   (    0.40 ms per token,  2522.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.66 ms /    29 tokens (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =  265737.83 ms /   393 runs   (  676.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268400.57 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2595.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.71 ms /    29 tokens (   49.71 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13383.56 ms /    20 runs   (  669.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14885.52 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    21 runs   (    0.39 ms per token,  2564.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.53 ms /    29 tokens (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13366.32 ms /    20 runs   (  668.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14852.64 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.32 ms /   394 runs   (    0.29 ms per token,  3477.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.32 ms /    30 tokens (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =  264612.18 ms /   393 runs   (  673.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =  267275.62 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    23 runs   (    0.39 ms per token,  2579.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1459.64 ms /    30 tokens (   48.65 ms per token,    20.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14339.78 ms /    22 runs   (  651.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15867.59 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     115.17 ms /   394 runs   (    0.29 ms per token,  3420.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.20 ms /    29 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =  264773.01 ms /   393 runs   (  673.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  267430.52 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.43 ms /    30 tokens (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.11 ms /    16 runs   (  671.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12269.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2623.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.80 ms /    30 tokens (   48.79 ms per token,    20.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10662.51 ms /    16 runs   (  666.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12176.65 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.98 ms /    29 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11294.06 ms /    17 runs   (  664.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12785.18 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    21 runs   (    0.39 ms per token,  2589.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.09 ms /    29 tokens (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   13495.77 ms /    20 runs   (  674.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14985.44 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     128.56 ms /   394 runs   (    0.33 ms per token,  3064.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.18 ms /    29 tokens (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =  265302.96 ms /   393 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  267932.99 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2550.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1476.80 ms /    30 tokens (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12523.22 ms /    19 runs   (  659.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14059.17 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    21 runs   (    0.38 ms per token,  2611.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1481.78 ms /    30 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   13180.50 ms /    20 runs   (  659.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14723.98 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.11 ms /   394 runs   (    0.29 ms per token,  3452.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.45 ms /    29 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =  266331.91 ms /   393 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268977.56 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2552.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.86 ms /    29 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10666.48 ms /    16 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12149.01 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    17 runs   (    0.45 ms per token,  2228.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1470.07 ms /    30 tokens (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11017.64 ms /    16 runs   (  688.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12543.33 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    22 runs   (    0.39 ms per token,  2562.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1487.10 ms /    30 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14071.72 ms /    21 runs   (  670.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15625.00 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.38 ms /    41 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.25 ms /    29 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   26738.48 ms /    40 runs   (  668.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28300.95 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    24 runs   (    0.39 ms per token,  2532.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.31 ms /    29 tokens (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   15501.88 ms /    23 runs   (  673.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17000.52 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.44 ms /    29 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11264.01 ms /    17 runs   (  662.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12752.37 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2624.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.63 ms /    28 tokens (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13342.51 ms /    20 runs   (  667.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14789.58 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2598.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.76 ms /    28 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11758.40 ms /    18 runs   (  653.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13222.53 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2579.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.95 ms /    28 tokens (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12818.48 ms /    19 runs   (  674.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14257.91 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2599.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.18 ms /    29 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11878.96 ms /    18 runs   (  659.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13365.38 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    23 runs   (    0.43 ms per token,  2350.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.00 ms /    29 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14946.63 ms /    22 runs   (  679.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16465.98 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.86 ms /    28 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12164.63 ms /    18 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13611.19 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    20 runs   (    0.39 ms per token,  2559.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.38 ms /    28 tokens (   49.76 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12773.46 ms /    19 runs   (  672.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14225.50 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2582.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1454.31 ms /    29 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10556.84 ms /    16 runs   (  659.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12060.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2593.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.58 ms /    29 tokens (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12138.66 ms /    18 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13618.27 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    21 runs   (    0.39 ms per token,  2551.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.01 ms /    28 tokens (   49.79 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13405.48 ms /    20 runs   (  670.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14862.20 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.22 ms /    29 tokens (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11341.88 ms /    17 runs   (  667.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12823.17 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2549.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.84 ms /    29 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12761.58 ms /    19 runs   (  671.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14266.66 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      22.16 ms /    52 runs   (    0.43 ms per token,  2346.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.95 ms /    28 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   34342.48 ms /    51 runs   (  673.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35901.34 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    19 runs   (    0.38 ms per token,  2616.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.35 ms /    28 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12124.73 ms /    18 runs   (  673.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13567.66 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.40 ms /   395 runs   (    0.29 ms per token,  3452.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.24 ms /    29 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =  265401.91 ms /   394 runs   (  673.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268089.85 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2582.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.47 ms /    29 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11467.80 ms /    17 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12958.04 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2527.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.17 ms /    28 tokens (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11420.16 ms /    17 runs   (  671.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12853.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    21 runs   (    0.40 ms per token,  2492.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.56 ms /    28 tokens (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13416.99 ms /    20 runs   (  670.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14867.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    19 runs   (    0.40 ms per token,  2498.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.50 ms /    29 tokens (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12045.86 ms /    18 runs   (  669.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13534.78 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.31 ms /    29 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10769.58 ms /    16 runs   (  673.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12293.33 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2644.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.13 ms /    28 tokens (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12022.74 ms /    18 runs   (  667.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13455.51 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    18 runs   (    0.41 ms per token,  2417.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.31 ms /    28 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11534.21 ms /    17 runs   (  678.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13013.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2625.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.72 ms /    28 tokens (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10687.58 ms /    16 runs   (  667.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12113.22 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.60 ms /    29 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12705.35 ms /    19 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14185.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2608.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.69 ms /    29 tokens (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11919.29 ms /    18 runs   (  662.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13401.88 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2607.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.53 ms /    28 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12008.70 ms /    18 runs   (  667.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13458.54 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2550.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.98 ms /    29 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10587.64 ms /    16 runs   (  661.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12083.75 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2585.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.13 ms /    29 tokens (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11344.12 ms /    17 runs   (  667.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12825.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.68 ms /    25 runs   (    0.39 ms per token,  2583.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.19 ms /    28 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   16219.70 ms /    24 runs   (  675.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17677.59 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.86 ms /    28 tokens (   49.49 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12859.11 ms /    19 runs   (  676.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14304.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    17 runs   (    0.40 ms per token,  2501.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.41 ms /    29 tokens (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10735.46 ms /    16 runs   (  670.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12205.67 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    18 runs   (    0.39 ms per token,  2532.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.90 ms /    29 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11532.90 ms /    17 runs   (  678.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13049.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2556.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.82 ms /    27 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11416.40 ms /    17 runs   (  671.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12832.13 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2552.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1324.61 ms /    27 tokens (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12753.97 ms /    19 runs   (  671.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14138.05 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2565.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.91 ms /    29 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12772.51 ms /    19 runs   (  672.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14310.33 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2552.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.54 ms /    29 tokens (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12647.46 ms /    19 runs   (  665.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14142.37 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2514.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.27 ms /    28 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11376.32 ms /    17 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12839.23 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2585.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.91 ms /    28 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12781.51 ms /    19 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14303.72 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    21 runs   (    0.39 ms per token,  2582.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.96 ms /    28 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13374.61 ms /    20 runs   (  668.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14850.86 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    19 runs   (    0.40 ms per token,  2524.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.72 ms /    29 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11913.30 ms /    18 runs   (  661.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13413.40 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    24 runs   (    0.39 ms per token,  2576.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.23 ms /    29 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   15437.58 ms /    23 runs   (  671.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16961.60 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.81 ms /   395 runs   (    0.29 ms per token,  3470.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.30 ms /    28 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =  265995.38 ms /   394 runs   (  675.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268687.38 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    22 runs   (    0.40 ms per token,  2531.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.30 ms /    27 tokens (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14246.66 ms /    21 runs   (  678.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15650.24 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2566.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.61 ms /    29 tokens (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10813.36 ms /    16 runs   (  675.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12284.23 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2565.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.72 ms /    29 tokens (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11504.47 ms /    17 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12983.55 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    21 runs   (    0.40 ms per token,  2514.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.28 ms /    28 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13434.54 ms /    20 runs   (  671.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14900.19 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    19 runs   (    0.40 ms per token,  2509.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.64 ms /    27 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12092.61 ms /    18 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13483.12 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2563.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.09 ms /    28 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11431.65 ms /    17 runs   (  672.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12888.78 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2547.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.51 ms /    28 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11972.72 ms /    18 runs   (  665.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13444.33 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2572.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.41 ms /    27 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12796.05 ms /    19 runs   (  673.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14189.16 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    21 runs   (    0.39 ms per token,  2546.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.55 ms /    26 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13315.10 ms /    20 runs   (  665.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14673.22 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    21 runs   (    0.40 ms per token,  2503.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.81 ms /    28 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13421.33 ms /    20 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14859.44 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    22 runs   (    0.39 ms per token,  2535.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.05 ms /    28 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   14071.70 ms /    21 runs   (  670.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15533.96 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    21 runs   (    0.39 ms per token,  2575.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.49 ms /    27 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   13379.10 ms /    20 runs   (  668.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14779.91 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    24 runs   (    0.39 ms per token,  2585.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.58 ms /    29 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   15320.20 ms /    23 runs   (  666.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16811.92 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    19 runs   (    0.40 ms per token,  2493.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.44 ms /    29 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11883.61 ms /    18 runs   (  660.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13374.49 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2614.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.92 ms /    28 tokens (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11137.16 ms /    17 runs   (  655.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12568.91 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2617.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.49 ms /    28 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12754.77 ms /    19 runs   (  671.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14200.87 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    25 runs   (    0.39 ms per token,  2534.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.58 ms /    29 tokens (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_print_timings:        eval time =   16179.92 ms /    24 runs   (  674.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17666.46 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2560.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.75 ms /    29 tokens (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12082.18 ms /    18 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13567.19 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2611.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.26 ms /    28 tokens (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11486.34 ms /    17 runs   (  675.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12920.16 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    21 runs   (    0.39 ms per token,  2574.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.34 ms /    28 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   13401.93 ms /    20 runs   (  670.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14929.28 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    21 runs   (    0.40 ms per token,  2528.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.30 ms /    29 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13480.96 ms /    20 runs   (  674.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14976.96 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.30 ms /    29 tokens (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12773.30 ms /    19 runs   (  672.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14246.11 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.86 ms /    23 runs   (    0.39 ms per token,  2595.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.09 ms /    28 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14729.89 ms /    22 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16200.20 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    21 runs   (    0.39 ms per token,  2581.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1544.61 ms /    28 tokens (   55.16 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13441.93 ms /    20 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15047.29 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.34 ms /   395 runs   (    0.29 ms per token,  3484.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.84 ms /    28 tokens (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_print_timings:        eval time =  266312.66 ms /   394 runs   (  675.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268885.53 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    17 runs   (    0.39 ms per token,  2555.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.62 ms /    29 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10756.25 ms /    16 runs   (  672.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12241.78 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.80 ms /   395 runs   (    0.29 ms per token,  3471.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.60 ms /    29 tokens (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =  266658.96 ms /   394 runs   (  676.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  269294.28 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    22 runs   (    0.39 ms per token,  2578.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.13 ms /    28 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   14043.11 ms /    21 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15497.60 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    16 runs   (    0.39 ms per token,  2575.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.99 ms /    28 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10023.03 ms /    15 runs   (  668.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11453.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2569.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.17 ms /    28 tokens (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11211.01 ms /    17 runs   (  659.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12647.38 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    17 runs   (    0.39 ms per token,  2536.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.01 ms /    27 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10701.31 ms /    16 runs   (  668.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12084.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2624.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.29 ms /    27 tokens (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   13758.44 ms /    20 runs   (  687.92 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15146.07 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2537.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.94 ms /    29 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11467.32 ms /    17 runs   (  674.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12957.94 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.77 ms /    29 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10933.42 ms /    16 runs   (  683.34 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12421.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.62 ms /    28 tokens (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12121.45 ms /    18 runs   (  673.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13570.60 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2593.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.85 ms /    28 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12137.02 ms /    18 runs   (  674.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13571.03 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.55 ms /    22 runs   (    0.39 ms per token,  2572.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.53 ms /    27 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13912.80 ms /    21 runs   (  662.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15313.30 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.30 ms /    29 tokens (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12162.82 ms /    18 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13639.77 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2631.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.12 ms /    29 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11263.27 ms /    17 runs   (  662.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12753.47 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2554.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.79 ms /    28 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12693.22 ms /    19 runs   (  668.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14163.03 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2552.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.61 ms /    29 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12595.60 ms /    19 runs   (  662.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14087.96 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2522.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.65 ms /    29 tokens (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10388.11 ms /    16 runs   (  649.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11872.53 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    19 runs   (    0.40 ms per token,  2515.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.92 ms /    28 tokens (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11939.84 ms /    18 runs   (  663.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13371.47 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2544.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.30 ms /    28 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11163.53 ms /    17 runs   (  656.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12706.17 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.64 ms /    41 runs   (    0.38 ms per token,  2620.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.18 ms /    28 tokens (   49.86 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   26974.27 ms /    40 runs   (  674.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28490.46 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    21 runs   (    0.39 ms per token,  2592.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.95 ms /    29 tokens (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   13178.31 ms /    20 runs   (  658.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14662.15 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2553.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.43 ms /    29 tokens (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12221.41 ms /    19 runs   (  643.23 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   13702.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2608.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.24 ms /    28 tokens (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11302.92 ms /    17 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12730.42 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.33 ms /   395 runs   (    0.29 ms per token,  3455.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.95 ms /    29 tokens (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =  267785.57 ms /   394 runs   (  679.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  270408.73 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2592.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.48 ms /    29 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11974.72 ms /    18 runs   (  665.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13472.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.86 ms /   395 runs   (    0.29 ms per token,  3438.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.87 ms /    28 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =  267369.59 ms /   394 runs   (  678.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  269961.98 ms /   422 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    19 runs   (    0.48 ms per token,  2091.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.37 ms /    28 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12069.08 ms /    18 runs   (  670.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13531.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      11.66 ms /    29 runs   (    0.40 ms per token,  2486.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.83 ms /    29 tokens (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:        eval time =   18838.13 ms /    28 runs   (  672.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20343.90 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    19 runs   (    0.40 ms per token,  2529.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.33 ms /    29 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12199.09 ms /    18 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13690.31 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2601.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.53 ms /    28 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12775.71 ms /    19 runs   (  672.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14223.12 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2597.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.92 ms /    28 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11316.34 ms /    17 runs   (  665.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12772.17 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    17 runs   (    0.44 ms per token,  2258.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.71 ms /    29 tokens (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10760.81 ms /    16 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12244.33 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    17 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.48 ms /    29 tokens (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10704.41 ms /    16 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12182.29 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.41 ms /   395 runs   (    0.29 ms per token,  3482.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.40 ms /    27 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =  268597.99 ms /   394 runs   (  681.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  271156.47 ms /   421 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2552.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.61 ms /    27 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11782.72 ms /    18 runs   (  654.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13174.41 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    21 runs   (    0.39 ms per token,  2571.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.81 ms /    28 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13443.36 ms /    20 runs   (  672.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14942.89 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2615.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.27 ms /    29 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12847.51 ms /    19 runs   (  676.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14341.75 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2579.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.27 ms /    29 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11820.50 ms /    18 runs   (  656.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13313.90 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.36 ms /    27 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11772.56 ms /    18 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13191.05 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    17 runs   (    0.44 ms per token,  2248.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.24 ms /    29 tokens (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10791.49 ms /    16 runs   (  674.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12270.82 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2572.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.09 ms /    29 tokens (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12733.32 ms /    19 runs   (  670.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14214.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2609.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.99 ms /    28 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12784.67 ms /    19 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14244.01 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2526.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.13 ms /    28 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12081.62 ms /    18 runs   (  671.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13536.16 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2534.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.28 ms /    29 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11491.60 ms /    17 runs   (  675.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12987.16 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.67 ms /    29 tokens (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10655.15 ms /    16 runs   (  665.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12132.00 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.48 ms /    28 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12528.09 ms /    19 runs   (  659.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14001.67 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2634.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.52 ms /    28 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11440.04 ms /    17 runs   (  672.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12901.91 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    19 runs   (    0.39 ms per token,  2540.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.69 ms /    28 tokens (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12015.00 ms /    18 runs   (  667.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13445.84 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    19 runs   (    0.40 ms per token,  2472.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.78 ms /    28 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12178.26 ms /    18 runs   (  676.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13629.72 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    20 runs   (    0.39 ms per token,  2582.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.98 ms /    27 tokens (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12532.54 ms /    19 runs   (  659.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13925.13 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2566.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.11 ms /    27 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11800.23 ms /    18 runs   (  655.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13219.35 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    17 runs   (    0.39 ms per token,  2587.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.12 ms /    28 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10728.83 ms /    16 runs   (  670.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12176.49 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2575.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.87 ms /    29 tokens (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12795.08 ms /    19 runs   (  673.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14288.45 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2592.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.78 ms /    29 tokens (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11619.04 ms /    18 runs   (  645.50 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   13113.49 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    22 runs   (    0.38 ms per token,  2624.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.01 ms /    28 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   14209.34 ms /    21 runs   (  676.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15665.84 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    22 runs   (    0.38 ms per token,  2605.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.48 ms /    29 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   13926.57 ms /    21 runs   (  663.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15425.16 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    19 runs   (    0.37 ms per token,  2669.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.86 ms /    29 tokens (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11919.90 ms /    18 runs   (  662.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13397.85 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    25 runs   (    0.38 ms per token,  2618.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.63 ms /    28 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   16088.79 ms /    24 runs   (  670.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17671.00 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    21 runs   (    0.38 ms per token,  2613.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.39 ms /    28 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   13541.27 ms /    20 runs   (  677.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15022.06 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2605.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.46 ms /    28 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10718.48 ms /    16 runs   (  669.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12152.68 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2586.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.62 ms /    28 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12676.22 ms /    19 runs   (  667.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14144.23 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.82 ms /    27 tokens (   51.59 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11355.87 ms /    17 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12802.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2624.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.88 ms /    27 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13302.71 ms /    20 runs   (  665.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14710.11 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2562.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.81 ms /    28 tokens (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11374.88 ms /    17 runs   (  669.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12806.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2576.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.77 ms /    29 tokens (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10756.15 ms /    16 runs   (  672.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12227.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2564.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.95 ms /    29 tokens (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12153.87 ms /    18 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13657.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2572.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.09 ms /    28 tokens (   50.29 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11216.47 ms /    17 runs   (  659.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12677.50 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2538.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.46 ms /    29 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11313.37 ms /    17 runs   (  665.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12819.63 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     113.09 ms /   395 runs   (    0.29 ms per token,  3492.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.93 ms /    29 tokens (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:        eval time =  264793.57 ms /   394 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =  267421.63 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2552.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.15 ms /    28 tokens (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11985.02 ms /    18 runs   (  665.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13433.96 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.38 ms per token,  2598.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.59 ms /    28 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11321.87 ms /    17 runs   (  665.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12775.66 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2573.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.20 ms /    28 tokens (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12114.30 ms /    18 runs   (  673.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13543.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2641.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1470.37 ms /    29 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10684.33 ms /    16 runs   (  667.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12204.81 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    21 runs   (    0.39 ms per token,  2553.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.63 ms /    29 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   13144.62 ms /    20 runs   (  657.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14670.13 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.35 ms /    27 tokens (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11340.02 ms /    17 runs   (  667.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12722.91 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    21 runs   (    0.38 ms per token,  2610.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.16 ms /    28 tokens (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   13489.55 ms /    20 runs   (  674.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14930.14 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    19 runs   (    0.39 ms per token,  2563.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.97 ms /    29 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   12142.58 ms /    18 runs   (  674.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13683.10 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     114.01 ms /   395 runs   (    0.29 ms per token,  3464.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.93 ms /    29 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =  267341.44 ms /   394 runs   (  678.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  269966.32 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2635.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.27 ms /    28 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11300.93 ms /    17 runs   (  664.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12741.42 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    17 runs   (    0.39 ms per token,  2546.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.48 ms /    29 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10683.01 ms /    16 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12185.38 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.61 ms /    29 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12070.02 ms /    18 runs   (  670.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13546.72 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.31 ms /    28 tokens (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12625.95 ms /    19 runs   (  664.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14063.51 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2596.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.53 ms /    28 tokens (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   13325.24 ms /    20 runs   (  666.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14769.70 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.49 ms /    23 runs   (    0.41 ms per token,  2422.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.91 ms /    29 tokens (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   14587.63 ms /    22 runs   (  663.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16099.15 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    19 runs   (    0.39 ms per token,  2553.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.76 ms /    29 tokens (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11796.18 ms /    18 runs   (  655.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13276.67 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    24 runs   (    0.38 ms per token,  2612.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.21 ms /    27 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   15396.16 ms /    23 runs   (  669.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16812.16 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2612.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.54 ms /    27 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11346.61 ms /    17 runs   (  667.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12758.30 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2543.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.12 ms /    29 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12077.17 ms /    18 runs   (  670.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13647.32 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2585.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.02 ms /    29 tokens (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11342.60 ms /    17 runs   (  667.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12828.62 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    20 runs   (    0.44 ms per token,  2268.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.07 ms /    28 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   12693.43 ms /    19 runs   (  668.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14181.59 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    20 runs   (    0.39 ms per token,  2578.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.23 ms /    28 tokens (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12595.40 ms /    19 runs   (  662.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14032.88 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    21 runs   (    0.40 ms per token,  2524.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.24 ms /    29 tokens (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   13244.42 ms /    20 runs   (  662.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14727.20 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.58 ms /    29 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11215.40 ms /    17 runs   (  659.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12747.38 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2635.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.39 ms /    28 tokens (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12937.55 ms /    19 runs   (  680.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14375.75 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    19 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.09 ms /    28 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12201.71 ms /    18 runs   (  677.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13728.74 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    17 runs   (    0.39 ms per token,  2553.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.54 ms /    28 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10823.09 ms /    16 runs   (  676.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12284.89 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    21 runs   (    0.39 ms per token,  2597.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.74 ms /    29 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13416.25 ms /    20 runs   (  670.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14922.88 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2591.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.84 ms /    29 tokens (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11301.59 ms /    17 runs   (  664.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12783.37 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      17.62 ms /    43 runs   (    0.41 ms per token,  2441.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.38 ms /    28 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   28266.92 ms /    42 runs   (  673.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29799.21 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2571.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.15 ms /    29 tokens (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12571.19 ms /    19 runs   (  661.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14052.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    18 runs   (    0.39 ms per token,  2563.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.37 ms /    29 tokens (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11325.03 ms /    17 runs   (  666.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12816.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      32.23 ms /    77 runs   (    0.42 ms per token,  2388.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.67 ms /    28 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   51147.07 ms /    76 runs   (  672.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   52777.99 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.86 ms /    28 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11466.08 ms /    17 runs   (  674.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12905.89 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      15.73 ms /    41 runs   (    0.38 ms per token,  2606.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.18 ms /    28 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:        eval time =   26739.30 ms /    40 runs   (  668.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28236.36 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2547.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1559.97 ms /    29 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12300.31 ms /    18 runs   (  683.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13915.28 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    17 runs   (    0.39 ms per token,  2566.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.81 ms /    29 tokens (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10691.31 ms /    16 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12171.35 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    21 runs   (    0.39 ms per token,  2590.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.12 ms /    28 tokens (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   13412.93 ms /    20 runs   (  670.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14864.17 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    18 runs   (    0.40 ms per token,  2509.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1489.85 ms /    29 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11471.58 ms /    17 runs   (  674.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13013.21 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    21 runs   (    0.39 ms per token,  2569.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.24 ms /    29 tokens (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13362.06 ms /    20 runs   (  668.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14843.50 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    23 runs   (    0.39 ms per token,  2585.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.89 ms /    28 tokens (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   14746.74 ms /    22 runs   (  670.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16198.44 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    21 runs   (    0.38 ms per token,  2635.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.46 ms /    28 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13238.18 ms /    20 runs   (  661.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14701.42 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =     115.06 ms /   395 runs   (    0.29 ms per token,  3433.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.68 ms /    27 tokens (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =  265782.67 ms /   394 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  268340.77 ms /   421 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2600.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.20 ms /    29 tokens (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12118.98 ms /    18 runs   (  673.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13590.58 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    12 runs   (    0.39 ms per token,  2532.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.57 ms /    29 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =    7358.55 ms /    11 runs   (  668.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8834.35 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2611.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.15 ms /    28 tokens (   49.01 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12363.98 ms /    18 runs   (  686.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13791.72 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    17 runs   (    0.39 ms per token,  2580.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.82 ms /    28 tokens (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10813.20 ms /    16 runs   (  675.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12239.71 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    19 runs   (    0.39 ms per token,  2547.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.07 ms /    29 tokens (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11660.96 ms /    18 runs   (  647.83 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13141.43 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    21 runs   (    0.39 ms per token,  2534.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.89 ms /    29 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13186.09 ms /    20 runs   (  659.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14695.66 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2585.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.95 ms /    28 tokens (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:        eval time =   13294.53 ms /    20 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14739.36 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    28 runs   (    0.39 ms per token,  2565.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.52 ms /    29 tokens (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_print_timings:        eval time =   18277.09 ms /    27 runs   (  676.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19784.69 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    19 runs   (    0.39 ms per token,  2589.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.58 ms /    29 tokens (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12142.08 ms /    18 runs   (  674.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13618.71 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    20 runs   (    0.40 ms per token,  2521.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.48 ms /    28 tokens (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12840.20 ms /    19 runs   (  675.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14272.84 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    20 runs   (    0.38 ms per token,  2651.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.20 ms /    28 tokens (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12914.54 ms /    19 runs   (  679.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14351.70 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2551.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.79 ms /    28 tokens (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11901.28 ms /    18 runs   (  661.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13327.89 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    19 runs   (    0.39 ms per token,  2574.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.86 ms /    28 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11782.83 ms /    18 runs   (  654.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13224.24 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    20 runs   (    0.39 ms per token,  2552.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.43 ms /    27 tokens (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12611.33 ms /    19 runs   (  663.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14004.44 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2611.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.87 ms /    27 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12505.97 ms /    19 runs   (  658.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13934.31 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2612.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1476.94 ms /    28 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12144.20 ms /    18 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13676.10 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2605.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.41 ms /    29 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10533.12 ms /    16 runs   (  658.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12011.50 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    20 runs   (    0.39 ms per token,  2566.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.87 ms /    29 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12716.87 ms /    19 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14247.65 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4801.15 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    18 runs   (    0.44 ms per token,  2295.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.05 ms /    28 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11536.75 ms /    17 runs   (  678.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12996.61 ms /    45 tokens\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(f\"Completed {i} rows\")\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        prompt= f\"{df.iloc[i, 0]} / {df.iloc[i, 1]} = ?\"\n",
    "\n",
    "\n",
    "        prompt_template=f'''SYSTEM: You are a math assistant.I will ask you some division questions. Please answer upto 12 digits after decimal point.For example, if I ask you '0.9 / 0.1 = ?', you should answer 'answer=9.000000000000'. Do not include any other information in your answer.\n",
    "        \n",
    "        USER: {prompt}\n",
    "        \n",
    "        ASSISTANT:'''\n",
    "        \n",
    "        response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                    repeat_penalty=1.2, top_k=150,\n",
    "                    echo=False)\n",
    "        \n",
    "        with open('division_12_digit.txt', 'a') as f:\n",
    "            answer=response[\"choices\"][0][\"text\"]\n",
    "            f.write(f\"{df.iloc[i, 0]} / {df.iloc[i, 1]} = {answer} \\n\")\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        \n",
    "        with open('division_12_digit.txt', 'a') as f:\n",
    "            f.write(f\"{df.iloc[i, 0]} / {df.iloc[i, 1]} = Error \\n\")\n",
    "            \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viveksdmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
