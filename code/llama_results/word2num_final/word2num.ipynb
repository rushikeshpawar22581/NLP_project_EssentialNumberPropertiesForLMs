{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required libraries\n",
    "# %pip install transformers\n",
    "# %pip install torchtext\n",
    "# %pip install sentencepiece\n",
    "# %pip install datasets\n",
    "# %pip install torchmetrics\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# #huggiface download\n",
    "# %pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/anaconda3/envs/viveksdmlenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the model llama 2 13b chat gguf\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is in bin format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf\n"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "#print toal path\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.36 GiB (5.51 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  8555.93 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   400.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    85.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '16'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= f\"what is minus three hundred and twenty one point two two?\"\n",
    "\n",
    "prompt_template=f'''You are a math assistant. I will ask you to find number from its word representation. Please answer in the correct format. For example, if I ask 'What is thirty-three , you should answer 'answer = 33'. Do not include any other information in your answer.\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT:'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    10 runs   (    0.44 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3912.57 ms /    80 tokens (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6294.15 ms /     9 runs   (  699.35 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   10235.23 ms /    89 tokens\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " answer = -321.22\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file in data folder int_addition.json\n",
    "with open('numeration_word2num.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive int</th>\n",
       "      <th>negative int</th>\n",
       "      <th>positive dec</th>\n",
       "      <th>negative dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>[zero, one, two, three, four, five, six, seven...</td>\n",
       "      <td>[zero, minus one, minus two, minus three, minu...</td>\n",
       "      <td>[five point zero one, three point six five, ni...</td>\n",
       "      <td>[minus seven point five eight, minus nine poin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>[ten, eleven, twelve, thirteen, fourteen, fift...</td>\n",
       "      <td>[minus ten, minus eleven, minus twelve, minus ...</td>\n",
       "      <td>[thirteen point two nine, twenty point zero se...</td>\n",
       "      <td>[minus ninety-two point one eight, minus ninet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>[two hundred and sixty-eight, five hundred and...</td>\n",
       "      <td>[minus seven hundred and fifty-four, minus two...</td>\n",
       "      <td>[one hundred and twenty-six point eight two, s...</td>\n",
       "      <td>[minus eight hundred and forty-five point eigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4</th>\n",
       "      <td>[one thousand, one hundred and sixty-seven, se...</td>\n",
       "      <td>[minus four thousand, nine hundred and forty-s...</td>\n",
       "      <td>[one thousand, three hundred and twenty-nine, ...</td>\n",
       "      <td>[minus six thousand, three hundred and fifty-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>[ninety-six thousand, two hundred and fifty-si...</td>\n",
       "      <td>[minus ninety-nine thousand, three hundred and...</td>\n",
       "      <td>[twenty-six thousand, one hundred and fifty po...</td>\n",
       "      <td>[minus fourteen thousand, four hundred and sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6</th>\n",
       "      <td>[seven hundred and eighty-seven thousand, seve...</td>\n",
       "      <td>[minus two hundred and fifty-eight thousand, o...</td>\n",
       "      <td>[six hundred and eighty-three thousand, three ...</td>\n",
       "      <td>[minus eight hundred and eighty-seven thousand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7</th>\n",
       "      <td>[five million, eight hundred and nineteen thou...</td>\n",
       "      <td>[minus five million, five hundred and two thou...</td>\n",
       "      <td>[nine million, one hundred and twenty-nine tho...</td>\n",
       "      <td>[minus seven million, three hundred and twenty...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         positive int  \\\n",
       "d1  [zero, one, two, three, four, five, six, seven...   \n",
       "d2  [ten, eleven, twelve, thirteen, fourteen, fift...   \n",
       "d3  [two hundred and sixty-eight, five hundred and...   \n",
       "d4  [one thousand, one hundred and sixty-seven, se...   \n",
       "d5  [ninety-six thousand, two hundred and fifty-si...   \n",
       "d6  [seven hundred and eighty-seven thousand, seve...   \n",
       "d7  [five million, eight hundred and nineteen thou...   \n",
       "\n",
       "                                         negative int  \\\n",
       "d1  [zero, minus one, minus two, minus three, minu...   \n",
       "d2  [minus ten, minus eleven, minus twelve, minus ...   \n",
       "d3  [minus seven hundred and fifty-four, minus two...   \n",
       "d4  [minus four thousand, nine hundred and forty-s...   \n",
       "d5  [minus ninety-nine thousand, three hundred and...   \n",
       "d6  [minus two hundred and fifty-eight thousand, o...   \n",
       "d7  [minus five million, five hundred and two thou...   \n",
       "\n",
       "                                         positive dec  \\\n",
       "d1  [five point zero one, three point six five, ni...   \n",
       "d2  [thirteen point two nine, twenty point zero se...   \n",
       "d3  [one hundred and twenty-six point eight two, s...   \n",
       "d4  [one thousand, three hundred and twenty-nine, ...   \n",
       "d5  [twenty-six thousand, one hundred and fifty po...   \n",
       "d6  [six hundred and eighty-three thousand, three ...   \n",
       "d7  [nine million, one hundred and twenty-nine tho...   \n",
       "\n",
       "                                         negative dec  \n",
       "d1  [minus seven point five eight, minus nine poin...  \n",
       "d2  [minus ninety-two point one eight, minus ninet...  \n",
       "d3  [minus eight hundred and forty-five point eigh...  \n",
       "d4  [minus six thousand, three hundred and fifty-s...  \n",
       "d5  [minus fourteen thousand, four hundred and sev...  \n",
       "d6  [minus eight hundred and eighty-seven thousand...  \n",
       "d7  [minus seven million, three hundred and twenty...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data as pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "#last 5 rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_colunm_data(column_index): \n",
    "    #load file in data folder int_addition.json\n",
    "    column_name=df.columns[column_index]\n",
    "    numeration_word2num=df[column_name].to_list()\n",
    "    numeration_word2num= [item for sublist in numeration_word2num for item in sublist]\n",
    "    \n",
    "    #create dataframe\n",
    "    df_numeration_word2num=pd.DataFrame(numeration_word2num)\n",
    "    \n",
    "    return df_numeration_word2num\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      0\n",
      "0                          minus seven point five eight\n",
      "1                            minus nine point two three\n",
      "2                            minus one point three four\n",
      "3                             minus one point zero four\n",
      "4                            minus nine point nine four\n",
      "...                                                 ...\n",
      "1395  minus one million, forty-four thousand, nine h...\n",
      "1396  minus two million, eight hundred and thirty-se...\n",
      "1397  minus five million, nine hundred and sixty-nin...\n",
      "1398  minus three million, three hundred and one tho...\n",
      "1399  minus one million, three hundred and thirty-ni...\n",
      "\n",
      "[1400 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(load_colunm_data(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load required data\n",
    "df=load_colunm_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     8 runs   (    0.45 ms per token,  2245.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2682.57 ms /    54 tokens (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:        eval time =    4923.39 ms /     7 runs   (  703.34 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    7628.27 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     8 runs   (    0.45 ms per token,  2213.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.65 ms /    13 tokens (   55.90 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4836.61 ms /     7 runs   (  690.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5586.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     8 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.99 ms /    13 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    4801.10 ms /     7 runs   (  685.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5519.27 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /     8 runs   (    0.57 ms per token,  1752.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.03 ms /    11 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4914.93 ms /     7 runs   (  702.13 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    5548.05 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2365.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.70 ms /    13 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    4831.06 ms /     7 runs   (  690.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5545.63 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.03 ms /    13 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4765.62 ms /     7 runs   (  680.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5498.83 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2360.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.79 ms /    13 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4716.58 ms /     7 runs   (  673.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5433.74 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.01 ms /    13 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    4779.94 ms /     7 runs   (  682.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5494.18 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     8 runs   (    0.44 ms per token,  2264.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.44 ms /    11 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    4804.96 ms /     7 runs   (  686.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5431.04 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2261.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.83 ms /    13 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    4782.20 ms /     7 runs   (  683.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5496.31 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     8 runs   (    0.43 ms per token,  2326.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.13 ms /    13 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    4763.93 ms /     7 runs   (  680.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5488.61 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     7 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.46 ms /    12 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =    4065.01 ms /     6 runs   (  677.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4735.91 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     7 runs   (    0.43 ms per token,  2350.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.36 ms /    12 tokens (   59.78 ms per token,    16.73 tokens per second)\n",
      "llama_print_timings:        eval time =    4076.03 ms /     6 runs   (  679.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4812.73 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.83 ms /    13 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    4754.08 ms /     7 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5493.88 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2366.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.94 ms /    13 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4895.35 ms /     7 runs   (  699.34 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    5622.61 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.83 ms /    13 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    4770.87 ms /     7 runs   (  681.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5503.10 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2346.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.24 ms /    13 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    4750.46 ms /     7 runs   (  678.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5467.00 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     8 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.18 ms /    13 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    4727.73 ms /     7 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5460.27 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     8 runs   (    0.41 ms per token,  2416.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.79 ms /    13 tokens (   55.98 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4721.76 ms /     7 runs   (  674.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5470.36 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2313.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.57 ms /    13 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    4708.50 ms /     7 runs   (  672.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5435.43 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.33 ms /    13 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4874.93 ms /     7 runs   (  696.42 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5584.76 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2334.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.76 ms /    12 tokens (   55.56 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =    4060.22 ms /     6 runs   (  676.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4745.77 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     8 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.65 ms /    13 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4761.16 ms /     7 runs   (  680.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5477.95 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.48 ms /    12 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    4109.40 ms /     6 runs   (  684.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    4784.76 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.58 ms /    13 tokens (   55.20 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =    4851.46 ms /     7 runs   (  693.07 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5590.88 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     8 runs   (    0.43 ms per token,  2338.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.70 ms /    13 tokens (   55.90 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4823.27 ms /     7 runs   (  689.04 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5572.06 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.83 ms /    13 tokens (   63.60 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =    4839.10 ms /     7 runs   (  691.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5687.48 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     8 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     757.66 ms /    13 tokens (   58.28 ms per token,    17.16 tokens per second)\n",
      "llama_print_timings:        eval time =    4794.80 ms /     7 runs   (  684.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5573.85 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2329.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.76 ms /    12 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4142.32 ms /     6 runs   (  690.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    4825.20 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     8 runs   (    0.49 ms per token,  2048.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.91 ms /    13 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    4899.62 ms /     7 runs   (  699.95 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    5617.61 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2380.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.90 ms /    13 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4627.39 ms /     7 runs   (  661.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5349.55 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     8 runs   (    0.44 ms per token,  2287.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     571.77 ms /    10 tokens (   57.18 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =    4733.97 ms /     7 runs   (  676.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5327.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2316.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.32 ms /    13 tokens (   55.72 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =    4806.97 ms /     7 runs   (  686.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5553.41 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.19 ms /    13 tokens (   55.17 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    4813.21 ms /     7 runs   (  687.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5552.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     8 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.68 ms /    13 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4741.90 ms /     7 runs   (  677.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5484.91 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     8 runs   (    0.42 ms per token,  2397.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     755.47 ms /    13 tokens (   58.11 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =    4827.50 ms /     7 runs   (  689.64 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5605.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /     8 runs   (    0.55 ms per token,  1809.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.80 ms /    13 tokens (   55.98 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4833.17 ms /     7 runs   (  690.45 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5584.89 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2365.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.36 ms /    13 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4809.06 ms /     7 runs   (  687.01 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5528.35 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     7 runs   (    0.42 ms per token,  2368.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.41 ms /    12 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =    4056.04 ms /     6 runs   (  676.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4720.84 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2329.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.21 ms /    13 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4724.49 ms /     7 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5443.14 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     8 runs   (    0.41 ms per token,  2411.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.30 ms /    13 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    4652.58 ms /     7 runs   (  664.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5373.10 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.84 ms /    13 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    4709.07 ms /     7 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5417.94 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2348.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.38 ms /    13 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    4710.06 ms /     7 runs   (  672.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5436.69 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2294.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.48 ms /    13 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    4781.81 ms /     7 runs   (  683.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5514.36 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     8 runs   (    0.45 ms per token,  2238.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.84 ms /    13 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =    4779.36 ms /     7 runs   (  682.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5515.68 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     8 runs   (    0.47 ms per token,  2105.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.22 ms /    13 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    4802.21 ms /     7 runs   (  686.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5517.62 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     8 runs   (    0.42 ms per token,  2400.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.12 ms /    13 tokens (   56.86 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =    4683.17 ms /     7 runs   (  669.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5444.02 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.46 ms /    13 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    4775.71 ms /     7 runs   (  682.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5497.45 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2346.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.89 ms /    13 tokens (   54.84 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4847.29 ms /     7 runs   (  692.47 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5582.11 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     7 runs   (    0.44 ms per token,  2259.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.58 ms /    12 tokens (   55.21 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    4050.90 ms /     6 runs   (  675.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4733.01 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2357.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.66 ms /    13 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    4760.28 ms /     7 runs   (  680.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5493.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     8 runs   (    0.42 ms per token,  2397.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.46 ms /    13 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    4682.22 ms /     7 runs   (  668.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5392.60 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2291.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.04 ms /    13 tokens (   57.39 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =    4748.54 ms /     7 runs   (  678.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5516.91 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     8 runs   (    0.42 ms per token,  2396.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.90 ms /    13 tokens (   56.61 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4769.20 ms /     7 runs   (  681.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5527.51 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.44 ms /    13 tokens (   55.42 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4803.26 ms /     7 runs   (  686.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5546.11 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2361.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.19 ms /    13 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4738.01 ms /     7 runs   (  676.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5462.31 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2316.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.08 ms /    13 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =    4861.20 ms /     7 runs   (  694.46 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5585.62 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     8 runs   (    0.44 ms per token,  2287.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.15 ms /    13 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4759.96 ms /     7 runs   (  679.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5470.34 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2277.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.59 ms /    13 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4646.94 ms /     7 runs   (  663.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5375.70 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /     8 runs   (    0.44 ms per token,  2252.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.03 ms /    13 tokens (   56.16 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =    4625.45 ms /     7 runs   (  660.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5377.62 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     7 runs   (    0.42 ms per token,  2374.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.40 ms /    12 tokens (   55.20 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =    3895.72 ms /     6 runs   (  649.29 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    4577.28 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     8 runs   (    0.45 ms per token,  2220.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.71 ms /    13 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4735.99 ms /     7 runs   (  676.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5477.47 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     5 runs   (    0.45 ms per token,  2214.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     570.94 ms /    10 tokens (   57.09 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2719.14 ms /     4 runs   (  679.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    3304.32 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     8 runs   (    0.45 ms per token,  2230.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.96 ms /    13 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    4655.26 ms /     7 runs   (  665.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5370.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.43 ms per token,  2351.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.84 ms /    13 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =    4719.79 ms /     7 runs   (  674.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5455.41 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     8 runs   (    0.43 ms per token,  2342.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.43 ms /    13 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =    4731.52 ms /     7 runs   (  675.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5460.47 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /     8 runs   (    0.46 ms per token,  2194.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.29 ms /    13 tokens (   55.48 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =    4762.40 ms /     7 runs   (  680.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5506.35 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2359.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.55 ms /    13 tokens (   55.43 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4620.89 ms /     7 runs   (  660.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5363.96 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.12 ms /    13 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =    4676.70 ms /     7 runs   (  668.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5398.75 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     8 runs   (    0.44 ms per token,  2273.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.53 ms /    13 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4729.65 ms /     7 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5447.96 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2334.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.66 ms /    13 tokens (   55.74 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    4731.81 ms /     7 runs   (  675.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5478.74 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     8 runs   (    0.45 ms per token,  2229.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.70 ms /    13 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    4770.38 ms /     7 runs   (  681.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5497.49 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2321.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.57 ms /    13 tokens (   54.81 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4692.26 ms /     7 runs   (  670.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5427.80 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2376.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.21 ms /    13 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    4673.23 ms /     7 runs   (  667.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5398.81 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.44 ms per token,  2295.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.43 ms /    11 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    4703.14 ms /     7 runs   (  671.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5323.55 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2316.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.66 ms /    13 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    4766.73 ms /     7 runs   (  680.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5494.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2321.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.14 ms /    13 tokens (   56.86 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =    4796.75 ms /     7 runs   (  685.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5558.21 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     8 runs   (    0.44 ms per token,  2268.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.82 ms /    13 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4785.26 ms /     7 runs   (  683.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5516.55 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.39 ms /    13 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    4725.73 ms /     7 runs   (  675.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5453.14 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     8 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.87 ms /    11 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4728.02 ms /     7 runs   (  675.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5349.57 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2374.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     566.77 ms /    10 tokens (   56.68 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4663.09 ms /     7 runs   (  666.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5251.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2277.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.47 ms /    13 tokens (   53.81 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =    4662.31 ms /     7 runs   (  666.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5384.62 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     7 runs   (    0.42 ms per token,  2366.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.24 ms /    12 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4081.25 ms /     6 runs   (  680.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4754.50 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2388.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.60 ms /    11 tokens (   56.87 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =    4711.89 ms /     7 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5359.23 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2343.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.35 ms /    13 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    4739.41 ms /     7 runs   (  677.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5463.53 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2289.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.70 ms /    13 tokens (   56.28 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =    4824.03 ms /     7 runs   (  689.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5578.18 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2360.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     740.90 ms /    13 tokens (   56.99 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4712.00 ms /     7 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5475.88 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2354.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.92 ms /    13 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    4780.06 ms /     7 runs   (  682.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5493.47 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     876.18 ms /    13 tokens (   67.40 ms per token,    14.84 tokens per second)\n",
      "llama_print_timings:        eval time =    4860.93 ms /     7 runs   (  694.42 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5759.89 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2279.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.59 ms /    13 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    4775.48 ms /     7 runs   (  682.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5502.34 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2305.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.78 ms /    13 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4742.85 ms /     7 runs   (  677.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5488.59 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /     8 runs   (    0.55 ms per token,  1828.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.88 ms /    13 tokens (   54.45 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    4731.57 ms /     7 runs   (  675.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5468.22 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.85 ms /    13 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    4748.40 ms /     7 runs   (  678.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5489.19 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2390.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.45 ms /    13 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4684.11 ms /     7 runs   (  669.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5409.15 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     7 runs   (    0.45 ms per token,  2224.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.13 ms /    12 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    4078.74 ms /     6 runs   (  679.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4750.72 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /     8 runs   (    0.46 ms per token,  2197.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.39 ms /    13 tokens (   53.95 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =    4972.41 ms /     7 runs   (  710.34 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    5697.15 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.78 ms /    13 tokens (   55.75 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    4870.53 ms /     7 runs   (  695.79 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5618.16 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2278.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.25 ms /    13 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    4758.79 ms /     7 runs   (  679.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5485.66 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2314.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.49 ms /    11 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    4815.03 ms /     7 runs   (  687.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5436.63 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     8 runs   (    0.45 ms per token,  2227.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.20 ms /    13 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    4653.91 ms /     7 runs   (  664.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5372.78 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     8 runs   (    0.44 ms per token,  2275.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.97 ms /    11 tokens (   56.09 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =    4732.60 ms /     7 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5372.20 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     7 runs   (    0.45 ms per token,  2216.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.92 ms /    12 tokens (   54.99 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =    4093.68 ms /     6 runs   (  682.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4773.75 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2348.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.97 ms /    13 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    4668.13 ms /     7 runs   (  666.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5398.79 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.88 ms /    13 tokens (   60.84 ms per token,    16.44 tokens per second)\n",
      "llama_print_timings:        eval time =    4599.15 ms /     7 runs   (  657.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5413.51 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2333.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.94 ms /    13 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    4736.81 ms /     7 runs   (  676.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5472.78 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2259.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.46 ms /    13 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4692.61 ms /     7 runs   (  670.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5413.66 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /     8 runs   (    0.41 ms per token,  2446.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.99 ms /    13 tokens (   55.38 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =    4868.04 ms /     7 runs   (  695.43 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5610.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.09 ms /    13 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    4838.90 ms /     7 runs   (  691.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5554.11 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.40 ms /    13 tokens (   54.80 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =    4736.59 ms /     7 runs   (  676.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5471.61 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     736.14 ms /    13 tokens (   56.63 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =    4729.58 ms /     7 runs   (  675.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5488.02 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2311.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.45 ms /    13 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4726.96 ms /     7 runs   (  675.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5467.74 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     8 runs   (    0.41 ms per token,  2411.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     714.39 ms /    13 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    4741.40 ms /     7 runs   (  677.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5478.73 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     8 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.80 ms /    13 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =    4749.30 ms /     7 runs   (  678.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5475.47 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     8 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.36 ms /    13 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4792.89 ms /     7 runs   (  684.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5541.49 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /     8 runs   (    0.44 ms per token,  2251.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.97 ms /    13 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4818.69 ms /     7 runs   (  688.38 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5565.83 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2292.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.22 ms /    13 tokens (   59.63 ms per token,    16.77 tokens per second)\n",
      "llama_print_timings:        eval time =    4705.39 ms /     7 runs   (  672.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5503.05 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     5 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     568.86 ms /    10 tokens (   56.89 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =    2744.23 ms /     4 runs   (  686.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    3327.51 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2377.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.57 ms /    12 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4746.75 ms /     7 runs   (  678.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5439.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2307.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.10 ms /    11 tokens (   56.37 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:        eval time =    4797.45 ms /     7 runs   (  685.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5440.10 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2346.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.51 ms /    13 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    4669.27 ms /     7 runs   (  667.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5395.45 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2364.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     624.04 ms /    11 tokens (   56.73 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =    4740.77 ms /     7 runs   (  677.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5387.62 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.42 ms /    13 tokens (   53.49 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4749.69 ms /     7 runs   (  678.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5467.73 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2360.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.42 ms /    13 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =    4560.56 ms /     7 runs   (  651.51 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    5285.44 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2318.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.34 ms /    13 tokens (   55.41 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4713.47 ms /     7 runs   (  673.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5457.07 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     8 runs   (    0.41 ms per token,  2414.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.51 ms /    13 tokens (   56.12 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =    4763.03 ms /     7 runs   (  680.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5515.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2256.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.50 ms /    13 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4781.80 ms /     7 runs   (  683.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5527.45 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     7 runs   (    0.41 ms per token,  2423.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.33 ms /    12 tokens (   54.69 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    3982.09 ms /     6 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    4658.53 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2380.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.67 ms /    13 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4707.23 ms /     7 runs   (  672.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5438.83 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2348.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     734.99 ms /    13 tokens (   56.54 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4746.98 ms /     7 runs   (  678.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5504.84 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2348.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.92 ms /    13 tokens (   55.30 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4786.97 ms /     7 runs   (  683.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5528.88 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     8 runs   (    0.42 ms per token,  2403.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.95 ms /    13 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    4697.27 ms /     7 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5429.44 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2316.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.62 ms /    13 tokens (   55.36 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4711.86 ms /     7 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5454.62 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2261.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.19 ms /    13 tokens (   54.48 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    4675.57 ms /     7 runs   (  667.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5406.12 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2311.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.07 ms /    13 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    4630.53 ms /     7 runs   (  661.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5366.74 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2385.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.80 ms /    13 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =    4751.43 ms /     7 runs   (  678.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5488.12 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /     8 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.86 ms /    13 tokens (   53.84 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    4627.39 ms /     7 runs   (  661.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5353.70 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     8 runs   (    0.44 ms per token,  2282.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.67 ms /    13 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =    4803.03 ms /     7 runs   (  686.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5528.33 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2311.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.97 ms /    13 tokens (   56.38 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:        eval time =    4673.95 ms /     7 runs   (  667.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5430.22 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     714.62 ms /    13 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4709.41 ms /     7 runs   (  672.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5447.21 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     7 runs   (    0.43 ms per token,  2301.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.00 ms /    12 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    3963.35 ms /     6 runs   (  660.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    4634.39 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     8 runs   (    0.44 ms per token,  2275.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.54 ms /    13 tokens (   54.81 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4869.29 ms /     7 runs   (  695.61 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5604.53 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2348.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.74 ms /    13 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =    4637.35 ms /     7 runs   (  662.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5352.44 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.63 ms /    13 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4755.19 ms /     7 runs   (  679.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5483.34 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     7 runs   (    0.43 ms per token,  2345.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.82 ms /    12 tokens (   60.74 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3993.04 ms /     6 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    4742.37 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.54 ms /    13 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    4699.85 ms /     7 runs   (  671.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5426.82 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     7 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.86 ms /    12 tokens (   55.66 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4078.76 ms /     6 runs   (  679.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4766.23 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2318.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.36 ms /    13 tokens (   54.57 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =    4818.73 ms /     7 runs   (  688.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5553.38 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     8 runs   (    0.45 ms per token,  2240.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.13 ms /    11 tokens (   56.65 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =    4757.86 ms /     7 runs   (  679.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5404.08 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     613.01 ms /    11 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    4724.83 ms /     7 runs   (  674.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5360.62 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     8 runs   (    0.43 ms per token,  2324.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.53 ms /    11 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    4820.40 ms /     7 runs   (  688.63 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5438.81 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     8 runs   (    0.41 ms per token,  2422.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.71 ms /    13 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    4743.52 ms /     7 runs   (  677.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5465.13 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2376.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.35 ms /    13 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    4818.28 ms /     7 runs   (  688.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5533.16 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2306.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.51 ms /    13 tokens (   63.04 ms per token,    15.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4717.08 ms /     7 runs   (  673.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5559.38 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2353.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     628.71 ms /    11 tokens (   57.16 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:        eval time =    4743.48 ms /     7 runs   (  677.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5395.08 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2279.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.63 ms /    13 tokens (   53.43 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =    4773.64 ms /     7 runs   (  681.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5491.14 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.11 ms /    13 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    4781.94 ms /     7 runs   (  683.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5505.26 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2330.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.74 ms /    11 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =    4624.83 ms /     7 runs   (  660.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5253.44 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     8 runs   (    0.43 ms per token,  2341.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.32 ms /    13 tokens (   56.33 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =    4811.86 ms /     7 runs   (  687.41 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5567.58 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2378.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.65 ms /    13 tokens (   55.74 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    4745.85 ms /     7 runs   (  677.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5493.13 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     7 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.44 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    4052.72 ms /     6 runs   (  675.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4716.85 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     8 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     626.75 ms /    11 tokens (   56.98 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4820.18 ms /     7 runs   (  688.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5470.50 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2302.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.94 ms /    13 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4634.41 ms /     7 runs   (  662.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5352.98 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     8 runs   (    0.43 ms per token,  2341.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.91 ms /    13 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    4674.95 ms /     7 runs   (  667.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5386.49 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.85 ms /    13 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    4640.44 ms /     7 runs   (  662.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5356.69 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2321.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.17 ms /    13 tokens (   55.24 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =    4555.91 ms /     7 runs   (  650.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    5296.76 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     7 runs   (    0.42 ms per token,  2365.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.96 ms /    12 tokens (   59.50 ms per token,    16.81 tokens per second)\n",
      "llama_print_timings:        eval time =    3997.18 ms /     6 runs   (  666.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    4730.77 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2371.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.50 ms /    13 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =    4853.91 ms /     7 runs   (  693.42 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5582.75 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2310.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.04 ms /    12 tokens (   55.17 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    4022.32 ms /     6 runs   (  670.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4704.26 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2256.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     714.57 ms /    13 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4748.45 ms /     7 runs   (  678.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5485.77 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2277.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.40 ms /    13 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    4766.13 ms /     7 runs   (  680.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5487.56 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     7 runs   (    0.42 ms per token,  2359.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.99 ms /    12 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    4394.78 ms /     6 runs   (  732.46 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    5067.91 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2333.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.84 ms /    13 tokens (   54.45 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4783.30 ms /     7 runs   (  683.33 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5514.47 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2370.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.57 ms /    13 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    4691.09 ms /     7 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5413.42 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.95 ms /    13 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4662.83 ms /     7 runs   (  666.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5384.59 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.06 ms /    13 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4727.78 ms /     7 runs   (  675.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5462.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     8 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.08 ms /    13 tokens (   53.78 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4797.41 ms /     7 runs   (  685.34 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5519.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2303.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.45 ms /    13 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4721.07 ms /     7 runs   (  674.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5440.14 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2343.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.08 ms /    13 tokens (   53.78 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4796.18 ms /     7 runs   (  685.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5518.18 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     7 runs   (    0.43 ms per token,  2324.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.91 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =    4329.10 ms /     6 runs   (  721.52 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    4997.29 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2292.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.71 ms /    13 tokens (   56.59 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4873.28 ms /     7 runs   (  696.18 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5631.90 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     7 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.76 ms /    12 tokens (   55.90 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4064.54 ms /     6 runs   (  677.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    4755.57 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     8 runs   (    0.43 ms per token,  2339.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.26 ms /    13 tokens (   54.10 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    4762.08 ms /     7 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5487.53 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2318.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.52 ms /    13 tokens (   56.81 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4790.95 ms /     7 runs   (  684.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5552.55 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     8 runs   (    0.44 ms per token,  2266.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.30 ms /    13 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    4657.78 ms /     7 runs   (  665.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5382.38 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /     8 runs   (    0.66 ms per token,  1506.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.33 ms /    11 tokens (   56.03 ms per token,    17.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4812.65 ms /     7 runs   (  687.52 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5461.90 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2316.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.64 ms /    13 tokens (   55.20 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    4917.38 ms /     7 runs   (  702.48 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    5658.19 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.81 ms /    13 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    4778.90 ms /     7 runs   (  682.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5519.67 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     8 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.84 ms /    13 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =    4812.29 ms /     7 runs   (  687.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5531.96 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2303.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.22 ms /    13 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =    4814.52 ms /     7 runs   (  687.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5545.90 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.86 ms /    13 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4773.51 ms /     7 runs   (  681.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5505.52 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2382.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.85 ms /    13 tokens (   54.76 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4728.94 ms /     7 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5464.15 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     8 runs   (    0.41 ms per token,  2411.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.34 ms /    13 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    4836.33 ms /     7 runs   (  690.90 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5560.89 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.50 ms /    13 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    4723.90 ms /     7 runs   (  674.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5446.13 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /     8 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.28 ms /    13 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    4864.20 ms /     7 runs   (  694.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5579.66 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     8 runs   (    0.42 ms per token,  2380.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.41 ms /    13 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4760.56 ms /     7 runs   (  680.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5508.24 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2377.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.89 ms /    13 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4781.29 ms /     7 runs   (  683.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5499.91 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2376.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.23 ms /    13 tokens (   56.02 ms per token,    17.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4928.13 ms /     7 runs   (  704.02 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    5679.45 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     7 runs   (    0.44 ms per token,  2250.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     567.21 ms /    10 tokens (   56.72 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =    4171.69 ms /     6 runs   (  695.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    4759.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     8 runs   (    0.44 ms per token,  2285.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.38 ms /    13 tokens (   53.95 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =    4745.79 ms /     7 runs   (  677.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5470.43 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /     8 runs   (    0.45 ms per token,  2205.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.33 ms /    13 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =    4694.42 ms /     7 runs   (  670.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5426.33 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2332.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.54 ms /    16 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5394.44 ms /     8 runs   (  674.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6259.84 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     9 runs   (    0.43 ms per token,  2339.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.47 ms /    14 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    5470.83 ms /     8 runs   (  683.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6248.82 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2367.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.33 ms /    16 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =    5535.90 ms /     8 runs   (  691.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6395.66 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /     9 runs   (    0.45 ms per token,  2216.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.26 ms /    13 tokens (   54.87 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    5485.92 ms /     8 runs   (  685.74 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6225.48 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /     9 runs   (    0.45 ms per token,  2246.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.39 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    5447.88 ms /     8 runs   (  680.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6301.21 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2331.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.45 ms /    15 tokens (   54.36 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =    4705.23 ms /     7 runs   (  672.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5543.73 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2343.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.00 ms /    16 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    5446.90 ms /     8 runs   (  680.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6325.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2284.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.46 ms /    13 tokens (   57.42 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =    3318.36 ms /     5 runs   (  663.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    4081.65 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    10 runs   (    0.43 ms per token,  2352.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.23 ms /    15 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6114.79 ms /     9 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6939.76 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2330.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     878.52 ms /    16 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =    5373.45 ms /     8 runs   (  671.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6277.76 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     9 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     802.26 ms /    15 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    5377.98 ms /     8 runs   (  672.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6205.88 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2324.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.69 ms /    16 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5356.99 ms /     8 runs   (  669.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6225.97 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.29 ms /    16 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    5465.74 ms /     8 runs   (  683.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6321.59 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2356.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.20 ms /    13 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    5273.65 ms /     8 runs   (  659.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6006.82 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /     9 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.79 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    5450.81 ms /     8 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6314.29 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2281.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.74 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =    5413.57 ms /     8 runs   (  676.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6263.65 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2342.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.67 ms /    15 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    5311.56 ms /     8 runs   (  663.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6121.37 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2387.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.73 ms /    14 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    5446.02 ms /     8 runs   (  680.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6218.42 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2307.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.67 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    5404.43 ms /     8 runs   (  675.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6264.22 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2310.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.71 ms /    16 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    5357.14 ms /     8 runs   (  669.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6209.52 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2387.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1001.52 ms /    17 tokens (   58.91 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5256.95 ms /     8 runs   (  657.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6283.44 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2361.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.08 ms /    15 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    5458.49 ms /     8 runs   (  682.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6303.42 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2355.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.50 ms /    16 tokens (   52.34 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    5384.76 ms /     8 runs   (  673.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6247.43 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2377.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     936.49 ms /    14 tokens (   66.89 ms per token,    14.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5299.50 ms /     8 runs   (  662.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6261.53 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2387.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.83 ms /    15 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    4615.01 ms /     7 runs   (  659.29 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5426.80 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     8 runs   (    0.41 ms per token,  2416.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.84 ms /    13 tokens (   55.53 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4646.41 ms /     7 runs   (  663.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5391.14 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2318.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.75 ms /    13 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    5352.27 ms /     8 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6081.37 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2384.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.65 ms /    15 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    5365.35 ms /     8 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6210.77 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /     9 runs   (    0.51 ms per token,  1976.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     946.63 ms /    17 tokens (   55.68 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5455.64 ms /     8 runs   (  681.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6432.24 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2350.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.94 ms /    16 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    5493.61 ms /     8 runs   (  686.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6353.81 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2351.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     800.67 ms /    15 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    5415.51 ms /     8 runs   (  676.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6241.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2323.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.29 ms /    13 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =    5411.52 ms /     8 runs   (  676.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6136.36 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2331.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     757.90 ms /    14 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    5467.83 ms /     8 runs   (  683.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6251.69 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2265.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.68 ms /    16 tokens (   64.54 ms per token,    15.49 tokens per second)\n",
      "llama_print_timings:        eval time =    5336.32 ms /     8 runs   (  667.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6394.74 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     9 runs   (    0.44 ms per token,  2291.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.77 ms /    15 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =    5289.93 ms /     8 runs   (  661.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6134.93 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /     9 runs   (    0.44 ms per token,  2295.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.76 ms /    14 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    5237.95 ms /     8 runs   (  654.74 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    6037.29 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2289.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.80 ms /    12 tokens (   56.48 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =    4829.35 ms /     7 runs   (  689.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5530.23 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2354.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.52 ms /    14 tokens (   54.75 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5372.10 ms /     8 runs   (  671.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6165.05 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2361.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.80 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =    5430.90 ms /     8 runs   (  678.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6290.52 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2360.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.80 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =    5455.53 ms /     8 runs   (  681.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6308.64 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /     9 runs   (    0.41 ms per token,  2412.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.68 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    5377.61 ms /     8 runs   (  672.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6225.87 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2310.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     860.41 ms /    16 tokens (   53.78 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    5474.34 ms /     8 runs   (  684.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6360.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.21 ms /    16 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5418.35 ms /     8 runs   (  677.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6287.39 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /     9 runs   (    0.44 ms per token,  2254.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.03 ms /    15 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5357.42 ms /     8 runs   (  669.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6176.18 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2360.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.52 ms /    15 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5520.52 ms /     8 runs   (  690.07 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6339.09 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     9 runs   (    0.43 ms per token,  2338.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.25 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    5309.47 ms /     8 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6161.22 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2343.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.95 ms /    16 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    5338.04 ms /     8 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6199.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2307.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.05 ms /    13 tokens (   55.93 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =    5379.14 ms /     8 runs   (  672.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6132.01 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2371.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.24 ms /    15 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    4737.36 ms /     7 runs   (  676.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5543.68 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     9 runs   (    0.43 ms per token,  2316.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.32 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    5404.27 ms /     8 runs   (  675.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6267.84 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2318.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.16 ms /    16 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =    5333.76 ms /     8 runs   (  666.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6194.12 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2326.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.11 ms /    13 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    5382.33 ms /     8 runs   (  672.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6115.75 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     9 runs   (    0.43 ms per token,  2311.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     932.78 ms /    17 tokens (   54.87 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    5398.25 ms /     8 runs   (  674.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6356.71 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2376.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.35 ms /    14 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =    5291.38 ms /     8 runs   (  661.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6065.03 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2370.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.86 ms /    16 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    5422.19 ms /     8 runs   (  677.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6279.87 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2326.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.13 ms /    16 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    5353.29 ms /     8 runs   (  669.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6234.60 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2367.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.13 ms /    15 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5437.56 ms /     8 runs   (  679.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6249.09 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     798.31 ms /    15 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    5495.34 ms /     8 runs   (  686.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6319.16 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /     9 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.30 ms /    15 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5405.46 ms /     8 runs   (  675.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6223.44 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2322.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.05 ms /    16 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5495.30 ms /     8 runs   (  686.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6364.58 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2305.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     940.76 ms /    17 tokens (   55.34 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5436.05 ms /     8 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6402.41 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.97 ms /    15 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5410.47 ms /     8 runs   (  676.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6230.46 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /     9 runs   (    0.42 ms per token,  2391.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.78 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    5500.87 ms /     8 runs   (  687.61 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6360.89 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2341.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     952.73 ms /    17 tokens (   56.04 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5456.18 ms /     8 runs   (  682.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6434.77 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2326.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.35 ms /    16 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =    5395.36 ms /     8 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6255.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2399.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.77 ms /    15 tokens (   57.65 ms per token,    17.35 tokens per second)\n",
      "llama_print_timings:        eval time =    5509.99 ms /     8 runs   (  688.75 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6400.73 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /     9 runs   (    0.44 ms per token,  2264.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.85 ms /    14 tokens (   54.63 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    5433.93 ms /     8 runs   (  679.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6224.58 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2268.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.54 ms /    16 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    5390.86 ms /     8 runs   (  673.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6271.05 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2328.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.01 ms /    16 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =    5355.90 ms /     8 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6215.41 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /     9 runs   (    0.42 ms per token,  2379.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.68 ms /    15 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5339.09 ms /     8 runs   (  667.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6156.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2307.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.60 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    5457.55 ms /     8 runs   (  682.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6309.58 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2318.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.23 ms /    13 tokens (   58.63 ms per token,    17.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5456.91 ms /     8 runs   (  682.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6244.08 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2329.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.28 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =    5401.50 ms /     8 runs   (  675.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6250.55 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /     9 runs   (    0.45 ms per token,  2228.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     936.00 ms /    17 tokens (   55.06 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =    5336.65 ms /     8 runs   (  667.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6298.98 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     8 runs   (    0.42 ms per token,  2408.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.53 ms /    16 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    4583.23 ms /     7 runs   (  654.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    5442.59 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2372.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.85 ms /    16 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    5623.85 ms /     8 runs   (  702.98 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6478.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2357.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.26 ms /    16 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =    5444.62 ms /     8 runs   (  680.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6304.56 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2359.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.85 ms /    16 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    5510.23 ms /     8 runs   (  688.78 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6384.90 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2353.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.15 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    5540.16 ms /     8 runs   (  692.52 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6395.04 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.84 ms /    15 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    4721.69 ms /     7 runs   (  674.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5542.12 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2318.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     798.04 ms /    15 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    5344.77 ms /     8 runs   (  668.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6168.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2343.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.91 ms /    15 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4853.30 ms /     7 runs   (  693.33 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5666.39 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     6 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.64 ms /    13 tokens (   56.20 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =    3306.12 ms /     5 runs   (  661.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    4054.23 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2299.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.42 ms /    14 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    5440.54 ms /     8 runs   (  680.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6229.53 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.16 ms /    14 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4654.38 ms /     7 runs   (  664.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5453.05 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     9 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     921.26 ms /    17 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    5274.86 ms /     8 runs   (  659.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6222.93 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2307.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.38 ms /    15 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5382.91 ms /     8 runs   (  672.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6195.55 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     9 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.34 ms /    17 tokens (   61.49 ms per token,    16.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5387.91 ms /     8 runs   (  673.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6459.23 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     9 runs   (    0.42 ms per token,  2408.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.00 ms /    15 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5560.28 ms /     8 runs   (  695.03 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6370.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     9 runs   (    0.42 ms per token,  2408.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.01 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5196.97 ms /     8 runs   (  649.62 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    6048.24 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2376.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     740.52 ms /    14 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    5293.49 ms /     8 runs   (  661.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6059.64 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2302.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.31 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =    5173.54 ms /     8 runs   (  646.69 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    6022.14 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2349.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     927.65 ms /    17 tokens (   54.57 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =    5285.42 ms /     8 runs   (  660.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6238.80 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2350.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.57 ms /    13 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    5391.32 ms /     8 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6135.47 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     9 runs   (    0.43 ms per token,  2311.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     955.80 ms /    17 tokens (   56.22 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =    5254.07 ms /     8 runs   (  656.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6236.33 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2341.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.19 ms /    14 tokens (   55.16 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5300.06 ms /     8 runs   (  662.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6098.20 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2317.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.64 ms /    16 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =    5445.55 ms /     8 runs   (  680.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6300.34 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2341.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.72 ms /    13 tokens (   56.06 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5279.09 ms /     8 runs   (  659.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6034.46 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     8 runs   (    0.45 ms per token,  2222.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.40 ms /    16 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4597.01 ms /     7 runs   (  656.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5458.25 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2362.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.78 ms /    15 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4627.07 ms /     7 runs   (  661.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    5458.79 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2284.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     938.94 ms /    17 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    5331.50 ms /     8 runs   (  666.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6296.47 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     8 runs   (    0.44 ms per token,  2248.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.89 ms /    14 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4689.31 ms /     7 runs   (  669.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5452.00 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.02 ms /     9 runs   (    0.45 ms per token,  2239.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.20 ms /    13 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =    5407.79 ms /     8 runs   (  675.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6142.72 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     9 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.32 ms /    15 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =    5420.63 ms /     8 runs   (  677.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6251.73 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /     9 runs   (    0.41 ms per token,  2429.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.86 ms /    16 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    5545.03 ms /     8 runs   (  693.13 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6401.54 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     892.23 ms /    16 tokens (   55.76 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5441.00 ms /     8 runs   (  680.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6359.21 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     6 runs   (    0.43 ms per token,  2341.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.38 ms /    14 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3392.95 ms /     5 runs   (  678.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    4157.88 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2342.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.84 ms /    15 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5336.97 ms /     8 runs   (  667.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6150.77 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2359.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.86 ms /    12 tokens (   66.99 ms per token,    14.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5569.49 ms /     8 runs   (  696.19 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6399.30 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     9 runs   (    0.43 ms per token,  2316.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.17 ms /    17 tokens (   54.72 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    5358.22 ms /     8 runs   (  669.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6314.48 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2268.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     944.94 ms /    17 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5482.20 ms /     8 runs   (  685.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6453.14 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2343.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.07 ms /    16 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5450.82 ms /     8 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6316.09 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2301.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.63 ms /    16 tokens (   68.41 ms per token,    14.62 tokens per second)\n",
      "llama_print_timings:        eval time =    5336.63 ms /     8 runs   (  667.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6457.46 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /     9 runs   (    0.46 ms per token,  2189.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     870.47 ms /    16 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    5265.05 ms /     8 runs   (  658.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6162.10 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /     9 runs   (    0.42 ms per token,  2380.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.58 ms /    14 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    5267.02 ms /     8 runs   (  658.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6058.15 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /     9 runs   (    0.42 ms per token,  2382.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     800.62 ms /    15 tokens (   53.38 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    5384.95 ms /     8 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6211.91 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2307.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.38 ms /    12 tokens (   55.45 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =    4774.54 ms /     7 runs   (  682.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5463.11 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2367.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.90 ms /    13 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    5410.41 ms /     8 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6146.10 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /     9 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.84 ms /    13 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    5578.40 ms /     8 runs   (  697.30 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6296.68 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2354.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.37 ms /    15 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5437.04 ms /     8 runs   (  679.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6260.67 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.83 ms /    15 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5538.74 ms /     8 runs   (  692.34 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6357.22 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.88 ms /    12 tokens (   55.99 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4783.62 ms /     7 runs   (  683.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5478.93 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2352.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.79 ms /    13 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    5723.81 ms /     8 runs   (  715.48 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    6454.12 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2373.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     757.10 ms /    14 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    5331.43 ms /     8 runs   (  666.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6114.60 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2354.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     937.38 ms /    17 tokens (   55.14 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =    5378.88 ms /     8 runs   (  672.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6344.66 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2341.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.53 ms /    15 tokens (   55.90 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5470.64 ms /     8 runs   (  683.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6335.15 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2370.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.11 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5441.03 ms /     8 runs   (  680.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6296.57 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2354.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.30 ms /    13 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =    5505.40 ms /     8 runs   (  688.18 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6247.99 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2376.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.60 ms /    15 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4694.98 ms /     7 runs   (  670.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    5504.46 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2359.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.32 ms /    17 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    5565.16 ms /     8 runs   (  695.64 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6520.47 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2308.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.98 ms /    13 tokens (   62.31 ms per token,    16.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5285.19 ms /     8 runs   (  660.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6122.31 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.24 ms /    15 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =    4761.74 ms /     7 runs   (  680.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5603.29 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2329.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     863.58 ms /    15 tokens (   57.57 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5429.13 ms /     8 runs   (  678.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6318.46 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2321.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     922.93 ms /    17 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    5326.96 ms /     8 runs   (  665.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6275.81 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2371.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     750.83 ms /    14 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    4612.00 ms /     7 runs   (  658.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5385.37 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.12 ms /    14 tokens (   60.58 ms per token,    16.51 tokens per second)\n",
      "llama_print_timings:        eval time =    5275.60 ms /     8 runs   (  659.45 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6149.71 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /     9 runs   (    0.44 ms per token,  2272.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.09 ms /    15 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5420.44 ms /     8 runs   (  677.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6234.59 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /     9 runs   (    0.46 ms per token,  2180.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     935.41 ms /    17 tokens (   55.02 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =    5469.18 ms /     8 runs   (  683.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6430.44 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /     9 runs   (    0.41 ms per token,  2431.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.75 ms /    15 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    5316.71 ms /     8 runs   (  664.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6128.38 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2324.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.29 ms /    15 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    5374.37 ms /     8 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6214.77 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     9 runs   (    0.43 ms per token,  2313.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.51 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    5533.10 ms /     8 runs   (  691.64 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6389.90 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.45 ms /    15 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    5442.48 ms /     8 runs   (  680.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6276.23 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2396.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.55 ms /    13 tokens (   54.89 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =    5409.82 ms /     8 runs   (  676.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6149.08 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2351.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     800.39 ms /    15 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    5484.31 ms /     8 runs   (  685.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6310.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /     9 runs   (    0.41 ms per token,  2416.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.75 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    5395.75 ms /     8 runs   (  674.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6250.75 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2327.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.95 ms /    15 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    5369.99 ms /     8 runs   (  671.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6192.28 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2376.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.16 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    5258.28 ms /     8 runs   (  657.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6111.47 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /     9 runs   (    0.44 ms per token,  2253.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.99 ms /    13 tokens (   59.15 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =    5520.49 ms /     8 runs   (  690.06 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6315.78 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2329.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.72 ms /    13 tokens (   56.90 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =    5510.86 ms /     8 runs   (  688.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6276.63 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     8 runs   (    0.42 ms per token,  2364.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.96 ms /    14 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4805.48 ms /     7 runs   (  686.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5577.93 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     9 runs   (    0.44 ms per token,  2292.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.34 ms /    13 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    5503.58 ms /     8 runs   (  687.95 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6236.27 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /     9 runs   (    0.44 ms per token,  2271.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.78 ms /    16 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5545.92 ms /     8 runs   (  693.24 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6410.24 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /     9 runs   (    0.42 ms per token,  2396.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.44 ms /    15 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =    5343.45 ms /     8 runs   (  667.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6150.19 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2357.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     801.45 ms /    15 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    5460.20 ms /     8 runs   (  682.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6286.97 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.02 ms /     9 runs   (    0.45 ms per token,  2236.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.39 ms /    15 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5458.86 ms /     8 runs   (  682.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6282.39 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.64 ms /    16 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4754.82 ms /     7 runs   (  679.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5634.16 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2321.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.60 ms /    16 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5428.73 ms /     8 runs   (  678.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6299.00 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /     9 runs   (    0.44 ms per token,  2294.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     923.19 ms /    17 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    5417.57 ms /     8 runs   (  677.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6366.26 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /     9 runs   (    0.44 ms per token,  2271.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.44 ms /    13 tokens (   56.26 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5415.86 ms /     8 runs   (  676.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6173.21 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2300.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.29 ms /    15 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =    5488.28 ms /     8 runs   (  686.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6293.46 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /     9 runs   (    0.41 ms per token,  2435.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.13 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    5426.91 ms /     8 runs   (  678.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6279.28 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     9 runs   (    0.43 ms per token,  2339.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.68 ms /    15 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5395.26 ms /     8 runs   (  674.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6210.21 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2345.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.17 ms /    13 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =    5479.96 ms /     8 runs   (  685.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6222.81 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     9 runs   (    0.44 ms per token,  2291.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.14 ms /    16 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    5297.50 ms /     8 runs   (  662.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6160.71 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2372.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.51 ms /    15 tokens (   57.10 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:        eval time =    5383.66 ms /     8 runs   (  672.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6265.57 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2362.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.80 ms /    15 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5382.06 ms /     8 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6195.36 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /     8 runs   (    0.46 ms per token,  2165.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.72 ms /    15 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    4816.48 ms /     7 runs   (  688.07 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5648.91 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2386.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.35 ms /    15 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =    5232.95 ms /     8 runs   (  654.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    6039.91 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2401.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.83 ms /    11 tokens (   55.17 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5453.44 ms /     8 runs   (  681.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6085.80 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2330.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     751.18 ms /    14 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    5452.64 ms /     8 runs   (  681.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6229.23 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     9 runs   (    0.43 ms per token,  2338.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.28 ms /    13 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    5450.36 ms /     8 runs   (  681.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6181.85 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.43 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    5484.88 ms /     8 runs   (  685.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6336.66 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     9 runs   (    0.44 ms per token,  2283.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.53 ms /    16 tokens (   63.03 ms per token,    15.86 tokens per second)\n",
      "llama_print_timings:        eval time =    5439.32 ms /     8 runs   (  679.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6473.83 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2260.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.97 ms /    12 tokens (   55.50 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =    4681.05 ms /     7 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5370.08 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2329.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.75 ms /    15 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5461.89 ms /     8 runs   (  682.74 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6277.47 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.06 ms /    16 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5422.59 ms /     8 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6295.75 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /     9 runs   (    0.42 ms per token,  2393.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     942.37 ms /    17 tokens (   55.43 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5420.30 ms /     8 runs   (  677.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6388.30 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2318.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     754.30 ms /    14 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    4680.04 ms /     7 runs   (  668.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5456.94 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.95 ms /    15 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5487.77 ms /     8 runs   (  685.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6297.60 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /     9 runs   (    0.45 ms per token,  2241.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.14 ms /    15 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    5508.06 ms /     8 runs   (  688.51 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6327.67 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /     9 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     801.29 ms /    15 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    5466.48 ms /     8 runs   (  683.31 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6293.74 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /     9 runs   (    0.45 ms per token,  2214.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.71 ms /    15 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    5481.12 ms /     8 runs   (  685.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6322.51 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     9 runs   (    0.44 ms per token,  2287.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.72 ms /    16 tokens (   82.36 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:        eval time =    5447.19 ms /     8 runs   (  680.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6791.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /     9 runs   (    0.45 ms per token,  2236.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.74 ms /    17 tokens (   70.40 ms per token,    14.21 tokens per second)\n",
      "llama_print_timings:        eval time =    5591.60 ms /     8 runs   (  698.95 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6814.37 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /     9 runs   (    0.57 ms per token,  1750.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.43 ms /    16 tokens (   60.09 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =    5653.26 ms /     8 runs   (  706.66 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6647.10 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2304.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     958.63 ms /    14 tokens (   68.47 ms per token,    14.60 tokens per second)\n",
      "llama_print_timings:        eval time =    5389.72 ms /     8 runs   (  673.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6377.71 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1041.15 ms /    16 tokens (   65.07 ms per token,    15.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5519.48 ms /     8 runs   (  689.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6586.53 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /     9 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     951.87 ms /    16 tokens (   59.49 ms per token,    16.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5498.20 ms /     8 runs   (  687.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6476.96 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /     9 runs   (    0.55 ms per token,  1802.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     870.60 ms /    15 tokens (   58.04 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =    5758.11 ms /     8 runs   (  719.76 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    6661.63 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /     9 runs   (    0.44 ms per token,  2251.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.57 ms /    16 tokens (   61.85 ms per token,    16.17 tokens per second)\n",
      "llama_print_timings:        eval time =    5689.40 ms /     8 runs   (  711.17 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    6705.57 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /     9 runs   (    0.46 ms per token,  2153.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.81 ms /    16 tokens (   62.05 ms per token,    16.12 tokens per second)\n",
      "llama_print_timings:        eval time =    5617.27 ms /     8 runs   (  702.16 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6636.40 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /     9 runs   (    0.45 ms per token,  2216.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.70 ms /    14 tokens (   72.91 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    5669.91 ms /     8 runs   (  708.74 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    6718.01 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /     9 runs   (    0.45 ms per token,  2232.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.89 ms /    14 tokens (   83.14 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5783.86 ms /     8 runs   (  722.98 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    6974.91 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /     8 runs   (    0.44 ms per token,  2253.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.32 ms /    13 tokens (   85.49 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:        eval time =    5043.73 ms /     7 runs   (  720.53 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    6179.38 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /     9 runs   (    0.49 ms per token,  2035.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.39 ms /    15 tokens (   80.16 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6018.17 ms /     8 runs   (  752.27 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =    7250.20 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /     9 runs   (    0.46 ms per token,  2159.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.53 ms /    15 tokens (   86.10 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:        eval time =    5796.04 ms /     8 runs   (  724.50 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    7114.92 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /     9 runs   (    0.47 ms per token,  2146.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.73 ms /    16 tokens (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:        eval time =    5575.36 ms /     8 runs   (  696.92 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6870.62 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /     9 runs   (    0.45 ms per token,  2220.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.03 ms /    15 tokens (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:        eval time =    5650.00 ms /     8 runs   (  706.25 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6855.66 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /     9 runs   (    0.46 ms per token,  2177.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.70 ms /    17 tokens (   87.86 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:        eval time =    5671.25 ms /     8 runs   (  708.91 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    7193.30 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /     9 runs   (    0.52 ms per token,  1927.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.17 ms /    15 tokens (   77.94 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:        eval time =    6022.76 ms /     8 runs   (  752.84 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =    7222.67 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    10 runs   (    0.46 ms per token,  2192.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1601.15 ms /    18 tokens (   88.95 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:        eval time =    6302.28 ms /     9 runs   (  700.25 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    7933.33 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    10 runs   (    0.45 ms per token,  2232.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.31 ms /    19 tokens (   79.33 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6233.79 ms /     9 runs   (  692.64 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7771.30 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    10 runs   (    0.44 ms per token,  2261.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.66 ms /    20 tokens (   59.63 ms per token,    16.77 tokens per second)\n",
      "llama_print_timings:        eval time =    6359.11 ms /     9 runs   (  706.57 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    7581.98 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    10 runs   (    0.45 ms per token,  2198.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.39 ms /    19 tokens (   63.55 ms per token,    15.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6367.04 ms /     9 runs   (  707.45 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    7603.47 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    10 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.83 ms /    19 tokens (   61.04 ms per token,    16.38 tokens per second)\n",
      "llama_print_timings:        eval time =    6401.11 ms /     9 runs   (  711.23 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    7590.72 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    10 runs   (    0.44 ms per token,  2258.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.95 ms /    19 tokens (   60.89 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =    6486.86 ms /     9 runs   (  720.76 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    7673.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.59 ms /    19 tokens (   67.98 ms per token,    14.71 tokens per second)\n",
      "llama_print_timings:        eval time =    6179.61 ms /     9 runs   (  686.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7499.59 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2279.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.87 ms /    18 tokens (   76.60 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:        eval time =    6019.30 ms /     9 runs   (  668.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7426.38 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2343.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.05 ms /    18 tokens (   79.00 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6261.19 ms /     9 runs   (  695.69 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7711.68 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    10 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.69 ms /    19 tokens (   68.04 ms per token,    14.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6030.85 ms /     9 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7352.04 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2339.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.94 ms /    13 tokens (   56.38 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6084.55 ms /     9 runs   (  676.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6845.74 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /     9 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     959.79 ms /    18 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    5388.82 ms /     8 runs   (  673.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6374.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2368.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.76 ms /    19 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    6187.51 ms /     9 runs   (  687.50 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7252.06 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2370.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.68 ms /    20 tokens (   53.23 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    6105.91 ms /     9 runs   (  678.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7199.83 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    10 runs   (    0.42 ms per token,  2355.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.93 ms /    16 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    6028.57 ms /     9 runs   (  669.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6899.10 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    10 runs   (    0.44 ms per token,  2271.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.46 ms /    20 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6056.37 ms /     9 runs   (  672.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7147.26 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.64 ms /    18 tokens (   56.26 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =    6107.14 ms /     9 runs   (  678.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7148.61 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.97 ms /    18 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    6091.48 ms /     9 runs   (  676.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7098.55 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    10 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.67 ms /    18 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5990.94 ms /     9 runs   (  665.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7020.63 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2293.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.10 ms /    19 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6062.29 ms /     9 runs   (  673.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7105.24 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2369.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.11 ms /    18 tokens (   60.56 ms per token,    16.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6052.70 ms /     9 runs   (  672.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7171.90 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    10 runs   (    0.44 ms per token,  2256.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.53 ms /    20 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    6119.66 ms /     9 runs   (  679.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7213.65 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2318.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.43 ms /    19 tokens (   73.55 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    6112.33 ms /     9 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7538.15 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.45 ms /    19 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6048.86 ms /     9 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7104.52 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2343.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.15 ms /    16 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =    6026.11 ms /     9 runs   (  669.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6885.40 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2320.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.55 ms /    19 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    6033.76 ms /     9 runs   (  670.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7085.53 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /     9 runs   (    0.44 ms per token,  2275.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.86 ms /    18 tokens (   55.71 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5333.36 ms /     8 runs   (  666.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6361.83 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2282.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.75 ms /    19 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    6068.30 ms /     9 runs   (  674.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7114.95 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.03 ms /    19 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    5991.97 ms /     9 runs   (  665.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7024.35 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2307.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.91 ms /    19 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =    6144.42 ms /     9 runs   (  682.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7192.92 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2269.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.79 ms /    16 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    6147.86 ms /     9 runs   (  683.10 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7028.22 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.32 ms /    18 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6154.07 ms /     9 runs   (  683.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7158.93 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2284.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.53 ms /    16 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6096.69 ms /     9 runs   (  677.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6959.41 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2338.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     922.62 ms /    17 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    6013.45 ms /     9 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6964.11 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    10 runs   (    0.45 ms per token,  2218.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.24 ms /    19 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6165.63 ms /     9 runs   (  685.07 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7207.37 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    10 runs   (    0.47 ms per token,  2127.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.67 ms /    19 tokens (   55.61 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =    6071.44 ms /     9 runs   (  674.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7158.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    10 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.78 ms /    20 tokens (   54.89 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =    6279.63 ms /     9 runs   (  697.74 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    7406.14 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /     9 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.24 ms /    18 tokens (   55.74 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5315.85 ms /     8 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6345.88 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2301.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     741.07 ms /    14 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5328.09 ms /     8 runs   (  666.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6094.88 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2290.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.55 ms /    17 tokens (   56.50 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =    5929.12 ms /     9 runs   (  658.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6918.53 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2306.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.00 ms /    19 tokens (   55.53 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =    5978.23 ms /     9 runs   (  664.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7062.72 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2288.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.54 ms /    19 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6297.96 ms /     9 runs   (  699.77 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    7336.23 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    10 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.50 ms /    18 tokens (   55.36 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =    6109.16 ms /     9 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7134.41 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    10 runs   (    0.45 ms per token,  2219.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.82 ms /    20 tokens (   60.54 ms per token,    16.52 tokens per second)\n",
      "llama_print_timings:        eval time =    6106.94 ms /     9 runs   (  678.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7346.64 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2367.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.77 ms /    18 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    6096.48 ms /     9 runs   (  677.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7086.56 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2321.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.25 ms /    18 tokens (   55.46 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6134.18 ms /     9 runs   (  681.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7161.15 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2316.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.37 ms /    19 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6076.85 ms /     9 runs   (  675.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7133.55 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2304.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.01 ms /    13 tokens (   54.39 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =    6089.61 ms /     9 runs   (  676.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6824.89 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2291.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.54 ms /    13 tokens (   65.96 ms per token,    15.16 tokens per second)\n",
      "llama_print_timings:        eval time =    6006.07 ms /     9 runs   (  667.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6892.45 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    10 runs   (    0.42 ms per token,  2384.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.25 ms /    16 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6239.51 ms /     9 runs   (  693.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7108.60 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2388.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.10 ms /    18 tokens (   56.12 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =    5410.69 ms /     8 runs   (  676.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6446.88 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    10 runs   (    0.42 ms per token,  2360.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.69 ms /    20 tokens (   54.73 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6247.98 ms /     9 runs   (  694.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7370.79 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2346.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.32 ms /    19 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6058.08 ms /     9 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7114.68 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2303.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.19 ms /    19 tokens (   56.06 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6187.72 ms /     9 runs   (  687.52 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7281.46 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2291.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.65 ms /    13 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6145.30 ms /     9 runs   (  682.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6865.05 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    10 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.51 ms /    19 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6210.39 ms /     9 runs   (  690.04 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7282.15 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2319.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.58 ms /    18 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    6137.26 ms /     9 runs   (  681.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7148.88 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2345.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     984.80 ms /    18 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    6100.52 ms /     9 runs   (  677.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7114.17 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    11 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.55 ms /    17 tokens (   65.39 ms per token,    15.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6763.73 ms /    10 runs   (  676.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7907.01 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.86 ms /    18 tokens (   56.60 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =    6019.62 ms /     9 runs   (  668.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7067.31 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2314.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.20 ms /    16 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6141.57 ms /     9 runs   (  682.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7021.18 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    10 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.80 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =    6066.99 ms /     9 runs   (  674.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6917.00 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2306.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.87 ms /    19 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5951.11 ms /     9 runs   (  661.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6986.60 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    10 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.92 ms /    20 tokens (   54.10 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    5946.57 ms /     9 runs   (  660.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7057.02 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2389.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.04 ms /    19 tokens (   54.63 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    5364.17 ms /     8 runs   (  670.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6427.52 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    10 runs   (    0.42 ms per token,  2359.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.44 ms /    18 tokens (   56.14 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =    6217.56 ms /     9 runs   (  690.84 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7256.91 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2323.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.54 ms /    13 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6249.65 ms /     9 runs   (  694.41 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7003.25 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    10 runs   (    0.42 ms per token,  2354.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     963.66 ms /    18 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6075.09 ms /     9 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7067.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    10 runs   (    0.45 ms per token,  2212.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.54 ms /    13 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5965.33 ms /     9 runs   (  662.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6702.91 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2323.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.06 ms /    18 tokens (   55.78 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6089.32 ms /     9 runs   (  676.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7122.72 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.95 ms /    20 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6067.75 ms /     9 runs   (  674.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7168.70 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    10 runs   (    0.44 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.85 ms /    19 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6071.71 ms /     9 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7105.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /     9 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.47 ms /    15 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    5363.42 ms /     8 runs   (  670.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6188.31 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    10 runs   (    0.45 ms per token,  2222.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.38 ms /    19 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    6083.65 ms /     9 runs   (  675.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7132.52 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    10 runs   (    0.42 ms per token,  2403.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.40 ms /    18 tokens (   58.52 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =    6087.93 ms /     9 runs   (  676.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7168.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.72 ms /    18 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6181.16 ms /     9 runs   (  686.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7184.80 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.53 ms /    18 tokens (   56.20 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =    6286.27 ms /     9 runs   (  698.47 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    7326.82 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2268.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.31 ms /    20 tokens (   55.17 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6187.42 ms /     9 runs   (  687.49 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7319.67 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2318.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.38 ms /    14 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5416.59 ms /     8 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6177.38 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2342.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.41 ms /    19 tokens (   56.28 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =    6095.47 ms /     9 runs   (  677.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7193.14 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2332.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.55 ms /    19 tokens (   54.45 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    6184.63 ms /     9 runs   (  687.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7247.77 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2301.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.01 ms /    15 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =    5404.99 ms /     8 runs   (  675.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6236.10 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2338.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.26 ms /    19 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6083.28 ms /     9 runs   (  675.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7168.46 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2318.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.99 ms /    15 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    5387.74 ms /     8 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6232.50 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2279.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.27 ms /    19 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =    6095.31 ms /     9 runs   (  677.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7132.63 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    10 runs   (    0.44 ms per token,  2272.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.38 ms /    18 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6086.31 ms /     9 runs   (  676.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7117.60 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    10 runs   (    0.44 ms per token,  2247.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.35 ms /    16 tokens (   67.15 ms per token,    14.89 tokens per second)\n",
      "llama_print_timings:        eval time =    6106.40 ms /     9 runs   (  678.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7210.22 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     984.42 ms /    18 tokens (   54.69 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    6089.81 ms /     9 runs   (  676.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7102.46 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2340.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.31 ms /    14 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5971.24 ms /     9 runs   (  663.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6773.56 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2290.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     918.47 ms /    17 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    5953.86 ms /     9 runs   (  661.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6900.47 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    10 runs   (    0.42 ms per token,  2373.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.08 ms /    20 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6187.43 ms /     9 runs   (  687.49 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7299.76 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2332.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.80 ms /    20 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6025.87 ms /     9 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7112.34 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.33 ms /    19 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6090.59 ms /     9 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7123.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    10 runs   (    0.42 ms per token,  2381.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.80 ms /    18 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    6086.29 ms /     9 runs   (  676.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7091.30 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.59 ms /    16 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    5956.04 ms /     9 runs   (  661.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6846.48 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    10 runs   (    0.42 ms per token,  2379.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.04 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    6019.09 ms /     9 runs   (  668.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6882.72 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    10 runs   (    0.44 ms per token,  2297.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.60 ms /    20 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    6108.75 ms /     9 runs   (  678.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7225.50 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    10 runs   (    0.48 ms per token,  2070.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.18 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    6081.15 ms /     9 runs   (  675.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6937.32 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2321.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.01 ms /    19 tokens (   57.16 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:        eval time =    6077.82 ms /     9 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7192.86 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    10 runs   (    0.42 ms per token,  2392.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.26 ms /    19 tokens (   54.96 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =    6166.70 ms /     9 runs   (  685.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7239.50 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2327.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.30 ms /    18 tokens (   55.02 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =    6136.70 ms /     9 runs   (  681.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7155.75 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2278.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.96 ms /    20 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    6181.52 ms /     9 runs   (  686.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7270.58 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     970.36 ms /    18 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6035.95 ms /     9 runs   (  670.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7035.28 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /     9 runs   (    0.44 ms per token,  2296.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     940.99 ms /    17 tokens (   55.35 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5505.23 ms /     8 runs   (  688.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6472.35 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.13 ms /    18 tokens (   66.90 ms per token,    14.95 tokens per second)\n",
      "llama_print_timings:        eval time =    6114.75 ms /     9 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7347.85 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2330.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.98 ms /    18 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    5527.25 ms /     8 runs   (  690.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6536.68 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    10 runs   (    0.46 ms per token,  2189.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.07 ms /    19 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6208.28 ms /     9 runs   (  689.81 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7254.54 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    10 runs   (    0.45 ms per token,  2207.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.74 ms /    19 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6122.67 ms /     9 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7191.55 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2283.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     994.47 ms /    18 tokens (   55.25 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =    5993.01 ms /     9 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7016.14 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2295.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.13 ms /    18 tokens (   55.17 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =    5987.23 ms /     9 runs   (  665.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7008.91 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    10 runs   (    0.42 ms per token,  2373.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.75 ms /    18 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    6055.15 ms /     9 runs   (  672.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7060.29 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    10 runs   (    0.42 ms per token,  2377.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     925.81 ms /    17 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    5982.40 ms /     9 runs   (  664.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6936.64 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    10 runs   (    0.42 ms per token,  2359.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.53 ms /    18 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    6081.18 ms /     9 runs   (  675.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7084.15 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2371.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.95 ms /    19 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    6099.25 ms /     9 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7150.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2313.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     970.01 ms /    18 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    6135.46 ms /     9 runs   (  681.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7133.65 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2313.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.74 ms /    20 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =    6121.04 ms /     9 runs   (  680.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7214.65 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    10 runs   (    0.42 ms per token,  2376.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.94 ms /    19 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6121.10 ms /     9 runs   (  680.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7179.58 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2303.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.77 ms /    20 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6144.95 ms /     9 runs   (  682.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7253.64 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    10 runs   (    0.42 ms per token,  2381.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.17 ms /    19 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6140.50 ms /     9 runs   (  682.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7170.88 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    10 runs   (    0.44 ms per token,  2262.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.40 ms /    18 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    6246.05 ms /     9 runs   (  694.01 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7251.22 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2321.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.62 ms /    18 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    6278.19 ms /     9 runs   (  697.58 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    7289.46 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2330.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.57 ms /    18 tokens (   54.81 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =    5996.46 ms /     9 runs   (  666.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7011.50 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2286.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.25 ms /    17 tokens (   54.66 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6031.28 ms /     9 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6989.19 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2346.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.16 ms /    19 tokens (   68.32 ms per token,    14.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6156.68 ms /     9 runs   (  684.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7482.40 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2310.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.72 ms /    18 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    5994.02 ms /     9 runs   (  666.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7005.53 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2265.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     997.46 ms /    18 tokens (   55.41 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =    6021.07 ms /     9 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7046.59 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.16 ms /    19 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =    6064.55 ms /     9 runs   (  673.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7137.96 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    10 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     985.12 ms /    18 tokens (   54.73 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6080.03 ms /     9 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7093.42 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.07 ms /    20 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    6041.86 ms /     9 runs   (  671.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7145.53 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /     9 runs   (    0.42 ms per token,  2382.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.41 ms /    14 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5401.90 ms /     8 runs   (  675.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6166.69 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.51 ms /    15 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6195.52 ms /     9 runs   (  688.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7005.96 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    10 runs   (    0.42 ms per token,  2379.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     963.94 ms /    18 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    5964.23 ms /     9 runs   (  662.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6956.79 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2333.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.09 ms /    19 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6106.61 ms /     9 runs   (  678.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7149.11 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2284.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     982.23 ms /    18 tokens (   54.57 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =    6030.65 ms /     9 runs   (  670.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7040.98 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2277.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.90 ms /    18 tokens (   55.88 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =    6117.92 ms /     9 runs   (  679.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7151.66 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2328.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.12 ms /    16 tokens (   52.51 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5939.93 ms /     9 runs   (  659.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6808.42 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     969.91 ms /    18 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    6090.25 ms /     9 runs   (  676.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7088.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2345.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.19 ms /    19 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    5895.85 ms /     9 runs   (  655.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    6955.89 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2319.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.83 ms /    19 tokens (   58.20 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =    5928.43 ms /     9 runs   (  658.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7063.40 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    10 runs   (    0.42 ms per token,  2356.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.42 ms /    18 tokens (   55.19 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =    6084.62 ms /     9 runs   (  676.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7106.86 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.90 ms /    18 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6049.36 ms /     9 runs   (  672.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7053.09 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    10 runs   (    0.45 ms per token,  2236.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.61 ms /    11 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6076.80 ms /     9 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6717.46 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2303.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.04 ms /    19 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6001.62 ms /     9 runs   (  666.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7028.35 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2314.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.78 ms /    16 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =    6003.63 ms /     9 runs   (  667.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6881.89 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    10 runs   (    0.43 ms per token,  2299.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.95 ms /    20 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6120.66 ms /     9 runs   (  680.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7232.90 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    10 runs   (    0.54 ms per token,  1844.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.62 ms /    19 tokens (   55.82 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6326.36 ms /     9 runs   (  702.93 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    7420.81 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    10 runs   (    0.43 ms per token,  2299.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.67 ms /    19 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =    6065.41 ms /     9 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7126.41 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2328.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     941.11 ms /    17 tokens (   55.36 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =    6164.00 ms /     9 runs   (  684.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7133.19 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2289.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.91 ms /    20 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6177.24 ms /     9 runs   (  686.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7268.59 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.64 ms /    16 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6167.18 ms /     9 runs   (  685.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7042.35 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    10 runs   (    0.48 ms per token,  2075.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     884.57 ms /    16 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    6113.18 ms /     9 runs   (  679.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7027.85 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2311.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.05 ms /    19 tokens (   69.06 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6034.90 ms /     9 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7375.92 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /     9 runs   (    0.44 ms per token,  2271.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.70 ms /    16 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    5261.51 ms /     8 runs   (  657.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6140.93 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2267.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.31 ms /    20 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    6065.27 ms /     9 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7149.14 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2320.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.01 ms /    17 tokens (   63.12 ms per token,    15.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6159.83 ms /     9 runs   (  684.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7261.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    10 runs   (    0.43 ms per token,  2350.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.48 ms /    13 tokens (   55.19 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =    6129.81 ms /     9 runs   (  681.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6875.97 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /     9 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.75 ms /    12 tokens (   56.15 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5421.00 ms /     8 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6120.56 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    10 runs   (    0.42 ms per token,  2402.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     979.20 ms /    18 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    5936.64 ms /     9 runs   (  659.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6943.74 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2276.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.40 ms /    18 tokens (   56.69 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6149.95 ms /     9 runs   (  683.33 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7198.83 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2324.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.94 ms /    19 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6063.68 ms /     9 runs   (  673.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7120.64 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2266.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.19 ms /    18 tokens (   57.45 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =    6122.89 ms /     9 runs   (  680.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7185.12 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2349.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.61 ms /    19 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    6050.51 ms /     9 runs   (  672.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7099.53 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2278.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.57 ms /    19 tokens (   55.66 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6106.24 ms /     9 runs   (  678.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7192.24 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2288.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.23 ms /    20 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6110.31 ms /     9 runs   (  678.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7237.50 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    10 runs   (    0.45 ms per token,  2245.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.39 ms /    19 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6134.11 ms /     9 runs   (  681.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7164.07 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    10 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     747.51 ms /    14 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    6124.50 ms /     9 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6901.11 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     7 runs   (    0.43 ms per token,  2306.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.10 ms /    16 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =    4028.55 ms /     6 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    4913.85 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.39 ms /    16 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6162.96 ms /     9 runs   (  684.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7032.45 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    10 runs   (    0.42 ms per token,  2382.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.52 ms /    16 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    6085.87 ms /     9 runs   (  676.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6976.04 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     955.62 ms /    17 tokens (   56.21 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =    6067.91 ms /     9 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7052.17 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     9 runs   (    0.43 ms per token,  2310.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.02 ms /    18 tokens (   61.89 ms per token,    16.16 tokens per second)\n",
      "llama_print_timings:        eval time =    5380.82 ms /     8 runs   (  672.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6520.70 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2278.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.10 ms /    16 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6074.85 ms /     9 runs   (  674.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6952.74 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    10 runs   (    0.45 ms per token,  2229.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.72 ms /    19 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    6159.85 ms /     9 runs   (  684.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7219.32 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    10 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     939.12 ms /    17 tokens (   55.24 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6066.96 ms /     9 runs   (  674.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7034.79 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2326.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.04 ms /    15 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5464.69 ms /     8 runs   (  683.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6282.87 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2285.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.99 ms /    19 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    6124.80 ms /     9 runs   (  680.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7182.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.89 ms /    16 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    6066.18 ms /     9 runs   (  674.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6936.50 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    10 runs   (    0.42 ms per token,  2356.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.44 ms /    20 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6109.57 ms /     9 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7191.64 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    10 runs   (    0.42 ms per token,  2362.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.10 ms /    18 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    6125.11 ms /     9 runs   (  680.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7114.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.11 ms /    17 tokens (   60.65 ms per token,    16.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6130.07 ms /     9 runs   (  681.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7190.01 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    10 runs   (    0.44 ms per token,  2256.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1046.17 ms /    19 tokens (   55.06 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =    6160.59 ms /     9 runs   (  684.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7235.60 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2279.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.46 ms /    14 tokens (   54.96 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =    6134.45 ms /     9 runs   (  681.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6932.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.82 ms /    18 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =    6172.81 ms /     9 runs   (  685.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7192.74 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    10 runs   (    0.44 ms per token,  2256.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.11 ms /    18 tokens (   55.56 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =    6069.60 ms /     9 runs   (  674.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7098.31 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    10 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.50 ms /    16 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6049.56 ms /     9 runs   (  672.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6932.26 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    10 runs   (    0.43 ms per token,  2300.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.80 ms /    16 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6123.70 ms /     9 runs   (  680.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6999.96 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2370.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     932.87 ms /    17 tokens (   54.87 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =    6120.01 ms /     9 runs   (  680.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7080.68 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    10 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     980.91 ms /    18 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =    6131.37 ms /     9 runs   (  681.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7140.32 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.03 ms /    19 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    6054.83 ms /     9 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7112.28 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2338.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.44 ms /    19 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    6146.43 ms /     9 runs   (  682.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7192.41 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /     9 runs   (    0.41 ms per token,  2436.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     962.68 ms /    18 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    5502.54 ms /     8 runs   (  687.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6491.06 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    10 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.55 ms /    18 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6184.34 ms /     9 runs   (  687.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7203.97 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    10 runs   (    0.46 ms per token,  2189.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.80 ms /    19 tokens (   54.94 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6080.37 ms /     9 runs   (  675.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7152.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2371.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.88 ms /    19 tokens (   56.41 ms per token,    17.73 tokens per second)\n",
      "llama_print_timings:        eval time =    6269.88 ms /     9 runs   (  696.65 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7370.54 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    10 runs   (    0.42 ms per token,  2385.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.89 ms /    16 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6012.19 ms /     9 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6900.29 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2341.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.22 ms /    16 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    5906.56 ms /     9 runs   (  656.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6783.93 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    10 runs   (    0.42 ms per token,  2407.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.45 ms /    18 tokens (   57.30 ms per token,    17.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6097.73 ms /     9 runs   (  677.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7157.76 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2336.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.91 ms /    16 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    6021.13 ms /     9 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6904.31 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2351.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.43 ms /    15 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5395.66 ms /     8 runs   (  674.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6214.11 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2283.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.42 ms /    20 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6105.56 ms /     9 runs   (  678.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7203.39 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     8 runs   (    0.45 ms per token,  2238.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.06 ms /    18 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4772.96 ms /     7 runs   (  681.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5791.20 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    10 runs   (    0.45 ms per token,  2229.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1001.49 ms /    19 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6011.53 ms /     9 runs   (  667.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7042.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    11 runs   (    0.43 ms per token,  2333.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.09 ms /    19 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6746.86 ms /    10 runs   (  674.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7794.25 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    12 runs   (    0.45 ms per token,  2220.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.82 ms /    22 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    7380.20 ms /    11 runs   (  670.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8567.22 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    10 runs   (    0.43 ms per token,  2351.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.47 ms /    19 tokens (   55.24 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6048.43 ms /     9 runs   (  672.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7125.91 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    11 runs   (    0.44 ms per token,  2270.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.45 ms /    22 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6745.19 ms /    10 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7946.83 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2305.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.15 ms /    19 tokens (   56.11 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6531.51 ms /    10 runs   (  653.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    7628.95 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    11 runs   (    0.44 ms per token,  2268.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.08 ms /    23 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =    6705.11 ms /    10 runs   (  670.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7903.10 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2341.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.01 ms /    14 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =    6169.11 ms /     9 runs   (  685.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6944.35 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    11 runs   (    0.44 ms per token,  2259.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.39 ms /    21 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    6741.65 ms /    10 runs   (  674.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7884.38 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2279.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.44 ms /    19 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    6646.39 ms /    10 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7698.75 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2311.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     963.74 ms /    18 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6739.46 ms /    10 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7734.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.10 ms /    12 runs   (    0.42 ms per token,  2353.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.69 ms /    21 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7451.34 ms /    11 runs   (  677.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8570.07 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    11 runs   (    0.42 ms per token,  2391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.05 ms /    21 tokens (   55.91 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =    6685.69 ms /    10 runs   (  668.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7891.17 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2327.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.87 ms /    19 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    6822.07 ms /    10 runs   (  682.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7885.58 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2313.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.18 ms /    23 tokens (   58.31 ms per token,    17.15 tokens per second)\n",
      "llama_print_timings:        eval time =    6622.20 ms /    10 runs   (  662.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7994.90 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2327.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.76 ms /    22 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6704.44 ms /    10 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7912.48 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    11 runs   (    0.42 ms per token,  2381.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.54 ms /    21 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6768.42 ms /    10 runs   (  676.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7888.05 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    11 runs   (    0.43 ms per token,  2340.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.34 ms /    21 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6663.42 ms /    10 runs   (  666.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7797.45 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    11 runs   (    0.43 ms per token,  2337.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.48 ms /    19 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6731.13 ms /    10 runs   (  673.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7786.94 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2267.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.23 ms /    16 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5446.32 ms /     8 runs   (  680.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6313.25 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.81 ms /    19 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5960.96 ms /     9 runs   (  662.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7036.89 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.02 ms /    11 runs   (    0.46 ms per token,  2190.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.94 ms /    22 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    6847.74 ms /    10 runs   (  684.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8060.21 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    12 runs   (    0.42 ms per token,  2406.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.24 ms /    22 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    7346.49 ms /    11 runs   (  667.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8521.91 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    11 runs   (    0.45 ms per token,  2232.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.53 ms /    22 tokens (   64.30 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6714.32 ms /    10 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8160.61 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    11 runs   (    0.45 ms per token,  2223.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.15 ms /    19 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    6732.75 ms /    10 runs   (  673.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7797.91 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    10 runs   (    0.45 ms per token,  2246.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.69 ms /    18 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6084.91 ms /     9 runs   (  676.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7089.39 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    11 runs   (    0.43 ms per token,  2347.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.32 ms /    19 tokens (   54.54 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =    6728.73 ms /    10 runs   (  672.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7796.48 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2312.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.80 ms /    21 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6817.78 ms /    10 runs   (  681.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7988.62 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2259.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.95 ms /    21 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7430.26 ms /    11 runs   (  675.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8588.00 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2258.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.89 ms /    23 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    7621.16 ms /    11 runs   (  692.83 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8868.04 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2305.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.05 ms /    20 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    6654.65 ms /    10 runs   (  665.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7746.95 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2316.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.65 ms /    22 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    7057.75 ms /    10 runs   (  705.77 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    8244.44 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    11 runs   (    0.44 ms per token,  2255.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.63 ms /    22 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6654.92 ms /    10 runs   (  665.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7853.73 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /    12 runs   (    0.45 ms per token,  2237.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.70 ms /    21 tokens (   53.18 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7228.44 ms /    11 runs   (  657.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8379.94 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    11 runs   (    0.42 ms per token,  2369.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.05 ms /    22 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6792.28 ms /    10 runs   (  679.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7968.02 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2303.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.01 ms /    22 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    6829.01 ms /    10 runs   (  682.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8025.11 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2238.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.54 ms /    20 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6725.14 ms /    10 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7830.56 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2323.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.82 ms /    22 tokens (   53.26 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =    6779.63 ms /    10 runs   (  677.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7983.24 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2302.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.84 ms /    22 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    6789.78 ms /    10 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7985.05 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    11 runs   (    0.42 ms per token,  2356.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.42 ms /    21 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    6866.06 ms /    10 runs   (  686.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8009.90 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2238.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.50 ms /    20 tokens (   54.27 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    6850.41 ms /    10 runs   (  685.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7967.28 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2281.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.86 ms /    19 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    6125.91 ms /     9 runs   (  680.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7178.95 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    11 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.52 ms /    19 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6518.39 ms /    10 runs   (  651.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    7559.69 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2238.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.25 ms /    22 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6760.19 ms /    10 runs   (  676.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7961.99 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    11 runs   (    0.45 ms per token,  2216.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.73 ms /    22 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6711.57 ms /    10 runs   (  671.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7911.42 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    11 runs   (    0.54 ms per token,  1845.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.01 ms /    23 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    6777.36 ms /    10 runs   (  677.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8023.69 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2279.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.95 ms /    22 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    6767.70 ms /    10 runs   (  676.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7952.03 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.06 ms /    19 tokens (   64.37 ms per token,    15.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6568.63 ms /    10 runs   (  656.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7823.58 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2307.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.19 ms /    20 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    6605.46 ms /    10 runs   (  660.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7684.99 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2276.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.35 ms /    19 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6676.30 ms /    10 runs   (  667.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7720.96 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2312.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.97 ms /    19 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6702.87 ms /    10 runs   (  670.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7747.53 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    12 runs   (    0.45 ms per token,  2243.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.26 ms /    22 tokens (   53.38 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7498.97 ms /    11 runs   (  681.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8708.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2300.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.30 ms /    20 tokens (   56.31 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6638.09 ms /    10 runs   (  663.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7796.06 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2314.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.61 ms /    22 tokens (   56.85 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =    6811.27 ms /    10 runs   (  681.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8093.24 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    11 runs   (    0.43 ms per token,  2340.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.93 ms /    21 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6734.69 ms /    10 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7881.44 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2302.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     921.42 ms /    17 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6132.69 ms /     9 runs   (  681.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7082.30 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    11 runs   (    0.43 ms per token,  2342.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.43 ms /    22 tokens (   64.29 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6798.56 ms /    10 runs   (  679.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8244.49 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2306.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.82 ms /    19 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =    6907.46 ms /    10 runs   (  690.75 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7989.30 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2317.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.60 ms /    21 tokens (   59.89 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6870.88 ms /    10 runs   (  687.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8160.59 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2281.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.24 ms /    19 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    6628.70 ms /    10 runs   (  662.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7680.86 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    11 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.61 ms /    21 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    6679.86 ms /    10 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7818.65 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    11 runs   (    0.45 ms per token,  2243.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.49 ms /    19 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6707.34 ms /    10 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7765.86 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2275.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     947.87 ms /    17 tokens (   55.76 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6203.04 ms /     9 runs   (  689.23 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7180.07 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    11 runs   (    0.48 ms per token,  2086.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.80 ms /    22 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6716.14 ms /    10 runs   (  671.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7918.86 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    11 runs   (    0.43 ms per token,  2336.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.34 ms /    19 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6643.19 ms /    10 runs   (  664.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7699.67 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    11 runs   (    0.43 ms per token,  2343.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.43 ms /    22 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6807.14 ms /    10 runs   (  680.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8027.02 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2301.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.14 ms /    16 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6883.18 ms /    10 runs   (  688.32 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7754.46 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.10 ms /    12 runs   (    0.43 ms per token,  2351.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.96 ms /    21 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    7339.78 ms /    11 runs   (  667.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8498.22 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2309.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.48 ms /    16 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6720.98 ms /    10 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7592.22 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /    11 runs   (    0.44 ms per token,  2296.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.20 ms /    21 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6874.82 ms /    10 runs   (  687.48 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7998.67 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    11 runs   (    0.43 ms per token,  2352.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.81 ms /    21 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    6804.17 ms /    10 runs   (  680.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7949.22 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2303.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.60 ms /    22 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6538.12 ms /    10 runs   (  653.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    7734.79 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2301.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.76 ms /    23 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6927.25 ms /    10 runs   (  692.73 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8137.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    11 runs   (    0.49 ms per token,  2061.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.96 ms /    19 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    6790.88 ms /    10 runs   (  679.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7841.05 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    11 runs   (    0.44 ms per token,  2263.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.96 ms /    19 tokens (   55.21 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    6626.15 ms /    10 runs   (  662.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7706.07 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    11 runs   (    0.44 ms per token,  2248.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.40 ms /    21 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6777.48 ms /    10 runs   (  677.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7903.57 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2324.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.96 ms /    23 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    6650.63 ms /    10 runs   (  665.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7873.51 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    11 runs   (    0.43 ms per token,  2350.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.71 ms /    13 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =    6690.47 ms /    10 runs   (  669.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7419.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2282.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.22 ms /    18 tokens (   55.46 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6708.21 ms /    10 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7737.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2276.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.90 ms /    20 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =    6690.76 ms /    10 runs   (  669.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7814.53 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    11 runs   (    0.44 ms per token,  2247.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.42 ms /    19 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    6498.43 ms /    10 runs   (  649.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    7541.30 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    11 runs   (    0.44 ms per token,  2266.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.91 ms /    21 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6696.90 ms /    10 runs   (  669.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7854.54 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2302.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.43 ms /    22 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    6692.14 ms /    10 runs   (  669.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7917.54 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    10 runs   (    0.45 ms per token,  2236.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.37 ms /    21 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    6049.87 ms /     9 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7178.32 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2310.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.05 ms /    22 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    6807.52 ms /    10 runs   (  680.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8022.42 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    11 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.07 ms /    23 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =    6776.90 ms /    10 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7975.74 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2234.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.38 ms /    23 tokens (   52.23 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =    6684.20 ms /    10 runs   (  668.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7917.22 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2367.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     963.65 ms /    17 tokens (   56.69 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =    5936.80 ms /     9 runs   (  659.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6928.19 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2275.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.57 ms /    20 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6567.33 ms /    10 runs   (  656.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7656.54 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    11 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.79 ms /    20 tokens (   61.09 ms per token,    16.37 tokens per second)\n",
      "llama_print_timings:        eval time =    6647.79 ms /    10 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7901.19 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2275.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1001.77 ms /    19 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6084.81 ms /     9 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7115.68 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    11 runs   (    0.43 ms per token,  2320.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.33 ms /    21 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    6678.73 ms /    10 runs   (  667.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7816.11 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    11 runs   (    0.43 ms per token,  2339.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.29 ms /    19 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    6917.42 ms /    10 runs   (  691.74 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7943.65 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    11 runs   (    0.44 ms per token,  2253.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.03 ms /    19 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6861.54 ms /    10 runs   (  686.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7936.82 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2284.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.54 ms /    21 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    6676.59 ms /    10 runs   (  667.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7824.40 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    11 runs   (    0.44 ms per token,  2250.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.95 ms /    22 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6776.47 ms /    10 runs   (  677.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7957.68 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.28 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    6828.58 ms /    10 runs   (  682.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7698.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    11 runs   (    0.43 ms per token,  2341.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.61 ms /    19 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =    6845.93 ms /    10 runs   (  684.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7909.69 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    11 runs   (    0.42 ms per token,  2380.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.63 ms /    16 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6842.00 ms /    10 runs   (  684.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7715.70 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    11 runs   (    0.46 ms per token,  2182.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.81 ms /    22 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6687.05 ms /    10 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7920.92 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.04 ms /    19 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    6765.43 ms /    10 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7821.37 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    11 runs   (    0.44 ms per token,  2257.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.97 ms /    18 tokens (   55.94 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =    6759.89 ms /    10 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7798.47 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.82 ms /    16 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6089.50 ms /     9 runs   (  676.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6964.39 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    11 runs   (    0.44 ms per token,  2286.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.31 ms /    19 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6660.24 ms /    10 runs   (  666.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7718.33 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    12 runs   (    0.43 ms per token,  2308.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.45 ms /    22 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    7290.34 ms /    11 runs   (  662.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8485.69 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2299.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.73 ms /    21 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6747.68 ms /    10 runs   (  674.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7882.49 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2304.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.70 ms /    21 tokens (   67.22 ms per token,    14.88 tokens per second)\n",
      "llama_print_timings:        eval time =    6935.32 ms /    10 runs   (  693.53 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8378.39 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2280.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.91 ms /    22 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    6891.34 ms /    10 runs   (  689.13 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8114.68 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    11 runs   (    0.48 ms per token,  2078.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.56 ms /    21 tokens (   56.98 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6907.67 ms /    10 runs   (  690.77 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8138.21 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2275.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.41 ms /    20 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6671.29 ms /    10 runs   (  667.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7787.79 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2275.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.40 ms /    22 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =    6787.67 ms /    10 runs   (  678.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7968.96 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2289.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.81 ms /    22 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    6740.50 ms /    10 runs   (  674.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7928.81 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2313.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.60 ms /    22 tokens (   55.53 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =    6720.08 ms /    10 runs   (  672.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7972.53 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    11 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.62 ms /    22 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6805.06 ms /    10 runs   (  680.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7984.08 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    11 runs   (    0.45 ms per token,  2203.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.55 ms /    22 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    6776.91 ms /    10 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7950.70 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    11 runs   (    0.44 ms per token,  2252.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.70 ms /    21 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6775.96 ms /    10 runs   (  677.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7927.44 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.66 ms /    11 runs   (    0.42 ms per token,  2360.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.50 ms /    22 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6785.02 ms /    10 runs   (  678.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8003.47 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    11 runs   (    0.43 ms per token,  2322.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.56 ms /    22 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6945.44 ms /    10 runs   (  694.54 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8186.80 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2307.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.80 ms /    22 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    6845.86 ms /    10 runs   (  684.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8030.42 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    12 runs   (    0.42 ms per token,  2376.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.45 ms /    22 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    7457.34 ms /    11 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8685.55 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    11 runs   (    0.42 ms per token,  2371.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.78 ms /    19 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6687.02 ms /    10 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7739.14 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2327.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.70 ms /    19 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    6771.12 ms /    10 runs   (  677.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7805.08 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2311.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     949.02 ms /    17 tokens (   55.82 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6177.20 ms /     9 runs   (  686.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7155.00 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2311.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.23 ms /    19 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6510.94 ms /    10 runs   (  651.09 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    7572.48 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    10 runs   (    0.45 ms per token,  2200.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.12 ms /    21 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6082.78 ms /     9 runs   (  675.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7231.81 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    11 runs   (    0.44 ms per token,  2260.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.15 ms /    18 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6718.48 ms /    10 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7726.03 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2313.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.20 ms /    22 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6588.02 ms /    10 runs   (  658.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7769.95 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    11 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.80 ms /    22 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6722.71 ms /    10 runs   (  672.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7922.35 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    11 runs   (    0.44 ms per token,  2287.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.49 ms /    21 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6620.46 ms /    10 runs   (  662.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7765.56 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    12 runs   (    0.43 ms per token,  2304.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.13 ms /    21 tokens (   53.43 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =    7320.34 ms /    11 runs   (  665.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8476.13 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2290.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.49 ms /    21 tokens (   77.31 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6812.85 ms /    10 runs   (  681.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8468.36 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    11 runs   (    0.44 ms per token,  2274.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.61 ms /    21 tokens (   63.93 ms per token,    15.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6747.80 ms /    10 runs   (  674.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8121.51 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.46 ms /    19 tokens (   52.87 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6861.42 ms /    10 runs   (  686.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7897.63 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2301.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.34 ms /    19 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6768.62 ms /    10 runs   (  676.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7821.21 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2315.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.90 ms /    18 tokens (   57.22 ms per token,    17.48 tokens per second)\n",
      "llama_print_timings:        eval time =    5994.34 ms /     9 runs   (  666.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7053.18 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    12 runs   (    0.43 ms per token,  2308.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.12 ms /    21 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    7144.98 ms /    11 runs   (  649.54 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    8280.18 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2313.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     979.19 ms /    17 tokens (   57.60 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =    6640.27 ms /    10 runs   (  664.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7651.02 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.89 ms /    11 runs   (    0.54 ms per token,  1866.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.82 ms /    21 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6807.50 ms /    10 runs   (  680.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7979.73 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    11 runs   (    0.44 ms per token,  2268.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.05 ms /    22 tokens (   58.14 ms per token,    17.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6804.37 ms /    10 runs   (  680.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8115.43 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    10 runs   (    0.43 ms per token,  2346.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.20 ms /    21 tokens (   52.34 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6063.33 ms /     9 runs   (  673.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7191.43 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    11 runs   (    0.42 ms per token,  2353.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.98 ms /    21 tokens (   66.19 ms per token,    15.11 tokens per second)\n",
      "llama_print_timings:        eval time =    6725.51 ms /    10 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8146.29 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2312.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.36 ms /    19 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6565.70 ms /    10 runs   (  656.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7625.73 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    11 runs   (    0.44 ms per token,  2270.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.10 ms /    22 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    6636.33 ms /    10 runs   (  663.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7839.12 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /    11 runs   (    0.44 ms per token,  2294.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.27 ms /    22 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =    6617.39 ms /    10 runs   (  661.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7832.22 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2280.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.57 ms /    21 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    6704.56 ms /    10 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7852.54 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2292.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.46 ms /    22 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    6213.09 ms /     9 runs   (  690.34 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7398.40 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2289.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     882.99 ms /    16 tokens (   55.19 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =    6169.84 ms /     9 runs   (  685.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7081.66 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2268.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.35 ms /    21 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    6204.13 ms /     9 runs   (  689.35 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7330.42 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2304.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.13 ms /    20 tokens (   67.86 ms per token,    14.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6652.14 ms /    10 runs   (  665.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8040.67 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    11 runs   (    0.42 ms per token,  2388.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.17 ms /    21 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6769.30 ms /    10 runs   (  676.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7913.49 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    11 runs   (    0.46 ms per token,  2183.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.84 ms /    22 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    6856.16 ms /    10 runs   (  685.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8036.80 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2300.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1233.31 ms /    23 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    6746.78 ms /    10 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8011.43 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    11 runs   (    0.43 ms per token,  2329.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.87 ms /    18 tokens (   55.94 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =    6715.32 ms /    10 runs   (  671.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7753.28 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    11 runs   (    0.43 ms per token,  2331.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.96 ms /    19 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6698.32 ms /    10 runs   (  669.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7732.65 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.25 ms /    19 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    6150.02 ms /     9 runs   (  683.34 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7215.27 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    11 runs   (    0.42 ms per token,  2372.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.95 ms /    19 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6824.72 ms /    10 runs   (  682.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7872.37 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2303.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.46 ms /    21 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6911.26 ms /    10 runs   (  691.13 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8038.03 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    11 runs   (    0.53 ms per token,  1875.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.75 ms /    22 tokens (   64.90 ms per token,    15.41 tokens per second)\n",
      "llama_print_timings:        eval time =    6802.23 ms /    10 runs   (  680.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8266.42 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    11 runs   (    0.42 ms per token,  2370.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.77 ms /    23 tokens (   58.86 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6623.20 ms /    10 runs   (  662.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8008.49 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2325.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.73 ms /    23 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6789.78 ms /    10 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8021.14 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    11 runs   (    0.43 ms per token,  2349.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.51 ms /    21 tokens (   55.83 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6686.50 ms /    10 runs   (  668.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7891.00 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    10 runs   (    0.43 ms per token,  2311.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.00 ms /    16 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    6093.13 ms /     9 runs   (  677.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6958.89 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    11 runs   (    0.41 ms per token,  2440.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.56 ms /    22 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    6703.78 ms /    10 runs   (  670.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7914.98 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    11 runs   (    0.44 ms per token,  2248.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.50 ms /    22 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    6931.76 ms /    10 runs   (  693.18 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8142.55 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2292.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.31 ms /    22 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6752.08 ms /    10 runs   (  675.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7927.94 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2305.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.18 ms /    19 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    6736.51 ms /    10 runs   (  673.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7817.78 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    11 runs   (    0.45 ms per token,  2220.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.19 ms /    17 tokens (   54.78 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    6833.76 ms /    10 runs   (  683.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7796.98 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    11 runs   (    0.43 ms per token,  2348.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.85 ms /    19 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    6733.80 ms /    10 runs   (  673.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7798.39 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    11 runs   (    0.45 ms per token,  2244.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.94 ms /    22 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6697.04 ms /    10 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7905.83 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2235.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.68 ms /    20 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6725.05 ms /    10 runs   (  672.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7819.10 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    10 runs   (    0.42 ms per token,  2406.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.34 ms /    20 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    6086.98 ms /     9 runs   (  676.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7210.23 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    11 runs   (    0.46 ms per token,  2167.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.75 ms /    22 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    6814.25 ms /    10 runs   (  681.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8031.83 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     8 runs   (    0.44 ms per token,  2287.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.91 ms /    13 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4716.49 ms /     7 runs   (  673.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5448.36 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    11 runs   (    0.45 ms per token,  2211.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.91 ms /    20 tokens (   56.00 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6962.79 ms /    10 runs   (  696.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8113.88 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.33 ms /    19 tokens (   57.91 ms per token,    17.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6736.39 ms /    10 runs   (  673.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7867.67 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    10 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.47 ms /    21 tokens (   53.55 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6022.47 ms /     9 runs   (  669.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7176.06 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    11 runs   (    0.44 ms per token,  2287.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.40 ms /    21 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6759.13 ms /    10 runs   (  675.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7959.78 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    11 runs   (    0.43 ms per token,  2345.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.61 ms /    22 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6773.02 ms /    10 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7946.28 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2303.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.88 ms /    21 tokens (   52.76 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6849.56 ms /    10 runs   (  684.96 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7988.49 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2284.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.37 ms /    19 tokens (   55.76 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6760.94 ms /    10 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7851.70 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    11 runs   (    0.43 ms per token,  2333.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.77 ms /    21 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6676.32 ms /    10 runs   (  667.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7834.51 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2313.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.96 ms /    22 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =    6494.06 ms /    10 runs   (  649.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    7663.31 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2308.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.76 ms /    22 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    6570.42 ms /    10 runs   (  657.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7776.32 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    11 runs   (    0.44 ms per token,  2268.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.33 ms /    22 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    6726.40 ms /    10 runs   (  672.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7915.29 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2289.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.14 ms /    22 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    6964.57 ms /    10 runs   (  696.46 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8146.92 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /    11 runs   (    0.44 ms per token,  2297.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.41 ms /    20 tokens (   56.17 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6772.97 ms /    10 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7928.19 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    11 runs   (    0.45 ms per token,  2246.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.27 ms /    21 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6710.52 ms /    10 runs   (  671.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7880.42 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /    12 runs   (    0.43 ms per token,  2334.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1132.48 ms /    21 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7468.84 ms /    11 runs   (  678.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8634.88 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2276.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.58 ms /    21 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    6823.04 ms /    10 runs   (  682.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7997.59 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    11 runs   (    0.45 ms per token,  2224.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.91 ms /    22 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6754.95 ms /    10 runs   (  675.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7957.06 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2326.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.96 ms /    22 tokens (   62.63 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6859.04 ms /    10 runs   (  685.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8269.32 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     999.10 ms /    19 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    6979.15 ms /    10 runs   (  697.91 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    8009.57 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    10 runs   (    0.44 ms per token,  2271.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.94 ms /    17 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    6174.13 ms /     9 runs   (  686.01 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7132.78 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    10 runs   (    0.43 ms per token,  2316.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.68 ms /    19 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6015.90 ms /     9 runs   (  668.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7065.40 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2278.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.95 ms /    19 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6693.71 ms /    10 runs   (  669.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7753.18 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    12 runs   (    0.43 ms per token,  2299.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.64 ms /    21 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7614.46 ms /    11 runs   (  692.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8765.36 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    11 runs   (    0.43 ms per token,  2343.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.95 ms /    18 tokens (   55.83 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6739.23 ms /    10 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7776.15 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    11 runs   (    0.44 ms per token,  2256.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.66 ms /    22 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    6759.56 ms /    10 runs   (  675.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7944.80 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    11 runs   (    0.43 ms per token,  2328.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.75 ms /    19 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    6799.52 ms /    10 runs   (  679.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7854.33 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    13 runs   (    0.43 ms per token,  2337.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.54 ms /    21 tokens (   55.98 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =    8235.45 ms /    12 runs   (  686.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9447.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.53 ms /    13 runs   (    0.43 ms per token,  2350.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.89 ms /    22 tokens (   52.81 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    8233.58 ms /    12 runs   (  686.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9432.20 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    14 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.25 ms /    23 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    8749.04 ms /    13 runs   (  673.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9997.44 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2301.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.59 ms /    25 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    8049.35 ms /    12 runs   (  670.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9379.14 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    13 runs   (    0.44 ms per token,  2253.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1132.44 ms /    22 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =    8179.77 ms /    12 runs   (  681.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9349.61 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    13 runs   (    0.44 ms per token,  2276.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.48 ms /    22 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    8116.18 ms /    12 runs   (  676.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9301.31 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.25 ms /    12 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.88 ms /    20 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    7367.92 ms /    11 runs   (  669.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8491.44 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2279.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.15 ms /    23 tokens (   58.79 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8090.40 ms /    12 runs   (  674.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9479.75 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    13 runs   (    0.43 ms per token,  2310.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.65 ms /    23 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8130.12 ms /    12 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9405.99 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2312.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.88 ms /    22 tokens (   52.81 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    8063.17 ms /    12 runs   (  671.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9261.71 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    12 runs   (    0.45 ms per token,  2220.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.23 ms /    23 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =    7472.97 ms /    11 runs   (  679.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8698.41 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    12 runs   (    0.43 ms per token,  2347.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.64 ms /    23 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7394.21 ms /    11 runs   (  672.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8649.39 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    11 runs   (    0.43 ms per token,  2304.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.65 ms /    20 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6755.49 ms /    10 runs   (  675.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7845.86 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2313.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.05 ms /    21 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    8062.52 ms /    12 runs   (  671.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9197.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2269.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.06 ms /    24 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8240.76 ms /    12 runs   (  686.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9521.90 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    13 runs   (    0.44 ms per token,  2256.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.26 ms /    25 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    8050.76 ms /    12 runs   (  670.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9435.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    12 runs   (    0.45 ms per token,  2204.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.49 ms /    27 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =    7384.99 ms /    11 runs   (  671.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8812.97 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    13 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.32 ms /    25 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8147.72 ms /    12 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9454.48 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    13 runs   (    0.44 ms per token,  2265.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.92 ms /    19 tokens (   55.57 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =    8073.06 ms /    12 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9165.89 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    13 runs   (    0.45 ms per token,  2226.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.89 ms /    24 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8153.14 ms /    12 runs   (  679.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9434.33 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    12 runs   (    0.45 ms per token,  2243.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.89 ms /    23 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    7587.98 ms /    11 runs   (  689.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8836.12 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2291.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.44 ms /    20 tokens (   55.37 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =    6645.64 ms /    10 runs   (  664.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7785.22 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /    12 runs   (    0.43 ms per token,  2333.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.67 ms /    18 tokens (   54.87 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =    7533.36 ms /    11 runs   (  684.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8556.06 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    10 runs   (    0.46 ms per token,  2179.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.44 ms /    15 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    6130.33 ms /     9 runs   (  681.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6947.12 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    12 runs   (    0.44 ms per token,  2274.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.95 ms /    22 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7479.01 ms /    11 runs   (  679.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8671.05 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    12 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.43 ms /    25 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7403.51 ms /    11 runs   (  673.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8729.27 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    13 runs   (    0.44 ms per token,  2249.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.99 ms /    26 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    8169.36 ms /    12 runs   (  680.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9566.56 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    12 runs   (    0.45 ms per token,  2214.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.52 ms /    23 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    7470.38 ms /    11 runs   (  679.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8698.09 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    13 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.68 ms /    22 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    8163.70 ms /    12 runs   (  680.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9383.52 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2260.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.02 ms /    25 tokens (   59.60 ms per token,    16.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7535.68 ms /    11 runs   (  685.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9059.85 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    12 runs   (    0.44 ms per token,  2297.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.39 ms /    21 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    7441.17 ms /    11 runs   (  676.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8588.50 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    13 runs   (    0.43 ms per token,  2337.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.00 ms /    22 tokens (   53.32 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8163.75 ms /    12 runs   (  680.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9374.09 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2281.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.11 ms /    22 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    8127.56 ms /    12 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9326.28 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    13 runs   (    0.43 ms per token,  2307.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.71 ms /    21 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =    8027.15 ms /    12 runs   (  668.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9183.24 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    13 runs   (    0.45 ms per token,  2219.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.56 ms /    21 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =    8179.64 ms /    12 runs   (  681.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9311.77 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    13 runs   (    0.43 ms per token,  2321.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.35 ms /    24 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8020.64 ms /    12 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9319.81 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    12 runs   (    0.44 ms per token,  2248.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.03 ms /    24 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =    7492.78 ms /    11 runs   (  681.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8832.48 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    14 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.72 ms /    25 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    8640.30 ms /    13 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10000.36 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2316.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.72 ms /    24 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    8171.32 ms /    12 runs   (  680.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9460.35 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2280.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.01 ms /    24 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    8080.71 ms /    12 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9359.87 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    11 runs   (    0.44 ms per token,  2260.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.54 ms /    24 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6813.20 ms /    10 runs   (  681.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8094.52 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    12 runs   (    0.43 ms per token,  2319.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.54 ms /    24 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    7416.31 ms /    11 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8699.37 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    13 runs   (    0.45 ms per token,  2235.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.61 ms /    22 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    7829.43 ms /    12 runs   (  652.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    9058.93 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.25 ms /    12 runs   (    0.44 ms per token,  2283.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.48 ms /    23 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    7550.30 ms /    11 runs   (  686.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8796.01 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2325.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.25 ms /    24 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8066.59 ms /    12 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9366.19 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    12 runs   (    0.47 ms per token,  2147.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.53 ms /    22 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    7422.62 ms /    11 runs   (  674.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8597.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    12 runs   (    0.43 ms per token,  2302.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.26 ms /    24 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    7427.41 ms /    11 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8696.36 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    12 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.54 ms /    23 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7343.35 ms /    11 runs   (  667.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8618.65 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    13 runs   (    0.47 ms per token,  2148.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.88 ms /    25 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =    8185.06 ms /    12 runs   (  682.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9507.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    13 runs   (    0.44 ms per token,  2255.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.00 ms /    21 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    8044.01 ms /    12 runs   (  670.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9221.93 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.87 ms /    13 runs   (    0.45 ms per token,  2213.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.86 ms /    23 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8188.98 ms /    12 runs   (  682.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9445.80 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    12 runs   (    0.44 ms per token,  2291.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.40 ms /    25 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    7442.55 ms /    11 runs   (  676.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8762.16 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    12 runs   (    0.44 ms per token,  2274.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.97 ms /    22 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    7678.47 ms /    11 runs   (  698.04 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    8897.27 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2260.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.05 ms /    20 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    7478.92 ms /    11 runs   (  679.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8589.03 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2312.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.46 ms /    25 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    8364.38 ms /    12 runs   (  697.03 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    9766.77 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    13 runs   (    0.45 ms per token,  2230.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.57 ms /    23 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    8062.20 ms /    12 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9302.46 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    12 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.86 ms /    26 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    7310.50 ms /    11 runs   (  664.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8759.44 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    13 runs   (    0.45 ms per token,  2211.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.22 ms /    24 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =    8091.37 ms /    12 runs   (  674.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9390.17 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    12 runs   (    0.45 ms per token,  2222.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.56 ms /    25 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    7423.19 ms /    11 runs   (  674.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8756.61 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.44 ms per token,  2297.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.63 ms /    23 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    7907.94 ms /    12 runs   (  658.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9155.41 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    12 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.71 ms /    25 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    7318.76 ms /    11 runs   (  665.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8675.32 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    13 runs   (    0.45 ms per token,  2241.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.77 ms /    16 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =    8259.58 ms /    12 runs   (  688.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9138.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2323.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.51 ms /    23 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    8046.38 ms /    12 runs   (  670.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9298.35 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    12 runs   (    0.45 ms per token,  2228.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.45 ms /    26 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    7468.98 ms /    11 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8872.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    13 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.68 ms /    23 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    8007.59 ms /    12 runs   (  667.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9264.13 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    12 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.82 ms /    22 tokens (   61.04 ms per token,    16.38 tokens per second)\n",
      "llama_print_timings:        eval time =    7247.96 ms /    11 runs   (  658.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8625.72 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    13 runs   (    0.44 ms per token,  2262.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.14 ms /    24 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8160.41 ms /    12 runs   (  680.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9438.84 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2302.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.81 ms /    24 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    8146.04 ms /    12 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9446.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    12 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     952.05 ms /    17 tokens (   56.00 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =    7502.91 ms /    11 runs   (  682.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8489.22 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.08 ms /    12 runs   (    0.42 ms per token,  2363.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.01 ms /    19 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7445.46 ms /    11 runs   (  676.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8495.02 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    13 runs   (    0.44 ms per token,  2251.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.19 ms /    20 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    8172.31 ms /    12 runs   (  681.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9299.59 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    13 runs   (    0.43 ms per token,  2320.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.23 ms /    25 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    8106.05 ms /    12 runs   (  675.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9431.56 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    13 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.50 ms /    25 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    8325.80 ms /    12 runs   (  693.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9664.60 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2293.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.20 ms /    25 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    8089.76 ms /    12 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9412.62 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    12 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.32 ms /    20 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    7421.31 ms /    11 runs   (  674.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8541.04 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2305.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.12 ms /    21 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    8035.95 ms /    12 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9171.35 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    12 runs   (    0.43 ms per token,  2324.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.88 ms /    23 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    7536.37 ms /    11 runs   (  685.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8782.63 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2288.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.93 ms /    25 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    8132.29 ms /    12 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9467.97 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2329.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.90 ms /    24 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8157.99 ms /    12 runs   (  679.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9420.85 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.82 ms /    19 tokens (   59.25 ms per token,    16.88 tokens per second)\n",
      "llama_print_timings:        eval time =    8179.10 ms /    12 runs   (  681.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9342.60 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    13 runs   (    0.44 ms per token,  2271.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.34 ms /    21 tokens (   51.83 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    8089.65 ms /    12 runs   (  674.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9216.78 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    13 runs   (    0.45 ms per token,  2229.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.50 ms /    23 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8092.65 ms /    12 runs   (  674.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9317.36 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2267.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.43 ms /    19 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    8071.30 ms /    12 runs   (  672.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9137.38 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    13 runs   (    0.44 ms per token,  2259.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.74 ms /    23 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    8057.82 ms /    12 runs   (  671.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9308.90 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    12 runs   (    0.44 ms per token,  2274.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.18 ms /    25 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    7415.11 ms /    11 runs   (  674.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8758.58 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    13 runs   (    0.46 ms per token,  2184.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.84 ms /    24 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =    8148.23 ms /    12 runs   (  679.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9424.53 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    13 runs   (    0.50 ms per token,  1981.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.76 ms /    23 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =    8439.73 ms /    12 runs   (  703.31 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    9731.41 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2302.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.36 ms /    21 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =    8047.14 ms /    12 runs   (  670.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9209.12 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.32 ms /    12 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.84 ms /    22 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7458.69 ms /    11 runs   (  678.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8677.29 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    12 runs   (    0.44 ms per token,  2277.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.48 ms /    26 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =    7338.96 ms /    11 runs   (  667.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8701.29 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2281.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.73 ms /    25 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8094.25 ms /    12 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9409.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    12 runs   (    0.42 ms per token,  2365.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.16 ms /    26 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7252.28 ms /    11 runs   (  659.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8604.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.81 ms /    13 runs   (    0.45 ms per token,  2238.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.38 ms /    25 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    8091.82 ms /    12 runs   (  674.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9438.82 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /    13 runs   (    0.42 ms per token,  2355.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.36 ms /    18 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8050.32 ms /    12 runs   (  670.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9092.32 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    13 runs   (    0.44 ms per token,  2273.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.18 ms /    25 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7963.49 ms /    12 runs   (  663.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9269.73 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2300.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.52 ms /    20 tokens (   62.68 ms per token,    15.96 tokens per second)\n",
      "llama_print_timings:        eval time =    8022.86 ms /    12 runs   (  668.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9315.10 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    12 runs   (    0.44 ms per token,  2279.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.26 ms /    21 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    7418.60 ms /    11 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8552.07 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2280.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.58 ms /    23 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    7787.41 ms /    12 runs   (  648.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    9031.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    12 runs   (    0.51 ms per token,  1946.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.17 ms /    23 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7089.19 ms /    11 runs   (  644.47 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    8354.60 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2281.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.04 ms /    24 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    8208.32 ms /    12 runs   (  684.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9500.18 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    12 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.55 ms /    23 tokens (   55.50 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7393.13 ms /    11 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8704.36 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    12 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.43 ms /    22 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    7377.89 ms /    11 runs   (  670.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8571.00 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2315.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.04 ms /    21 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =    7944.71 ms /    12 runs   (  662.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9115.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /    13 runs   (    0.42 ms per token,  2355.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.20 ms /    25 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    8103.97 ms /    12 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9441.62 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    13 runs   (    0.45 ms per token,  2227.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.76 ms /    23 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =    8107.59 ms /    12 runs   (  675.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9353.87 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.42 ms /    25 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =    8141.65 ms /    12 runs   (  678.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9451.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    13 runs   (    0.45 ms per token,  2209.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.03 ms /    26 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8000.91 ms /    12 runs   (  666.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9417.95 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    12 runs   (    0.44 ms per token,  2266.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.40 ms /    23 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7621.88 ms /    11 runs   (  692.90 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8882.94 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    13 runs   (    0.42 ms per token,  2357.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.36 ms /    25 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8102.15 ms /    12 runs   (  675.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9468.63 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2318.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.60 ms /    22 tokens (   57.39 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =    8021.98 ms /    12 runs   (  668.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9322.10 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    12 runs   (    0.43 ms per token,  2350.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.00 ms /    21 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    7248.22 ms /    11 runs   (  658.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8390.25 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2289.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.10 ms /    27 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    8107.09 ms /    12 runs   (  675.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9533.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    12 runs   (    0.45 ms per token,  2213.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.53 ms /    24 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    7207.40 ms /    11 runs   (  655.22 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    8484.66 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    13 runs   (    0.43 ms per token,  2338.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.64 ms /    24 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    8079.58 ms /    12 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9366.85 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    13 runs   (    0.44 ms per token,  2275.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.59 ms /    21 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =    8021.59 ms /    12 runs   (  668.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9197.43 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2289.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.73 ms /    23 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    8080.35 ms /    12 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9329.10 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.13 ms /    12 runs   (    0.43 ms per token,  2337.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.32 ms /    24 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =    7382.00 ms /    11 runs   (  671.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8657.91 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1233.25 ms /    23 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =    8172.29 ms /    12 runs   (  681.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9442.67 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2317.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.92 ms /    24 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    8223.26 ms /    12 runs   (  685.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9509.15 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    13 runs   (    0.44 ms per token,  2272.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.65 ms /    24 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    8245.01 ms /    12 runs   (  687.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9543.94 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    12 runs   (    0.45 ms per token,  2204.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.84 ms /    22 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    7514.66 ms /    11 runs   (  683.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8740.12 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2305.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.85 ms /    21 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    7981.45 ms /    12 runs   (  665.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9137.25 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    13 runs   (    0.47 ms per token,  2149.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.08 ms /    21 tokens (   55.62 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =    8175.03 ms /    12 runs   (  681.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9383.98 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    13 runs   (    0.44 ms per token,  2250.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.94 ms /    25 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    7967.94 ms /    12 runs   (  664.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9289.96 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    12 runs   (    0.43 ms per token,  2313.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.35 ms /    20 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7359.17 ms /    11 runs   (  669.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8461.05 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    12 runs   (    0.44 ms per token,  2273.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.43 ms /    21 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =    7310.93 ms /    11 runs   (  664.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8443.85 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2318.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.30 ms /    21 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    8152.20 ms /    12 runs   (  679.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9301.68 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    12 runs   (    0.43 ms per token,  2302.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.69 ms /    22 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =    7231.55 ms /    11 runs   (  657.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8408.66 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    13 runs   (    0.42 ms per token,  2357.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.87 ms /    21 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8126.19 ms /    12 runs   (  677.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9275.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    12 runs   (    0.43 ms per token,  2312.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.44 ms /    27 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7348.50 ms /    11 runs   (  668.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8731.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    12 runs   (    0.44 ms per token,  2289.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.52 ms /    19 tokens (   66.24 ms per token,    15.10 tokens per second)\n",
      "llama_print_timings:        eval time =    7467.31 ms /    11 runs   (  678.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8759.77 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2269.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.92 ms /    24 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8165.93 ms /    12 runs   (  680.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9448.44 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    13 runs   (    0.43 ms per token,  2343.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.79 ms /    23 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8198.37 ms /    12 runs   (  683.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9456.94 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    12 runs   (    0.44 ms per token,  2253.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.66 ms /    23 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    7618.77 ms /    11 runs   (  692.62 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8854.45 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    10 runs   (    0.44 ms per token,  2286.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     957.46 ms /    17 tokens (   56.32 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6262.30 ms /     9 runs   (  695.81 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7248.93 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    12 runs   (    0.44 ms per token,  2292.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.69 ms /    24 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    7439.25 ms /    11 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8738.27 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2325.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.86 ms /    16 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =    8235.27 ms /    12 runs   (  686.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9134.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    13 runs   (    0.44 ms per token,  2261.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.21 ms /    20 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8228.24 ms /    12 runs   (  685.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9334.49 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    12 runs   (    0.44 ms per token,  2294.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.79 ms /    23 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =    7531.02 ms /    11 runs   (  684.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8773.45 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    11 runs   (    0.45 ms per token,  2229.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.76 ms /    21 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6820.98 ms /    10 runs   (  682.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7987.34 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    12 runs   (    0.43 ms per token,  2308.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.11 ms /    19 tokens (   55.43 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    7499.41 ms /    11 runs   (  681.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8586.78 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    12 runs   (    0.43 ms per token,  2311.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     994.45 ms /    18 tokens (   55.25 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =    7416.49 ms /    11 runs   (  674.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8444.76 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    13 runs   (    0.45 ms per token,  2244.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.96 ms /    19 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    8233.44 ms /    12 runs   (  686.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9295.83 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.45 ms /    12 runs   (    0.45 ms per token,  2201.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.93 ms /    25 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =    7354.35 ms /    11 runs   (  668.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8701.35 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2327.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.40 ms /    23 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    8082.68 ms /    12 runs   (  673.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9381.63 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    13 runs   (    0.43 ms per token,  2322.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.66 ms /    24 tokens (   55.94 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8034.16 ms /    12 runs   (  669.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9413.79 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2323.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.39 ms /    23 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =    8156.76 ms /    12 runs   (  679.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9373.19 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    13 runs   (    0.43 ms per token,  2335.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.26 ms /    20 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8415.94 ms /    12 runs   (  701.33 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    9513.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    12 runs   (    0.43 ms per token,  2322.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.90 ms /    23 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    7463.38 ms /    11 runs   (  678.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8730.25 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    12 runs   (    0.44 ms per token,  2252.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     993.41 ms /    18 tokens (   55.19 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =    7503.36 ms /    11 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8530.70 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    12 runs   (    0.43 ms per token,  2303.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.73 ms /    22 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    7464.11 ms /    11 runs   (  678.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8665.62 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2331.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.74 ms /    20 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    8095.07 ms /    12 runs   (  674.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9188.92 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    12 runs   (    0.45 ms per token,  2224.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.41 ms /    23 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    7571.56 ms /    11 runs   (  688.32 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8821.20 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.25 ms /    12 runs   (    0.44 ms per token,  2287.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.97 ms /    26 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    7644.29 ms /    11 runs   (  694.94 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9046.13 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    12 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.32 ms /    23 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7536.83 ms /    11 runs   (  685.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8810.50 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2329.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.77 ms /    24 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8089.20 ms /    12 runs   (  674.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9370.62 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2315.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.25 ms /    24 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6909.90 ms /    10 runs   (  690.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8162.82 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2290.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.70 ms /    22 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7886.88 ms /    12 runs   (  657.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9095.35 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    13 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.36 ms /    24 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8192.25 ms /    12 runs   (  682.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9511.79 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    12 runs   (    0.44 ms per token,  2295.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.32 ms /    23 tokens (   54.36 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =    7604.21 ms /    11 runs   (  691.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8888.76 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    13 runs   (    0.43 ms per token,  2344.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.12 ms /    21 tokens (   55.48 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =    8409.79 ms /    12 runs   (  700.82 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    9612.64 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    12 runs   (    0.45 ms per token,  2245.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.42 ms /    22 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7260.01 ms /    11 runs   (  660.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8467.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    13 runs   (    0.44 ms per token,  2253.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.27 ms /    25 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    8349.86 ms /    12 runs   (  695.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9673.56 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    11 runs   (    0.43 ms per token,  2300.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.90 ms /    20 tokens (   54.45 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    6574.04 ms /    10 runs   (  657.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7694.98 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2313.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.16 ms /    22 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    8208.56 ms /    12 runs   (  684.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9441.12 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    13 runs   (    0.42 ms per token,  2380.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.64 ms /    20 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    7973.03 ms /    12 runs   (  664.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9074.27 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    13 runs   (    0.43 ms per token,  2342.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.52 ms /    21 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    8022.86 ms /    12 runs   (  668.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9165.12 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    12 runs   (    0.45 ms per token,  2228.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.80 ms /    23 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7444.07 ms /    11 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8715.99 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    13 runs   (    0.44 ms per token,  2275.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.08 ms /    25 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    8120.93 ms /    12 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9447.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    12 runs   (    0.45 ms per token,  2234.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.18 ms /    21 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    7427.76 ms /    11 runs   (  675.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8574.09 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    13 runs   (    0.45 ms per token,  2245.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.00 ms /    24 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =    8083.97 ms /    12 runs   (  673.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9350.48 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2330.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.97 ms /    18 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    8189.12 ms /    12 runs   (  682.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9187.27 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    13 runs   (    0.44 ms per token,  2285.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.23 ms /    23 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    8150.04 ms /    12 runs   (  679.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9396.82 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    11 runs   (    0.43 ms per token,  2322.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.85 ms /    24 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =    6827.94 ms /    10 runs   (  682.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8101.31 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    13 runs   (    0.45 ms per token,  2240.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.83 ms /    23 tokens (   58.51 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =    8313.84 ms /    12 runs   (  692.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9697.56 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    10 runs   (    0.42 ms per token,  2362.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.62 ms /    15 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    6161.37 ms /     9 runs   (  684.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6994.97 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    12 runs   (    0.43 ms per token,  2323.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.50 ms /    23 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    7399.82 ms /    11 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8650.33 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    12 runs   (    0.45 ms per token,  2228.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.53 ms /    24 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    7403.86 ms /    11 runs   (  673.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8686.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.73 ms /    26 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    7365.40 ms /    11 runs   (  669.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8752.33 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.28 ms /    13 runs   (    0.48 ms per token,  2071.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.11 ms /    23 tokens (   52.40 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    8329.52 ms /    12 runs   (  694.13 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9576.62 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2316.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.97 ms /    22 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8259.27 ms /    12 runs   (  688.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9433.26 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    13 runs   (    0.43 ms per token,  2309.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1664.79 ms /    26 tokens (   64.03 ms per token,    15.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8100.51 ms /    12 runs   (  675.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9802.41 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    12 runs   (    0.44 ms per token,  2282.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.93 ms /    26 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7406.55 ms /    11 runs   (  673.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8808.41 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    13 runs   (    0.44 ms per token,  2264.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.89 ms /    23 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8123.36 ms /    12 runs   (  676.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9370.41 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /    13 runs   (    0.42 ms per token,  2354.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.09 ms /    21 tokens (   55.53 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8152.64 ms /    12 runs   (  679.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9355.19 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    13 runs   (    0.42 ms per token,  2371.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.76 ms /    26 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    8095.23 ms /    12 runs   (  674.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9471.49 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    13 runs   (    0.52 ms per token,  1939.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.75 ms /    21 tokens (   60.18 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8184.15 ms /    12 runs   (  682.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9491.27 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.53 ms /    13 runs   (    0.43 ms per token,  2351.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.73 ms /    23 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    7991.88 ms /    12 runs   (  665.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9228.14 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    12 runs   (    0.43 ms per token,  2321.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.13 ms /    21 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    7757.57 ms /    11 runs   (  705.23 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    8907.50 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2300.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.70 ms /    21 tokens (   54.51 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8087.40 ms /    12 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9269.58 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    12 runs   (    0.43 ms per token,  2327.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.71 ms /    26 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    7405.14 ms /    11 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8775.34 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    13 runs   (    0.42 ms per token,  2377.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.81 ms /    22 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8085.37 ms /    12 runs   (  673.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9295.59 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2281.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.18 ms /    23 tokens (   55.75 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    7854.83 ms /    12 runs   (  654.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    9173.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    12 runs   (    0.43 ms per token,  2319.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.60 ms /    22 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    7193.85 ms /    11 runs   (  653.99 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    8389.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    12 runs   (    0.45 ms per token,  2242.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.12 ms /    23 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7395.45 ms /    11 runs   (  672.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8655.20 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    12 runs   (    0.45 ms per token,  2211.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.21 ms /    26 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    7458.26 ms /    11 runs   (  678.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8838.12 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    13 runs   (    0.44 ms per token,  2259.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1553.67 ms /    25 tokens (   62.15 ms per token,    16.09 tokens per second)\n",
      "llama_print_timings:        eval time =    7894.41 ms /    12 runs   (  657.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9485.90 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    13 runs   (    0.43 ms per token,  2338.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.73 ms /    20 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    8026.24 ms /    12 runs   (  668.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9141.21 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    13 runs   (    0.45 ms per token,  2240.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.93 ms /    21 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7919.49 ms /    12 runs   (  659.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9077.76 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2319.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.30 ms /    19 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =    6127.89 ms /     9 runs   (  680.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7193.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2281.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.24 ms /    28 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    8084.76 ms /    12 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9574.79 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.89 ms /    13 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.87 ms /    20 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    8134.02 ms /    12 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9234.75 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.87 ms /    13 runs   (    0.45 ms per token,  2215.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.00 ms /    28 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8255.59 ms /    12 runs   (  687.97 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9720.58 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2312.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.16 ms /    26 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8240.97 ms /    12 runs   (  686.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9620.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.43 ms /    13 runs   (    0.42 ms per token,  2392.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.47 ms /    28 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    8091.82 ms /    12 runs   (  674.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9563.92 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    13 runs   (    0.43 ms per token,  2338.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.25 ms /    23 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    8135.32 ms /    12 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9389.38 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    13 runs   (    0.44 ms per token,  2258.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.40 ms /    22 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    7975.90 ms /    12 runs   (  664.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9165.17 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    14 runs   (    0.43 ms per token,  2317.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.81 ms /    30 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    8581.76 ms /    13 runs   (  660.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10168.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2303.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.06 ms /    24 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    7976.75 ms /    12 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9239.99 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    13 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.82 ms /    27 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    8227.02 ms /    12 runs   (  685.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9668.42 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.43 ms /    12 runs   (    0.45 ms per token,  2211.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1572.58 ms /    26 tokens (   60.48 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7510.57 ms /    11 runs   (  682.78 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9117.24 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    14 runs   (    0.43 ms per token,  2334.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.45 ms /    25 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8809.11 ms /    13 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10116.69 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2327.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.75 ms /    27 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8209.08 ms /    12 runs   (  684.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9677.51 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    14 runs   (    0.42 ms per token,  2356.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.23 ms /    22 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    8897.26 ms /    13 runs   (  684.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10084.58 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    12 runs   (    0.42 ms per token,  2366.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.32 ms /    23 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    7498.68 ms /    11 runs   (  681.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8739.38 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    13 runs   (    0.44 ms per token,  2284.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.18 ms /    25 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8245.15 ms /    12 runs   (  687.10 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9552.80 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    13 runs   (    0.42 ms per token,  2358.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.71 ms /    26 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    8103.04 ms /    12 runs   (  675.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9548.34 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2269.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1469.05 ms /    29 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8030.30 ms /    12 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9536.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    13 runs   (    0.44 ms per token,  2254.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.22 ms /    26 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7957.29 ms /    12 runs   (  663.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9310.68 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    13 runs   (    0.43 ms per token,  2332.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.03 ms /    22 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    8055.73 ms /    12 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9295.33 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    14 runs   (    0.42 ms per token,  2360.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.83 ms /    24 tokens (   56.28 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =    8662.07 ms /    13 runs   (  666.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10052.31 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2281.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.95 ms /    27 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8090.41 ms /    12 runs   (  674.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9526.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    14 runs   (    0.44 ms per token,  2266.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.52 ms /    28 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =    8741.87 ms /    13 runs   (  672.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10212.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    14 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.84 ms /    26 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8979.02 ms /    13 runs   (  690.69 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   10344.36 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2323.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.05 ms /    28 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8130.87 ms /    12 runs   (  677.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9612.49 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2312.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.86 ms /    25 tokens (   52.23 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =    7973.02 ms /    12 runs   (  664.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9316.34 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    15 runs   (    0.47 ms per token,  2123.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.94 ms /    24 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    9719.11 ms /    14 runs   (  694.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   11024.42 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    13 runs   (    0.45 ms per token,  2245.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.37 ms /    25 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8069.74 ms /    12 runs   (  672.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9427.84 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    14 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.36 ms /    27 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =    8816.41 ms /    13 runs   (  678.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10238.82 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    13 runs   (    0.44 ms per token,  2285.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.65 ms /    26 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8245.95 ms /    12 runs   (  687.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9662.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2317.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.96 ms /    24 tokens (   51.67 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    8035.06 ms /    12 runs   (  669.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9311.41 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    14 runs   (    0.45 ms per token,  2198.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.55 ms /    21 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    8588.89 ms /    13 runs   (  660.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9741.50 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    14 runs   (    0.41 ms per token,  2412.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.67 ms /    26 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    8609.68 ms /    13 runs   (  662.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10010.97 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.14 ms /    14 runs   (    0.44 ms per token,  2281.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.71 ms /    27 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    8704.45 ms /    13 runs   (  669.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10181.13 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    14 runs   (    0.43 ms per token,  2320.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.93 ms /    26 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8802.44 ms /    13 runs   (  677.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10162.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    13 runs   (    0.44 ms per token,  2273.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.51 ms /    22 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =    8209.61 ms /    12 runs   (  684.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9448.87 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    13 runs   (    0.45 ms per token,  2199.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.74 ms /    26 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8118.10 ms /    12 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9484.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    13 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1684.21 ms /    28 tokens (   60.15 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8173.24 ms /    12 runs   (  681.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9894.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    14 runs   (    0.44 ms per token,  2296.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.43 ms /    24 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =    8751.58 ms /    13 runs   (  673.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10044.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    14 runs   (    0.42 ms per token,  2388.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.65 ms /    24 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8772.86 ms /    13 runs   (  674.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10102.15 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    13 runs   (    0.42 ms per token,  2380.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.44 ms /    23 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    8224.54 ms /    12 runs   (  685.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9479.84 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.62 ms /    28 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8103.48 ms /    12 runs   (  675.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9585.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    14 runs   (    0.44 ms per token,  2286.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.81 ms /    28 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    8660.39 ms /    13 runs   (  666.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10136.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2326.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.43 ms /    23 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7918.12 ms /    12 runs   (  659.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9180.25 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    14 runs   (    0.43 ms per token,  2315.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.43 ms /    22 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    8799.82 ms /    13 runs   (  676.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9983.50 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    12 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.08 ms /    21 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    7307.55 ms /    11 runs   (  664.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8429.99 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2292.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.16 ms /    28 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8030.08 ms /    12 runs   (  669.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9518.39 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    13 runs   (    0.43 ms per token,  2309.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.34 ms /    23 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    8146.36 ms /    12 runs   (  678.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9389.14 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2323.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.69 ms /    22 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6084.24 ms /     9 runs   (  676.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7320.12 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    15 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.69 ms /    27 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    9588.10 ms /    14 runs   (  684.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11011.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    14 runs   (    0.44 ms per token,  2247.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.91 ms /    28 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =    8969.72 ms /    13 runs   (  689.98 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   10474.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    13 runs   (    0.44 ms per token,  2251.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.18 ms /    25 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    8095.42 ms /    12 runs   (  674.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9438.08 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    14 runs   (    0.43 ms per token,  2350.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.52 ms /    25 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    8653.70 ms /    13 runs   (  665.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9976.03 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    14 runs   (    0.42 ms per token,  2399.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.56 ms /    24 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    8628.48 ms /    13 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9924.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.02 ms /    12 runs   (    0.42 ms per token,  2389.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.38 ms /    28 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7426.81 ms /    11 runs   (  675.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8876.30 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    13 runs   (    0.43 ms per token,  2307.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.08 ms /    27 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8300.83 ms /    12 runs   (  691.74 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9717.81 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    13 runs   (    0.42 ms per token,  2368.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.38 ms /    25 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8032.62 ms /    12 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9359.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    14 runs   (    0.44 ms per token,  2265.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.05 ms /    26 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    8786.01 ms /    13 runs   (  675.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10162.79 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    13 runs   (    0.43 ms per token,  2342.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.39 ms /    30 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8072.48 ms /    12 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9627.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    13 runs   (    0.42 ms per token,  2388.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.95 ms /    23 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8065.77 ms /    12 runs   (  672.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9328.55 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    14 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.76 ms /    28 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =    8606.47 ms /    13 runs   (  662.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10103.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    14 runs   (    0.43 ms per token,  2319.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.70 ms /    23 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    8661.69 ms /    13 runs   (  666.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9908.24 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2314.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.00 ms /    26 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =    7789.09 ms /    12 runs   (  649.09 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    9166.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    14 runs   (    0.43 ms per token,  2341.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.38 ms /    26 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8910.93 ms /    13 runs   (  685.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10293.38 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    14 runs   (    0.43 ms per token,  2345.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.86 ms /    25 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8878.04 ms /    13 runs   (  682.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10215.23 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2306.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.59 ms /    27 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    8104.36 ms /    12 runs   (  675.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9525.38 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.09 ms /    14 runs   (    0.44 ms per token,  2297.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.57 ms /    23 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    8893.02 ms /    13 runs   (  684.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10142.51 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    13 runs   (    0.45 ms per token,  2231.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.68 ms /    25 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    8159.03 ms /    12 runs   (  679.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9519.24 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    13 runs   (    0.44 ms per token,  2264.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.63 ms /    26 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    8220.57 ms /    12 runs   (  685.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9596.24 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    13 runs   (    0.42 ms per token,  2366.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.22 ms /    27 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8162.37 ms /    12 runs   (  680.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9592.82 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    12 runs   (    0.44 ms per token,  2281.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.87 ms /    25 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    7583.55 ms /    11 runs   (  689.41 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8906.97 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    14 runs   (    0.44 ms per token,  2271.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.06 ms /    27 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =    8769.52 ms /    13 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10227.80 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2319.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.24 ms /    25 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    8193.74 ms /    12 runs   (  682.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9540.39 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    13 runs   (    0.46 ms per token,  2179.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.85 ms /    25 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    8153.56 ms /    12 runs   (  679.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9503.09 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    14 runs   (    0.43 ms per token,  2320.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.11 ms /    27 tokens (   51.37 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    8856.59 ms /    13 runs   (  681.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10284.66 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    14 runs   (    0.42 ms per token,  2403.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.19 ms /    28 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8820.74 ms /    13 runs   (  678.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10288.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2315.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.94 ms /    26 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    8120.92 ms /    12 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9494.46 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2282.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.25 ms /    24 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    8099.71 ms /    12 runs   (  674.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9386.46 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    14 runs   (    0.43 ms per token,  2334.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.78 ms /    25 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    8817.70 ms /    13 runs   (  678.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10164.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2291.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.64 ms /    26 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8092.86 ms /    12 runs   (  674.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9451.95 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    13 runs   (    0.45 ms per token,  2232.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.77 ms /    27 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =    8115.77 ms /    12 runs   (  676.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9531.25 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    14 runs   (    0.42 ms per token,  2365.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.39 ms /    28 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =    8800.44 ms /    13 runs   (  676.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10253.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2306.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1540.34 ms /    29 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =    8195.77 ms /    12 runs   (  682.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9773.82 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2303.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1364.62 ms /    27 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =    8209.44 ms /    12 runs   (  684.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9612.01 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.44 ms per token,  2296.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.13 ms /    29 tokens (   57.66 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =    8060.11 ms /    12 runs   (  671.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9769.86 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    14 runs   (    0.42 ms per token,  2368.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.19 ms /    25 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8676.28 ms /    13 runs   (  667.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10043.02 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    14 runs   (    0.42 ms per token,  2370.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.02 ms /    24 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =    8660.26 ms /    13 runs   (  666.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9929.68 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    12 runs   (    0.46 ms per token,  2158.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.10 ms /    24 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    7480.47 ms /    11 runs   (  680.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8776.74 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    13 runs   (    0.43 ms per token,  2334.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.61 ms /    28 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =    8281.80 ms /    12 runs   (  690.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9750.56 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.09 ms /    14 runs   (    0.44 ms per token,  2298.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.03 ms /    28 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    8835.68 ms /    13 runs   (  679.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10324.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2287.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.00 ms /    27 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =    8212.98 ms /    12 runs   (  684.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9699.80 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2287.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.51 ms /    25 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =    8016.46 ms /    12 runs   (  668.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9345.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    14 runs   (    0.44 ms per token,  2286.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.09 ms /    27 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =    8835.84 ms /    13 runs   (  679.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10263.23 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.13 ms /    12 runs   (    0.43 ms per token,  2338.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.37 ms /    27 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7380.23 ms /    11 runs   (  670.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8796.92 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.06 ms /    14 runs   (    0.43 ms per token,  2309.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.09 ms /    25 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =    8888.19 ms /    13 runs   (  683.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10200.58 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    14 runs   (    0.42 ms per token,  2362.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1475.30 ms /    29 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =    8965.47 ms /    13 runs   (  689.65 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   10481.12 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    14 runs   (    0.44 ms per token,  2292.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.07 ms /    26 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    8738.01 ms /    13 runs   (  672.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10114.22 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    14 runs   (    0.44 ms per token,  2290.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.36 ms /    26 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =    8546.85 ms /    13 runs   (  657.45 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9922.81 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2293.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.72 ms /    24 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8159.96 ms /    12 runs   (  680.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9503.11 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    13 runs   (    0.42 ms per token,  2367.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.35 ms /    24 tokens (   54.93 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    7966.11 ms /    12 runs   (  663.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9322.50 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2279.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.99 ms /    27 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    8257.01 ms /    12 runs   (  688.08 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9724.39 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.32 ms /    12 runs   (    0.44 ms per token,  2256.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.70 ms /    29 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =    7431.93 ms /    11 runs   (  675.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8950.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.02 ms /    14 runs   (    0.43 ms per token,  2327.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.24 ms /    24 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8643.59 ms /    13 runs   (  664.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9910.03 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    13 runs   (    0.45 ms per token,  2223.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.81 ms /    25 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    7928.52 ms /    12 runs   (  660.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9276.56 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.53 ms /    13 runs   (    0.43 ms per token,  2352.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.16 ms /    29 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8314.14 ms /    12 runs   (  692.84 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9818.86 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.44 ms per token,  2296.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.72 ms /    25 tokens (   57.79 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =    8098.23 ms /    12 runs   (  674.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9580.84 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    13 runs   (    0.46 ms per token,  2187.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.73 ms /    29 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =    8253.31 ms /    12 runs   (  687.78 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9774.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    14 runs   (    0.44 ms per token,  2283.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.40 ms /    27 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    8901.39 ms /    13 runs   (  684.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10372.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2316.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.54 ms /    22 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    8215.55 ms /    12 runs   (  684.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9401.56 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    13 runs   (    0.44 ms per token,  2283.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.41 ms /    25 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =    8063.48 ms /    12 runs   (  671.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9402.85 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    13 runs   (    0.42 ms per token,  2358.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.74 ms /    21 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    8117.45 ms /    12 runs   (  676.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9274.55 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    14 runs   (    0.42 ms per token,  2370.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.43 ms /    21 tokens (   54.73 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    8724.80 ms /    13 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9914.71 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    14 runs   (    0.45 ms per token,  2220.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.96 ms /    25 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =    8867.81 ms /    13 runs   (  682.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10188.98 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    14 runs   (    0.44 ms per token,  2276.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.87 ms /    27 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    8810.96 ms /    13 runs   (  677.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10257.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    12 runs   (    0.44 ms per token,  2295.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.93 ms /    28 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =    7379.01 ms /    11 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8851.53 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    14 runs   (    0.44 ms per token,  2286.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.19 ms /    25 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    8860.21 ms /    13 runs   (  681.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10185.66 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2311.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1547.52 ms /    28 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    8060.60 ms /    12 runs   (  671.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9646.38 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    12 runs   (    0.43 ms per token,  2299.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.64 ms /    21 tokens (   52.51 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =    7494.83 ms /    11 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8631.85 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.07 ms /    14 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.53 ms /    21 tokens (   62.50 ms per token,    16.00 tokens per second)\n",
      "llama_print_timings:        eval time =    8919.54 ms /    13 runs   (  686.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10272.20 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    13 runs   (    0.43 ms per token,  2304.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.04 ms /    27 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8104.18 ms /    12 runs   (  675.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9565.23 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    13 runs   (    0.42 ms per token,  2380.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.22 ms /    21 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    8118.49 ms /    12 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9269.28 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    13 runs   (    0.44 ms per token,  2261.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.89 ms /    21 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    8242.56 ms /    12 runs   (  686.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9378.15 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    14 runs   (    0.45 ms per token,  2223.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.27 ms /    25 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    8721.74 ms /    13 runs   (  670.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10043.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2324.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.57 ms /    27 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    7935.34 ms /    12 runs   (  661.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9385.25 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.10 ms /    26 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    8150.91 ms /    12 runs   (  679.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9523.27 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.50 ms /    13 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.60 ms /    28 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =    8142.92 ms /    12 runs   (  678.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9612.16 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2258.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.67 ms /    22 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7485.07 ms /    11 runs   (  680.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8696.65 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    14 runs   (    0.43 ms per token,  2322.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.10 ms /    25 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =    8855.06 ms /    13 runs   (  681.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10168.48 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.44 ms per token,  2298.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.40 ms /    21 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =    8007.63 ms /    12 runs   (  667.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9160.32 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.20 ms /    12 runs   (    0.52 ms per token,  1934.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.09 ms /    22 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    7487.61 ms /    11 runs   (  680.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8686.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    14 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.72 ms /    26 tokens (   54.99 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =    8685.60 ms /    13 runs   (  668.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10155.55 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    13 runs   (    0.43 ms per token,  2344.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.18 ms /    25 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =    8139.36 ms /    12 runs   (  678.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9490.47 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.44 ms per token,  2297.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.66 ms /    27 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =    8154.05 ms /    12 runs   (  679.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9575.39 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    13 runs   (    0.44 ms per token,  2274.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.56 ms /    25 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    8075.39 ms /    12 runs   (  672.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9450.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    13 runs   (    0.43 ms per token,  2326.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.78 ms /    25 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    8183.03 ms /    12 runs   (  681.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9520.84 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    13 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.63 ms /    24 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8167.36 ms /    12 runs   (  680.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9476.18 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2301.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.43 ms /    22 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    8286.56 ms /    12 runs   (  690.55 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9498.80 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2316.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.41 ms /    25 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    7998.15 ms /    12 runs   (  666.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9393.65 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2308.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.28 ms /    23 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    6682.66 ms /    10 runs   (  668.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7916.38 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.09 ms /    12 runs   (    0.42 ms per token,  2356.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.76 ms /    25 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =    7404.47 ms /    11 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8724.28 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    13 runs   (    0.43 ms per token,  2316.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.82 ms /    27 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    8107.91 ms /    12 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9551.26 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    14 runs   (    0.44 ms per token,  2295.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.19 ms /    28 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8720.60 ms /    13 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10191.32 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2294.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.11 ms /    27 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    8175.39 ms /    12 runs   (  681.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9614.77 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    13 runs   (    0.52 ms per token,  1938.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.20 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8284.37 ms /    12 runs   (  690.36 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9602.09 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    13 runs   (    0.42 ms per token,  2357.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.89 ms /    23 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8338.30 ms /    12 runs   (  694.86 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9596.32 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    13 runs   (    0.44 ms per token,  2275.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.23 ms /    22 tokens (   57.78 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =    8285.50 ms /    12 runs   (  690.46 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9594.14 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    13 runs   (    0.44 ms per token,  2256.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.73 ms /    29 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    8286.91 ms /    12 runs   (  690.58 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9818.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    13 runs   (    0.43 ms per token,  2309.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.39 ms /    28 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =    8161.77 ms /    12 runs   (  680.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9656.38 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    13 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.73 ms /    23 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    8088.10 ms /    12 runs   (  674.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9339.11 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    14 runs   (    0.43 ms per token,  2336.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.47 ms /    26 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =    8752.61 ms /    13 runs   (  673.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10123.10 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    13 runs   (    0.44 ms per token,  2287.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.96 ms /    28 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =    8069.19 ms /    12 runs   (  672.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9543.08 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    13 runs   (    0.45 ms per token,  2230.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.39 ms /    19 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8124.35 ms /    12 runs   (  677.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9197.47 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    14 runs   (    0.42 ms per token,  2373.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1567.84 ms /    30 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    8865.04 ms /    13 runs   (  681.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10473.32 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    13 runs   (    0.44 ms per token,  2273.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1529.80 ms /    24 tokens (   63.74 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =    7977.89 ms /    12 runs   (  664.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9545.81 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    14 runs   (    0.44 ms per token,  2292.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.88 ms /    24 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8925.57 ms /    13 runs   (  686.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10211.05 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2269.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.81 ms /    24 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    8208.50 ms /    12 runs   (  684.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9468.76 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    14 runs   (    0.43 ms per token,  2304.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.88 ms /    25 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =    8863.00 ms /    13 runs   (  681.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10182.11 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    12 runs   (    0.44 ms per token,  2294.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.11 ms /    29 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =    7433.06 ms /    11 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8945.22 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    14 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.62 ms /    24 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =    8889.88 ms /    13 runs   (  683.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10172.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2312.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.08 ms /    26 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    8182.91 ms /    12 runs   (  681.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9581.35 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    14 runs   (    0.42 ms per token,  2381.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.88 ms /    24 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =    8741.71 ms /    13 runs   (  672.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10032.01 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    14 runs   (    0.44 ms per token,  2292.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.94 ms /    23 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8755.74 ms /    13 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10032.47 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    13 runs   (    0.43 ms per token,  2344.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.61 ms /    25 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =    8081.33 ms /    12 runs   (  673.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9390.68 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2292.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.13 ms /    25 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    8142.99 ms /    12 runs   (  678.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9477.87 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    10 runs   (    0.54 ms per token,  1853.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.66 ms /    19 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    6205.23 ms /     9 runs   (  689.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7250.83 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    13 runs   (    0.44 ms per token,  2269.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.25 ms /    24 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8118.20 ms /    12 runs   (  676.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9382.17 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    13 runs   (    0.43 ms per token,  2344.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.59 ms /    29 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =    8257.60 ms /    12 runs   (  688.13 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9791.99 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    14 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.50 ms /    23 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =    9007.62 ms /    13 runs   (  692.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   10297.24 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2312.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.62 ms /    29 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8097.79 ms /    12 runs   (  674.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9614.58 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    13 runs   (    0.43 ms per token,  2347.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.33 ms /    28 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8144.36 ms /    12 runs   (  678.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9608.52 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    14 runs   (    0.43 ms per token,  2316.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.99 ms /    24 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8906.20 ms /    13 runs   (  685.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10186.52 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    13 runs   (    0.43 ms per token,  2322.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.71 ms /    27 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    8096.75 ms /    12 runs   (  674.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9535.72 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    13 runs   (    0.43 ms per token,  2341.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.49 ms /    24 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =    8032.30 ms /    12 runs   (  669.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9396.69 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    13 runs   (    0.49 ms per token,  2044.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.11 ms /    27 tokens (   58.78 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8182.98 ms /    12 runs   (  681.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9813.66 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    13 runs   (    0.45 ms per token,  2244.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1502.30 ms /    27 tokens (   55.64 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8413.04 ms /    12 runs   (  701.09 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    9953.61 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    14 runs   (    0.43 ms per token,  2335.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.38 ms /    22 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    8710.32 ms /    13 runs   (  670.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9911.44 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.53 ms /    13 runs   (    0.43 ms per token,  2349.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.03 ms /    25 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8144.48 ms /    12 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9510.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2331.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.01 ms /    24 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    8047.47 ms /    12 runs   (  670.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9358.14 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    13 runs   (    0.43 ms per token,  2311.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.95 ms /    21 tokens (   56.05 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =    8082.56 ms /    12 runs   (  673.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9297.16 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    13 runs   (    0.44 ms per token,  2259.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.06 ms /    27 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8037.93 ms /    12 runs   (  669.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9468.81 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    13 runs   (    0.43 ms per token,  2341.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.82 ms /    27 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8080.63 ms /    12 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9497.33 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    14 runs   (    0.44 ms per token,  2288.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.80 ms /    25 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =    8857.52 ms /    13 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10180.21 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    14 runs   (    0.43 ms per token,  2333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.71 ms /    29 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    8635.71 ms /    13 runs   (  664.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10167.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    13 runs   (    0.45 ms per token,  2235.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.24 ms /    27 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8132.44 ms /    12 runs   (  677.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9564.30 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    13 runs   (    0.45 ms per token,  2233.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.79 ms /    25 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    7967.35 ms /    12 runs   (  663.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9315.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    14 runs   (    0.43 ms per token,  2315.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.72 ms /    21 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8826.11 ms /    13 runs   (  678.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9990.93 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2299.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.56 ms /    25 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    8032.74 ms /    12 runs   (  669.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9343.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.50 ms /    13 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.37 ms /    24 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    7989.60 ms /    12 runs   (  665.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9282.94 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    13 runs   (    0.43 ms per token,  2300.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.30 ms /    28 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =    8095.45 ms /    12 runs   (  674.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9557.69 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    14 runs   (    0.42 ms per token,  2405.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.03 ms /    26 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    8882.72 ms /    13 runs   (  683.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10283.68 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    13 runs   (    0.44 ms per token,  2260.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.06 ms /    23 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    8202.14 ms /    12 runs   (  683.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9418.74 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    14 runs   (    0.43 ms per token,  2339.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.08 ms /    25 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8840.62 ms /    13 runs   (  680.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10195.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    13 runs   (    0.43 ms per token,  2335.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.65 ms /    22 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8128.85 ms /    12 runs   (  677.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9329.23 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2279.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.92 ms /    23 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =    8216.72 ms /    12 runs   (  684.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9459.15 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    13 runs   (    0.44 ms per token,  2290.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.79 ms /    23 tokens (   63.64 ms per token,    15.71 tokens per second)\n",
      "llama_print_timings:        eval time =    8097.39 ms /    12 runs   (  674.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9598.64 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    15 runs   (    0.43 ms per token,  2341.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.28 ms /    24 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =    9561.40 ms /    14 runs   (  682.96 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10832.49 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    13 runs   (    0.44 ms per token,  2295.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1550.56 ms /    30 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8033.85 ms /    12 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9621.57 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    13 runs   (    0.44 ms per token,  2254.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.34 ms /    21 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8136.48 ms /    12 runs   (  678.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9257.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    13 runs   (    0.43 ms per token,  2340.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.31 ms /    28 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    8270.32 ms /    12 runs   (  689.19 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9756.65 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    14 runs   (    0.43 ms per token,  2302.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.36 ms /    22 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8848.95 ms /    13 runs   (  680.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10060.38 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    16 runs   (    0.43 ms per token,  2329.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.60 ms /    28 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10289.58 ms /    15 runs   (  685.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11753.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    16 runs   (    0.44 ms per token,  2274.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.54 ms /    28 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10337.49 ms /    15 runs   (  689.17 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11860.59 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    17 runs   (    0.43 ms per token,  2334.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.57 ms /    29 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10902.27 ms /    16 runs   (  681.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12412.57 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    16 runs   (    0.45 ms per token,  2236.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1545.29 ms /    31 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10125.44 ms /    15 runs   (  675.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11716.96 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    16 runs   (    0.47 ms per token,  2111.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.82 ms /    31 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10077.12 ms /    15 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11756.57 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    16 runs   (    0.43 ms per token,  2309.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.12 ms /    28 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =    9841.25 ms /    15 runs   (  656.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11319.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    16 runs   (    0.43 ms per token,  2343.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.81 ms /    30 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =    9834.90 ms /    15 runs   (  655.66 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11417.39 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    16 runs   (    0.42 ms per token,  2374.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.03 ms /    25 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10141.14 ms /    15 runs   (  676.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11482.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    16 runs   (    0.43 ms per token,  2305.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1561.13 ms /    30 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10149.92 ms /    15 runs   (  676.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11757.44 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    16 runs   (    0.50 ms per token,  1990.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.87 ms /    30 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10061.43 ms /    15 runs   (  670.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11621.70 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    16 runs   (    0.43 ms per token,  2335.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1502.28 ms /    29 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10272.90 ms /    15 runs   (  684.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11820.79 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    16 runs   (    0.43 ms per token,  2300.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.10 ms /    25 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10367.21 ms /    15 runs   (  691.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11725.85 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    15 runs   (    0.44 ms per token,  2286.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.26 ms /    24 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =    9519.77 ms /    14 runs   (  679.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10817.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    16 runs   (    0.42 ms per token,  2370.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1567.41 ms /    31 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10106.02 ms /    15 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11719.54 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2286.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1469.13 ms /    29 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10018.19 ms /    15 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11532.98 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    16 runs   (    0.43 ms per token,  2348.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.48 ms /    27 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10419.09 ms /    15 runs   (  694.61 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   11859.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    16 runs   (    0.43 ms per token,  2346.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.94 ms /    27 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10349.62 ms /    15 runs   (  689.97 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11791.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    16 runs   (    0.43 ms per token,  2348.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.99 ms /    26 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10345.01 ms /    15 runs   (  689.67 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11740.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2320.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.62 ms /    27 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10207.47 ms /    15 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11660.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    16 runs   (    0.44 ms per token,  2292.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.72 ms /    31 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10241.83 ms /    15 runs   (  682.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11891.26 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    16 runs   (    0.44 ms per token,  2262.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.58 ms /    32 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10152.04 ms /    15 runs   (  676.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11821.72 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    15 runs   (    0.43 ms per token,  2300.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.67 ms /    29 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =    9498.59 ms /    14 runs   (  678.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11005.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    16 runs   (    0.43 ms per token,  2336.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.36 ms /    27 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10234.95 ms /    15 runs   (  682.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11716.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    20 runs   (    0.42 ms per token,  2385.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.53 ms /    31 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   12834.92 ms /    19 runs   (  675.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14534.29 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    17 runs   (    0.43 ms per token,  2343.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1551.13 ms /    31 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10908.79 ms /    16 runs   (  681.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12508.37 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    20 runs   (    0.43 ms per token,  2345.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.82 ms /    30 tokens (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12967.02 ms /    19 runs   (  682.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14510.65 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    16 runs   (    0.44 ms per token,  2289.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.08 ms /    26 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10234.33 ms /    15 runs   (  682.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11643.10 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    16 runs   (    0.42 ms per token,  2353.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.50 ms /    27 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10309.34 ms /    15 runs   (  687.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11748.48 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    16 runs   (    0.44 ms per token,  2267.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1559.43 ms /    30 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    9857.52 ms /    15 runs   (  657.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11463.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2313.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1510.84 ms /    30 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10416.46 ms /    15 runs   (  694.43 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   11974.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    16 runs   (    0.44 ms per token,  2282.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1480.31 ms /    29 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10248.04 ms /    15 runs   (  683.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11774.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2313.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1595.51 ms /    32 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10154.51 ms /    15 runs   (  676.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11796.56 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    16 runs   (    0.43 ms per token,  2316.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.20 ms /    30 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10167.30 ms /    15 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11725.67 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    16 runs   (    0.43 ms per token,  2309.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1474.75 ms /    29 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10340.40 ms /    15 runs   (  689.36 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11861.86 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2322.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.50 ms /    29 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10108.47 ms /    15 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11669.85 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    16 runs   (    0.42 ms per token,  2399.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.79 ms /    31 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10087.70 ms /    15 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11718.30 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2322.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1609.69 ms /    32 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10225.59 ms /    15 runs   (  681.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11881.70 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    16 runs   (    0.43 ms per token,  2336.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.06 ms /    25 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10075.16 ms /    15 runs   (  671.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11437.78 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    16 runs   (    0.43 ms per token,  2347.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.77 ms /    28 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10019.41 ms /    15 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11491.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    16 runs   (    0.44 ms per token,  2289.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1754.41 ms /    32 tokens (   54.83 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10116.71 ms /    15 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11918.56 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    16 runs   (    0.43 ms per token,  2331.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.52 ms /    24 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10265.25 ms /    15 runs   (  684.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11591.26 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.21 ms /    31 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10198.20 ms /    15 runs   (  679.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11832.04 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    16 runs   (    0.42 ms per token,  2353.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1470.67 ms /    29 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10310.83 ms /    15 runs   (  687.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11827.72 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    15 runs   (    0.44 ms per token,  2298.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.86 ms /    26 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    9468.19 ms /    14 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10946.10 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    16 runs   (    0.42 ms per token,  2356.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.83 ms /    28 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10114.07 ms /    15 runs   (  674.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11593.87 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    15 runs   (    0.43 ms per token,  2328.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.80 ms /    30 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9546.28 ms /    14 runs   (  681.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11139.38 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    15 runs   (    0.42 ms per token,  2356.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.67 ms /    30 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =    9332.44 ms /    14 runs   (  666.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10895.15 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    16 runs   (    0.43 ms per token,  2308.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.40 ms /    25 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   10168.75 ms /    15 runs   (  677.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11491.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    16 runs   (    0.45 ms per token,  2246.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.73 ms /    25 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10150.81 ms /    15 runs   (  676.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11494.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    16 runs   (    0.44 ms per token,  2295.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.33 ms /    28 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10151.95 ms /    15 runs   (  676.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11634.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    15 runs   (    0.42 ms per token,  2369.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.05 ms /    28 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9401.65 ms /    14 runs   (  671.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10928.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2286.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1768.19 ms /    30 tokens (   58.94 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10202.64 ms /    15 runs   (  680.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12017.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2286.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.71 ms /    29 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10231.73 ms /    15 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11769.76 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    16 runs   (    0.43 ms per token,  2338.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.63 ms /    27 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10343.73 ms /    15 runs   (  689.58 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11758.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    16 runs   (    0.44 ms per token,  2258.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.25 ms /    29 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10000.34 ms /    15 runs   (  666.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11562.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    16 runs   (    0.43 ms per token,  2309.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1599.40 ms /    31 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10213.92 ms /    15 runs   (  680.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11860.80 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    15 runs   (    0.43 ms per token,  2319.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.37 ms /    27 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =    9398.57 ms /    14 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10803.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    15 runs   (    0.44 ms per token,  2281.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.88 ms /    21 tokens (   53.38 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    9449.47 ms /    14 runs   (  674.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10615.05 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    16 runs   (    0.47 ms per token,  2142.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.32 ms /    26 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10173.77 ms /    15 runs   (  678.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11629.95 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    16 runs   (    0.43 ms per token,  2352.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1531.85 ms /    30 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10173.40 ms /    15 runs   (  678.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11751.09 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    16 runs   (    0.44 ms per token,  2255.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.85 ms /    25 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10134.69 ms /    15 runs   (  675.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11496.14 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    15 runs   (    0.43 ms per token,  2299.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     994.79 ms /    18 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    9513.59 ms /    14 runs   (  679.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10551.61 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    16 runs   (    0.43 ms per token,  2306.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1581.68 ms /    27 tokens (   58.58 ms per token,    17.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10169.84 ms /    15 runs   (  677.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11798.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    16 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1553.38 ms /    31 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10131.15 ms /    15 runs   (  675.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11730.33 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2311.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.30 ms /    28 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10075.01 ms /    15 runs   (  671.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11568.51 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    16 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1552.03 ms /    31 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10102.72 ms /    15 runs   (  673.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11701.04 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    16 runs   (    0.44 ms per token,  2275.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1543.53 ms /    30 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10188.50 ms /    15 runs   (  679.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11777.87 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    16 runs   (    0.44 ms per token,  2298.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.53 ms /    29 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10168.45 ms /    15 runs   (  677.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11700.96 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    16 runs   (    0.42 ms per token,  2354.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1848.80 ms /    32 tokens (   57.77 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10245.80 ms /    15 runs   (  683.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12140.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2319.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.32 ms /    28 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10053.80 ms /    15 runs   (  670.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11600.03 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    16 runs   (    0.43 ms per token,  2340.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.54 ms /    32 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10189.10 ms /    15 runs   (  679.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11864.20 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    16 runs   (    0.42 ms per token,  2383.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.28 ms /    28 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10074.05 ms /    15 runs   (  671.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11606.23 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    15 runs   (    0.43 ms per token,  2315.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1504.94 ms /    30 tokens (   50.16 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =    9421.39 ms /    14 runs   (  672.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10969.40 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    16 runs   (    0.44 ms per token,  2258.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.83 ms /    30 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10128.25 ms /    15 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11691.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    16 runs   (    0.41 ms per token,  2415.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1553.10 ms /    31 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10221.26 ms /    15 runs   (  681.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11821.09 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    16 runs   (    0.44 ms per token,  2282.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.37 ms /    28 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10120.81 ms /    15 runs   (  674.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11628.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    13 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.38 ms /    22 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =    7982.56 ms /    12 runs   (  665.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9186.71 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    14 runs   (    0.47 ms per token,  2150.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.76 ms /    25 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8808.47 ms /    13 runs   (  677.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10143.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    16 runs   (    0.43 ms per token,  2329.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.59 ms /    28 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10213.07 ms /    15 runs   (  680.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11730.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    16 runs   (    0.43 ms per token,  2339.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1563.92 ms /    31 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =    9986.97 ms /    15 runs   (  665.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11598.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    16 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.16 ms /    32 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10126.99 ms /    15 runs   (  675.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11809.15 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    10 runs   (    0.44 ms per token,  2260.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.89 ms /    19 tokens (   55.68 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6102.78 ms /     9 runs   (  678.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7190.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    16 runs   (    0.43 ms per token,  2339.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.38 ms /    25 tokens (   58.94 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10050.60 ms /    15 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11570.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    16 runs   (    0.43 ms per token,  2306.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.11 ms /    24 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10100.34 ms /    15 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11436.84 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    16 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1524.04 ms /    30 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10089.68 ms /    15 runs   (  672.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11661.09 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    16 runs   (    0.43 ms per token,  2348.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.12 ms /    19 tokens (   54.48 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10026.40 ms /    15 runs   (  668.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11108.15 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    16 runs   (    0.43 ms per token,  2301.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.73 ms /    24 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10162.63 ms /    15 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11433.26 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    16 runs   (    0.43 ms per token,  2305.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1534.01 ms /    30 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10116.15 ms /    15 runs   (  674.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11697.03 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    16 runs   (    0.44 ms per token,  2282.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.13 ms /    31 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10226.46 ms /    15 runs   (  681.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11878.15 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    16 runs   (    0.44 ms per token,  2292.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.75 ms /    25 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10154.84 ms /    15 runs   (  676.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11508.02 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    16 runs   (    0.44 ms per token,  2282.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.60 ms /    31 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10129.66 ms /    15 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11813.60 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2320.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1768.00 ms /    30 tokens (   58.93 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10189.66 ms /    15 runs   (  679.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12004.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    16 runs   (    0.44 ms per token,  2274.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1498.74 ms /    29 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10125.70 ms /    15 runs   (  675.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11671.53 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    16 runs   (    0.43 ms per token,  2341.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.59 ms /    29 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10117.70 ms /    15 runs   (  674.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11616.19 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    16 runs   (    0.43 ms per token,  2307.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1562.14 ms /    31 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10067.21 ms /    15 runs   (  671.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11675.38 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    15 runs   (    0.42 ms per token,  2370.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.62 ms /    27 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =    9386.34 ms /    14 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10827.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    16 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.94 ms /    26 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10071.34 ms /    15 runs   (  671.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11468.43 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    16 runs   (    0.43 ms per token,  2347.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.87 ms /    30 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10000.44 ms /    15 runs   (  666.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11563.21 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    16 runs   (    0.43 ms per token,  2304.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.49 ms /    29 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10201.08 ms /    15 runs   (  680.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11731.98 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    15 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1517.68 ms /    30 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =    9288.90 ms /    14 runs   (  663.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10850.09 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    15 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.45 ms /    27 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =    9227.47 ms /    14 runs   (  659.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   10626.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    16 runs   (    0.43 ms per token,  2325.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.29 ms /    29 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10202.73 ms /    15 runs   (  680.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11765.11 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    15 runs   (    0.43 ms per token,  2326.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.40 ms /    28 tokens (   50.26 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =    9430.23 ms /    14 runs   (  673.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10882.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    16 runs   (    0.44 ms per token,  2295.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1640.68 ms /    25 tokens (   65.63 ms per token,    15.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10183.88 ms /    15 runs   (  678.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11872.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2312.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.80 ms /    27 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10117.43 ms /    15 runs   (  674.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11537.81 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    16 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.34 ms /    28 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10213.47 ms /    15 runs   (  680.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11692.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2285.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.26 ms /    27 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10208.82 ms /    15 runs   (  680.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11636.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2321.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1577.13 ms /    31 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10336.45 ms /    15 runs   (  689.10 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11960.28 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    16 runs   (    0.47 ms per token,  2116.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.40 ms /    26 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10239.36 ms /    15 runs   (  682.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11679.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    16 runs   (    0.42 ms per token,  2374.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.96 ms /    24 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10216.07 ms /    15 runs   (  681.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11507.38 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    16 runs   (    0.43 ms per token,  2349.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.53 ms /    28 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10100.04 ms /    15 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11580.24 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    15 runs   (    0.43 ms per token,  2299.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.26 ms /    30 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =    9475.84 ms /    14 runs   (  676.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11123.62 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    16 runs   (    0.43 ms per token,  2302.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1529.05 ms /    30 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10170.23 ms /    15 runs   (  678.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11745.82 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.53 ms /    32 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10205.94 ms /    15 runs   (  680.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11891.64 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    16 runs   (    0.44 ms per token,  2289.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.61 ms /    27 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10135.92 ms /    15 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11565.86 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    16 runs   (    0.42 ms per token,  2357.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.00 ms /    28 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10192.13 ms /    15 runs   (  679.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11666.89 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2293.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.29 ms /    29 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =    9296.79 ms /    14 runs   (  664.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10788.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    16 runs   (    0.44 ms per token,  2275.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.71 ms /    28 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10214.19 ms /    15 runs   (  680.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11734.90 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2323.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.20 ms /    32 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10091.76 ms /    15 runs   (  672.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11741.11 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    16 runs   (    0.42 ms per token,  2391.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.27 ms /    27 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    9930.40 ms /    15 runs   (  662.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11369.19 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2311.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.39 ms /    28 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10142.58 ms /    15 runs   (  676.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11708.93 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    16 runs   (    0.44 ms per token,  2293.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1528.89 ms /    30 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =    9763.40 ms /    15 runs   (  650.89 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   11339.75 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    16 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.34 ms /    29 tokens (   52.29 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10216.19 ms /    15 runs   (  681.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11779.83 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    16 runs   (    0.43 ms per token,  2303.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.71 ms /    32 tokens (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10183.09 ms /    15 runs   (  678.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11822.22 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    15 runs   (    0.43 ms per token,  2319.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1539.00 ms /    30 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =    9429.28 ms /    14 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11012.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    16 runs   (    0.46 ms per token,  2179.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.38 ms /    29 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10229.23 ms /    15 runs   (  681.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11757.12 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    16 runs   (    0.46 ms per token,  2167.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.02 ms /    30 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10002.88 ms /    15 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11554.85 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    16 runs   (    0.42 ms per token,  2379.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1645.94 ms /    32 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10073.05 ms /    15 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11765.74 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2319.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1660.25 ms /    32 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    9908.14 ms /    15 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11616.25 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2313.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.91 ms /    30 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10061.83 ms /    15 runs   (  670.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11620.98 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2318.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.55 ms /    28 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10058.90 ms /    15 runs   (  670.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11567.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    16 runs   (    0.43 ms per token,  2316.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1599.76 ms /    32 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10282.49 ms /    15 runs   (  685.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11930.21 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    16 runs   (    0.42 ms per token,  2371.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.46 ms /    28 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10184.53 ms /    15 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11698.54 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    16 runs   (    0.46 ms per token,  2197.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.42 ms /    28 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10256.07 ms /    15 runs   (  683.74 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11753.69 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    16 runs   (    0.43 ms per token,  2302.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.48 ms /    27 tokens (   56.35 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10202.41 ms /    15 runs   (  680.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11771.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    20 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.03 ms /    32 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12778.71 ms /    19 runs   (  672.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14495.05 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    16 runs   (    0.44 ms per token,  2295.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1480.73 ms /    29 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10333.14 ms /    15 runs   (  688.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11860.80 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    16 runs   (    0.46 ms per token,  2180.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.88 ms /    27 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10314.03 ms /    15 runs   (  687.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11767.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.86 ms /    27 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10170.02 ms /    15 runs   (  678.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11610.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    17 runs   (    0.44 ms per token,  2264.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1654.09 ms /    31 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10980.02 ms /    16 runs   (  686.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12684.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2318.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.03 ms /    29 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10183.19 ms /    15 runs   (  678.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11695.90 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    16 runs   (    0.44 ms per token,  2292.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.28 ms /    25 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10273.02 ms /    15 runs   (  684.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11597.78 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1769.49 ms /    29 tokens (   61.02 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10273.78 ms /    15 runs   (  684.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12089.33 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    16 runs   (    0.43 ms per token,  2300.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.01 ms /    29 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10023.41 ms /    15 runs   (  668.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11523.32 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    16 runs   (    0.44 ms per token,  2298.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.77 ms /    27 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10089.83 ms /    15 runs   (  672.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11559.53 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    16 runs   (    0.45 ms per token,  2234.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1607.51 ms /    31 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10178.36 ms /    15 runs   (  678.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11833.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    13 runs   (    0.44 ms per token,  2280.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.94 ms /    25 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8146.06 ms /    12 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9476.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    16 runs   (    0.44 ms per token,  2249.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1564.85 ms /    31 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10234.25 ms /    15 runs   (  682.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11845.45 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    16 runs   (    0.44 ms per token,  2288.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.65 ms /    28 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10130.85 ms /    15 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11649.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    15 runs   (    0.43 ms per token,  2335.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.77 ms /    27 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9436.78 ms /    14 runs   (  674.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10855.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    16 runs   (    0.44 ms per token,  2294.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1509.52 ms /    30 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10374.43 ms /    15 runs   (  691.63 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11930.42 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    16 runs   (    0.43 ms per token,  2348.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.83 ms /    30 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    9823.18 ms /    15 runs   (  654.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11416.78 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    16 runs   (    0.42 ms per token,  2374.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.51 ms /    30 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =    9897.98 ms /    15 runs   (  659.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11445.97 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    16 runs   (    0.45 ms per token,  2218.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.47 ms /    26 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10107.09 ms /    15 runs   (  673.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11486.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    16 runs   (    0.43 ms per token,  2345.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1454.00 ms /    28 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10187.83 ms /    15 runs   (  679.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11689.45 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    16 runs   (    0.44 ms per token,  2287.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.97 ms /    29 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10275.72 ms /    15 runs   (  685.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11789.17 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2331.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.86 ms /    19 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8364.43 ms /    12 runs   (  697.04 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    9441.44 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    16 runs   (    0.43 ms per token,  2312.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1562.56 ms /    31 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10092.62 ms /    15 runs   (  672.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11701.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    16 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1527.93 ms /    30 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10122.01 ms /    15 runs   (  674.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11696.48 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    16 runs   (    0.44 ms per token,  2279.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.45 ms /    27 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10292.08 ms /    15 runs   (  686.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11724.90 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    16 runs   (    0.44 ms per token,  2291.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.58 ms /    28 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10178.03 ms /    15 runs   (  678.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11646.51 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    15 runs   (    0.45 ms per token,  2246.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.86 ms /    26 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    9513.25 ms /    14 runs   (  679.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10894.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    16 runs   (    0.42 ms per token,  2366.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.23 ms /    26 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10251.81 ms /    15 runs   (  683.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11652.04 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2323.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.26 ms /    29 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10035.58 ms /    15 runs   (  669.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11550.16 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    16 runs   (    0.43 ms per token,  2315.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.35 ms /    27 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10079.67 ms /    15 runs   (  671.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11511.38 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    16 runs   (    0.44 ms per token,  2289.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1777.88 ms /    30 tokens (   59.26 ms per token,    16.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10315.72 ms /    15 runs   (  687.71 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12141.19 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    17 runs   (    0.43 ms per token,  2352.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1520.14 ms /    30 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10812.97 ms /    16 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12383.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    16 runs   (    0.43 ms per token,  2303.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.04 ms /    31 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10183.42 ms /    15 runs   (  678.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11855.76 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    16 runs   (    0.44 ms per token,  2284.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.26 ms /    27 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10204.85 ms /    15 runs   (  680.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11663.34 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    16 runs   (    0.43 ms per token,  2348.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.75 ms /    27 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10129.67 ms /    15 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11577.35 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2292.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.98 ms /    26 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =    9366.49 ms /    14 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10742.74 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2321.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.03 ms /    27 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10025.39 ms /    15 runs   (  668.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11475.76 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.20 ms /    14 runs   (    0.44 ms per token,  2258.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.26 ms /    27 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8665.58 ms /    13 runs   (  666.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10076.69 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    15 runs   (    0.42 ms per token,  2370.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.26 ms /    22 tokens (   52.78 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9528.68 ms /    14 runs   (  680.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10733.17 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    16 runs   (    0.44 ms per token,  2266.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.18 ms /    28 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10054.51 ms /    15 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11608.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    16 runs   (    0.44 ms per token,  2297.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1581.32 ms /    30 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10093.88 ms /    15 runs   (  672.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11722.29 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    16 runs   (    0.42 ms per token,  2377.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.03 ms /    27 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10338.28 ms /    15 runs   (  689.22 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11771.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2234.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.31 ms /    25 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6744.18 ms /    10 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8077.66 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    16 runs   (    0.43 ms per token,  2328.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.62 ms /    31 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10158.63 ms /    15 runs   (  677.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11792.87 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    16 runs   (    0.43 ms per token,  2332.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.55 ms /    28 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9957.05 ms /    15 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11449.70 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2321.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.88 ms /    27 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =    9998.07 ms /    15 runs   (  666.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11434.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    16 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1542.85 ms /    30 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10203.14 ms /    15 runs   (  680.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11791.66 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    16 runs   (    0.42 ms per token,  2369.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1651.70 ms /    27 tokens (   61.17 ms per token,    16.35 tokens per second)\n",
      "llama_print_timings:        eval time =    9969.41 ms /    15 runs   (  664.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11668.53 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    16 runs   (    0.43 ms per token,  2335.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.67 ms /    29 tokens (   50.26 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10102.34 ms /    15 runs   (  673.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11606.92 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2318.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1541.65 ms /    30 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10253.07 ms /    15 runs   (  683.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11840.97 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    15 runs   (    0.44 ms per token,  2296.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.66 ms /    27 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =    9447.64 ms /    14 runs   (  674.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10892.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    16 runs   (    0.43 ms per token,  2340.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1590.25 ms /    30 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10318.33 ms /    15 runs   (  687.89 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11955.30 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    16 runs   (    0.44 ms per token,  2289.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1568.89 ms /    31 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10219.34 ms /    15 runs   (  681.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11835.29 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    16 runs   (    0.43 ms per token,  2307.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1564.00 ms /    31 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10049.60 ms /    15 runs   (  669.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11660.97 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    16 runs   (    0.43 ms per token,  2323.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1537.27 ms /    31 tokens (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10072.59 ms /    15 runs   (  671.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11657.00 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    16 runs   (    0.44 ms per token,  2266.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.16 ms /    25 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10060.56 ms /    15 runs   (  670.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11427.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    16 runs   (    0.43 ms per token,  2335.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1504.48 ms /    30 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10184.87 ms /    15 runs   (  678.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11735.96 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    15 runs   (    0.43 ms per token,  2340.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.00 ms /    22 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    9477.59 ms /    14 runs   (  676.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10678.33 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    16 runs   (    0.44 ms per token,  2269.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.96 ms /    29 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10310.00 ms /    15 runs   (  687.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11804.33 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    16 runs   (    0.44 ms per token,  2268.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.28 ms /    32 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10066.80 ms /    15 runs   (  671.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11733.48 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    14 runs   (    0.43 ms per token,  2302.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.61 ms /    24 tokens (   54.69 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8880.22 ms /    13 runs   (  683.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10233.72 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    16 runs   (    0.43 ms per token,  2318.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.88 ms /    30 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9953.82 ms /    15 runs   (  663.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11549.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    16 runs   (    0.44 ms per token,  2294.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1553.97 ms /    31 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10087.04 ms /    15 runs   (  672.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11687.70 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    16 runs   (    0.44 ms per token,  2255.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.64 ms /    28 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10097.75 ms /    15 runs   (  673.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11618.02 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3913.18 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    16 runs   (    0.43 ms per token,  2314.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1537.13 ms /    30 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10053.58 ms /    15 runs   (  670.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11637.65 ms /    45 tokens\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(f\"Completed {i} rows\")\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        prompt= f\"What is {df.iloc[i, 0]}\"\n",
    "        \n",
    "        prompt_template=f'''You are a math assistant. I will ask you to find number from its word representation. Please answer in the correct format. For example, if I ask 'What is thirty-three' , you should answer 'answer = 33'. Do not include any other information in your answer.\n",
    "\n",
    "        USER: {prompt}\n",
    "        \n",
    "        ASSISTANT:'''\n",
    "        \n",
    "        response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                    repeat_penalty=1.2, top_k=150,\n",
    "                    echo=False)\n",
    "        \n",
    "        with open('word2num_neg_dec.txt', 'a') as f:\n",
    "            answer=response[\"choices\"][0][\"text\"]\n",
    "            f.write(f\"{df.iloc[i, 0]} = {answer} \\n\")\n",
    "            \n",
    "            \n",
    "    except:\n",
    "    \n",
    "        with open('word2num_neg_dec.txt', 'a') as f:\n",
    "            f.write(f\"{df.iloc[i, 0]} = Error \\n\")\n",
    "            \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viveksdmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
