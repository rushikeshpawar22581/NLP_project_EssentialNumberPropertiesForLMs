{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required libraries\n",
    "# %pip install transformers\n",
    "# %pip install torchtext\n",
    "# %pip install sentencepiece\n",
    "# %pip install datasets\n",
    "# %pip install torchmetrics\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# #huggiface download\n",
    "# %pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/anaconda3/envs/viveksdmlenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the model llama 2 13b chat gguf\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is in bin format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf\n"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "#print toal path\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.36 GiB (5.51 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  8555.93 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   400.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    85.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '16'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= f\"Sort the list [3, -1, 4, 1]\"\n",
    "\n",
    "prompt_template=f'''SYSTEM: You are a math assistant.I will ask you to sort list. Please answer in the correct format and do not say anything extra. For example, if I ask 'Sort the numbers list [3, 1, -4, -2]', you should answer '[-4, -2, 1, 3]'\n",
    "\n",
    "USER: {prompt}\n",
    "        \n",
    "ASSISTANT:'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4763.44 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    13 runs   (    0.43 ms per token,  2330.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4763.12 ms /    99 tokens (   48.11 ms per token,    20.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8268.51 ms /    12 runs   (  689.04 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13067.59 ms /   111 tokens\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-1, 1, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file in data folder int_addition.json\n",
    "with open('lists.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lists_size_3_pos</th>\n",
       "      <th>lists_size_5_pos</th>\n",
       "      <th>lists_size_10_pos</th>\n",
       "      <th>lists_size_3_neg</th>\n",
       "      <th>lists_size_5_neg</th>\n",
       "      <th>lists_size_10_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[27222, 90204, 63001]</td>\n",
       "      <td>[27222, 90204, 63001, 43332, 30737]</td>\n",
       "      <td>[27222, 90204, 63001, 43332, 30737, 358, 1671,...</td>\n",
       "      <td>[-27222, 90204, -63001]</td>\n",
       "      <td>[-27222, -90204, -63001, 43332, 30737]</td>\n",
       "      <td>[-27222, -90204, -63001, 43332, -30737, 358, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>[75255, 87690, 64763]</td>\n",
       "      <td>[75255, 87690, 64763, 19548, 11807]</td>\n",
       "      <td>[75255, 87690, 64763, 19548, 11807, 67070, 983...</td>\n",
       "      <td>[-75255, 87690, 64763]</td>\n",
       "      <td>[-75255, 87690, 64763, 19548, -11807]</td>\n",
       "      <td>[75255, -87690, -64763, 19548, -11807, 67070, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[33540, 84454, 30298]</td>\n",
       "      <td>[33540, 84454, 30298, 59867, 38800]</td>\n",
       "      <td>[33540, 84454, 30298, 59867, 38800, 34619, 608...</td>\n",
       "      <td>[-33540, -84454, 30298]</td>\n",
       "      <td>[-33540, -84454, 30298, 59867, 38800]</td>\n",
       "      <td>[33540, -84454, 30298, -59867, -38800, -34619,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[5170, 38085, 47214]</td>\n",
       "      <td>[5170, 38085, 47214, 88705, 40987]</td>\n",
       "      <td>[5170, 38085, 47214, 88705, 40987, 55836, 9680...</td>\n",
       "      <td>[5170, -38085, 47214]</td>\n",
       "      <td>[-5170, -38085, 47214, -88705, -40987]</td>\n",
       "      <td>[-5170, -38085, -47214, 88705, -40987, 55836, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[6014, 1267, 18139]</td>\n",
       "      <td>[6014, 1267, 18139, 86947, 84829]</td>\n",
       "      <td>[6014, 1267, 18139, 86947, 84829, 22349, 43078...</td>\n",
       "      <td>[-6014, -1267, -18139]</td>\n",
       "      <td>[-6014, 1267, -18139, -86947, 84829]</td>\n",
       "      <td>[6014, -1267, -18139, -86947, 84829, -22349, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lists_size_3_pos                     lists_size_5_pos  \\\n",
       "495  [27222, 90204, 63001]  [27222, 90204, 63001, 43332, 30737]   \n",
       "496  [75255, 87690, 64763]  [75255, 87690, 64763, 19548, 11807]   \n",
       "497  [33540, 84454, 30298]  [33540, 84454, 30298, 59867, 38800]   \n",
       "498   [5170, 38085, 47214]   [5170, 38085, 47214, 88705, 40987]   \n",
       "499    [6014, 1267, 18139]    [6014, 1267, 18139, 86947, 84829]   \n",
       "\n",
       "                                     lists_size_10_pos  \\\n",
       "495  [27222, 90204, 63001, 43332, 30737, 358, 1671,...   \n",
       "496  [75255, 87690, 64763, 19548, 11807, 67070, 983...   \n",
       "497  [33540, 84454, 30298, 59867, 38800, 34619, 608...   \n",
       "498  [5170, 38085, 47214, 88705, 40987, 55836, 9680...   \n",
       "499  [6014, 1267, 18139, 86947, 84829, 22349, 43078...   \n",
       "\n",
       "            lists_size_3_neg                        lists_size_5_neg  \\\n",
       "495  [-27222, 90204, -63001]  [-27222, -90204, -63001, 43332, 30737]   \n",
       "496   [-75255, 87690, 64763]   [-75255, 87690, 64763, 19548, -11807]   \n",
       "497  [-33540, -84454, 30298]   [-33540, -84454, 30298, 59867, 38800]   \n",
       "498    [5170, -38085, 47214]  [-5170, -38085, 47214, -88705, -40987]   \n",
       "499   [-6014, -1267, -18139]    [-6014, 1267, -18139, -86947, 84829]   \n",
       "\n",
       "                                     lists_size_10_neg  \n",
       "495  [-27222, -90204, -63001, 43332, -30737, 358, -...  \n",
       "496  [75255, -87690, -64763, 19548, -11807, 67070, ...  \n",
       "497  [33540, -84454, 30298, -59867, -38800, -34619,...  \n",
       "498  [-5170, -38085, -47214, 88705, -40987, 55836, ...  \n",
       "499  [6014, -1267, -18139, -86947, 84829, -22349, -...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data as pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "#last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4291.91 ms /    88 tokens (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_print_timings:        eval time =    6069.98 ms /     9 runs   (  674.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10389.68 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    14 runs   (    0.39 ms per token,  2565.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     922.50 ms /    17 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    8794.27 ms /    13 runs   (  676.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9753.27 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    10 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     939.26 ms /    17 tokens (   55.25 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6149.79 ms /     9 runs   (  683.31 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7114.69 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.43 ms /    17 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11434.13 ms /    17 runs   (  672.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12410.32 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2571.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     743.65 ms /    14 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11529.10 ms /    17 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12318.79 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    10 runs   (    0.39 ms per token,  2540.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     968.17 ms /    17 tokens (   56.95 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =    6229.52 ms /     9 runs   (  692.17 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7223.61 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    18 runs   (    0.40 ms per token,  2521.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.50 ms /    17 tokens (   54.79 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11503.60 ms /    17 runs   (  676.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12481.82 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    10 runs   (    0.39 ms per token,  2541.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.69 ms /    17 tokens (   54.75 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6099.15 ms /     9 runs   (  677.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7055.87 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     959.70 ms /    17 tokens (   56.45 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11484.43 ms /    17 runs   (  675.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12491.09 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    18 runs   (    0.40 ms per token,  2505.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.30 ms /    17 tokens (   56.49 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11533.68 ms /    17 runs   (  678.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12541.98 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.32 ms /    14 tokens (   55.02 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11512.92 ms /    17 runs   (  677.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12331.41 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    10 runs   (    0.38 ms per token,  2615.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.78 ms /    17 tokens (   55.81 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =    5966.95 ms /     9 runs   (  662.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6941.87 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    14 runs   (    0.38 ms per token,  2598.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     951.55 ms /    17 tokens (   55.97 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8856.04 ms /    13 runs   (  681.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9844.78 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    10 runs   (    0.38 ms per token,  2637.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     939.97 ms /    17 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =    6001.06 ms /     9 runs   (  666.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6967.55 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /    10 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     749.21 ms /    14 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =    6130.71 ms /     9 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6906.05 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    10 runs   (    0.41 ms per token,  2428.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     952.85 ms /    17 tokens (   56.05 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6118.31 ms /     9 runs   (  679.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7098.00 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.72 ms /    10 runs   (    0.37 ms per token,  2685.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.71 ms /    17 tokens (   57.34 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =    6116.14 ms /     9 runs   (  679.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7116.69 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    10 runs   (    0.38 ms per token,  2664.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     914.92 ms /    17 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =    6058.18 ms /     9 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6998.99 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2574.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     917.16 ms /    17 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   11447.26 ms /    17 runs   (  673.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12412.04 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    10 runs   (    0.42 ms per token,  2406.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.50 ms /    17 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6167.31 ms /     9 runs   (  685.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7125.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    10 runs   (    0.39 ms per token,  2575.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.24 ms /    17 tokens (   54.66 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6241.18 ms /     9 runs   (  693.46 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7196.41 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    10 runs   (    0.39 ms per token,  2552.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     926.55 ms /    17 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =    5913.97 ms /     9 runs   (  657.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6867.76 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    10 runs   (    0.38 ms per token,  2618.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     946.10 ms /    17 tokens (   55.65 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6095.67 ms /     9 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7068.32 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.52 ms /    17 tokens (   57.44 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:        eval time =    6168.53 ms /     9 runs   (  685.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7172.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.38 ms per token,  2598.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     947.92 ms /    17 tokens (   55.76 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6138.28 ms /     9 runs   (  682.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7112.61 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    14 runs   (    0.40 ms per token,  2526.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     932.67 ms /    17 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =    8894.47 ms /    13 runs   (  684.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9864.75 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    10 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.04 ms /    17 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    6260.26 ms /     9 runs   (  695.58 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7217.38 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.56 ms /    17 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6187.41 ms /     9 runs   (  687.49 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7145.08 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    14 runs   (    0.39 ms per token,  2542.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.94 ms /    17 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8917.06 ms /    13 runs   (  685.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9884.32 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    10 runs   (    0.39 ms per token,  2588.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     933.50 ms /    17 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =    5957.75 ms /     9 runs   (  661.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6917.75 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    10 runs   (    0.39 ms per token,  2556.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     947.69 ms /    17 tokens (   55.75 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6052.75 ms /     9 runs   (  672.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7026.94 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /    10 runs   (    0.40 ms per token,  2517.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     933.89 ms /    17 tokens (   54.93 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6028.55 ms /     9 runs   (  669.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6989.14 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    10 runs   (    0.39 ms per token,  2556.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     933.57 ms /    17 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6068.26 ms /     9 runs   (  674.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7028.11 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /    10 runs   (    0.40 ms per token,  2516.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     940.20 ms /    17 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =    6033.81 ms /     9 runs   (  670.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7000.75 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    14 runs   (    0.38 ms per token,  2601.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.87 ms /    17 tokens (   54.76 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    8749.90 ms /    13 runs   (  673.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9717.64 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    18 runs   (    0.40 ms per token,  2486.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     918.95 ms /    17 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11472.59 ms /    17 runs   (  674.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12440.15 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2623.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     958.61 ms /    17 tokens (   56.39 ms per token,    17.73 tokens per second)\n",
      "llama_print_timings:        eval time =    6042.33 ms /     9 runs   (  671.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7028.09 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /    10 runs   (    0.40 ms per token,  2529.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     911.03 ms /    17 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6046.59 ms /     9 runs   (  671.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6983.89 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    10 runs   (    0.39 ms per token,  2585.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     947.34 ms /    17 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6125.85 ms /     9 runs   (  680.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7100.22 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    10 runs   (    0.38 ms per token,  2650.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     942.28 ms /    17 tokens (   55.43 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6035.69 ms /     9 runs   (  670.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7005.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    10 runs   (    0.39 ms per token,  2591.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     924.96 ms /    17 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =    6104.15 ms /     9 runs   (  678.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7056.24 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    10 runs   (    0.48 ms per token,  2102.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     944.70 ms /    17 tokens (   55.57 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =    6166.78 ms /     9 runs   (  685.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7143.73 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    10 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.19 ms /    14 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    6144.24 ms /     9 runs   (  682.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6933.48 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     944.48 ms /    17 tokens (   55.56 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5997.80 ms /     9 runs   (  666.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6969.34 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    10 runs   (    0.39 ms per token,  2593.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     947.66 ms /    17 tokens (   55.74 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6194.39 ms /     9 runs   (  688.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7169.20 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2608.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     949.57 ms /    17 tokens (   55.86 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:        eval time =    5972.98 ms /     9 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6949.27 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    18 runs   (    0.40 ms per token,  2517.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     972.55 ms /    17 tokens (   57.21 ms per token,    17.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11336.56 ms /    17 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12357.78 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    21 runs   (    0.39 ms per token,  2573.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.54 ms /    17 tokens (   58.21 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13857.28 ms /    20 runs   (  692.86 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   14903.89 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    14 runs   (    0.40 ms per token,  2519.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.12 ms /    17 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    8960.95 ms /    13 runs   (  689.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9930.54 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.43 ms /    14 runs   (    0.39 ms per token,  2580.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     963.73 ms /    17 tokens (   56.69 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =    8886.55 ms /    13 runs   (  683.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9888.03 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    10 runs   (    0.39 ms per token,  2545.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     941.57 ms /    17 tokens (   55.39 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =    6131.66 ms /     9 runs   (  681.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7099.93 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    10 runs   (    0.39 ms per token,  2558.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     957.70 ms /    17 tokens (   56.34 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6150.33 ms /     9 runs   (  683.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7135.60 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    18 runs   (    0.40 ms per token,  2492.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     980.57 ms /    17 tokens (   57.68 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11272.24 ms /    17 runs   (  663.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12302.22 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2553.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     964.41 ms /    17 tokens (   56.73 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11289.65 ms /    17 runs   (  664.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12303.11 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    14 runs   (    0.39 ms per token,  2557.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     944.28 ms /    17 tokens (   55.55 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =    8835.32 ms /    13 runs   (  679.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9818.02 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2626.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.00 ms /    14 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    6103.01 ms /     9 runs   (  678.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6878.03 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    10 runs   (    0.38 ms per token,  2658.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     919.50 ms /    17 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6131.92 ms /     9 runs   (  681.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7078.40 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    10 runs   (    0.39 ms per token,  2558.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.45 ms /    17 tokens (   55.79 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6086.43 ms /     9 runs   (  676.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7062.39 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /    10 runs   (    0.40 ms per token,  2508.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     938.65 ms /    17 tokens (   55.21 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    6131.86 ms /     9 runs   (  681.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7097.23 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    10 runs   (    0.39 ms per token,  2558.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     942.43 ms /    17 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6202.35 ms /     9 runs   (  689.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7171.80 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2601.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     935.62 ms /    17 tokens (   55.04 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6161.34 ms /     9 runs   (  684.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7124.17 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /    10 runs   (    0.40 ms per token,  2523.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     947.42 ms /    17 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6411.34 ms /     9 runs   (  712.37 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    7386.36 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    10 runs   (    0.37 ms per token,  2669.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     969.41 ms /    17 tokens (   57.02 ms per token,    17.54 tokens per second)\n",
      "llama_print_timings:        eval time =    6452.74 ms /     9 runs   (  716.97 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    7449.34 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /    10 runs   (    0.41 ms per token,  2463.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.30 ms /    17 tokens (   54.72 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6168.23 ms /     9 runs   (  685.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7125.64 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.38 ms per token,  2599.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.66 ms /    17 tokens (   56.57 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6113.79 ms /     9 runs   (  679.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7101.97 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /    10 runs   (    0.37 ms per token,  2677.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.08 ms /    17 tokens (   55.77 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6032.56 ms /     9 runs   (  670.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7007.94 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    10 runs   (    0.40 ms per token,  2499.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     952.17 ms /    17 tokens (   56.01 ms per token,    17.85 tokens per second)\n",
      "llama_print_timings:        eval time =    6172.12 ms /     9 runs   (  685.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7151.48 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    10 runs   (    0.39 ms per token,  2568.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     946.74 ms /    17 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6113.94 ms /     9 runs   (  679.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7088.10 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    10 runs   (    0.39 ms per token,  2541.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     957.50 ms /    17 tokens (   56.32 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6132.81 ms /     9 runs   (  681.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7117.21 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    10 runs   (    0.39 ms per token,  2543.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     936.06 ms /    17 tokens (   55.06 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =    5814.29 ms /     9 runs   (  646.03 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    6777.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2591.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     940.39 ms /    17 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11071.96 ms /    17 runs   (  651.29 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   12061.14 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    10 runs   (    0.39 ms per token,  2576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     953.21 ms /    17 tokens (   56.07 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =    5955.21 ms /     9 runs   (  661.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6935.79 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    10 runs   (    0.39 ms per token,  2543.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.62 ms /    14 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6050.71 ms /     9 runs   (  672.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6817.20 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2626.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     943.25 ms /    17 tokens (   55.49 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5924.05 ms /     9 runs   (  658.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    6893.89 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    10 runs   (    0.39 ms per token,  2587.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     925.63 ms /    17 tokens (   54.45 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5978.83 ms /     9 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    6931.84 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     952.66 ms /    17 tokens (   56.04 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5999.44 ms /     9 runs   (  666.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6979.09 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    14 runs   (    0.38 ms per token,  2604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.73 ms /    17 tokens (   55.81 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8766.96 ms /    13 runs   (  674.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9753.91 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.12 ms /    13 runs   (    0.39 ms per token,  2540.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     938.94 ms /    17 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =    7949.82 ms /    12 runs   (  662.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8924.86 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /    10 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.79 ms /    17 tokens (   61.11 ms per token,    16.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5864.26 ms /     9 runs   (  651.58 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    6930.31 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2546.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     951.03 ms /    17 tokens (   55.94 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11388.44 ms /    17 runs   (  669.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12389.72 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    10 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     940.26 ms /    17 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =    6029.14 ms /     9 runs   (  669.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6997.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    10 runs   (    0.39 ms per token,  2553.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.59 ms /    17 tokens (   57.39 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =    6001.06 ms /     9 runs   (  666.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7004.34 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /    10 runs   (    0.39 ms per token,  2534.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     946.61 ms /    17 tokens (   55.68 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6046.14 ms /     9 runs   (  671.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7020.02 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2610.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     934.84 ms /    17 tokens (   54.99 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =    6094.92 ms /     9 runs   (  677.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7056.94 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    10 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     943.92 ms /    17 tokens (   55.52 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =    6034.66 ms /     9 runs   (  670.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7005.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    10 runs   (    0.39 ms per token,  2572.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.23 ms /    17 tokens (   55.78 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6066.58 ms /     9 runs   (  674.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7041.49 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2612.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     967.58 ms /    17 tokens (   56.92 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =    6075.46 ms /     9 runs   (  675.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7069.85 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    13 runs   (    0.38 ms per token,  2615.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.83 ms /    17 tokens (   60.17 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8111.91 ms /    12 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9170.05 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    10 runs   (    0.38 ms per token,  2644.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     953.31 ms /    17 tokens (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =    6069.95 ms /     9 runs   (  674.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7050.01 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    14 runs   (    0.39 ms per token,  2553.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     965.31 ms /    17 tokens (   56.78 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8874.28 ms /    13 runs   (  682.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9877.71 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     917.08 ms /    17 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    6238.57 ms /     9 runs   (  693.17 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7182.53 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2568.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     927.54 ms /    17 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11498.76 ms /    17 runs   (  676.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12475.73 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    10 runs   (    0.39 ms per token,  2579.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     937.50 ms /    17 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6115.98 ms /     9 runs   (  679.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7080.48 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    21 runs   (    0.39 ms per token,  2575.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.50 ms /    17 tokens (   56.56 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   13689.58 ms /    20 runs   (  684.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14709.54 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    14 runs   (    0.39 ms per token,  2558.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.23 ms /    17 tokens (   56.48 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8941.42 ms /    13 runs   (  687.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9940.16 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2610.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     939.38 ms /    17 tokens (   55.26 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6039.23 ms /     9 runs   (  671.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7005.62 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    10 runs   (    0.39 ms per token,  2540.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     935.18 ms /    17 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =    6046.69 ms /     9 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7009.70 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2612.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     921.48 ms /    17 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6077.81 ms /     9 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7026.61 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    18 runs   (    0.39 ms per token,  2589.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     945.55 ms /    17 tokens (   55.62 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11529.25 ms /    17 runs   (  678.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12523.06 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    10 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     935.45 ms /    17 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6115.71 ms /     9 runs   (  679.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7078.47 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    13 runs   (    0.39 ms per token,  2580.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.58 ms /    20 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8200.07 ms /    12 runs   (  683.34 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9324.36 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2622.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.33 ms /    20 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10891.91 ms /    16 runs   (  680.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12000.47 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2520.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.43 ms /    20 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10856.24 ms /    16 runs   (  678.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11964.11 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2630.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.70 ms /    20 tokens (   53.63 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10612.76 ms /    16 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11731.94 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    13 runs   (    0.37 ms per token,  2688.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.59 ms /    19 tokens (   54.45 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    8066.40 ms /    12 runs   (  672.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9136.07 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    13 runs   (    0.38 ms per token,  2648.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.03 ms /    20 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8038.95 ms /    12 runs   (  669.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9139.54 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    13 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.92 ms /    20 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =    7907.44 ms /    12 runs   (  658.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9023.61 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    13 runs   (    0.38 ms per token,  2622.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.60 ms /    20 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8110.81 ms /    12 runs   (  675.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9209.07 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    17 runs   (    0.39 ms per token,  2560.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.96 ms /    20 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10781.71 ms /    16 runs   (  673.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11899.28 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2606.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.25 ms /    19 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10693.05 ms /    16 runs   (  668.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11743.34 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.08 ms /    13 runs   (    0.39 ms per token,  2559.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.58 ms /    20 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8137.56 ms /    12 runs   (  678.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9241.73 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    13 runs   (    0.39 ms per token,  2581.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.33 ms /    20 tokens (   55.12 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =    8166.47 ms /    12 runs   (  680.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9304.50 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    13 runs   (    0.38 ms per token,  2653.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.88 ms /    20 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8096.60 ms /    12 runs   (  674.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9209.33 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    16 runs   (    0.38 ms per token,  2614.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.89 ms /    19 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10007.76 ms /    15 runs   (  667.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11089.64 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    13 runs   (    0.40 ms per token,  2488.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.24 ms /    20 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =    8047.48 ms /    12 runs   (  670.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9158.39 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.02 ms /    13 runs   (    0.39 ms per token,  2591.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.92 ms /    20 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =    8166.13 ms /    12 runs   (  680.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9251.12 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    13 runs   (    0.41 ms per token,  2461.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.81 ms /    20 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    8136.99 ms /    12 runs   (  678.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9230.61 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    13 runs   (    0.37 ms per token,  2682.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.76 ms /    20 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8198.13 ms /    12 runs   (  683.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9294.31 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    13 runs   (    0.41 ms per token,  2450.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.54 ms /    20 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8219.43 ms /    12 runs   (  684.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9309.90 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    12 runs   (    0.40 ms per token,  2508.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.30 ms /    19 tokens (   54.75 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =    7452.82 ms /    11 runs   (  677.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8526.50 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.02 ms /    13 runs   (    0.39 ms per token,  2589.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.04 ms /    20 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8151.28 ms /    12 runs   (  679.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9247.78 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    17 runs   (    0.40 ms per token,  2478.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.14 ms /    20 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10836.22 ms /    16 runs   (  677.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11946.43 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    13 runs   (    0.40 ms per token,  2492.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.89 ms /    20 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    8229.98 ms /    12 runs   (  685.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9357.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    12 runs   (    0.39 ms per token,  2535.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.70 ms /    19 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =    7588.10 ms /    11 runs   (  689.83 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8651.12 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    13 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.88 ms /    20 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    8454.28 ms /    12 runs   (  704.52 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    9544.00 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    13 runs   (    0.41 ms per token,  2433.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.11 ms /    19 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =    8170.57 ms /    12 runs   (  680.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9211.85 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    13 runs   (    0.37 ms per token,  2702.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.20 ms /    20 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8238.82 ms /    12 runs   (  686.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9341.87 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    13 runs   (    0.39 ms per token,  2570.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.88 ms /    20 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8278.90 ms /    12 runs   (  689.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9380.07 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    13 runs   (    0.38 ms per token,  2657.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.21 ms /    20 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =    8196.46 ms /    12 runs   (  683.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9280.89 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    12 runs   (    0.40 ms per token,  2491.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     998.95 ms /    18 tokens (   55.50 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7335.98 ms /    11 runs   (  666.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8367.92 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2603.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.26 ms /    20 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10830.39 ms /    16 runs   (  676.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11960.50 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    13 runs   (    0.40 ms per token,  2472.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.16 ms /    19 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    8150.18 ms /    12 runs   (  679.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9200.62 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    13 runs   (    0.41 ms per token,  2420.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.15 ms /    20 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8274.87 ms /    12 runs   (  689.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9381.34 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    13 runs   (    0.40 ms per token,  2519.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.10 ms /    20 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8145.81 ms /    12 runs   (  678.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9252.64 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    13 runs   (    0.38 ms per token,  2612.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.01 ms /    20 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =    8122.72 ms /    12 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9222.51 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    12 runs   (    0.39 ms per token,  2571.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.03 ms /    19 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    7489.22 ms /    11 runs   (  680.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8529.13 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    16 runs   (    0.38 ms per token,  2598.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.06 ms /    19 tokens (   55.37 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10369.90 ms /    15 runs   (  691.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11464.74 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    13 runs   (    0.39 ms per token,  2578.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.50 ms /    20 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    8093.50 ms /    12 runs   (  674.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9191.05 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.07 ms /    18 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    9600.47 ms /    14 runs   (  685.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10616.86 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    12 runs   (    0.40 ms per token,  2482.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.66 ms /    19 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    7293.05 ms /    11 runs   (  663.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8331.36 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2604.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.13 ms /    20 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10824.92 ms /    16 runs   (  676.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11945.04 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.18 ms /    13 runs   (    0.40 ms per token,  2507.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.91 ms /    20 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =    8103.13 ms /    12 runs   (  675.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9206.64 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    13 runs   (    0.38 ms per token,  2619.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.67 ms /    20 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    8101.73 ms /    12 runs   (  675.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9216.09 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    13 runs   (    0.39 ms per token,  2544.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.57 ms /    19 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8117.65 ms /    12 runs   (  676.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9166.15 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.37 ms per token,  2669.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.10 ms /    19 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =    7439.77 ms /    11 runs   (  676.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8510.09 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    16 runs   (    0.39 ms per token,  2559.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.04 ms /    19 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10226.28 ms /    15 runs   (  681.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11289.34 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2621.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.54 ms /    20 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10939.16 ms /    16 runs   (  683.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12078.43 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.00 ms /    13 runs   (    0.38 ms per token,  2600.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.64 ms /    20 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8111.54 ms /    12 runs   (  675.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9216.47 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    13 runs   (    0.41 ms per token,  2432.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.10 ms /    20 tokens (   53.01 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8013.62 ms /    12 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9109.58 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    13 runs   (    0.38 ms per token,  2636.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.62 ms /    19 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =    7973.34 ms /    12 runs   (  664.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9055.39 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    11 runs   (    0.49 ms per token,  2042.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.99 ms /    19 tokens (   53.32 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6637.22 ms /    10 runs   (  663.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    7683.11 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    13 runs   (    0.40 ms per token,  2482.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.50 ms /    20 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8114.77 ms /    12 runs   (  676.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9219.90 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    13 runs   (    0.38 ms per token,  2634.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.69 ms /    20 tokens (   53.98 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =    7895.56 ms /    12 runs   (  657.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9011.29 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2647.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.72 ms /    19 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10727.39 ms /    16 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11810.03 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    12 runs   (    0.39 ms per token,  2563.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.07 ms /    19 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    7565.86 ms /    11 runs   (  687.81 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8622.02 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    13 runs   (    0.38 ms per token,  2634.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.96 ms /    20 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8170.49 ms /    12 runs   (  680.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9281.07 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2628.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.56 ms /    20 tokens (   54.78 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10825.07 ms /    16 runs   (  676.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11967.46 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    12 runs   (    0.39 ms per token,  2572.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.04 ms /    19 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7414.81 ms /    11 runs   (  674.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8462.74 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    13 runs   (    0.37 ms per token,  2686.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.03 ms /    20 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =    8154.89 ms /    12 runs   (  679.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9274.78 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    17 runs   (    0.39 ms per token,  2575.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.41 ms /    20 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10828.89 ms /    16 runs   (  676.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11974.74 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    12 runs   (    0.39 ms per token,  2562.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.11 ms /    19 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    7460.16 ms /    11 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8551.13 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    13 runs   (    0.38 ms per token,  2618.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.73 ms /    20 tokens (   54.69 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =    7903.95 ms /    12 runs   (  658.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9033.38 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    13 runs   (    0.38 ms per token,  2603.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.81 ms /    20 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =    8184.78 ms /    12 runs   (  682.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9278.42 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    13 runs   (    0.39 ms per token,  2543.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.87 ms /    20 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    8195.34 ms /    12 runs   (  682.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9303.85 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    15 runs   (    0.40 ms per token,  2513.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.88 ms /    19 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    9625.35 ms /    14 runs   (  687.52 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   10691.79 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2638.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.50 ms /    20 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10940.70 ms /    16 runs   (  683.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12034.27 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    13 runs   (    0.38 ms per token,  2637.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.40 ms /    20 tokens (   55.12 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =    7921.00 ms /    12 runs   (  660.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9059.77 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    13 runs   (    0.38 ms per token,  2606.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.66 ms /    20 tokens (   55.68 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =    8158.53 ms /    12 runs   (  679.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9308.87 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    13 runs   (    0.38 ms per token,  2603.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.09 ms /    20 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    8096.37 ms /    12 runs   (  674.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9185.26 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    13 runs   (    0.38 ms per token,  2635.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.24 ms /    20 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =    8245.08 ms /    12 runs   (  687.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9344.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    11 runs   (    0.40 ms per token,  2524.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     969.25 ms /    18 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =    6818.64 ms /    10 runs   (  681.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7818.16 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    13 runs   (    0.38 ms per token,  2616.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.24 ms /    19 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =    8118.64 ms /    12 runs   (  676.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9187.15 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    13 runs   (    0.38 ms per token,  2660.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.39 ms /    19 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    7965.55 ms /    12 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9038.85 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.99 ms /    20 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10641.26 ms /    16 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11750.61 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    13 runs   (    0.41 ms per token,  2416.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.15 ms /    20 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =    7991.35 ms /    12 runs   (  665.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9113.66 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    16 runs   (    0.38 ms per token,  2610.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.06 ms /    19 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    9974.84 ms /    15 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11029.16 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2546.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.12 ms /    16 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10770.34 ms /    16 runs   (  673.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11660.96 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    13 runs   (    0.41 ms per token,  2464.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.99 ms /    20 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    8103.49 ms /    12 runs   (  675.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9177.38 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    17 runs   (    0.40 ms per token,  2479.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.01 ms /    19 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   10664.00 ms /    16 runs   (  666.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11739.80 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2625.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.40 ms /    20 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10806.26 ms /    16 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11939.87 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    16 runs   (    0.39 ms per token,  2575.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.41 ms /    19 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10009.80 ms /    15 runs   (  667.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11084.44 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    12 runs   (    0.37 ms per token,  2697.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.84 ms /    19 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7259.79 ms /    11 runs   (  659.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    8302.37 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    12 runs   (    0.41 ms per token,  2443.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.56 ms /    19 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =    7456.13 ms /    11 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8533.93 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    13 runs   (    0.40 ms per token,  2483.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.12 ms /    20 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =    8182.84 ms /    12 runs   (  681.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9310.14 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    17 runs   (    0.40 ms per token,  2516.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.12 ms /    20 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10824.08 ms /    16 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11934.12 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /    13 runs   (    0.39 ms per token,  2593.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.22 ms /    20 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    8226.89 ms /    12 runs   (  685.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9352.88 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    13 runs   (    0.37 ms per token,  2687.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.49 ms /    20 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8122.36 ms /    12 runs   (  676.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9229.53 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    12 runs   (    0.40 ms per token,  2514.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.45 ms /    19 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =    7505.40 ms /    11 runs   (  682.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8559.32 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    13 runs   (    0.38 ms per token,  2633.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.11 ms /    19 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =    8161.13 ms /    12 runs   (  680.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9221.27 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    13 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.40 ms /    19 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =    8085.37 ms /    12 runs   (  673.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9159.40 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /    13 runs   (    0.39 ms per token,  2594.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.62 ms /    20 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8090.49 ms /    12 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9214.79 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    13 runs   (    0.40 ms per token,  2488.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.09 ms /    20 tokens (   55.70 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =    8150.65 ms /    12 runs   (  679.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9301.07 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    13 runs   (    0.38 ms per token,  2618.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.94 ms /    20 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =    8294.47 ms /    12 runs   (  691.21 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9408.70 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    13 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.83 ms /    20 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    7951.90 ms /    12 runs   (  662.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9069.96 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    18 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.90 ms /    19 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11747.27 ms /    17 runs   (  691.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12793.72 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    11 runs   (    0.39 ms per token,  2576.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.02 ms /    18 tokens (   54.33 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =    6802.62 ms /    10 runs   (  680.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7810.15 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    16 runs   (    0.40 ms per token,  2518.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.60 ms /    19 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10052.33 ms /    15 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11113.68 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    12 runs   (    0.39 ms per token,  2552.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.88 ms /    19 tokens (   54.57 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =    7436.53 ms /    11 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8506.77 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2605.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     981.35 ms /    18 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =    7361.52 ms /    11 runs   (  669.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8376.39 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2614.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.98 ms /    20 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10756.12 ms /    16 runs   (  672.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11883.12 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2549.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.36 ms /    22 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12197.23 ms /    18 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13380.79 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    20 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.05 ms /    23 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12927.25 ms /    19 runs   (  680.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14174.19 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2575.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.57 ms /    22 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12905.49 ms /    19 runs   (  679.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14142.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.36 ms /    22 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9616.73 ms /    14 runs   (  686.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10813.63 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2644.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.05 ms /    22 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    9452.17 ms /    14 runs   (  675.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10653.59 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2625.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.04 ms /    23 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12871.26 ms /    19 runs   (  677.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14127.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    20 runs   (    0.39 ms per token,  2539.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.60 ms /    23 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12817.06 ms /    19 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14077.17 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.96 ms /    23 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   13089.27 ms /    19 runs   (  688.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14341.90 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2571.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.65 ms /    22 tokens (   53.58 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12228.44 ms /    18 runs   (  679.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13459.27 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    20 runs   (    0.40 ms per token,  2530.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.20 ms /    23 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   13097.21 ms /    19 runs   (  689.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14330.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2623.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.92 ms /    23 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12786.97 ms /    19 runs   (  673.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14041.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    20 runs   (    0.40 ms per token,  2510.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.66 ms /    23 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12825.17 ms /    19 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14120.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2627.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.95 ms /    23 tokens (   52.56 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12698.38 ms /    19 runs   (  668.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13961.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    20 runs   (    0.38 ms per token,  2637.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.69 ms /    23 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12729.24 ms /    19 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13983.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    20 runs   (    0.38 ms per token,  2642.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.94 ms /    23 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   12775.17 ms /    19 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14006.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.08 ms /    21 tokens (   56.48 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12824.44 ms /    19 runs   (  674.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14065.33 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    20 runs   (    0.39 ms per token,  2590.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.24 ms /    22 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12857.09 ms /    19 runs   (  676.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14071.22 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    20 runs   (    0.43 ms per token,  2305.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.15 ms /    23 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12964.26 ms /    19 runs   (  682.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14234.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    20 runs   (    0.38 ms per token,  2663.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.05 ms /    23 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12892.67 ms /    19 runs   (  678.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14188.35 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    19 runs   (    0.40 ms per token,  2529.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.38 ms /    22 tokens (   53.84 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12154.72 ms /    18 runs   (  675.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13392.02 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2615.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.62 ms /    23 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12633.01 ms /    19 runs   (  664.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13931.48 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2615.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.95 ms /    23 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12830.82 ms /    19 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14110.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    16 runs   (    0.39 ms per token,  2560.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.23 ms /    22 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =    9986.65 ms /    15 runs   (  665.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11201.61 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2579.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.24 ms /    22 tokens (   58.92 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12338.56 ms /    18 runs   (  685.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13686.57 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    18 runs   (    0.40 ms per token,  2517.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.06 ms /    21 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11370.33 ms /    17 runs   (  668.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12513.73 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2600.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.24 ms /    23 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13063.23 ms /    19 runs   (  687.54 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14342.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    20 runs   (    0.44 ms per token,  2275.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.44 ms /    23 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12961.23 ms /    19 runs   (  682.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14205.96 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2594.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.56 ms /    23 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   13020.32 ms /    19 runs   (  685.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14316.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    19 runs   (    0.39 ms per token,  2544.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.99 ms /    22 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   12079.82 ms /    18 runs   (  671.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13298.36 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    20 runs   (    0.40 ms per token,  2509.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.47 ms /    23 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12903.17 ms /    19 runs   (  679.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14180.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2635.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.99 ms /    23 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12813.15 ms /    19 runs   (  674.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14069.76 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    19 runs   (    0.39 ms per token,  2592.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.21 ms /    22 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12121.68 ms /    18 runs   (  673.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13345.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2629.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.61 ms /    23 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12967.04 ms /    19 runs   (  682.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14237.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2604.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.45 ms /    22 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12213.21 ms /    18 runs   (  678.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13447.81 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2571.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.87 ms /    23 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12852.53 ms /    19 runs   (  676.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14108.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    20 runs   (    0.38 ms per token,  2660.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.69 ms /    22 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13163.01 ms /    19 runs   (  692.79 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   14392.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    16 runs   (    0.38 ms per token,  2619.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.67 ms /    23 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10088.05 ms /    15 runs   (  672.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11324.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    16 runs   (    0.38 ms per token,  2632.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.42 ms /    23 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10278.54 ms /    15 runs   (  685.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11520.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    20 runs   (    0.39 ms per token,  2587.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.83 ms /    23 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12835.83 ms /    19 runs   (  675.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14090.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2549.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.56 ms /    23 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12595.12 ms /    19 runs   (  662.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13833.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    15 runs   (    0.38 ms per token,  2599.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.78 ms /    22 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    9303.14 ms /    14 runs   (  664.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10485.06 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1233.42 ms /    23 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12713.93 ms /    19 runs   (  669.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14003.16 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    20 runs   (    0.41 ms per token,  2457.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.41 ms /    23 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12832.57 ms /    19 runs   (  675.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14167.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2562.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.55 ms /    23 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12888.32 ms /    19 runs   (  678.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14153.38 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2560.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.57 ms /    22 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12025.75 ms /    18 runs   (  668.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13245.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    18 runs   (    0.39 ms per token,  2553.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.10 ms /    20 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11569.85 ms /    17 runs   (  680.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12667.80 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    20 runs   (    0.39 ms per token,  2591.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.20 ms /    23 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12880.31 ms /    19 runs   (  677.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14153.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    19 runs   (    0.38 ms per token,  2600.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.06 ms /    22 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12195.11 ms /    18 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13399.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.33 ms /    23 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13090.80 ms /    19 runs   (  688.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14400.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    20 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.24 ms /    23 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12927.55 ms /    19 runs   (  680.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14185.43 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    14 runs   (    0.37 ms per token,  2677.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.25 ms /    21 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =    8906.18 ms /    13 runs   (  685.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10040.29 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    20 runs   (    0.40 ms per token,  2480.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.94 ms /    23 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12983.90 ms /    19 runs   (  683.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14234.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2633.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.05 ms /    23 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12858.95 ms /    19 runs   (  676.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14135.99 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    16 runs   (    0.37 ms per token,  2685.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.06 ms /    23 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10283.19 ms /    15 runs   (  685.55 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11533.36 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2598.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.01 ms /    23 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12839.64 ms /    19 runs   (  675.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14106.34 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2704.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.67 ms /    22 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =    9433.32 ms /    14 runs   (  673.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10621.06 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.12 ms /    22 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12727.17 ms /    19 runs   (  669.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13940.78 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2629.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.31 ms /    23 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12796.81 ms /    19 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14070.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    19 runs   (    0.39 ms per token,  2572.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.65 ms /    22 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12103.06 ms /    18 runs   (  672.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13306.69 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2560.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.63 ms /    23 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12871.76 ms /    19 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14128.99 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2602.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.64 ms /    23 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12882.92 ms /    19 runs   (  678.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14133.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2597.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.31 ms /    23 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12948.96 ms /    19 runs   (  681.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14201.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.88 ms /    23 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   12898.00 ms /    19 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14172.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    20 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.25 ms /    23 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12888.92 ms /    19 runs   (  678.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14133.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    20 runs   (    0.39 ms per token,  2562.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.35 ms /    23 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12823.64 ms /    19 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14066.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.65 ms /    20 runs   (    0.43 ms per token,  2313.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.53 ms /    23 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12906.75 ms /    19 runs   (  679.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14173.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2610.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.59 ms /    23 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12908.86 ms /    19 runs   (  679.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14155.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2611.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.86 ms /    23 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12937.86 ms /    19 runs   (  680.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14196.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    19 runs   (    0.40 ms per token,  2484.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.88 ms /    22 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12231.54 ms /    18 runs   (  679.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13479.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2609.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.79 ms /    22 tokens (   51.85 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   13153.83 ms /    19 runs   (  692.31 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   14350.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.01 ms /    16 runs   (    0.38 ms per token,  2661.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.12 ms /    23 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10239.67 ms /    15 runs   (  682.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11515.17 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.16 ms /    22 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12211.83 ms /    18 runs   (  678.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13454.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    18 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.25 ms /    21 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11635.54 ms /    17 runs   (  684.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12782.86 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2606.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.64 ms /    23 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13005.65 ms /    19 runs   (  684.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14279.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    19 runs   (    0.39 ms per token,  2568.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.17 ms /    22 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12131.43 ms /    18 runs   (  673.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13347.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    20 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.25 ms /    23 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12972.41 ms /    19 runs   (  682.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14246.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    20 runs   (    0.40 ms per token,  2517.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.61 ms /    23 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12867.29 ms /    19 runs   (  677.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14121.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2599.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.08 ms /    23 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12927.81 ms /    19 runs   (  680.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14203.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    20 runs   (    0.41 ms per token,  2460.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.09 ms /    23 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12495.87 ms /    19 runs   (  657.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13763.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    20 runs   (    0.41 ms per token,  2456.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.53 ms /    23 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12923.34 ms /    19 runs   (  680.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14186.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    20 runs   (    0.38 ms per token,  2644.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.75 ms /    23 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12703.45 ms /    19 runs   (  668.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13976.11 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    20 runs   (    0.39 ms per token,  2573.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.22 ms /    22 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12741.36 ms /    19 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13930.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.31 ms /    23 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12914.55 ms /    19 runs   (  679.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14226.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    19 runs   (    0.39 ms per token,  2578.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.30 ms /    22 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12290.16 ms /    18 runs   (  682.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13511.85 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    20 runs   (    0.38 ms per token,  2599.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.80 ms /    23 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12822.02 ms /    19 runs   (  674.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14078.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2611.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.30 ms /    22 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12081.40 ms /    18 runs   (  671.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13292.80 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    20 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.21 ms /    23 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12786.53 ms /    19 runs   (  672.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14047.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    20 runs   (    0.40 ms per token,  2509.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.18 ms /    21 tokens (   55.20 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12954.72 ms /    19 runs   (  681.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14170.27 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2592.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.09 ms /    23 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12719.84 ms /    19 runs   (  669.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13992.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    20 runs   (    0.39 ms per token,  2549.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.79 ms /    23 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   13161.68 ms /    19 runs   (  692.72 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   14396.55 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    20 runs   (    0.40 ms per token,  2506.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.38 ms /    22 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12652.73 ms /    19 runs   (  665.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13870.38 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    20 runs   (    0.39 ms per token,  2548.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.51 ms /    23 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12597.61 ms /    19 runs   (  663.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13843.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.13 ms /    23 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12831.18 ms /    19 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14094.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2592.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.64 ms /    23 tokens (   53.98 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   12758.09 ms /    19 runs   (  671.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14056.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2619.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.41 ms /    20 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12114.66 ms /    18 runs   (  673.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13216.25 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    16 runs   (    0.38 ms per token,  2599.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.10 ms /    23 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10186.39 ms /    15 runs   (  679.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11425.67 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2568.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.91 ms /    21 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11404.14 ms /    17 runs   (  670.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12568.69 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    19 runs   (    0.38 ms per token,  2606.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.14 ms /    22 tokens (   51.51 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12091.09 ms /    18 runs   (  671.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13277.93 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    20 runs   (    0.38 ms per token,  2614.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.95 ms /    23 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12843.96 ms /    19 runs   (  676.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14083.58 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    20 runs   (    0.38 ms per token,  2636.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1180.56 ms /    23 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12984.10 ms /    19 runs   (  683.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14219.83 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    23 runs   (    0.38 ms per token,  2621.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.90 ms /    26 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   14725.48 ms /    22 runs   (  669.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16110.72 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    20 runs   (    0.39 ms per token,  2593.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.61 ms /    23 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13085.29 ms /    19 runs   (  688.70 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14368.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    23 runs   (    0.40 ms per token,  2503.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.67 ms /    26 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   14868.15 ms /    22 runs   (  675.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16273.14 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    23 runs   (    0.39 ms per token,  2572.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.92 ms /    26 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   14852.84 ms /    22 runs   (  675.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16262.54 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    23 runs   (    0.40 ms per token,  2520.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.24 ms /    26 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14893.01 ms /    22 runs   (  676.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16320.42 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2527.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.98 ms /    26 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   14908.47 ms /    22 runs   (  677.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16309.36 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    23 runs   (    0.39 ms per token,  2577.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.00 ms /    26 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   14839.40 ms /    22 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16236.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    22 runs   (    0.39 ms per token,  2540.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.98 ms /    25 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   14322.21 ms /    21 runs   (  682.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15691.69 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.34 ms /    26 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   14950.69 ms /    22 runs   (  679.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16376.79 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    23 runs   (    0.38 ms per token,  2602.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.54 ms /    26 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15023.16 ms /    22 runs   (  682.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16404.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    23 runs   (    0.39 ms per token,  2583.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.39 ms /    26 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   14928.55 ms /    22 runs   (  678.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16325.91 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.75 ms /    22 runs   (    0.40 ms per token,  2513.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.85 ms /    25 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14243.00 ms /    21 runs   (  678.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15585.00 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.88 ms /    25 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11469.26 ms /    17 runs   (  674.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12814.27 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.75 ms /    23 runs   (    0.38 ms per token,  2629.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.55 ms /    26 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   14841.95 ms /    22 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16340.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.64 ms /    23 runs   (    0.42 ms per token,  2386.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.16 ms /    26 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   15023.75 ms /    22 runs   (  682.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16472.14 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    22 runs   (    0.40 ms per token,  2495.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.06 ms /    25 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   14352.82 ms /    21 runs   (  683.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15752.50 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    23 runs   (    0.40 ms per token,  2517.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.09 ms /    25 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   15096.42 ms /    22 runs   (  686.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16443.40 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.74 ms /    23 runs   (    0.38 ms per token,  2631.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.36 ms /    26 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   14973.22 ms /    22 runs   (  680.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16343.02 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    23 runs   (    0.40 ms per token,  2481.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.33 ms /    26 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   15017.80 ms /    22 runs   (  682.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16424.26 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    23 runs   (    0.39 ms per token,  2588.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.04 ms /    26 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   15030.53 ms /    22 runs   (  683.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16426.98 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    22 runs   (    0.39 ms per token,  2537.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.59 ms /    25 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   14404.93 ms /    21 runs   (  685.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15758.30 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    23 runs   (    0.39 ms per token,  2543.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.17 ms /    26 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14917.97 ms /    22 runs   (  678.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16308.50 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    23 runs   (    0.40 ms per token,  2499.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.39 ms /    25 tokens (   54.78 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   14765.59 ms /    22 runs   (  671.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16199.85 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.16 ms /    23 runs   (    0.40 ms per token,  2510.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.91 ms /    26 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14828.92 ms /    22 runs   (  674.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16223.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.91 ms /    23 runs   (    0.39 ms per token,  2580.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.64 ms /    25 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14942.55 ms /    22 runs   (  679.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16287.34 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    23 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.49 ms /    26 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   14967.91 ms /    22 runs   (  680.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16388.22 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    22 runs   (    0.40 ms per token,  2529.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.61 ms /    25 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   13997.26 ms /    21 runs   (  666.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15359.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    23 runs   (    0.39 ms per token,  2536.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.32 ms /    26 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   14800.59 ms /    22 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16206.53 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    23 runs   (    0.40 ms per token,  2523.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.26 ms /    26 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14886.47 ms /    22 runs   (  676.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16270.38 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    23 runs   (    0.38 ms per token,  2601.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.65 ms /    26 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   14740.81 ms /    22 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16149.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    23 runs   (    0.39 ms per token,  2531.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.24 ms /    25 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   14854.45 ms /    22 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16226.61 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.99 ms /    23 runs   (    0.39 ms per token,  2558.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.86 ms /    26 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   15036.42 ms /    22 runs   (  683.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16462.57 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.01 ms /    23 runs   (    0.39 ms per token,  2553.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.04 ms /    26 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   15033.92 ms /    22 runs   (  683.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16413.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    23 runs   (    0.39 ms per token,  2549.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.69 ms /    26 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   15110.76 ms /    22 runs   (  686.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16537.16 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    22 runs   (    0.38 ms per token,  2607.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.20 ms /    25 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   14333.74 ms /    21 runs   (  682.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15709.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    23 runs   (    0.40 ms per token,  2500.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.91 ms /    25 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   15178.03 ms /    22 runs   (  689.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   16538.36 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2527.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.85 ms /    26 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   14926.62 ms /    22 runs   (  678.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16307.18 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    23 runs   (    0.40 ms per token,  2520.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.68 ms /    26 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14773.56 ms /    22 runs   (  671.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16169.87 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    23 runs   (    0.39 ms per token,  2543.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.38 ms /    26 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14803.75 ms /    22 runs   (  672.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16197.62 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2528.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.99 ms /    26 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   14804.36 ms /    22 runs   (  672.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16236.44 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    23 runs   (    0.39 ms per token,  2574.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.21 ms /    26 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14831.16 ms /    22 runs   (  674.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16227.67 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    23 runs   (    0.38 ms per token,  2607.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.83 ms /    26 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   14615.60 ms /    22 runs   (  664.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16078.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    22 runs   (    0.39 ms per token,  2569.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.35 ms /    24 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14054.04 ms /    21 runs   (  669.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15392.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    23 runs   (    0.39 ms per token,  2561.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.66 ms /    26 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14673.15 ms /    22 runs   (  666.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16048.02 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.00 ms /    23 runs   (    0.39 ms per token,  2555.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.48 ms /    26 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14555.60 ms /    22 runs   (  661.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15952.65 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    23 runs   (    0.39 ms per token,  2535.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.71 ms /    26 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   14708.97 ms /    22 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16154.70 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    22 runs   (    0.39 ms per token,  2555.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.05 ms /    23 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14041.07 ms /    21 runs   (  668.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15340.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    23 runs   (    0.38 ms per token,  2635.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.68 ms /    26 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14760.03 ms /    22 runs   (  670.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16186.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    23 runs   (    0.39 ms per token,  2549.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.04 ms /    26 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15066.61 ms /    22 runs   (  684.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16441.72 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.06 ms /    23 runs   (    0.39 ms per token,  2539.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.23 ms /    26 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15062.67 ms /    22 runs   (  684.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16508.22 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    23 runs   (    0.38 ms per token,  2640.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.03 ms /    25 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   14994.57 ms /    22 runs   (  681.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16331.25 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    23 runs   (    0.40 ms per token,  2480.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.99 ms /    26 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   15034.64 ms /    22 runs   (  683.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16446.94 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    22 runs   (    0.40 ms per token,  2510.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.96 ms /    25 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   14441.55 ms /    21 runs   (  687.69 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15848.37 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    23 runs   (    0.38 ms per token,  2619.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.44 ms /    26 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   14787.53 ms /    22 runs   (  672.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16220.35 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    23 runs   (    0.39 ms per token,  2534.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.82 ms /    26 tokens (   56.49 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14778.41 ms /    22 runs   (  671.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16311.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2528.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.10 ms /    26 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   14735.85 ms /    22 runs   (  669.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16145.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    23 runs   (    0.39 ms per token,  2543.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.73 ms /    25 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   14831.66 ms /    22 runs   (  674.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16171.21 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    23 runs   (    0.40 ms per token,  2476.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.82 ms /    26 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   14679.74 ms /    22 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16111.66 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    23 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.18 ms /    26 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   14935.66 ms /    22 runs   (  678.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16337.00 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    23 runs   (    0.39 ms per token,  2546.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.48 ms /    26 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   14878.87 ms /    22 runs   (  676.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16260.77 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    23 runs   (    0.39 ms per token,  2531.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.24 ms /    25 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   14933.63 ms /    22 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16279.47 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    23 runs   (    0.40 ms per token,  2523.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.65 ms /    26 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   14911.61 ms /    22 runs   (  677.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16336.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    23 runs   (    0.40 ms per token,  2494.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.27 ms /    26 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14996.93 ms /    22 runs   (  681.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16390.72 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    23 runs   (    0.40 ms per token,  2503.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.76 ms /    26 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   14743.95 ms /    22 runs   (  670.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16144.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.00 ms /    23 runs   (    0.39 ms per token,  2554.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.93 ms /    26 tokens (   55.65 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   14701.14 ms /    22 runs   (  668.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16214.05 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    22 runs   (    0.39 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.22 ms /    25 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13914.23 ms /    21 runs   (  662.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15305.31 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2528.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.32 ms /    26 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14527.44 ms /    22 runs   (  660.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15941.62 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.45 ms /    23 runs   (    0.41 ms per token,  2434.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.84 ms /    26 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   14877.47 ms /    22 runs   (  676.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16251.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       5.25 ms /    14 runs   (    0.38 ms per token,  2665.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.77 ms /    26 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =    8834.98 ms /    13 runs   (  679.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10187.55 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    23 runs   (    0.39 ms per token,  2550.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.90 ms /    26 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   14578.74 ms /    22 runs   (  662.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15962.04 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.99 ms /    23 runs   (    0.39 ms per token,  2557.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.26 ms /    26 tokens (   54.93 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   14859.85 ms /    22 runs   (  675.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16353.97 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    23 runs   (    0.39 ms per token,  2568.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.94 ms /    26 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   14982.29 ms /    22 runs   (  681.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16461.19 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    23 runs   (    0.40 ms per token,  2504.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.94 ms /    26 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14924.80 ms /    22 runs   (  678.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16303.93 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    23 runs   (    0.41 ms per token,  2453.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.37 ms /    26 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   15111.33 ms /    22 runs   (  686.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16480.91 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    23 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.38 ms /    26 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   15007.02 ms /    22 runs   (  682.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16428.15 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    23 runs   (    0.38 ms per token,  2622.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.61 ms /    25 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   15074.33 ms /    22 runs   (  685.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16429.58 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.84 ms /    23 runs   (    0.43 ms per token,  2336.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.04 ms /    26 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   15044.25 ms /    22 runs   (  683.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16433.43 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    23 runs   (    0.39 ms per token,  2531.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.20 ms /    26 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14622.09 ms /    22 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16007.83 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    23 runs   (    0.40 ms per token,  2507.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.59 ms /    26 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   14798.96 ms /    22 runs   (  672.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16206.33 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    23 runs   (    0.39 ms per token,  2563.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.62 ms /    26 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   14828.02 ms /    22 runs   (  674.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16242.00 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.00 ms /    23 runs   (    0.39 ms per token,  2554.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.27 ms /    25 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   14858.66 ms /    22 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16193.61 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    23 runs   (    0.40 ms per token,  2521.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.60 ms /    26 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14735.93 ms /    22 runs   (  669.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16120.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    23 runs   (    0.39 ms per token,  2540.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.34 ms /    25 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   14631.71 ms /    22 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15964.87 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    23 runs   (    0.40 ms per token,  2513.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.76 ms /    26 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14600.49 ms /    22 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15985.32 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    22 runs   (    0.39 ms per token,  2535.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.50 ms /    25 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14078.66 ms /    21 runs   (  670.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15410.30 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    23 runs   (    0.39 ms per token,  2571.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.24 ms /    26 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   14858.40 ms /    22 runs   (  675.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16246.79 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    23 runs   (    0.40 ms per token,  2506.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.98 ms /    26 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14660.02 ms /    22 runs   (  666.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16055.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    22 runs   (    0.40 ms per token,  2499.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.29 ms /    25 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   13997.51 ms /    21 runs   (  666.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15350.92 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2603.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.50 ms /    25 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11345.16 ms /    17 runs   (  667.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12668.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    23 runs   (    0.38 ms per token,  2609.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.73 ms /    26 tokens (   50.34 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15139.73 ms /    22 runs   (  688.17 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   16513.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2528.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.22 ms /    26 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14861.82 ms /    22 runs   (  675.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16246.18 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    23 runs   (    0.39 ms per token,  2545.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.84 ms /    26 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14932.02 ms /    22 runs   (  678.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16357.24 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    19 runs   (    0.39 ms per token,  2559.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.83 ms /    22 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12182.05 ms /    18 runs   (  676.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13371.39 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    22 runs   (    0.39 ms per token,  2580.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.53 ms /    25 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13896.72 ms /    21 runs   (  661.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15273.35 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.99 ms /    23 runs   (    0.39 ms per token,  2558.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.42 ms /    26 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14984.32 ms /    22 runs   (  681.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16397.33 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    23 runs   (    0.39 ms per token,  2572.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.02 ms /    26 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   15028.94 ms /    22 runs   (  683.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16433.39 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    23 runs   (    0.40 ms per token,  2470.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.73 ms /    26 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   14991.53 ms /    22 runs   (  681.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16379.26 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2526.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.51 ms /    26 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   15050.65 ms /    22 runs   (  684.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16460.62 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    21 runs   (    0.38 ms per token,  2647.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.07 ms /    24 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   13593.59 ms /    20 runs   (  679.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14931.54 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    22 runs   (    0.39 ms per token,  2548.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.98 ms /    25 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   14270.87 ms /    21 runs   (  679.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15619.55 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    26 runs   (    0.41 ms per token,  2428.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.12 ms /    27 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   17007.08 ms /    25 runs   (  680.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18433.21 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.82 ms /    25 runs   (    0.39 ms per token,  2545.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.97 ms /    28 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   16258.57 ms /    24 runs   (  677.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17740.66 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    26 runs   (    0.42 ms per token,  2394.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.00 ms /    29 tokens (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   17012.96 ms /    25 runs   (  680.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18531.96 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.82 ms /    26 runs   (    0.38 ms per token,  2646.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.26 ms /    29 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   17103.29 ms /    25 runs   (  684.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18630.62 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.23 ms /    26 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.50 ms /    28 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   16952.99 ms /    25 runs   (  678.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18472.75 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.64 ms /    26 runs   (    0.41 ms per token,  2444.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.62 ms /    29 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:        eval time =   16848.84 ms /    25 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18365.59 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    26 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.53 ms /    29 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   16967.81 ms /    25 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18489.01 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    25 runs   (    0.41 ms per token,  2455.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.30 ms /    28 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   16293.91 ms /    24 runs   (  678.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17794.80 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    25 runs   (    0.39 ms per token,  2577.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.68 ms /    28 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16420.07 ms /    24 runs   (  684.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17897.29 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    26 runs   (    0.41 ms per token,  2456.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.18 ms /    29 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   16990.54 ms /    25 runs   (  679.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18531.75 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.46 ms /    26 runs   (    0.40 ms per token,  2486.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.77 ms /    28 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   17023.56 ms /    25 runs   (  680.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18515.91 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.49 ms /    26 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.20 ms /    29 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   17019.79 ms /    25 runs   (  680.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18533.21 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    26 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.53 ms /    29 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   16706.73 ms /    25 runs   (  668.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18293.70 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    26 runs   (    0.41 ms per token,  2457.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1467.25 ms /    29 tokens (   50.59 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   17312.41 ms /    25 runs   (  692.50 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   18851.60 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.89 ms /    26 runs   (    0.38 ms per token,  2628.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.37 ms /    29 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16728.46 ms /    25 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18283.50 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.33 ms /    25 runs   (    0.41 ms per token,  2420.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.35 ms /    28 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   16412.13 ms /    24 runs   (  683.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17916.15 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.27 ms /    26 runs   (    0.39 ms per token,  2532.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.78 ms /    29 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   17113.48 ms /    25 runs   (  684.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18665.81 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.99 ms /    25 runs   (    0.40 ms per token,  2502.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.75 ms /    28 tokens (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   16210.78 ms /    24 runs   (  675.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17675.31 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.68 ms /    26 runs   (    0.41 ms per token,  2434.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.96 ms /    29 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   16812.43 ms /    25 runs   (  672.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18338.30 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.35 ms /    26 runs   (    0.40 ms per token,  2511.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.46 ms /    29 tokens (   50.77 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   16681.16 ms /    25 runs   (  667.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18228.26 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.07 ms /    26 runs   (    0.39 ms per token,  2581.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1616.17 ms /    29 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   16760.50 ms /    25 runs   (  670.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18448.98 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    25 runs   (    0.38 ms per token,  2627.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.72 ms /    28 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   15843.27 ms /    24 runs   (  660.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17317.45 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    23 runs   (    0.39 ms per token,  2584.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.09 ms /    26 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14830.74 ms /    22 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16221.87 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.44 ms /    24 runs   (    0.39 ms per token,  2542.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.68 ms /    27 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   15568.47 ms /    23 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17024.35 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    26 runs   (    0.42 ms per token,  2401.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.71 ms /    29 tokens (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_print_timings:        eval time =   16854.40 ms /    25 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18367.67 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.31 ms /    26 runs   (    0.40 ms per token,  2522.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1474.29 ms /    29 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   17023.07 ms /    25 runs   (  680.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18571.27 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.52 ms /    26 runs   (    0.40 ms per token,  2470.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.90 ms /    29 tokens (   50.24 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   16535.38 ms /    25 runs   (  661.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18066.57 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    26 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.75 ms /    27 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   17023.20 ms /    25 runs   (  680.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18469.83 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.05 ms /    25 runs   (    0.40 ms per token,  2488.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.09 ms /    28 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   16440.83 ms /    24 runs   (  685.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17930.81 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.78 ms /    26 runs   (    0.41 ms per token,  2412.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.65 ms /    29 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   16709.84 ms /    25 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18233.07 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.32 ms /    26 runs   (    0.40 ms per token,  2520.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.75 ms /    29 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   17001.29 ms /    25 runs   (  680.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18547.28 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.30 ms /    25 runs   (    0.41 ms per token,  2426.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.95 ms /    27 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   16233.19 ms /    24 runs   (  676.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17683.68 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.60 ms /    26 runs   (    0.41 ms per token,  2452.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.63 ms /    28 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   16961.50 ms /    25 runs   (  678.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18444.88 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.49 ms /    26 runs   (    0.40 ms per token,  2479.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.21 ms /    29 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   16940.01 ms /    25 runs   (  677.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18482.72 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    25 runs   (    0.40 ms per token,  2472.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.90 ms /    28 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   16483.75 ms /    24 runs   (  686.82 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17958.01 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    25 runs   (    0.38 ms per token,  2629.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.67 ms /    28 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   16279.48 ms /    24 runs   (  678.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17846.99 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    26 runs   (    0.41 ms per token,  2419.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.95 ms /    29 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   16833.07 ms /    25 runs   (  673.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18398.53 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.75 ms /    26 runs   (    0.37 ms per token,  2667.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.39 ms /    29 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   17041.14 ms /    25 runs   (  681.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18572.41 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.50 ms /    26 runs   (    0.40 ms per token,  2477.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.79 ms /    29 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   16946.89 ms /    25 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18470.41 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    24 runs   (    0.40 ms per token,  2498.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.26 ms /    27 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   15644.44 ms /    23 runs   (  680.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17098.58 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    25 runs   (    0.41 ms per token,  2461.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.81 ms /    28 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15912.35 ms /    24 runs   (  663.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17469.57 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    26 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.72 ms /    29 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   16911.03 ms /    25 runs   (  676.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18457.89 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    26 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.60 ms /    29 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   16831.72 ms /    25 runs   (  673.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18377.17 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    26 runs   (    0.39 ms per token,  2577.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.04 ms /    29 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   16592.12 ms /    25 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18114.90 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.79 ms /    26 runs   (    0.42 ms per token,  2408.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.61 ms /    29 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16908.09 ms /    25 runs   (  676.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18465.40 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    26 runs   (    0.41 ms per token,  2448.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.93 ms /    29 tokens (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   16620.12 ms /    25 runs   (  664.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18137.89 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.47 ms /    25 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.57 ms /    28 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   15839.07 ms /    24 runs   (  659.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17335.80 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.66 ms /    26 runs   (    0.41 ms per token,  2439.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.62 ms /    29 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   16678.10 ms /    25 runs   (  667.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18220.43 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.93 ms /    26 runs   (    0.38 ms per token,  2617.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.67 ms /    28 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16829.84 ms /    25 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18334.19 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    25 runs   (    0.41 ms per token,  2453.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.66 ms /    28 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   16367.06 ms /    24 runs   (  681.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17877.60 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    25 runs   (    0.40 ms per token,  2473.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1564.54 ms /    28 tokens (   55.88 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:        eval time =   16160.65 ms /    24 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17795.41 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.81 ms /    26 runs   (    0.42 ms per token,  2406.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.16 ms /    29 tokens (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   16913.87 ms /    25 runs   (  676.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18429.46 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.94 ms /    26 runs   (    0.38 ms per token,  2616.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.52 ms /    29 tokens (   50.09 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   16978.39 ms /    25 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18504.90 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /    26 runs   (    0.38 ms per token,  2613.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.36 ms /    29 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   16622.67 ms /    25 runs   (  664.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18165.63 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      11.00 ms /    26 runs   (    0.42 ms per token,  2362.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.05 ms /    29 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   17115.25 ms /    25 runs   (  684.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18638.54 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.71 ms /    26 runs   (    0.37 ms per token,  2676.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1489.85 ms /    29 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   16951.51 ms /    25 runs   (  678.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18513.72 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    26 runs   (    0.42 ms per token,  2392.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.84 ms /    29 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   16853.59 ms /    25 runs   (  674.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18407.69 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    26 runs   (    0.38 ms per token,  2659.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1470.42 ms /    29 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   17080.65 ms /    25 runs   (  683.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18624.59 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    25 runs   (    0.45 ms per token,  2223.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.68 ms /    28 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   16086.61 ms /    24 runs   (  670.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17598.13 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    25 runs   (    0.41 ms per token,  2436.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.24 ms /    28 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   16245.70 ms /    24 runs   (  676.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17713.79 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.99 ms /    26 runs   (    0.42 ms per token,  2365.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.11 ms /    29 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17084.74 ms /    25 runs   (  683.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18616.91 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.27 ms /    25 runs   (    0.41 ms per token,  2433.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.70 ms /    28 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   16543.91 ms /    24 runs   (  689.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   18039.85 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      11.49 ms /    26 runs   (    0.44 ms per token,  2263.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.81 ms /    28 tokens (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   17584.89 ms /    25 runs   (  703.40 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   19059.21 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    25 runs   (    0.40 ms per token,  2524.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1460.71 ms /    28 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   16361.27 ms /    24 runs   (  681.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17893.12 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    26 runs   (    0.41 ms per token,  2448.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.69 ms /    29 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   16947.96 ms /    25 runs   (  677.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18498.66 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    25 runs   (    0.41 ms per token,  2436.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.72 ms /    28 tokens (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   16152.18 ms /    24 runs   (  673.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17625.86 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.68 ms /    26 runs   (    0.41 ms per token,  2433.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.85 ms /    29 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16466.08 ms /    25 runs   (  658.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18023.89 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.99 ms /    26 runs   (    0.38 ms per token,  2601.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.85 ms /    29 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   16633.24 ms /    25 runs   (  665.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18160.98 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    26 runs   (    0.39 ms per token,  2589.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.90 ms /    29 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   16607.41 ms /    25 runs   (  664.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18138.09 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    26 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.32 ms /    29 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   16363.52 ms /    25 runs   (  654.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17906.12 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.59 ms /    25 runs   (    0.38 ms per token,  2605.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.80 ms /    28 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   15596.35 ms /    24 runs   (  649.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   17118.33 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.12 ms /    25 runs   (    0.40 ms per token,  2471.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.18 ms /    28 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   16120.87 ms /    24 runs   (  671.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17603.77 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    26 runs   (    0.42 ms per token,  2392.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.71 ms /    29 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   16585.75 ms /    25 runs   (  663.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18134.43 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    26 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.18 ms /    29 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   16976.90 ms /    25 runs   (  679.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18517.85 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    26 runs   (    0.38 ms per token,  2639.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1545.44 ms /    29 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   16876.48 ms /    25 runs   (  675.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18496.87 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    26 runs   (    0.39 ms per token,  2574.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1459.00 ms /    29 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   16678.52 ms /    25 runs   (  667.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18212.50 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.67 ms /    26 runs   (    0.41 ms per token,  2437.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.43 ms /    29 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   16650.89 ms /    25 runs   (  666.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18188.29 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    26 runs   (    0.39 ms per token,  2551.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1819.19 ms /    29 tokens (   62.73 ms per token,    15.94 tokens per second)\n",
      "llama_print_timings:        eval time =   16859.72 ms /    25 runs   (  674.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18752.27 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.39 ms /    26 runs   (    0.40 ms per token,  2501.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1464.45 ms /    29 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   16507.47 ms /    25 runs   (  660.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18045.47 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    26 runs   (    0.42 ms per token,  2391.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1480.67 ms /    29 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   17136.75 ms /    25 runs   (  685.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18692.57 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    25 runs   (    0.39 ms per token,  2556.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.25 ms /    28 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   16255.79 ms /    24 runs   (  677.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17747.56 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    26 runs   (    0.39 ms per token,  2553.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.85 ms /    29 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   16628.01 ms /    25 runs   (  665.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18169.13 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    24 runs   (    0.39 ms per token,  2550.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.18 ms /    27 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   15724.37 ms /    23 runs   (  683.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17185.47 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    26 runs   (    0.41 ms per token,  2413.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.88 ms /    29 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   17048.76 ms /    25 runs   (  681.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18606.85 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.80 ms /    26 runs   (    0.42 ms per token,  2407.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.58 ms /    28 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17184.88 ms /    25 runs   (  687.40 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   18689.47 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.71 ms /    24 runs   (    0.40 ms per token,  2471.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.67 ms /    27 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   15616.95 ms /    23 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17063.53 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.05 ms /    26 runs   (    0.39 ms per token,  2587.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.45 ms /    29 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   16897.43 ms /    25 runs   (  675.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18470.32 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    25 runs   (    0.41 ms per token,  2436.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.15 ms /    28 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   16377.48 ms /    24 runs   (  682.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17874.13 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    26 runs   (    0.42 ms per token,  2390.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.88 ms /    28 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   16931.64 ms /    25 runs   (  677.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18444.93 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    25 runs   (    0.41 ms per token,  2456.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.31 ms /    28 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   16300.47 ms /    24 runs   (  679.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17798.24 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    26 runs   (    0.41 ms per token,  2449.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.75 ms /    29 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   17129.58 ms /    25 runs   (  685.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18687.37 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.60 ms /    26 runs   (    0.41 ms per token,  2453.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1460.01 ms /    29 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   16810.44 ms /    25 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18343.87 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    26 runs   (    0.41 ms per token,  2428.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1489.98 ms /    29 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   16670.03 ms /    25 runs   (  666.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18233.66 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    26 runs   (    0.38 ms per token,  2658.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.71 ms /    29 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   16541.09 ms /    25 runs   (  661.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18067.56 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.65 ms /    26 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.66 ms /    29 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   16498.81 ms /    25 runs   (  659.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18016.39 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.30 ms /    26 runs   (    0.40 ms per token,  2523.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.50 ms /    29 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   16949.93 ms /    25 runs   (  678.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18473.31 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    26 runs   (    0.39 ms per token,  2596.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.54 ms /    29 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   16789.18 ms /    25 runs   (  671.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18323.16 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.65 ms /    26 runs   (    0.41 ms per token,  2441.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.15 ms /    29 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   16696.14 ms /    25 runs   (  667.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18212.28 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =      10.06 ms /    25 runs   (    0.40 ms per token,  2484.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.93 ms /    28 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   15931.10 ms /    24 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17436.68 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4292.20 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    24 runs   (    0.39 ms per token,  2585.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.77 ms /    27 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   15658.22 ms /    23 runs   (  680.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17087.89 ms /    50 tokens\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#run for list_size_3_pos first column of datafram df\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(f\"Completed {i} rows\")\n",
    "        \n",
    "    try:\n",
    "        #change the column(i) as per the data\n",
    "        prompt= f\"Sort the list {df.iloc[i, 0]}\"\n",
    "\n",
    "\n",
    "        prompt_template=f'''SYSTEM: You are a math assistant.I will ask you to sort list. Please answer in the correct format. For example, if I ask 'Sort the numbers list [4, 8, 2]', you should answer '[2, 4, 8]'\n",
    "\n",
    "        USER: {prompt}\n",
    "        \n",
    "        ASSISTANT:'''\n",
    "        \n",
    "        response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                    repeat_penalty=1.2, top_k=150,\n",
    "                    echo=False)\n",
    "        \n",
    "        with open('sort_output_3_pos.txt', 'a') as f:\n",
    "            answer=response[\"choices\"][0][\"text\"]\n",
    "            f.write(f\"{df.iloc[i, 0]} = {answer} \\n\")\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        #write in min_output.txt'\n",
    "        with open('sort_output_3_pos.txt', 'a') as f:\n",
    "            f.write(f\"{df.iloc[i, 0]} = Error \\n\")\n",
    "            \n",
    "        time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viveksdmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
