{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required libraries\n",
    "# %pip install transformers\n",
    "# %pip install torchtext\n",
    "# %pip install sentencepiece\n",
    "# %pip install datasets\n",
    "# %pip install torchmetrics\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# #huggiface download\n",
    "# %pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/viveksdmlenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the model llama 2 7b\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is in bin format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viveksd/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "#print toal path\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /home/viveksd/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.36 GiB (5.51 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  8555.93 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   400.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    85.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '16'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"1000 + -2300 = ?\"\n",
    "prompt_template=f'''SYSTEM: You are a math assistant. I will ask you some addition questions. Please answer in the correct format. For example, if I ask 2+3=? you should answer 5. Let's start.\n",
    "\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    23 runs   (    0.37 ms per token,  2686.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   15744.73 ms /    23 runs   (  684.55 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15798.74 ms /    24 tokens\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=100, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sum of 1000 and -2300 is -1300.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file in data folder int_addition.json\n",
    "with open('int_addition.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     8 runs   (    0.38 ms per token,  2613.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5405.65 ms /    66 tokens (   81.90 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:        eval time =    4930.14 ms /     7 runs   (  704.31 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   10355.31 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     8 runs   (    0.38 ms per token,  2606.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.60 ms /    15 tokens (   76.31 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =    4929.48 ms /     7 runs   (  704.21 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6093.19 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2669.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.51 ms /    15 tokens (   83.17 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5625.34 ms /     8 runs   (  703.17 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6893.63 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     8 runs   (    0.39 ms per token,  2589.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.93 ms /    15 tokens (   83.86 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4797.10 ms /     7 runs   (  685.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6073.42 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.91 ms /    15 tokens (   82.73 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4838.32 ms /     7 runs   (  691.19 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6097.99 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2633.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.76 ms /    15 tokens (   84.12 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5522.29 ms /     8 runs   (  690.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6804.75 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.50 ms /    15 tokens (   82.90 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5520.85 ms /     8 runs   (  690.11 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6785.29 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2664.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.58 ms /    12 tokens (   85.96 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =    5575.75 ms /     8 runs   (  696.97 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6628.82 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     8 runs   (    0.37 ms per token,  2669.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.14 ms /    15 tokens (   83.21 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    4868.99 ms /     7 runs   (  695.57 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6136.04 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2672.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.21 ms /    15 tokens (   83.75 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5530.89 ms /     8 runs   (  691.36 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6808.26 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2712.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.16 ms /    15 tokens (   83.48 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    4795.14 ms /     7 runs   (  685.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6066.02 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /     8 runs   (    0.36 ms per token,  2775.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.20 ms /    15 tokens (   82.95 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    4904.17 ms /     7 runs   (  700.60 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6167.52 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2688.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.92 ms /    12 tokens (   84.49 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:        eval time =    4846.01 ms /     7 runs   (  692.29 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5878.73 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /     8 runs   (    0.36 ms per token,  2809.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.42 ms /    15 tokens (   82.96 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4851.96 ms /     7 runs   (  693.14 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6114.66 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2626.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.53 ms /    15 tokens (   83.44 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5571.45 ms /     8 runs   (  696.43 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6845.12 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2712.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.46 ms /    15 tokens (   83.56 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5573.11 ms /     8 runs   (  696.64 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6847.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.23 ms /    15 tokens (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5521.65 ms /     8 runs   (  690.21 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6789.47 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     8 runs   (    0.37 ms per token,  2689.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.24 ms /    15 tokens (   83.42 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4875.06 ms /     7 runs   (  696.44 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6144.65 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     8 runs   (    0.36 ms per token,  2769.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.34 ms /    15 tokens (   83.56 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4836.07 ms /     7 runs   (  690.87 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6108.79 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2655.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.35 ms /    15 tokens (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =    5522.05 ms /     8 runs   (  690.26 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6808.41 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /     8 runs   (    0.37 ms per token,  2735.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.45 ms /    15 tokens (   83.30 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4864.78 ms /     7 runs   (  694.97 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6133.05 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2663.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.58 ms /    12 tokens (   84.97 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5526.81 ms /     8 runs   (  690.85 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6567.90 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2706.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.09 ms /    15 tokens (   83.27 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4827.19 ms /     7 runs   (  689.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6095.40 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2681.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.81 ms /    15 tokens (   83.72 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =    4833.34 ms /     7 runs   (  690.48 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6108.44 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2651.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.36 ms /    15 tokens (   83.02 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5583.50 ms /     8 runs   (  697.94 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6850.81 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2636.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.97 ms /    15 tokens (   83.86 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =    5526.89 ms /     8 runs   (  690.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6806.59 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2639.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.79 ms /    12 tokens (   84.40 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4896.01 ms /     7 runs   (  699.43 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    5928.43 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2684.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.78 ms /    15 tokens (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5479.91 ms /     8 runs   (  684.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6745.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2621.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.89 ms /    15 tokens (   83.19 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5504.74 ms /     8 runs   (  688.09 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6774.06 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2689.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.43 ms /    15 tokens (   77.23 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5482.76 ms /     8 runs   (  685.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6662.76 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2698.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.25 ms /    15 tokens (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4855.83 ms /     7 runs   (  693.69 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6121.86 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2680.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.85 ms /    15 tokens (   83.59 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5523.38 ms /     8 runs   (  690.42 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6798.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2706.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.60 ms /    15 tokens (   71.71 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5531.70 ms /     8 runs   (  691.46 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6629.52 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.36 ms /    15 tokens (   83.62 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5531.71 ms /     8 runs   (  691.46 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6807.36 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2660.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.96 ms /    15 tokens (   82.73 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =    5532.00 ms /     8 runs   (  691.50 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6794.61 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2704.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.61 ms /    15 tokens (   81.51 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:        eval time =    4799.09 ms /     7 runs   (  685.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6040.74 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2715.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.17 ms /    15 tokens (   83.34 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =    4801.89 ms /     7 runs   (  685.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6071.68 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     8 runs   (    0.37 ms per token,  2729.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.11 ms /    15 tokens (   83.61 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4801.07 ms /     7 runs   (  685.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6074.29 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2673.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.41 ms /    15 tokens (   83.23 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5487.62 ms /     8 runs   (  685.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6758.10 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.26 ms /     9 runs   (    0.36 ms per token,  2764.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.36 ms /    15 tokens (   83.69 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5501.75 ms /     8 runs   (  687.72 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6779.18 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2598.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.82 ms /    12 tokens (   84.57 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:        eval time =    5532.30 ms /     8 runs   (  691.54 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6569.27 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /     8 runs   (    0.36 ms per token,  2763.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.63 ms /    15 tokens (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4771.60 ms /     7 runs   (  681.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6033.30 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2635.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.74 ms /    15 tokens (   83.12 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5463.96 ms /     8 runs   (  683.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6732.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.12 ms /    15 tokens (   83.54 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5502.26 ms /     8 runs   (  687.78 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6777.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     9 runs   (    0.37 ms per token,  2693.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.64 ms /    15 tokens (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5480.98 ms /     8 runs   (  685.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6745.99 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2720.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.68 ms /    12 tokens (   85.64 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:        eval time =    5502.60 ms /     8 runs   (  687.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6551.90 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /     8 runs   (    0.36 ms per token,  2758.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.93 ms /    15 tokens (   83.33 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =    4937.15 ms /     7 runs   (  705.31 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6206.75 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2671.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.46 ms /    15 tokens (   83.56 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5535.80 ms /     8 runs   (  691.98 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6813.59 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /     9 runs   (    0.47 ms per token,  2122.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.53 ms /    15 tokens (   83.04 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5510.66 ms /     8 runs   (  688.83 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6779.75 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2642.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.20 ms /    15 tokens (   82.81 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4762.18 ms /     7 runs   (  680.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6023.43 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2688.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.56 ms /    15 tokens (   82.90 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    4739.04 ms /     7 runs   (  677.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6001.72 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2708.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.10 ms /    15 tokens (   82.81 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4814.83 ms /     7 runs   (  687.83 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6076.38 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2661.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.78 ms /    12 tokens (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:        eval time =    5481.58 ms /     8 runs   (  685.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6518.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /     9 runs   (    0.36 ms per token,  2744.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.03 ms /    15 tokens (   83.07 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5484.47 ms /     8 runs   (  685.56 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6751.90 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     8 runs   (    0.36 ms per token,  2764.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.56 ms /    12 tokens (   84.38 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4830.69 ms /     7 runs   (  690.10 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5862.32 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2654.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.51 ms /    15 tokens (   82.77 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5492.53 ms /     8 runs   (  686.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6756.28 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /     8 runs   (    0.36 ms per token,  2754.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.85 ms /    15 tokens (   84.19 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =    4760.76 ms /     7 runs   (  680.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6043.09 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2607.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.08 ms /    15 tokens (   82.94 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5519.55 ms /     8 runs   (  689.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6785.73 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2712.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.65 ms /    15 tokens (   82.91 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5503.89 ms /     8 runs   (  687.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6769.06 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /     8 runs   (    0.37 ms per token,  2738.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.14 ms /    15 tokens (   81.54 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4810.90 ms /     7 runs   (  687.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6053.17 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.47 ms /    15 tokens (   83.43 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5459.25 ms /     8 runs   (  682.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6733.19 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     8 runs   (    0.38 ms per token,  2664.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.57 ms /    15 tokens (   82.97 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4788.62 ms /     7 runs   (  684.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6053.09 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     8 runs   (    0.39 ms per token,  2574.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.74 ms /    15 tokens (   82.85 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4888.01 ms /     7 runs   (  698.29 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6150.13 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2651.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.48 ms /    12 tokens (   82.62 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:        eval time =    4799.82 ms /     7 runs   (  685.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5811.31 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2625.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.34 ms /    15 tokens (   83.16 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5480.56 ms /     8 runs   (  685.07 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6750.03 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2626.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.35 ms /    15 tokens (   83.02 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5558.76 ms /     8 runs   (  694.84 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6826.68 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2632.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.21 ms /    15 tokens (   76.88 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:        eval time =    5567.13 ms /     8 runs   (  695.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6743.07 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /     9 runs   (    0.36 ms per token,  2748.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.77 ms /    15 tokens (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5488.47 ms /     8 runs   (  686.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6753.99 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     8 runs   (    0.36 ms per token,  2772.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.52 ms /    15 tokens (   83.23 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4817.84 ms /     7 runs   (  688.26 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6085.87 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2719.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.48 ms /    15 tokens (   82.90 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5615.27 ms /     8 runs   (  701.91 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6880.60 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     8 runs   (    0.36 ms per token,  2770.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.26 ms /    15 tokens (   83.22 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    4780.23 ms /     7 runs   (  682.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6048.22 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     8 runs   (    0.37 ms per token,  2697.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.53 ms /    15 tokens (   84.77 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:        eval time =    4920.63 ms /     7 runs   (  702.95 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6211.68 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.93 ms /    15 tokens (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4929.00 ms /     7 runs   (  704.14 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6193.52 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.40 ms /    15 tokens (   83.63 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5482.46 ms /     8 runs   (  685.31 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6758.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2669.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.86 ms /    15 tokens (   82.99 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5497.08 ms /     8 runs   (  687.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6764.53 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     9 runs   (    0.37 ms per token,  2733.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.84 ms /    15 tokens (   82.99 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5545.49 ms /     8 runs   (  693.19 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6812.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2683.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.02 ms /    15 tokens (   83.33 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5537.75 ms /     8 runs   (  692.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6809.92 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /     8 runs   (    0.40 ms per token,  2507.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.60 ms /    12 tokens (   84.72 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:        eval time =    4818.37 ms /     7 runs   (  688.34 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5855.56 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     8 runs   (    0.37 ms per token,  2729.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.73 ms /    15 tokens (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4778.81 ms /     7 runs   (  682.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6040.09 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2648.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.24 ms /    15 tokens (   83.55 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5442.25 ms /     8 runs   (  680.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6717.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.05 ms /    15 tokens (   83.07 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5388.14 ms /     8 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6656.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2689.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.14 ms /    15 tokens (   78.08 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:        eval time =    4814.50 ms /     7 runs   (  687.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6005.78 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     8 runs   (    0.39 ms per token,  2588.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     965.09 ms /    12 tokens (   80.42 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:        eval time =    4748.04 ms /     7 runs   (  678.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5733.46 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2689.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.64 ms /    15 tokens (   77.31 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5484.19 ms /     8 runs   (  685.52 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6665.74 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2685.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.39 ms /    15 tokens (   82.76 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5495.28 ms /     8 runs   (  686.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6759.02 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2701.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.04 ms /    15 tokens (   82.87 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4849.53 ms /     7 runs   (  692.79 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6111.67 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     9 runs   (    0.37 ms per token,  2696.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.95 ms /    15 tokens (   83.66 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5497.59 ms /     8 runs   (  687.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6775.18 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2646.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.97 ms /    15 tokens (   83.46 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    4818.95 ms /     7 runs   (  688.42 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6091.15 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     9 runs   (    0.37 ms per token,  2697.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.61 ms /    15 tokens (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:        eval time =    5511.53 ms /     8 runs   (  688.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6764.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /     8 runs   (    0.36 ms per token,  2778.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.25 ms /    15 tokens (   70.48 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4840.27 ms /     7 runs   (  691.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5917.23 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /     8 runs   (    0.36 ms per token,  2782.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.60 ms /    15 tokens (   70.04 ms per token,    14.28 tokens per second)\n",
      "llama_print_timings:        eval time =    4825.65 ms /     7 runs   (  689.38 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5895.87 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /     8 runs   (    0.36 ms per token,  2757.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.50 ms /    12 tokens (   84.71 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:        eval time =    4846.98 ms /     7 runs   (  692.43 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    5883.61 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5447.04 ms /     8 runs   (  680.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5466.80 ms /     9 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2689.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.10 ms /    15 tokens (   83.67 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:        eval time =    4878.95 ms /     7 runs   (  696.99 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6154.17 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2629.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.40 ms /    15 tokens (   82.96 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5460.79 ms /     8 runs   (  682.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6727.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2601.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.42 ms /    15 tokens (   82.83 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5500.61 ms /     8 runs   (  687.58 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6764.89 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2698.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.84 ms /    15 tokens (   86.46 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:        eval time =    5498.36 ms /     8 runs   (  687.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6817.28 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2661.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1014.04 ms /    12 tokens (   84.50 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:        eval time =    5530.87 ms /     8 runs   (  691.36 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6567.29 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.04 ms /    15 tokens (   83.20 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    4783.50 ms /     7 runs   (  683.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6051.26 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     8 runs   (    0.36 ms per token,  2764.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.60 ms /    12 tokens (   84.30 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4733.54 ms /     7 runs   (  676.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5764.48 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 100th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     8 runs   (    0.38 ms per token,  2626.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.80 ms /    15 tokens (   83.52 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4781.97 ms /     7 runs   (  683.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6055.10 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2641.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.17 ms /    15 tokens (   82.88 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4846.75 ms /     7 runs   (  692.39 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6109.08 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     8 runs   (    0.39 ms per token,  2589.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.66 ms /    15 tokens (   82.98 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4856.40 ms /     7 runs   (  693.77 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6121.21 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2686.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.27 ms /    15 tokens (   80.08 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:        eval time =    4802.44 ms /     7 runs   (  686.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6023.75 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     8 runs   (    0.37 ms per token,  2674.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.54 ms /    15 tokens (   82.97 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4835.33 ms /     7 runs   (  690.76 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6100.01 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     9 runs   (    0.39 ms per token,  2569.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.50 ms /    15 tokens (   82.83 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5491.52 ms /     8 runs   (  686.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6756.35 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2711.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.91 ms /    15 tokens (   82.93 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    4825.70 ms /     7 runs   (  689.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6089.26 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2703.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.40 ms /    15 tokens (   83.16 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5481.57 ms /     8 runs   (  685.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6751.24 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /     9 runs   (    0.46 ms per token,  2152.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.73 ms /    15 tokens (   83.52 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5524.36 ms /     8 runs   (  690.54 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6804.10 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2641.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.86 ms /    15 tokens (   83.26 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4806.54 ms /     7 runs   (  686.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6075.95 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2699.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.97 ms /    15 tokens (   75.66 ms per token,    13.22 tokens per second)\n",
      "llama_print_timings:        eval time =    4835.42 ms /     7 runs   (  690.77 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5990.01 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2632.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.69 ms /    12 tokens (   84.31 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4773.46 ms /     7 runs   (  681.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5805.57 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2646.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.16 ms /    15 tokens (   83.28 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    5483.76 ms /     8 runs   (  685.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6755.04 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2632.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.18 ms /    15 tokens (   83.28 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4781.80 ms /     7 runs   (  683.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6050.28 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2701.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.71 ms /    15 tokens (   84.11 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =    4802.56 ms /     7 runs   (  686.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6084.50 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2606.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.66 ms /    15 tokens (   85.44 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:        eval time =    5430.02 ms /     8 runs   (  678.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6734.16 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     9 runs   (    0.37 ms per token,  2697.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.06 ms /    15 tokens (   82.80 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5631.53 ms /     8 runs   (  703.94 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6895.67 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     8 runs   (    0.37 ms per token,  2672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.50 ms /    15 tokens (   82.77 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4794.41 ms /     7 runs   (  684.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6055.86 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2606.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.02 ms /    15 tokens (   83.53 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5511.23 ms /     8 runs   (  688.90 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6786.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     9 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.90 ms /    15 tokens (   83.59 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5493.72 ms /     8 runs   (  686.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6770.27 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2712.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.81 ms /    15 tokens (   83.45 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    4812.52 ms /     7 runs   (  687.50 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6084.53 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.86 ms /    15 tokens (   83.39 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4821.11 ms /     7 runs   (  688.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6092.54 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     8 runs   (    0.38 ms per token,  2613.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.13 ms /    15 tokens (   83.61 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4855.16 ms /     7 runs   (  693.59 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6129.66 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     9 runs   (    0.39 ms per token,  2566.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.79 ms /    15 tokens (   82.85 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5543.38 ms /     8 runs   (  692.92 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6808.91 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2714.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.20 ms /    15 tokens (   83.28 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4802.97 ms /     7 runs   (  686.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6072.15 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2665.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.41 ms /    15 tokens (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5517.84 ms /     8 runs   (  689.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6792.90 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     8 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.13 ms /    15 tokens (   83.54 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4884.09 ms /     7 runs   (  697.73 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6157.03 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.65 ms /    15 tokens (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4879.71 ms /     7 runs   (  697.10 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6142.94 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     9 runs   (    0.39 ms per token,  2579.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.35 ms /    15 tokens (   83.36 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5530.39 ms /     8 runs   (  691.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6804.05 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     9 runs   (    0.40 ms per token,  2516.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.84 ms /    15 tokens (   69.59 ms per token,    14.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5564.74 ms /     8 runs   (  695.59 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6631.29 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     8 runs   (    0.39 ms per token,  2592.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.45 ms /    15 tokens (   83.23 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4971.09 ms /     7 runs   (  710.16 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    6239.81 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     8 runs   (    0.37 ms per token,  2691.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.07 ms /    15 tokens (   82.87 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4816.18 ms /     7 runs   (  688.03 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6079.37 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2698.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.31 ms /    15 tokens (   82.89 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5531.61 ms /     8 runs   (  691.45 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6797.08 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2707.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.77 ms /    15 tokens (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    4927.91 ms /     7 runs   (  703.99 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6191.42 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2611.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.57 ms /    15 tokens (   83.50 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5492.02 ms /     8 runs   (  686.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6766.97 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2701.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.12 ms /    15 tokens (   82.81 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5504.02 ms /     8 runs   (  688.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6769.02 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2634.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.18 ms /    15 tokens (   83.55 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4877.80 ms /     7 runs   (  696.83 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6150.63 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2649.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.63 ms /    15 tokens (   82.71 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4783.33 ms /     7 runs   (  683.33 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6043.83 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2327.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.56 ms /    15 tokens (   82.97 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5526.32 ms /     8 runs   (  690.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6796.76 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2664.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.37 ms /    15 tokens (   84.09 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5475.26 ms /     8 runs   (  684.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6758.55 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     9 runs   (    0.39 ms per token,  2563.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.87 ms /    15 tokens (   84.26 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5535.66 ms /     8 runs   (  691.96 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6822.49 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     9 runs   (    0.40 ms per token,  2500.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.43 ms /    15 tokens (   83.50 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5518.05 ms /     8 runs   (  689.76 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6793.37 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /     9 runs   (    0.41 ms per token,  2465.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.03 ms /    15 tokens (   83.40 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5541.10 ms /     8 runs   (  692.64 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6817.21 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2709.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.88 ms /    15 tokens (   83.19 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5535.02 ms /     8 runs   (  691.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6805.58 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2606.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.01 ms /    15 tokens (   83.07 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5475.46 ms /     8 runs   (  684.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6743.81 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2714.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.85 ms /    15 tokens (   83.19 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5501.78 ms /     8 runs   (  687.72 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6772.20 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.58 ms /    15 tokens (   82.77 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5519.58 ms /     8 runs   (  689.95 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6783.65 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2719.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.26 ms /    15 tokens (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5468.35 ms /     8 runs   (  683.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6737.23 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.37 ms /    15 tokens (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =    5474.23 ms /     8 runs   (  684.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6699.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     8 runs   (    0.37 ms per token,  2672.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.12 ms /    15 tokens (   82.87 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4859.72 ms /     7 runs   (  694.25 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6123.15 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2626.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.60 ms /    15 tokens (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5490.66 ms /     8 runs   (  686.33 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6755.79 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.38 ms per token,  2599.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.07 ms /    15 tokens (   82.80 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4938.42 ms /     7 runs   (  705.49 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6200.64 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /     9 runs   (    0.50 ms per token,  1991.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.58 ms /    15 tokens (   83.11 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5663.61 ms /     8 runs   (  707.95 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    6937.37 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /     8 runs   (    0.39 ms per token,  2546.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.69 ms /    15 tokens (   83.31 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =    4895.46 ms /     7 runs   (  699.35 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6164.94 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2637.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.41 ms /    12 tokens (   84.20 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =    4884.83 ms /     7 runs   (  697.83 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    5915.78 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /     8 runs   (    0.40 ms per token,  2511.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.94 ms /    15 tokens (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4969.94 ms /     7 runs   (  709.99 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    6235.89 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2587.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.38 ms /    15 tokens (   71.76 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5447.92 ms /     8 runs   (  680.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6547.96 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.85 ms /    15 tokens (   82.99 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4879.61 ms /     7 runs   (  697.09 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6145.13 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.38 ms per token,  2598.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.18 ms /    15 tokens (   83.88 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4870.62 ms /     7 runs   (  695.80 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6148.41 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     9 runs   (    0.40 ms per token,  2504.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.92 ms /    15 tokens (   82.79 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5547.28 ms /     8 runs   (  693.41 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6812.19 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2630.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.50 ms /    15 tokens (   82.50 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:        eval time =    5664.88 ms /     8 runs   (  708.11 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    6925.62 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     8 runs   (    0.39 ms per token,  2583.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.30 ms /    15 tokens (   82.95 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5003.70 ms /     7 runs   (  714.81 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    6268.71 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     8 runs   (    0.38 ms per token,  2625.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.95 ms /    15 tokens (   83.53 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4914.05 ms /     7 runs   (  702.01 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6187.86 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     9 runs   (    0.39 ms per token,  2542.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.35 ms /    15 tokens (   82.89 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5668.49 ms /     8 runs   (  708.56 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    6935.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     8 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.12 ms /    15 tokens (   82.87 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4884.34 ms /     7 runs   (  697.76 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6147.97 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /     8 runs   (    0.39 ms per token,  2546.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.74 ms /    15 tokens (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4989.13 ms /     7 runs   (  712.73 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    6251.18 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.39 ms per token,  2593.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.58 ms /    15 tokens (   83.11 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    4839.76 ms /     7 runs   (  691.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6107.41 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.39 ms per token,  2593.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.84 ms /    15 tokens (   84.59 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:        eval time =    4939.46 ms /     7 runs   (  705.64 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    6229.17 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /     9 runs   (    0.40 ms per token,  2495.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.64 ms /    15 tokens (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5736.69 ms /     8 runs   (  717.09 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    7002.64 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2587.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1011.02 ms /    12 tokens (   84.25 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5773.47 ms /     8 runs   (  721.68 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    6807.68 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.33 ms /    15 tokens (   83.02 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4947.54 ms /     7 runs   (  706.79 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    6213.13 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2675.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.41 ms /    12 tokens (   84.12 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5598.75 ms /     8 runs   (  699.84 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6631.56 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     8 runs   (    0.39 ms per token,  2585.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.76 ms /    15 tokens (   83.25 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4845.46 ms /     7 runs   (  692.21 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6114.01 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2633.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.50 ms /    15 tokens (   82.97 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5581.38 ms /     8 runs   (  697.67 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6848.39 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.41 ms /    15 tokens (   82.83 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5469.36 ms /     8 runs   (  683.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6734.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2632.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.89 ms /    15 tokens (   82.99 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4857.46 ms /     7 runs   (  693.92 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6122.27 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2625.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.50 ms /    15 tokens (   83.03 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5586.17 ms /     8 runs   (  698.27 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6854.76 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /     8 runs   (    0.37 ms per token,  2716.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.19 ms /    15 tokens (   82.68 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4863.48 ms /     7 runs   (  694.78 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6123.12 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.39 ms per token,  2593.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5517.12 ms /     8 runs   (  689.64 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5536.84 ms /     9 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2705.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.42 ms /    15 tokens (   81.49 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:        eval time =    5375.18 ms /     8 runs   (  671.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6619.26 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     9 runs   (    0.37 ms per token,  2692.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.81 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =    5371.63 ms /     8 runs   (  671.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6163.75 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     8 runs   (    0.37 ms per token,  2733.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.73 ms /    15 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4759.71 ms /     7 runs   (  679.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5560.99 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2676.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.79 ms /    15 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =    5330.84 ms /     8 runs   (  666.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6138.16 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2687.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.47 ms /    12 tokens (   55.62 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5362.62 ms /     8 runs   (  670.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6052.48 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2688.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.25 ms /    15 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =    5429.95 ms /     8 runs   (  678.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6221.51 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2701.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.94 ms /    15 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5443.55 ms /     8 runs   (  680.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6245.15 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2722.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.82 ms /    15 tokens (   51.99 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =    5392.76 ms /     8 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6194.31 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     8 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.80 ms /    15 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4753.00 ms /     7 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5579.79 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2685.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.85 ms /    15 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4674.44 ms /     7 runs   (  667.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    5482.63 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2654.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.57 ms /    15 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    5450.93 ms /     8 runs   (  681.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6276.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2704.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.50 ms /    15 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =    4788.90 ms /     7 runs   (  684.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5593.76 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     9 runs   (    0.38 ms per token,  2614.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.57 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =    5408.73 ms /     8 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6196.42 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2661.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.62 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =    5517.72 ms /     8 runs   (  689.71 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6175.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     8 runs   (    0.36 ms per token,  2766.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.16 ms /    15 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4715.98 ms /     7 runs   (  673.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5524.28 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2715.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.83 ms /    15 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =    5443.31 ms /     8 runs   (  680.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6229.89 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     8 runs   (    0.37 ms per token,  2679.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.61 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =    4717.54 ms /     7 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5503.02 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2630.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.38 ms /    15 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =    5475.09 ms /     8 runs   (  684.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6280.56 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     8 runs   (    0.36 ms per token,  2766.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.96 ms /    15 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4801.94 ms /     7 runs   (  685.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5612.75 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     9 runs   (    0.39 ms per token,  2556.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.83 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =    5486.10 ms /     8 runs   (  685.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6277.39 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /     8 runs   (    0.36 ms per token,  2749.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.54 ms /    15 tokens (   55.97 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =    4761.80 ms /     7 runs   (  680.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5620.46 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 200th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     8 runs   (    0.37 ms per token,  2728.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     875.75 ms /    16 tokens (   54.73 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =    4805.96 ms /     7 runs   (  686.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5701.46 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     8 runs   (    0.38 ms per token,  2623.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     970.37 ms /    15 tokens (   64.69 ms per token,    15.46 tokens per second)\n",
      "llama_print_timings:        eval time =    4759.52 ms /     7 runs   (  679.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5749.14 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2687.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.55 ms /    15 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5455.68 ms /     8 runs   (  681.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6267.82 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     9 runs   (    0.39 ms per token,  2559.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.61 ms /    15 tokens (   74.11 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    5604.44 ms /     8 runs   (  700.56 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6739.50 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.08 ms /    15 tokens (   82.94 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5549.79 ms /     8 runs   (  693.72 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6817.02 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2630.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.60 ms /    15 tokens (   70.44 ms per token,    14.20 tokens per second)\n",
      "llama_print_timings:        eval time =    5489.49 ms /     8 runs   (  686.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6569.58 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     8 runs   (    0.39 ms per token,  2585.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.68 ms /    15 tokens (   72.18 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4808.32 ms /     7 runs   (  686.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5911.46 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.64 ms /    12 tokens (   64.30 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4923.51 ms /     7 runs   (  703.36 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    5715.66 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2647.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.30 ms /    15 tokens (   76.29 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =    5546.03 ms /     8 runs   (  693.25 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6713.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2635.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.99 ms /    15 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    4767.40 ms /     7 runs   (  681.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5584.02 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2704.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.56 ms /    15 tokens (   70.57 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =    5463.57 ms /     8 runs   (  682.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6545.53 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.54 ms /    15 tokens (   70.77 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5449.35 ms /     8 runs   (  681.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6534.04 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     9 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.94 ms /    15 tokens (   76.60 ms per token,    13.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5442.00 ms /     8 runs   (  680.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6614.60 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2594.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.90 ms /    15 tokens (   71.73 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5520.30 ms /     8 runs   (  690.04 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6619.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2586.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.91 ms /    15 tokens (   73.39 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    5441.90 ms /     8 runs   (  680.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6566.60 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2585.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     866.51 ms /    12 tokens (   72.21 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =    5496.51 ms /     8 runs   (  687.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6386.08 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2658.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.81 ms /    15 tokens (   83.12 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5412.28 ms /     8 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6682.63 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2667.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.31 ms /    15 tokens (   82.62 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:        eval time =    5458.19 ms /     8 runs   (  682.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6721.21 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2589.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     863.22 ms /    12 tokens (   71.94 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =    5445.31 ms /     8 runs   (  680.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6332.54 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2665.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.57 ms /    15 tokens (   71.84 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    5505.18 ms /     8 runs   (  688.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6606.26 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2609.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.52 ms /    15 tokens (   82.63 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:        eval time =    5502.67 ms /     8 runs   (  687.83 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6765.73 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.03 ms /    15 tokens (   83.47 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5469.86 ms /     8 runs   (  683.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6744.97 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2596.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.67 ms /    15 tokens (   71.91 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =    5456.44 ms /     8 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6558.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2609.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.03 ms /    15 tokens (   72.00 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5481.46 ms /     8 runs   (  685.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6585.43 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /     9 runs   (    0.40 ms per token,  2482.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     981.15 ms /    12 tokens (   81.76 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:        eval time =    5544.17 ms /     8 runs   (  693.02 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6550.42 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.02 ms /    15 tokens (   77.60 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:        eval time =     709.06 ms /     1 runs   (  709.06 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1879.49 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     896.81 ms /    12 tokens (   74.73 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =     666.69 ms /     1 runs   (  666.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1568.68 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2595.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.85 ms /    15 tokens (   74.92 ms per token,    13.35 tokens per second)\n",
      "llama_print_timings:        eval time =    5489.30 ms /     8 runs   (  686.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6637.80 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2595.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.21 ms /    15 tokens (   71.41 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5460.21 ms /     8 runs   (  682.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6556.13 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     9 runs   (    0.40 ms per token,  2513.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.47 ms /    15 tokens (   75.83 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:        eval time =    5492.59 ms /     8 runs   (  686.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6654.56 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2708.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.36 ms /    15 tokens (   74.89 ms per token,    13.35 tokens per second)\n",
      "llama_print_timings:        eval time =    5446.69 ms /     8 runs   (  680.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6594.57 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2661.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.69 ms /    15 tokens (   74.71 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =    5444.31 ms /     8 runs   (  680.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6588.57 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2623.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.60 ms /    15 tokens (   83.24 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    5424.12 ms /     8 runs   (  678.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6695.96 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2626.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.21 ms /    15 tokens (   71.61 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5429.70 ms /     8 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6526.97 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2585.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.77 ms /    15 tokens (   70.25 ms per token,    14.23 tokens per second)\n",
      "llama_print_timings:        eval time =    5500.77 ms /     8 runs   (  687.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6579.11 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     9 runs   (    0.40 ms per token,  2502.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    6179.51 ms /     9 runs   (  686.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6203.44 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     9 runs   (    0.39 ms per token,  2540.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.52 ms /    15 tokens (   72.97 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    5452.28 ms /     8 runs   (  681.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6570.80 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     9 runs   (    0.39 ms per token,  2567.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.73 ms /    15 tokens (   71.78 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5467.52 ms /     8 runs   (  683.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6567.65 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2636.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.22 ms /    15 tokens (   83.68 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5462.18 ms /     8 runs   (  682.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6740.81 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2587.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.32 ms /    15 tokens (   77.29 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5429.06 ms /     8 runs   (  678.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6612.51 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     9 runs   (    0.39 ms per token,  2540.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.07 ms /    15 tokens (   73.47 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =    5489.24 ms /     8 runs   (  686.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6615.33 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2607.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.08 ms /    15 tokens (   71.94 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =    5517.26 ms /     8 runs   (  689.66 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6619.87 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.69 ms /    15 tokens (   74.38 ms per token,    13.44 tokens per second)\n",
      "llama_print_timings:        eval time =    4820.22 ms /     7 runs   (  688.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5958.24 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2650.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.37 ms /    15 tokens (   72.56 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =    5411.71 ms /     8 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6523.61 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     9 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.49 ms /    15 tokens (   71.83 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    5395.58 ms /     8 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6497.25 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2644.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.83 ms /    15 tokens (   83.12 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5519.50 ms /     8 runs   (  689.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6790.55 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.94 ms /    15 tokens (   78.33 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5481.90 ms /     8 runs   (  685.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6680.15 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2699.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.22 ms /    15 tokens (   73.48 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =    5403.10 ms /     8 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6528.49 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.21 ms /    15 tokens (   77.75 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:        eval time =     695.30 ms /     1 runs   (  695.30 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1866.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2658.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.35 ms /    15 tokens (   83.62 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5470.50 ms /     8 runs   (  683.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6748.80 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2690.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.64 ms /    15 tokens (   78.38 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:        eval time =    5512.19 ms /     8 runs   (  689.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6711.21 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2639.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.13 ms /    15 tokens (   84.14 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =    5493.19 ms /     8 runs   (  686.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6778.93 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     9 runs   (    0.39 ms per token,  2567.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.44 ms /    15 tokens (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:        eval time =    5476.01 ms /     8 runs   (  684.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6687.81 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2680.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.58 ms /    15 tokens (   79.31 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:        eval time =    5514.93 ms /     8 runs   (  689.37 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6727.78 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2606.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.89 ms /    15 tokens (   79.06 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:        eval time =    5505.83 ms /     8 runs   (  688.23 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6715.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.12 ms /    15 tokens (   73.81 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    5513.95 ms /     8 runs   (  689.24 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6644.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.81 ms /    15 tokens (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:        eval time =    5457.56 ms /     8 runs   (  682.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6693.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2640.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.01 ms /    15 tokens (   83.53 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    5484.70 ms /     8 runs   (  685.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6761.67 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2591.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.45 ms /    15 tokens (   72.76 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =    5512.93 ms /     8 runs   (  689.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6628.64 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     8 runs   (    0.38 ms per token,  2664.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.09 ms /    15 tokens (   74.21 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =    4728.03 ms /     7 runs   (  675.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5862.32 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2635.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.87 ms /    15 tokens (   77.79 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4739.75 ms /     7 runs   (  677.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5927.77 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2640.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.86 ms /    15 tokens (   76.66 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5464.94 ms /     8 runs   (  683.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6639.06 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     9 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.66 ms /    15 tokens (   71.04 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5431.87 ms /     8 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6521.27 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2598.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.35 ms /    15 tokens (   75.42 ms per token,    13.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5392.75 ms /     8 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6548.64 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     9 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.14 ms /    15 tokens (   70.74 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =    5385.28 ms /     8 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6470.08 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     8 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.67 ms /    15 tokens (   70.31 ms per token,    14.22 tokens per second)\n",
      "llama_print_timings:        eval time =    4820.97 ms /     7 runs   (  688.71 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5897.55 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2586.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.82 ms /    15 tokens (   73.92 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    5504.39 ms /     8 runs   (  688.05 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6637.38 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2639.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.60 ms /    15 tokens (   79.77 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:        eval time =    5449.49 ms /     8 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6670.36 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     9 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.43 ms /    15 tokens (   77.70 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5456.87 ms /     8 runs   (  682.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6646.02 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2629.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.64 ms /    15 tokens (   72.18 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    5465.07 ms /     8 runs   (  683.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6572.75 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     8 runs   (    0.39 ms per token,  2555.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.39 ms /    15 tokens (   77.83 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4756.90 ms /     7 runs   (  679.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5945.18 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     8 runs   (    0.38 ms per token,  2655.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.84 ms /    15 tokens (   70.26 ms per token,    14.23 tokens per second)\n",
      "llama_print_timings:        eval time =    4795.08 ms /     7 runs   (  685.01 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5869.78 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.49 ms /    15 tokens (   71.03 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5549.89 ms /     8 runs   (  693.74 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6639.27 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2589.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.95 ms /    15 tokens (   83.46 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5532.56 ms /     8 runs   (  691.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6808.09 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /     9 runs   (    0.45 ms per token,  2204.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.71 ms /    15 tokens (   71.31 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5512.78 ms /     8 runs   (  689.10 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6608.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2639.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.27 ms /    15 tokens (   73.02 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    4832.05 ms /     7 runs   (  690.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    5949.44 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2644.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.26 ms /    15 tokens (   71.55 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5495.34 ms /     8 runs   (  686.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6592.31 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2707.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.69 ms /    15 tokens (   76.05 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =    4620.13 ms /     7 runs   (  660.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    5781.39 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2603.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.10 ms /    15 tokens (   70.81 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =    5434.01 ms /     8 runs   (  679.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6519.66 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2669.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     880.99 ms /    12 tokens (   73.42 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =    5541.28 ms /     8 runs   (  692.66 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6445.98 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2599.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.71 ms /    15 tokens (   83.85 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5477.71 ms /     8 runs   (  684.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6759.48 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2661.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.20 ms /    15 tokens (   71.48 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5542.41 ms /     8 runs   (  692.80 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6638.55 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2646.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.87 ms /    15 tokens (   72.39 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5518.69 ms /     8 runs   (  689.84 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6628.70 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2623.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.67 ms /    15 tokens (   73.78 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    5477.66 ms /     8 runs   (  684.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6608.60 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2709.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.47 ms /    15 tokens (   75.36 ms per token,    13.27 tokens per second)\n",
      "llama_print_timings:        eval time =    4737.19 ms /     7 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5889.19 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2596.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.24 ms /    15 tokens (   81.55 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5361.15 ms /     8 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6608.77 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2626.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     934.47 ms /    12 tokens (   77.87 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5357.93 ms /     8 runs   (  669.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6317.19 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     9 runs   (    0.39 ms per token,  2571.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.18 ms /    15 tokens (   83.61 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5347.21 ms /     8 runs   (  668.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    6625.03 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.62 ms /    15 tokens (   83.37 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =     659.55 ms /     1 runs   (  659.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1916.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     9 runs   (    0.39 ms per token,  2578.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.67 ms /    15 tokens (   74.58 ms per token,    13.41 tokens per second)\n",
      "llama_print_timings:        eval time =    5542.77 ms /     8 runs   (  692.85 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6685.80 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2609.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.64 ms /    15 tokens (   70.64 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =    5555.24 ms /     8 runs   (  694.40 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6638.18 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     8 runs   (    0.39 ms per token,  2572.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.94 ms /    15 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =    4780.07 ms /     7 runs   (  682.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5617.74 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.29 ms /    15 tokens (   73.35 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    5475.07 ms /     8 runs   (  684.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6598.96 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2644.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.54 ms /    15 tokens (   72.10 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =    4754.00 ms /     7 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    5856.48 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.71 ms /    15 tokens (   73.85 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =    5459.69 ms /     8 runs   (  682.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6591.12 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2689.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.03 ms /    15 tokens (   73.80 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    5491.58 ms /     8 runs   (  686.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6621.79 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     8 runs   (    0.39 ms per token,  2579.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.45 ms /    15 tokens (   83.63 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4751.73 ms /     7 runs   (  678.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6027.26 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.38 ms /    15 tokens (   71.29 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =     676.49 ms /     1 runs   (  676.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1751.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     9 runs   (    0.39 ms per token,  2581.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1180.25 ms /    15 tokens (   78.68 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:        eval time =    5540.68 ms /     8 runs   (  692.59 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6744.82 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2654.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.73 ms /    15 tokens (   71.72 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5571.08 ms /     8 runs   (  696.38 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6670.62 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 300th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2719.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.33 ms /    15 tokens (   79.49 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:        eval time =    5491.19 ms /     8 runs   (  686.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6707.77 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.72 ms /    10 runs   (    0.37 ms per token,  2689.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.71 ms /    15 tokens (   73.65 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    6124.91 ms /     9 runs   (  680.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7255.79 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    10 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.81 ms /    15 tokens (   74.45 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =    6248.22 ms /     9 runs   (  694.25 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7392.08 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2627.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.99 ms /    15 tokens (   71.40 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =    6182.96 ms /     9 runs   (  687.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7280.34 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2609.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.15 ms /    15 tokens (   83.28 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    6112.22 ms /     9 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7388.26 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    10 runs   (    0.39 ms per token,  2592.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.29 ms /    15 tokens (   71.75 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6149.62 ms /     9 runs   (  683.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7253.05 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2626.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.21 ms /    15 tokens (   71.68 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =    6125.57 ms /     9 runs   (  680.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7227.04 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    10 runs   (    0.38 ms per token,  2644.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.21 ms /    15 tokens (   70.55 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6126.53 ms /     9 runs   (  680.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7211.48 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2676.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.78 ms /    15 tokens (   72.12 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5392.77 ms /     8 runs   (  674.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6498.46 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    10 runs   (    0.38 ms per token,  2633.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.70 ms /    15 tokens (   84.38 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =    6070.40 ms /     9 runs   (  674.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7362.21 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    10 runs   (    0.38 ms per token,  2648.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.65 ms /    15 tokens (   79.51 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:        eval time =    6185.52 ms /     9 runs   (  687.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7404.31 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /    10 runs   (    0.40 ms per token,  2505.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.89 ms /    15 tokens (   71.93 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =    6102.85 ms /     9 runs   (  678.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7210.02 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /    10 runs   (    0.40 ms per token,  2529.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.74 ms /    15 tokens (   72.25 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6239.06 ms /     9 runs   (  693.23 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7350.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2626.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.86 ms /    15 tokens (   72.86 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =    5432.77 ms /     8 runs   (  679.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6549.21 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    10 runs   (    0.38 ms per token,  2616.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.76 ms /    15 tokens (   79.92 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6158.85 ms /     9 runs   (  684.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7384.51 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2593.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.58 ms /    15 tokens (   70.51 ms per token,    14.18 tokens per second)\n",
      "llama_print_timings:        eval time =    5544.03 ms /     8 runs   (  693.00 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6625.76 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2601.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.84 ms /    15 tokens (   73.92 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6270.64 ms /     9 runs   (  696.74 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7406.01 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2600.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.38 ms /    15 tokens (   70.76 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5474.59 ms /     8 runs   (  684.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6559.96 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    10 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.16 ms /    15 tokens (   77.08 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6087.22 ms /     9 runs   (  676.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7269.86 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    10 runs   (    0.37 ms per token,  2668.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.59 ms /    15 tokens (   85.44 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6144.73 ms /     9 runs   (  682.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7453.51 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2592.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     887.58 ms /    12 tokens (   73.97 ms per token,    13.52 tokens per second)\n",
      "llama_print_timings:        eval time =    5445.09 ms /     8 runs   (  680.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6357.00 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    10 runs   (    0.39 ms per token,  2559.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.14 ms /    15 tokens (   78.34 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6180.93 ms /     9 runs   (  686.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7384.34 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2606.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.74 ms /    15 tokens (   73.65 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    6110.82 ms /     9 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7242.25 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2670.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.96 ms /    15 tokens (   82.40 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:        eval time =    5456.99 ms /     8 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6717.01 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    10 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.32 ms /    15 tokens (   83.29 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    6192.33 ms /     9 runs   (  688.04 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7468.40 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    10 runs   (    0.39 ms per token,  2593.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.04 ms /    15 tokens (   83.34 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =    6151.60 ms /     9 runs   (  683.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7428.94 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2684.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.73 ms /    15 tokens (   75.38 ms per token,    13.27 tokens per second)\n",
      "llama_print_timings:        eval time =    5425.38 ms /     8 runs   (  678.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6580.63 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     9 runs   (    0.39 ms per token,  2566.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.89 ms /    15 tokens (   83.59 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5535.55 ms /     8 runs   (  691.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6813.40 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     8 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.29 ms /    15 tokens (   78.55 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:        eval time =    4799.96 ms /     7 runs   (  685.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5999.45 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2658.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.03 ms /    15 tokens (   71.54 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5495.45 ms /     8 runs   (  686.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6591.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     9 runs   (    0.39 ms per token,  2559.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.60 ms /    15 tokens (   65.24 ms per token,    15.33 tokens per second)\n",
      "llama_print_timings:        eval time =    5438.32 ms /     8 runs   (  679.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6440.04 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    10 runs   (    0.37 ms per token,  2713.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.69 ms /    15 tokens (   70.78 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6144.12 ms /     9 runs   (  682.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7231.83 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2610.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.19 ms /    15 tokens (   71.35 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =    6151.81 ms /     9 runs   (  683.53 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7248.85 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    10 runs   (    0.38 ms per token,  2646.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.72 ms /    15 tokens (   72.71 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6048.05 ms /     9 runs   (  672.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7166.17 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2710.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.61 ms /    15 tokens (   73.04 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =    5421.53 ms /     8 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6541.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     9 runs   (    0.39 ms per token,  2545.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.59 ms /    15 tokens (   71.44 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5520.96 ms /     8 runs   (  690.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6616.57 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    10 runs   (    0.39 ms per token,  2570.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.69 ms /    15 tokens (   74.58 ms per token,    13.41 tokens per second)\n",
      "llama_print_timings:        eval time =    6185.95 ms /     9 runs   (  687.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    7332.48 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     9 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.70 ms /    15 tokens (   83.45 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5516.62 ms /     8 runs   (  689.58 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6792.83 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    10 runs   (    0.38 ms per token,  2619.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.55 ms /    15 tokens (   72.10 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6154.50 ms /     9 runs   (  683.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7262.91 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2628.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.55 ms /    15 tokens (   76.50 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5517.10 ms /     8 runs   (  689.64 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6688.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /    10 runs   (    0.37 ms per token,  2670.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.04 ms /    15 tokens (   71.27 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6139.26 ms /     9 runs   (  682.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7235.09 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    10 runs   (    0.45 ms per token,  2241.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.62 ms /    15 tokens (   76.57 ms per token,    13.06 tokens per second)\n",
      "llama_print_timings:        eval time =    6126.99 ms /     9 runs   (  680.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7307.35 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.87 ms /    15 tokens (   71.19 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =    6231.49 ms /     9 runs   (  692.39 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7326.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2627.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.81 ms /    15 tokens (   83.12 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6114.98 ms /     9 runs   (  679.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7389.30 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /    10 runs   (    0.39 ms per token,  2532.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.27 ms /    15 tokens (   72.08 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6093.55 ms /     9 runs   (  677.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7202.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2623.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.80 ms /    15 tokens (   75.45 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    6104.91 ms /     9 runs   (  678.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7263.78 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2606.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.22 ms /    15 tokens (   75.21 ms per token,    13.30 tokens per second)\n",
      "llama_print_timings:        eval time =    6157.15 ms /     9 runs   (  684.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7312.00 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     9 runs   (    0.39 ms per token,  2551.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.57 ms /    15 tokens (   76.90 ms per token,    13.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5356.30 ms /     8 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6535.15 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2681.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     874.82 ms /    12 tokens (   72.90 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    5446.70 ms /     8 runs   (  680.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6345.42 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /    10 runs   (    0.39 ms per token,  2565.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.78 ms /    15 tokens (   72.59 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =    6130.25 ms /     9 runs   (  681.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7247.03 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    10 runs   (    0.39 ms per token,  2584.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.81 ms /    15 tokens (   83.12 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6062.35 ms /     9 runs   (  673.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7337.51 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2583.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.16 ms /    15 tokens (   73.28 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =    5485.05 ms /     8 runs   (  685.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6609.68 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2643.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.01 ms /    15 tokens (   71.67 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5435.44 ms /     8 runs   (  679.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6534.38 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2650.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     879.13 ms /    12 tokens (   73.26 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =    5436.06 ms /     8 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6339.08 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     9 runs   (    0.37 ms per token,  2693.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.72 ms /    15 tokens (   72.91 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =    5484.74 ms /     8 runs   (  685.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6602.86 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.79 ms /    15 tokens (   73.99 ms per token,    13.52 tokens per second)\n",
      "llama_print_timings:        eval time =    6113.19 ms /     9 runs   (  679.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7249.72 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    10 runs   (    0.39 ms per token,  2569.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.67 ms /    15 tokens (   80.58 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:        eval time =    6141.02 ms /     9 runs   (  682.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7375.81 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2626.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.48 ms /    15 tokens (   83.10 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6165.32 ms /     9 runs   (  685.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7437.73 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     9 runs   (    0.39 ms per token,  2589.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.61 ms /    15 tokens (   73.51 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    5551.25 ms /     8 runs   (  693.91 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    6679.17 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    10 runs   (    0.39 ms per token,  2579.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.65 ms /    15 tokens (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6123.31 ms /     9 runs   (  680.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7382.83 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    10 runs   (    0.38 ms per token,  2656.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.98 ms /    15 tokens (   71.33 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =    6107.34 ms /     9 runs   (  678.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7203.83 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    10 runs   (    0.38 ms per token,  2634.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.52 ms /    15 tokens (   74.50 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =    6160.14 ms /     9 runs   (  684.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7304.68 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2650.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.06 ms /    15 tokens (   83.40 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5420.80 ms /     8 runs   (  677.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6695.47 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     9 runs   (    0.40 ms per token,  2505.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.79 ms /    15 tokens (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:        eval time =    5386.52 ms /     8 runs   (  673.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    6629.55 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2606.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.41 ms /    15 tokens (   74.23 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =    6125.20 ms /     9 runs   (  680.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7264.91 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2621.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.19 ms /    15 tokens (   76.15 ms per token,    13.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6080.48 ms /     9 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7248.91 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2710.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.26 ms /    15 tokens (   72.15 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    5454.10 ms /     8 runs   (  681.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6560.05 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /    10 runs   (    0.37 ms per token,  2673.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.61 ms /    15 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6187.44 ms /     9 runs   (  687.49 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6990.83 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2690.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.64 ms /    15 tokens (   70.78 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5504.50 ms /     8 runs   (  688.06 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6589.94 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.45 ms /    15 tokens (   74.03 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6131.81 ms /     9 runs   (  681.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7268.87 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2604.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.11 ms /    15 tokens (   72.01 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5423.99 ms /     8 runs   (  678.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6527.99 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.38 ms per token,  2598.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.23 ms /    15 tokens (   70.68 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =    6134.07 ms /     9 runs   (  681.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7220.98 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2651.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.61 ms /    15 tokens (   71.97 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5469.88 ms /     8 runs   (  683.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6574.78 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2623.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.85 ms /    15 tokens (   70.92 ms per token,    14.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6061.98 ms /     9 runs   (  673.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7152.71 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    10 runs   (    0.39 ms per token,  2579.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.82 ms /    15 tokens (   72.05 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    6139.89 ms /     9 runs   (  682.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7248.04 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2613.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.10 ms /    15 tokens (   70.67 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =    6094.61 ms /     9 runs   (  677.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7181.19 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    10 runs   (    0.38 ms per token,  2650.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.94 ms /    15 tokens (   71.53 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =    6135.74 ms /     9 runs   (  681.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7236.38 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2610.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.31 ms /    15 tokens (   75.69 ms per token,    13.21 tokens per second)\n",
      "llama_print_timings:        eval time =    5609.98 ms /     8 runs   (  701.25 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6770.13 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /    10 runs   (    0.37 ms per token,  2698.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.40 ms /    15 tokens (   83.09 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6230.96 ms /     9 runs   (  692.33 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7504.73 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.56 ms /    15 tokens (   83.30 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5399.41 ms /     8 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6673.32 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    10 runs   (    0.38 ms per token,  2628.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.84 ms /    15 tokens (   72.92 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =    6167.24 ms /     9 runs   (  685.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7288.45 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    10 runs   (    0.39 ms per token,  2579.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.39 ms /    15 tokens (   83.43 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6069.17 ms /     9 runs   (  674.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7347.78 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    10 runs   (    0.38 ms per token,  2653.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.90 ms /    15 tokens (   70.79 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6059.82 ms /     9 runs   (  673.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7147.93 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2595.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.89 ms /    15 tokens (   76.79 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =    5482.79 ms /     8 runs   (  685.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6658.78 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    10 runs   (    0.38 ms per token,  2637.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.66 ms /    15 tokens (   73.31 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6096.54 ms /     9 runs   (  677.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7222.39 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     9 runs   (    0.39 ms per token,  2558.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.50 ms /    15 tokens (   72.43 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5406.59 ms /     8 runs   (  675.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6516.77 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2600.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     887.04 ms /    12 tokens (   73.92 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    5450.77 ms /     8 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6361.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2661.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.70 ms /    15 tokens (   73.71 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    5512.36 ms /     8 runs   (  689.04 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    6643.19 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2668.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.79 ms /    15 tokens (   74.39 ms per token,    13.44 tokens per second)\n",
      "llama_print_timings:        eval time =    5416.99 ms /     8 runs   (  677.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    6556.27 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    10 runs   (    0.39 ms per token,  2581.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.18 ms /    15 tokens (   76.68 ms per token,    13.04 tokens per second)\n",
      "llama_print_timings:        eval time =    6100.40 ms /     9 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7277.63 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2640.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     944.24 ms /    12 tokens (   78.69 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:        eval time =    5594.72 ms /     8 runs   (  699.34 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    6563.06 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2636.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     865.28 ms /    12 tokens (   72.11 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5473.77 ms /     8 runs   (  684.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6363.45 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    10 runs   (    0.38 ms per token,  2656.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.96 ms /    15 tokens (   71.20 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =    6077.54 ms /     9 runs   (  675.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7172.17 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.20 ms /    15 tokens (   71.88 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =    5461.87 ms /     8 runs   (  682.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6564.76 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2608.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.36 ms /    12 tokens (   85.78 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6097.34 ms /     9 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7154.98 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     8 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.71 ms /    15 tokens (   73.51 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4803.79 ms /     7 runs   (  686.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    5928.73 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2610.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1082.38 ms /    15 tokens (   72.16 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6249.82 ms /     9 runs   (  694.42 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    7360.16 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.38 ms per token,  2598.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.79 ms /    15 tokens (   73.19 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6151.61 ms /     9 runs   (  683.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7276.09 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2643.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1087.26 ms /    15 tokens (   72.48 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =    5472.23 ms /     8 runs   (  684.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    6583.37 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    10 runs   (    0.38 ms per token,  2643.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.92 ms /    15 tokens (   77.39 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6113.94 ms /     9 runs   (  679.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7302.08 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 400th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /    11 runs   (    0.37 ms per token,  2706.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.36 ms /    18 tokens (   74.85 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =    6753.61 ms /    10 runs   (  675.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8130.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.28 ms /    17 tokens (   74.96 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =    7397.09 ms /    11 runs   (  672.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8702.75 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    12 runs   (    0.37 ms per token,  2685.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.87 ms /    17 tokens (   73.52 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    7525.18 ms /    11 runs   (  684.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8806.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    11 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.04 ms /    17 tokens (   74.00 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6841.75 ms /    10 runs   (  684.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8129.21 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /    11 runs   (    0.37 ms per token,  2690.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.28 ms /    16 tokens (   69.64 ms per token,    14.36 tokens per second)\n",
      "llama_print_timings:        eval time =    6881.96 ms /    10 runs   (  688.20 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8025.23 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.48 ms /    17 tokens (   74.68 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:        eval time =    7468.62 ms /    11 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8770.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    12 runs   (    0.37 ms per token,  2702.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.87 ms /    17 tokens (   77.58 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:        eval time =    7583.60 ms /    11 runs   (  689.42 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8934.48 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2636.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.97 ms /    16 tokens (   72.75 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7415.74 ms /    11 runs   (  674.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8611.79 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.38 ms per token,  2665.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.88 ms /    17 tokens (   84.99 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:        eval time =    7518.64 ms /    11 runs   (  683.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8995.67 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    11 runs   (    0.37 ms per token,  2668.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.09 ms /    16 tokens (   72.07 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    6868.05 ms /    10 runs   (  686.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8050.80 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    12 runs   (    0.37 ms per token,  2711.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.90 ms /    17 tokens (   75.41 ms per token,    13.26 tokens per second)\n",
      "llama_print_timings:        eval time =    7465.23 ms /    11 runs   (  678.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8779.40 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2623.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.15 ms /    17 tokens (   85.30 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7480.32 ms /    11 runs   (  680.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8962.81 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.52 ms /    16 tokens (   83.16 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    7354.46 ms /    11 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8717.71 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.35 ms /    17 tokens (   72.67 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7559.61 ms /    11 runs   (  687.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8827.66 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    11 runs   (    0.36 ms per token,  2740.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.80 ms /    17 tokens (   75.69 ms per token,    13.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6834.50 ms /    10 runs   (  683.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8150.35 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2649.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.11 ms /    17 tokens (   78.30 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:        eval time =    7484.25 ms /    11 runs   (  680.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8847.60 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2674.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.14 ms /    16 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =    6768.36 ms /    10 runs   (  676.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7954.41 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    11 runs   (    0.37 ms per token,  2673.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.81 ms /    17 tokens (   71.28 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6741.36 ms /    10 runs   (  674.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7981.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    11 runs   (    0.38 ms per token,  2644.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.85 ms /    17 tokens (   77.17 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6823.74 ms /    10 runs   (  682.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8165.42 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    11 runs   (    0.54 ms per token,  1839.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.88 ms /    17 tokens (   72.99 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6769.34 ms /    10 runs   (  676.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8048.70 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.39 ms per token,  2596.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.58 ms /    17 tokens (   79.80 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7518.32 ms /    11 runs   (  683.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8906.77 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    12 runs   (    0.37 ms per token,  2713.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.24 ms /    17 tokens (   85.13 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7424.56 ms /    11 runs   (  674.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8905.25 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2636.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.92 ms /    17 tokens (   84.11 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =    7508.45 ms /    11 runs   (  682.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8970.88 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /    11 runs   (    0.38 ms per token,  2664.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.47 ms /    17 tokens (   76.79 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =    6870.00 ms /    10 runs   (  687.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8205.90 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    12 runs   (    0.37 ms per token,  2687.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.41 ms /    17 tokens (   75.20 ms per token,    13.30 tokens per second)\n",
      "llama_print_timings:        eval time =    7456.75 ms /    11 runs   (  677.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8768.35 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2609.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.17 ms /    17 tokens (   73.48 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =    7417.64 ms /    11 runs   (  674.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8699.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2660.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.61 ms /    17 tokens (   74.98 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =    7417.56 ms /    11 runs   (  674.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8725.02 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /    11 runs   (    0.37 ms per token,  2690.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.00 ms /    17 tokens (   72.24 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6930.36 ms /    10 runs   (  693.04 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8188.61 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2593.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.35 ms /    17 tokens (   78.61 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7524.47 ms /    11 runs   (  684.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8893.86 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2658.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1522.76 ms /    17 tokens (   89.57 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:        eval time =    7509.07 ms /    11 runs   (  682.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9064.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2614.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.92 ms /    17 tokens (   74.70 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:        eval time =    7614.15 ms /    11 runs   (  692.20 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8918.17 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    12 runs   (    0.37 ms per token,  2677.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.47 ms /    17 tokens (   74.44 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =    7477.14 ms /    11 runs   (  679.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8774.82 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    11 runs   (    0.39 ms per token,  2579.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.35 ms /    17 tokens (   85.20 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6767.90 ms /    10 runs   (  676.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8246.16 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    11 runs   (    0.37 ms per token,  2728.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     968.09 ms /    13 tokens (   74.47 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =    6789.85 ms /    10 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7787.90 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2637.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.34 ms /    17 tokens (   73.84 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7558.72 ms /    11 runs   (  687.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8846.09 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    11 runs   (    0.37 ms per token,  2684.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.10 ms /    17 tokens (   81.18 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:        eval time =    6842.39 ms /    10 runs   (  684.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8251.45 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    12 runs   (    0.37 ms per token,  2716.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.99 ms /    17 tokens (   74.47 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =    7420.26 ms /    11 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8718.45 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    11 runs   (    0.38 ms per token,  2648.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.41 ms /    17 tokens (   74.14 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6911.90 ms /    10 runs   (  691.19 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8201.79 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /    11 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.85 ms /    17 tokens (   80.52 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:        eval time =    6822.21 ms /    10 runs   (  682.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8221.14 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    12 runs   (    0.37 ms per token,  2683.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.28 ms /    17 tokens (   72.25 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7436.08 ms /    11 runs   (  676.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8696.23 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2677.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.25 ms /    16 tokens (   74.14 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6826.16 ms /    10 runs   (  682.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8042.94 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2612.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.60 ms /    17 tokens (   85.74 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =    7460.28 ms /    11 runs   (  678.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8949.87 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2609.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.96 ms /    17 tokens (   72.12 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =    7443.40 ms /    11 runs   (  676.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8701.73 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2676.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.99 ms /    17 tokens (   76.06 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =    6862.00 ms /    10 runs   (  686.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8184.59 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2648.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.20 ms /    17 tokens (   84.07 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =    7470.60 ms /    11 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8931.80 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    12 runs   (    0.37 ms per token,  2694.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.10 ms /    17 tokens (   81.65 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:        eval time =    7470.16 ms /    11 runs   (  679.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8889.93 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    12 runs   (    0.37 ms per token,  2718.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.84 ms /    17 tokens (   82.46 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:        eval time =    7566.02 ms /    11 runs   (  687.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8999.46 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2640.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.06 ms /    17 tokens (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:        eval time =    7465.73 ms /    11 runs   (  678.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8882.50 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    11 runs   (    0.37 ms per token,  2671.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.44 ms /    17 tokens (   85.32 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =    6780.17 ms /    10 runs   (  678.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8259.81 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    11 runs   (    0.38 ms per token,  2627.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.60 ms /    17 tokens (   74.04 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6814.88 ms /    10 runs   (  681.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8104.04 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2658.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.42 ms /    17 tokens (   72.02 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    7384.33 ms /    11 runs   (  671.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8641.46 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    12 runs   (    0.36 ms per token,  2747.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.01 ms /    17 tokens (   75.47 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    7420.32 ms /    11 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8735.33 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    11 runs   (    0.38 ms per token,  2601.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.13 ms /    17 tokens (   78.83 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:        eval time =    6693.28 ms /    10 runs   (  669.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8062.76 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2653.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.02 ms /    17 tokens (   82.47 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:        eval time =    7460.57 ms /    11 runs   (  678.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8894.65 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /    11 runs   (    0.38 ms per token,  2660.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.03 ms /    17 tokens (   79.65 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:        eval time =    6821.81 ms /    10 runs   (  682.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8205.25 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    11 runs   (    0.38 ms per token,  2649.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.01 ms /    17 tokens (   73.06 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =    6915.13 ms /    10 runs   (  691.51 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8190.03 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    11 runs   (    0.40 ms per token,  2517.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.47 ms /    17 tokens (   75.15 ms per token,    13.31 tokens per second)\n",
      "llama_print_timings:        eval time =    6844.53 ms /    10 runs   (  684.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8152.02 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    12 runs   (    0.37 ms per token,  2711.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.80 ms /    17 tokens (   72.05 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    7665.90 ms /    11 runs   (  696.90 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    8922.40 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    11 runs   (    0.38 ms per token,  2636.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.75 ms /    17 tokens (   77.40 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6859.20 ms /    10 runs   (  685.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8205.03 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    12 runs   (    0.37 ms per token,  2670.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.80 ms /    17 tokens (   77.81 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:        eval time =    7295.01 ms /    11 runs   (  663.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8650.68 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    12 runs   (    0.37 ms per token,  2693.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.01 ms /    17 tokens (   85.00 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7688.87 ms /    11 runs   (  698.99 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    9166.41 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    11 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.92 ms /    17 tokens (   82.70 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =    6739.56 ms /    10 runs   (  673.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8174.62 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    11 runs   (    0.38 ms per token,  2649.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.03 ms /    17 tokens (   73.65 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    6843.56 ms /    10 runs   (  684.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8126.01 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    12 runs   (    0.37 ms per token,  2697.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.81 ms /    17 tokens (   73.81 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    7468.93 ms /    11 runs   (  678.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8756.86 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.65 ms /    17 tokens (   75.39 ms per token,    13.26 tokens per second)\n",
      "llama_print_timings:        eval time =    7448.58 ms /    11 runs   (  677.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8762.13 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    11 runs   (    0.38 ms per token,  2627.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.07 ms /    17 tokens (   72.83 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =    6919.69 ms /    10 runs   (  691.97 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8186.21 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2679.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.37 ms /    17 tokens (   57.55 ms per token,    17.38 tokens per second)\n",
      "llama_print_timings:        eval time =    6804.24 ms /    10 runs   (  680.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7812.03 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.76 ms /    17 tokens (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:        eval time =    7426.47 ms /    11 runs   (  675.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8917.46 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    11 runs   (    0.39 ms per token,  2573.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.17 ms /    17 tokens (   72.42 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =    6896.13 ms /    10 runs   (  689.61 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8157.00 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2635.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.38 ms /    17 tokens (   72.26 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7392.12 ms /    11 runs   (  672.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8652.81 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2647.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.91 ms /    17 tokens (   75.05 ms per token,    13.32 tokens per second)\n",
      "llama_print_timings:        eval time =    7503.13 ms /    11 runs   (  682.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8811.10 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.00 ms /    16 tokens (   70.87 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =    7467.95 ms /    11 runs   (  678.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8633.57 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    11 runs   (    0.36 ms per token,  2739.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1459.66 ms /    17 tokens (   85.86 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:        eval time =    6765.62 ms /    10 runs   (  676.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8255.46 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2676.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.10 ms /    17 tokens (   75.95 ms per token,    13.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6769.11 ms /    10 runs   (  676.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8089.35 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2653.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.98 ms /    17 tokens (   74.47 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =    7458.22 ms /    11 runs   (  678.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8756.52 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2629.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.25 ms /    17 tokens (   72.25 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7509.41 ms /    11 runs   (  682.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8770.65 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /    11 runs   (    0.37 ms per token,  2702.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.54 ms /    17 tokens (   83.68 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:        eval time =    6743.97 ms /    10 runs   (  674.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8195.82 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    11 runs   (    0.36 ms per token,  2753.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.48 ms /    16 tokens (   75.65 ms per token,    13.22 tokens per second)\n",
      "llama_print_timings:        eval time =    6881.14 ms /    10 runs   (  688.11 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8121.56 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2612.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.95 ms /    17 tokens (   73.11 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    7463.31 ms /    11 runs   (  678.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8739.40 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    12 runs   (    0.37 ms per token,  2705.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.73 ms /    17 tokens (   73.57 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =    7446.39 ms /    11 runs   (  676.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8730.46 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.69 ms /    17 tokens (   74.51 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =    7510.53 ms /    11 runs   (  682.78 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8809.30 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.15 ms /    16 tokens (   70.13 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =    7601.81 ms /    11 runs   (  691.07 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8756.62 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2658.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.21 ms /    17 tokens (   79.42 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:        eval time =    7477.90 ms /    11 runs   (  679.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8861.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.37 ms per token,  2667.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.44 ms /    17 tokens (   77.61 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:        eval time =    7511.90 ms /    11 runs   (  682.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8864.17 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /    11 runs   (    0.37 ms per token,  2687.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.74 ms /    17 tokens (   74.10 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6800.98 ms /    10 runs   (  680.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8090.50 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2606.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.35 ms /    17 tokens (   73.90 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7568.86 ms /    11 runs   (  688.08 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8856.75 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2626.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.95 ms /    17 tokens (   75.35 ms per token,    13.27 tokens per second)\n",
      "llama_print_timings:        eval time =    7445.13 ms /    11 runs   (  676.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8758.30 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2646.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.88 ms /    17 tokens (   83.29 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    7447.89 ms /    11 runs   (  677.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8896.47 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2648.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.59 ms /    17 tokens (   74.92 ms per token,    13.35 tokens per second)\n",
      "llama_print_timings:        eval time =    7464.69 ms /    11 runs   (  678.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8770.42 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    11 runs   (    0.37 ms per token,  2682.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.13 ms /    17 tokens (   72.48 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6784.42 ms /    10 runs   (  678.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8046.42 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    11 runs   (    0.38 ms per token,  2622.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.54 ms /    17 tokens (   73.80 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6854.42 ms /    10 runs   (  685.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8139.23 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.17 ms /    17 tokens (   74.30 ms per token,    13.46 tokens per second)\n",
      "llama_print_timings:        eval time =    7530.35 ms /    11 runs   (  684.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8826.00 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    12 runs   (    0.37 ms per token,  2672.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.86 ms /    17 tokens (   73.34 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    7652.88 ms /    11 runs   (  695.72 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8932.42 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    11 runs   (    0.37 ms per token,  2698.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.98 ms /    17 tokens (   80.18 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =    6820.64 ms /    10 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8213.93 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    12 runs   (    0.36 ms per token,  2759.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.69 ms /    16 tokens (   83.29 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =    7459.16 ms /    11 runs   (  678.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8824.90 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2610.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.12 ms /    17 tokens (   85.65 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:        eval time =    7443.89 ms /    11 runs   (  676.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8933.27 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    12 runs   (    0.37 ms per token,  2683.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.71 ms /    17 tokens (   75.98 ms per token,    13.16 tokens per second)\n",
      "llama_print_timings:        eval time =    7544.62 ms /    11 runs   (  685.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8868.06 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    11 runs   (    0.38 ms per token,  2634.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1454.69 ms /    17 tokens (   85.57 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:        eval time =    6843.11 ms /    10 runs   (  684.31 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8327.90 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    11 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.47 ms /    17 tokens (   73.09 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6745.77 ms /    10 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8017.17 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    11 runs   (    0.38 ms per token,  2644.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.77 ms /    17 tokens (   72.87 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    6858.16 ms /    10 runs   (  685.82 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8126.97 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 500th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2653.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1324.77 ms /    17 tokens (   77.93 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:        eval time =    7522.85 ms /    11 runs   (  683.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8879.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.38 ms per token,  2599.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.24 ms /    17 tokens (   85.13 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7512.86 ms /    11 runs   (  682.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8992.83 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2626.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.25 ms /    17 tokens (   85.19 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7547.47 ms /    11 runs   (  686.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9028.49 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    11 runs   (    0.38 ms per token,  2644.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.23 ms /    17 tokens (   71.37 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =    6868.35 ms /    10 runs   (  686.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8112.42 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    12 runs   (    0.39 ms per token,  2564.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.67 ms /    17 tokens (   77.75 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:        eval time =    7472.69 ms /    11 runs   (  679.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8827.56 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    12 runs   (    0.39 ms per token,  2539.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.01 ms /    16 tokens (   73.00 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7550.50 ms /    11 runs   (  686.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8751.85 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.24 ms /    17 tokens (   75.96 ms per token,    13.17 tokens per second)\n",
      "llama_print_timings:        eval time =    6100.80 ms /     9 runs   (  677.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7419.90 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2613.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.05 ms /    17 tokens (   78.36 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7542.48 ms /    11 runs   (  685.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8907.14 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    12 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.29 ms /    17 tokens (   72.25 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7587.07 ms /    11 runs   (  689.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8848.33 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    11 runs   (    0.38 ms per token,  2621.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.99 ms /    17 tokens (   78.94 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:        eval time =    6784.88 ms /    10 runs   (  678.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8157.39 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2677.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.87 ms /    17 tokens (   74.58 ms per token,    13.41 tokens per second)\n",
      "llama_print_timings:        eval time =    6988.39 ms /    10 runs   (  698.84 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    8285.60 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.98 ms /    17 tokens (   77.82 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:        eval time =    7478.49 ms /    11 runs   (  679.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8833.60 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2605.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.46 ms /    17 tokens (   85.09 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7557.26 ms /    11 runs   (  687.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9036.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.62 ms /    17 tokens (   75.51 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =    7614.51 ms /    11 runs   (  692.23 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8931.22 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    11 runs   (    0.38 ms per token,  2612.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.53 ms /    16 tokens (   70.35 ms per token,    14.22 tokens per second)\n",
      "llama_print_timings:        eval time =    6817.08 ms /    10 runs   (  681.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7972.60 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2653.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.51 ms /    17 tokens (   74.85 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7452.31 ms /    11 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8757.26 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.38 ms per token,  2598.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.84 ms /    17 tokens (   76.40 ms per token,    13.09 tokens per second)\n",
      "llama_print_timings:        eval time =    7535.48 ms /    11 runs   (  685.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8867.88 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    11 runs   (    0.38 ms per token,  2609.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1462.24 ms /    17 tokens (   86.01 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =    6861.76 ms /    10 runs   (  686.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8353.47 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    12 runs   (    0.37 ms per token,  2685.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.45 ms /    17 tokens (   74.73 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =    7547.35 ms /    11 runs   (  686.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8849.63 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2650.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.91 ms /    16 tokens (   71.43 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =    7506.28 ms /    11 runs   (  682.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8681.70 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    12 runs   (    0.39 ms per token,  2545.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.38 ms /    17 tokens (   75.73 ms per token,    13.21 tokens per second)\n",
      "llama_print_timings:        eval time =    7523.63 ms /    11 runs   (  683.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8844.26 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /    13 runs   (    0.39 ms per token,  2593.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.83 ms /    16 tokens (   75.24 ms per token,    13.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8089.09 ms /    12 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9329.37 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /    12 runs   (    0.39 ms per token,  2580.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1454.90 ms /    17 tokens (   85.58 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:        eval time =    7423.99 ms /    11 runs   (  674.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8911.04 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    12 runs   (    0.39 ms per token,  2571.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.05 ms /    17 tokens (   73.06 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =    7392.14 ms /    11 runs   (  672.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8667.27 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2656.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.13 ms /    17 tokens (   77.13 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:        eval time =    7510.72 ms /    11 runs   (  682.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8854.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.24 ms /    17 tokens (   72.84 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =    7505.22 ms /    11 runs   (  682.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8775.73 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /    12 runs   (    0.39 ms per token,  2578.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.14 ms /    16 tokens (   71.95 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =    7538.27 ms /    11 runs   (  685.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8721.19 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    11 runs   (    0.38 ms per token,  2633.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     933.82 ms /    17 tokens (   54.93 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6836.05 ms /    10 runs   (  683.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7799.57 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    12 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.85 ms /    16 tokens (   71.87 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =    7519.77 ms /    11 runs   (  683.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8703.69 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    12 runs   (    0.39 ms per token,  2584.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.33 ms /    16 tokens (   74.15 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    7562.82 ms /    11 runs   (  687.53 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8781.51 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    11 runs   (    0.38 ms per token,  2619.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.92 ms /    17 tokens (   72.35 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6803.89 ms /    10 runs   (  680.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8063.69 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2631.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.03 ms /    17 tokens (   71.35 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =    7358.75 ms /    11 runs   (  668.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8603.73 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    11 runs   (    0.39 ms per token,  2560.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.33 ms /    17 tokens (   74.84 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =    6815.10 ms /    10 runs   (  681.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8117.44 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.38 ms per token,  2599.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.00 ms /    17 tokens (   78.24 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7491.52 ms /    11 runs   (  681.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8853.94 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    12 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.10 ms /    17 tokens (   74.83 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7553.97 ms /    11 runs   (  686.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8859.44 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2606.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.75 ms /    17 tokens (   85.22 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:        eval time =    7529.22 ms /    11 runs   (  684.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9009.40 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2593.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.67 ms /    17 tokens (   72.86 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7459.62 ms /    11 runs   (  678.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8730.71 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    12 runs   (    0.39 ms per token,  2569.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.94 ms /    17 tokens (   76.82 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7432.19 ms /    11 runs   (  675.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8770.59 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2639.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.16 ms /    17 tokens (   76.83 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7469.41 ms /    11 runs   (  679.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8808.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2635.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.55 ms /    17 tokens (   79.68 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:        eval time =    7541.92 ms /    11 runs   (  685.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8929.70 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2629.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.28 ms /    17 tokens (   86.37 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7525.11 ms /    11 runs   (  684.10 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9026.18 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.98 ms /    16 tokens (   75.50 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    7474.20 ms /    11 runs   (  679.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8714.76 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2620.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.32 ms /    16 tokens (   77.33 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =    7412.79 ms /    11 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8683.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.38 ms per token,  2600.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.31 ms /    16 tokens (   71.46 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =    7491.68 ms /    11 runs   (  681.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8666.90 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    12 runs   (    0.37 ms per token,  2670.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.85 ms /    17 tokens (   75.64 ms per token,    13.22 tokens per second)\n",
      "llama_print_timings:        eval time =    7454.55 ms /    11 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8772.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1533.31 ms /    17 tokens (   90.19 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:        eval time =    7533.65 ms /    11 runs   (  684.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9098.94 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    12 runs   (    0.39 ms per token,  2586.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.27 ms /    17 tokens (   71.84 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    7582.09 ms /    11 runs   (  689.28 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8836.26 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    13 runs   (    0.38 ms per token,  2660.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.90 ms /    17 tokens (   85.17 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8186.41 ms /    12 runs   (  682.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9669.28 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    11 runs   (    0.38 ms per token,  2653.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.40 ms /    16 tokens (   71.53 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =    6914.78 ms /    10 runs   (  691.48 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8088.51 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2612.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.67 ms /    17 tokens (   73.51 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    7456.10 ms /    11 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8738.23 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.93 ms /    17 tokens (   72.35 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    7508.02 ms /    11 runs   (  682.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8771.95 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.42 ms /    17 tokens (   80.14 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:        eval time =    7594.61 ms /    11 runs   (  690.42 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8989.86 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.38 ms per token,  2598.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.57 ms /    17 tokens (   73.50 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    7491.07 ms /    11 runs   (  681.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8773.91 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    12 runs   (    0.40 ms per token,  2531.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.53 ms /    17 tokens (   74.03 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:        eval time =    7448.03 ms /    11 runs   (  677.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8739.64 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2639.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.01 ms /    17 tokens (   80.06 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:        eval time =    7456.29 ms /    11 runs   (  677.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8850.20 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2616.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.88 ms /    17 tokens (   74.99 ms per token,    13.33 tokens per second)\n",
      "llama_print_timings:        eval time =    7444.30 ms /    11 runs   (  676.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8751.55 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    11 runs   (    0.38 ms per token,  2606.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.58 ms /    17 tokens (   77.68 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6891.11 ms /    10 runs   (  689.11 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8240.71 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2612.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     917.75 ms /    17 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =    7488.36 ms /    11 runs   (  680.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8438.07 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /    10 runs   (    0.40 ms per token,  2527.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.91 ms /    17 tokens (   79.76 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:        eval time =    6070.16 ms /     9 runs   (  674.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7452.97 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    11 runs   (    0.39 ms per token,  2583.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.00 ms /    17 tokens (   85.18 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6873.86 ms /    10 runs   (  687.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8351.38 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.66 ms /    12 runs   (    0.39 ms per token,  2576.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.76 ms /    17 tokens (   74.22 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =    7528.99 ms /    11 runs   (  684.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8823.51 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.38 ms per token,  2597.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.19 ms /    17 tokens (   84.89 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7468.60 ms /    11 runs   (  678.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8944.78 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    12 runs   (    0.40 ms per token,  2513.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1227.31 ms /    17 tokens (   72.19 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =    7473.63 ms /    11 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8733.08 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2601.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.79 ms /    17 tokens (   79.28 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:        eval time =    7413.82 ms /    11 runs   (  673.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8794.07 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    12 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.51 ms /    17 tokens (   73.09 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    7467.93 ms /    11 runs   (  678.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8743.77 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /    12 runs   (    0.39 ms per token,  2579.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.21 ms /    17 tokens (   75.72 ms per token,    13.21 tokens per second)\n",
      "llama_print_timings:        eval time =    7559.52 ms /    11 runs   (  687.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8879.51 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2608.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.00 ms /    13 tokens (   78.23 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7497.88 ms /    11 runs   (  681.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8547.52 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    11 runs   (    0.39 ms per token,  2579.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.67 ms /    16 tokens (   78.42 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6831.63 ms /    10 runs   (  683.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8118.21 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    12 runs   (    0.39 ms per token,  2565.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.62 ms /    17 tokens (   72.15 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    7433.75 ms /    11 runs   (  675.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8693.77 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2647.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.44 ms /    17 tokens (   80.32 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:        eval time =    7496.67 ms /    11 runs   (  681.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8894.70 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.24 ms /    17 tokens (   85.43 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:        eval time =    7523.55 ms /    11 runs   (  683.96 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9008.36 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    12 runs   (    0.39 ms per token,  2549.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.67 ms /    17 tokens (   76.51 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:        eval time =    7622.26 ms /    11 runs   (  692.93 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8955.75 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    11 runs   (    0.38 ms per token,  2599.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.83 ms /    17 tokens (   75.05 ms per token,    13.32 tokens per second)\n",
      "llama_print_timings:        eval time =    6833.40 ms /    10 runs   (  683.34 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8139.13 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2629.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.37 ms /    17 tokens (   76.79 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7452.59 ms /    11 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8790.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2656.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.21 ms /    17 tokens (   75.84 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:        eval time =    7540.32 ms /    11 runs   (  685.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8862.24 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2629.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.55 ms /    17 tokens (   73.68 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    7500.07 ms /    11 runs   (  681.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8785.28 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    12 runs   (    0.39 ms per token,  2588.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.14 ms /    17 tokens (   74.30 ms per token,    13.46 tokens per second)\n",
      "llama_print_timings:        eval time =    7644.28 ms /    11 runs   (  694.93 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8940.71 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2644.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.89 ms /    16 tokens (   78.74 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7594.47 ms /    11 runs   (  690.41 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8887.18 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    12 runs   (    0.45 ms per token,  2243.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.13 ms /    17 tokens (   71.77 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =    7533.97 ms /    11 runs   (  684.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8788.47 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2640.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.60 ms /    17 tokens (   85.62 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:        eval time =    7456.34 ms /    11 runs   (  677.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8945.45 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2635.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.51 ms /    17 tokens (   74.27 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =    7472.71 ms /    11 runs   (  679.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8767.11 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    12 runs   (    0.39 ms per token,  2555.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.03 ms /    17 tokens (   76.06 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =    7473.60 ms /    11 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8800.30 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    11 runs   (    0.38 ms per token,  2618.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.98 ms /    17 tokens (   84.94 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:        eval time =    6748.28 ms /    10 runs   (  674.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8222.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2592.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.42 ms /    17 tokens (   82.08 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:        eval time =    7448.66 ms /    11 runs   (  677.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8877.50 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    11 runs   (    0.39 ms per token,  2594.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.75 ms /    17 tokens (   74.63 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =    6852.53 ms /    10 runs   (  685.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8151.70 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    12 runs   (    0.37 ms per token,  2684.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.14 ms /    17 tokens (   73.30 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =    7462.01 ms /    11 runs   (  678.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8740.22 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    12 runs   (    0.37 ms per token,  2726.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.82 ms /    17 tokens (   74.11 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    7433.43 ms /    11 runs   (  675.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8725.68 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    11 runs   (    0.38 ms per token,  2633.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.33 ms /    17 tokens (   61.96 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =    6829.86 ms /    10 runs   (  682.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7912.32 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    12 runs   (    0.37 ms per token,  2692.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.59 ms /    17 tokens (   85.27 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:        eval time =    7427.99 ms /    11 runs   (  675.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8909.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.94 ms /    17 tokens (   75.88 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =    7469.65 ms /    11 runs   (  679.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8792.09 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    12 runs   (    0.40 ms per token,  2514.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.91 ms /    17 tokens (   84.52 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:        eval time =    7628.24 ms /    11 runs   (  693.48 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9098.49 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2622.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.57 ms /    17 tokens (   72.68 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7466.04 ms /    11 runs   (  678.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8734.92 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2613.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.18 ms /    17 tokens (   75.25 ms per token,    13.29 tokens per second)\n",
      "llama_print_timings:        eval time =    7510.30 ms /    11 runs   (  682.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8821.83 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2627.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.11 ms /    17 tokens (   82.71 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =    7433.28 ms /    11 runs   (  675.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8871.53 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /    12 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.88 ms /    17 tokens (   74.88 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7500.85 ms /    11 runs   (  681.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8806.54 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    12 runs   (    0.40 ms per token,  2508.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.76 ms /    17 tokens (   75.46 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    7403.38 ms /    11 runs   (  673.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8719.42 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2651.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.68 ms /    17 tokens (   72.63 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =    7418.93 ms /    11 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8686.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    11 runs   (    0.40 ms per token,  2521.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.22 ms /    17 tokens (   72.37 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6798.15 ms /    10 runs   (  679.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8058.76 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    11 runs   (    0.38 ms per token,  2632.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.05 ms /    16 tokens (   77.32 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6822.65 ms /    10 runs   (  682.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8089.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2642.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.38 ms /    17 tokens (   87.79 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:        eval time =    7525.78 ms /    11 runs   (  684.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9051.14 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 600th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2618.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.75 ms /    18 tokens (   71.60 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =    7465.28 ms /    11 runs   (  678.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8786.18 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.38 ms per token,  2663.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.05 ms /    17 tokens (   77.47 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:        eval time =    7494.09 ms /    11 runs   (  681.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8842.99 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2604.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.62 ms /    17 tokens (   85.51 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:        eval time =    7445.95 ms /    11 runs   (  676.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8932.76 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    12 runs   (    0.37 ms per token,  2704.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.91 ms /    17 tokens (   72.76 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7520.20 ms /    11 runs   (  683.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8789.01 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    11 runs   (    0.38 ms per token,  2609.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.68 ms /    17 tokens (   72.33 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6816.72 ms /    10 runs   (  681.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8076.67 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    12 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.69 ms /    17 tokens (   77.22 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:        eval time =    7423.97 ms /    11 runs   (  674.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8769.46 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2635.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.50 ms /    17 tokens (   85.15 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7475.40 ms /    11 runs   (  679.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8955.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2629.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.05 ms /    17 tokens (   74.65 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =    7506.76 ms /    11 runs   (  682.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8808.06 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.12 ms /    17 tokens (   73.83 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7461.30 ms /    11 runs   (  678.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8748.35 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    10 runs   (    0.38 ms per token,  2656.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.37 ms /    17 tokens (   74.96 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =    6122.48 ms /     9 runs   (  680.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7424.10 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.37 ms per token,  2668.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.59 ms /    17 tokens (   73.45 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =    7546.97 ms /    11 runs   (  686.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8829.87 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2624.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1299.47 ms /    17 tokens (   76.44 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =    7581.95 ms /    11 runs   (  689.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8913.99 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2612.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.48 ms /    17 tokens (   85.26 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:        eval time =    7556.32 ms /    11 runs   (  686.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9039.13 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    12 runs   (    0.37 ms per token,  2716.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.57 ms /    17 tokens (   76.27 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =    7507.55 ms /    11 runs   (  682.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8837.13 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2607.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.03 ms /    17 tokens (   75.53 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =    7516.49 ms /    11 runs   (  683.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8833.07 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    11 runs   (    0.37 ms per token,  2681.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.20 ms /    17 tokens (   77.19 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6584.73 ms /    10 runs   (  658.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    7928.35 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    12 runs   (    0.41 ms per token,  2458.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.53 ms /    17 tokens (   73.91 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7496.02 ms /    11 runs   (  681.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8786.35 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    12 runs   (    0.37 ms per token,  2695.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.10 ms /    17 tokens (   83.83 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:        eval time =    7566.40 ms /    11 runs   (  687.85 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9022.77 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    11 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.27 ms /    17 tokens (   85.78 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6929.60 ms /    10 runs   (  692.96 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8417.86 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2630.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.93 ms /    17 tokens (   79.05 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:        eval time =    7437.89 ms /    11 runs   (  676.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8814.17 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2647.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.71 ms /    17 tokens (   73.87 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7531.23 ms /    11 runs   (  684.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8818.79 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    12 runs   (    0.37 ms per token,  2697.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.09 ms /    17 tokens (   72.89 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7447.48 ms /    11 runs   (  677.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8719.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    10 runs   (    0.38 ms per token,  2626.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.95 ms /    17 tokens (   73.64 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    6149.60 ms /     9 runs   (  683.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7428.10 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    11 runs   (    0.37 ms per token,  2683.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.50 ms /    17 tokens (   72.97 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6788.82 ms /    10 runs   (  678.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8058.85 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2589.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.99 ms /    17 tokens (   73.00 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7469.56 ms /    11 runs   (  679.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8743.81 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    11 runs   (    0.36 ms per token,  2747.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.91 ms /    17 tokens (   75.35 ms per token,    13.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6879.44 ms /    10 runs   (  687.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8190.98 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    12 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.00 ms /    17 tokens (   85.18 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7512.34 ms /    11 runs   (  682.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8993.84 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    12 runs   (    0.37 ms per token,  2673.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.47 ms /    17 tokens (   82.20 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:        eval time =    7618.83 ms /    11 runs   (  692.62 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9049.00 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    12 runs   (    0.39 ms per token,  2584.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.04 ms /    16 tokens (   73.63 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7429.63 ms /    11 runs   (  675.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8641.94 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    12 runs   (    0.37 ms per token,  2705.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.01 ms /    17 tokens (   74.65 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =    7438.75 ms /    11 runs   (  676.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8740.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2610.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.47 ms /    17 tokens (   73.79 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6044.14 ms /     9 runs   (  671.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7326.04 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2660.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.91 ms /    17 tokens (   72.11 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =    7491.26 ms /    11 runs   (  681.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8749.49 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2631.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.89 ms /    17 tokens (   73.76 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =    7380.06 ms /    11 runs   (  670.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8666.78 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    11 runs   (    0.37 ms per token,  2684.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.41 ms /    17 tokens (   74.02 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6789.99 ms /    10 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8078.33 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    10 runs   (    0.39 ms per token,  2551.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.58 ms /    17 tokens (   74.21 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6151.38 ms /     9 runs   (  683.49 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    7440.33 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    12 runs   (    0.37 ms per token,  2682.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.60 ms /    17 tokens (   79.51 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7454.53 ms /    11 runs   (  677.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8838.02 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.37 ms per token,  2667.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.01 ms /    17 tokens (   73.18 ms per token,    13.67 tokens per second)\n",
      "llama_print_timings:        eval time =    7494.00 ms /    11 runs   (  681.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8769.88 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /    11 runs   (    0.38 ms per token,  2656.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.64 ms /    17 tokens (   78.10 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6857.49 ms /    10 runs   (  685.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8215.39 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2650.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.04 ms /    17 tokens (   82.53 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:        eval time =    7519.45 ms /    11 runs   (  683.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8955.02 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    11 runs   (    0.37 ms per token,  2683.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.28 ms /    17 tokens (   85.02 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6864.35 ms /    10 runs   (  686.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8339.68 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.37 ms /    17 tokens (   74.20 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =    7463.45 ms /    11 runs   (  678.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8757.93 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2647.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.34 ms /    17 tokens (   74.73 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =    7437.20 ms /    11 runs   (  676.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8739.95 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /    11 runs   (    0.37 ms per token,  2700.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.13 ms /    17 tokens (   84.48 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6755.54 ms /    10 runs   (  675.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8221.43 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    12 runs   (    0.39 ms per token,  2532.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.67 ms /    17 tokens (   74.57 ms per token,    13.41 tokens per second)\n",
      "llama_print_timings:        eval time =    7549.41 ms /    11 runs   (  686.31 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8850.48 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    12 runs   (    0.40 ms per token,  2526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.76 ms /    17 tokens (   72.40 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7582.00 ms /    11 runs   (  689.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8846.18 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.89 ms /    17 tokens (   73.82 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    7655.09 ms /    11 runs   (  695.92 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8943.56 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    12 runs   (    0.47 ms per token,  2147.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.49 ms /    17 tokens (   76.56 ms per token,    13.06 tokens per second)\n",
      "llama_print_timings:        eval time =    7563.55 ms /    11 runs   (  687.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8902.70 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    11 runs   (    0.39 ms per token,  2549.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.00 ms /    17 tokens (   80.18 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =    6814.20 ms /    10 runs   (  681.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8208.19 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2656.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     918.85 ms /    17 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =    7647.96 ms /    11 runs   (  695.27 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8598.45 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2660.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.51 ms /    17 tokens (   72.97 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7486.25 ms /    11 runs   (  680.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8759.72 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    10 runs   (    0.38 ms per token,  2639.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.30 ms /    17 tokens (   72.49 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6112.19 ms /     9 runs   (  679.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7372.17 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    10 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     942.09 ms /    13 tokens (   72.47 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6094.38 ms /     9 runs   (  677.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7063.43 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    12 runs   (    0.37 ms per token,  2673.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.68 ms /    17 tokens (   72.75 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7482.94 ms /    11 runs   (  680.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8751.78 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.36 ms /    17 tokens (   73.37 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    7484.26 ms /    11 runs   (  680.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8763.92 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.42 ms /    17 tokens (   73.14 ms per token,    13.67 tokens per second)\n",
      "llama_print_timings:        eval time =    7437.68 ms /    11 runs   (  676.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8713.59 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    12 runs   (    0.39 ms per token,  2570.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.19 ms /    16 tokens (   76.64 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:        eval time =    7458.48 ms /    11 runs   (  678.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8717.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2609.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.69 ms /    16 tokens (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    7524.53 ms /    11 runs   (  684.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8883.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2622.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.65 ms /    17 tokens (   77.16 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:        eval time =    7500.71 ms /    11 runs   (  681.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8845.04 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2644.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.56 ms /    16 tokens (   71.85 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    7513.52 ms /    11 runs   (  683.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8695.76 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2640.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.08 ms /    17 tokens (   74.89 ms per token,    13.35 tokens per second)\n",
      "llama_print_timings:        eval time =    7501.98 ms /    11 runs   (  682.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8808.78 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    11 runs   (    0.38 ms per token,  2621.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.93 ms /    17 tokens (   73.23 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6795.02 ms /    10 runs   (  679.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8071.15 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    12 runs   (    0.37 ms per token,  2730.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.13 ms /    16 tokens (   72.88 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7588.42 ms /    11 runs   (  689.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8787.12 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    13 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.17 ms /    17 tokens (   73.30 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =    8088.75 ms /    12 runs   (  674.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9370.36 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    11 runs   (    0.38 ms per token,  2625.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.75 ms /    17 tokens (   75.87 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =    6794.20 ms /    10 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8113.60 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    11 runs   (    0.38 ms per token,  2651.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.23 ms /    17 tokens (   82.13 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:        eval time =    6768.22 ms /    10 runs   (  676.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8194.70 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.38 ms /    17 tokens (   85.32 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7496.24 ms /    11 runs   (  681.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8978.78 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    12 runs   (    0.37 ms per token,  2683.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.50 ms /    17 tokens (   73.56 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =    7437.00 ms /    11 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8719.68 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2637.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.71 ms /    16 tokens (   79.73 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7535.33 ms /    11 runs   (  685.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8843.49 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    11 runs   (    0.38 ms per token,  2635.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.06 ms /    17 tokens (   76.77 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6722.88 ms /    10 runs   (  672.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8058.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    12 runs   (    0.38 ms per token,  2608.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.69 ms /    17 tokens (   75.28 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =    7408.90 ms /    11 runs   (  673.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8721.98 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    11 runs   (    0.39 ms per token,  2576.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.79 ms /    17 tokens (   84.34 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6791.98 ms /    10 runs   (  679.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8257.12 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.66 ms /    12 runs   (    0.39 ms per token,  2576.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.18 ms /    17 tokens (   85.19 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7451.11 ms /    11 runs   (  677.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8931.56 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.39 ms per token,  2595.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.55 ms /    17 tokens (   72.27 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7445.81 ms /    11 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8707.08 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    12 runs   (    0.38 ms per token,  2639.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.67 ms /    17 tokens (   77.63 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:        eval time =    7481.49 ms /    11 runs   (  680.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8833.42 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    12 runs   (    0.39 ms per token,  2554.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.01 ms /    17 tokens (   85.00 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7503.22 ms /    11 runs   (  682.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8982.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /    11 runs   (    0.38 ms per token,  2657.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.76 ms /    17 tokens (   75.04 ms per token,    13.33 tokens per second)\n",
      "llama_print_timings:        eval time =    6829.53 ms /    10 runs   (  682.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8135.95 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    12 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.45 ms /    17 tokens (   79.50 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7479.79 ms /    11 runs   (  679.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8864.26 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.38 ms per token,  2598.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.97 ms /    17 tokens (   74.00 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:        eval time =    7440.63 ms /    11 runs   (  676.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8732.20 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2624.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.51 ms /    17 tokens (   75.79 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:        eval time =    7531.95 ms /    11 runs   (  684.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8852.75 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2591.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     962.79 ms /    17 tokens (   56.63 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =    7575.78 ms /    11 runs   (  688.71 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8571.11 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.12 ms /    17 tokens (   73.89 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7464.13 ms /    11 runs   (  678.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8753.15 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /    11 runs   (    0.37 ms per token,  2700.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.11 ms /    17 tokens (   74.12 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    6853.32 ms /    10 runs   (  685.33 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8143.32 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    11 runs   (    0.38 ms per token,  2637.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.06 ms /    17 tokens (   72.36 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6738.52 ms /    10 runs   (  673.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7998.02 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2657.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.40 ms /    17 tokens (   84.91 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7442.38 ms /    11 runs   (  676.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8917.99 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.52 ms /    17 tokens (   72.62 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =    7383.27 ms /    11 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8649.87 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    12 runs   (    0.37 ms per token,  2709.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.47 ms /    17 tokens (   84.32 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =    7432.49 ms /    11 runs   (  675.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8898.58 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    11 runs   (    0.39 ms per token,  2554.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1467.10 ms /    17 tokens (   86.30 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:        eval time =    6701.17 ms /    10 runs   (  670.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8198.37 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    12 runs   (    0.37 ms per token,  2697.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.77 ms /    17 tokens (   73.69 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    7451.25 ms /    11 runs   (  677.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8736.49 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2627.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.45 ms /    17 tokens (   76.26 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =    7439.35 ms /    11 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8768.28 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    11 runs   (    0.37 ms per token,  2722.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1346.24 ms /    17 tokens (   79.19 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:        eval time =    6753.01 ms /    10 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8128.85 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    10 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.42 ms /    17 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =    6055.80 ms /     9 runs   (  672.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7313.00 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.80 ms /    17 tokens (   73.58 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =    7340.59 ms /    11 runs   (  667.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8624.41 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    12 runs   (    0.37 ms per token,  2674.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.05 ms /    17 tokens (   84.53 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:        eval time =    7481.57 ms /    11 runs   (  680.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8951.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /    10 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.49 ms /    17 tokens (   75.85 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =    6084.71 ms /     9 runs   (  676.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    7403.12 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    10 runs   (    0.38 ms per token,  2643.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.39 ms /    17 tokens (   72.73 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6313.60 ms /     9 runs   (  701.51 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    7576.50 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    12 runs   (    0.37 ms per token,  2674.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.56 ms /    17 tokens (   72.27 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7301.69 ms /    11 runs   (  663.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    8563.17 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    12 runs   (    0.39 ms per token,  2539.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.60 ms /    17 tokens (   76.39 ms per token,    13.09 tokens per second)\n",
      "llama_print_timings:        eval time =    7526.95 ms /    11 runs   (  684.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8857.79 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2612.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.09 ms /    17 tokens (   74.71 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =    7404.92 ms /    11 runs   (  673.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8707.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2646.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.24 ms /    17 tokens (   76.72 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:        eval time =    7350.01 ms /    11 runs   (  668.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8687.32 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /    10 runs   (    0.40 ms per token,  2513.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.04 ms /    17 tokens (   73.24 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =    6106.22 ms /     9 runs   (  678.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    7379.07 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 700th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    13 runs   (    0.37 ms per token,  2684.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.59 ms /    17 tokens (   72.33 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =    8135.55 ms /    12 runs   (  677.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9399.94 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    13 runs   (    0.38 ms per token,  2620.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.38 ms /    17 tokens (   72.67 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8046.58 ms /    12 runs   (  670.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9316.19 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    13 runs   (    0.38 ms per token,  2660.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.03 ms /    17 tokens (   78.53 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:        eval time =    8144.38 ms /    12 runs   (  678.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9514.23 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.37 ms per token,  2669.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.58 ms /    17 tokens (   86.27 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:        eval time =    7499.83 ms /    11 runs   (  681.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8999.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    13 runs   (    0.37 ms per token,  2669.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.68 ms /    17 tokens (   73.69 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8063.30 ms /    12 runs   (  671.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9351.41 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    13 runs   (    0.39 ms per token,  2544.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.46 ms /    17 tokens (   75.32 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8141.00 ms /    12 runs   (  678.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9457.92 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    13 runs   (    0.39 ms per token,  2563.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.65 ms /    16 tokens (   71.85 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8110.97 ms /    12 runs   (  675.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9296.74 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    13 runs   (    0.38 ms per token,  2643.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.24 ms /    17 tokens (   77.48 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:        eval time =    8154.21 ms /    12 runs   (  679.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9507.66 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2589.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.50 ms /    17 tokens (   72.50 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =    7642.97 ms /    11 runs   (  694.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    8908.80 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    13 runs   (    0.37 ms per token,  2702.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.50 ms /    17 tokens (   65.97 ms per token,    15.16 tokens per second)\n",
      "llama_print_timings:        eval time =    8231.95 ms /    12 runs   (  686.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9388.08 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    13 runs   (    0.39 ms per token,  2580.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.53 ms /    17 tokens (   71.15 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =    8123.70 ms /    12 runs   (  676.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9369.06 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2628.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.01 ms /    17 tokens (   85.65 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:        eval time =    7382.79 ms /    11 runs   (  671.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8871.02 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    12 runs   (    0.39 ms per token,  2543.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.59 ms /    17 tokens (   84.39 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =    7430.92 ms /    11 runs   (  675.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8897.79 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    12 runs   (    0.37 ms per token,  2682.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.38 ms /    17 tokens (   74.32 ms per token,    13.46 tokens per second)\n",
      "llama_print_timings:        eval time =    7446.84 ms /    11 runs   (  676.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8743.28 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.12 ms /    13 runs   (    0.39 ms per token,  2541.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.28 ms /    17 tokens (   76.84 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8086.44 ms /    12 runs   (  673.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9428.30 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    13 runs   (    0.39 ms per token,  2580.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.82 ms /    17 tokens (   72.34 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8115.25 ms /    12 runs   (  676.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9380.21 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    13 runs   (    0.40 ms per token,  2503.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.74 ms /    13 tokens (   71.60 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8191.59 ms /    12 runs   (  682.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9159.61 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2624.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.92 ms /    17 tokens (   78.05 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7521.83 ms /    11 runs   (  683.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8881.51 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    13 runs   (    0.38 ms per token,  2650.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.21 ms /    16 tokens (   73.08 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    8197.26 ms /    12 runs   (  683.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9402.54 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    13 runs   (    0.37 ms per token,  2671.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.60 ms /    17 tokens (   85.33 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7927.43 ms /    12 runs   (  660.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9412.95 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.09 ms /    13 runs   (    0.39 ms per token,  2553.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.28 ms /    17 tokens (   74.78 ms per token,    13.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8222.19 ms /    12 runs   (  685.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9529.38 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.83 ms /    17 tokens (   79.81 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7599.85 ms /    11 runs   (  690.90 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8989.75 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    13 runs   (    0.37 ms per token,  2671.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.26 ms /    17 tokens (   73.60 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8337.68 ms /    12 runs   (  694.81 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9624.62 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.03 ms /    13 runs   (    0.39 ms per token,  2582.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.13 ms /    17 tokens (   76.71 ms per token,    13.04 tokens per second)\n",
      "llama_print_timings:        eval time =    8117.82 ms /    12 runs   (  676.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9457.78 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.08 ms /    13 runs   (    0.39 ms per token,  2561.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.40 ms /    17 tokens (   84.85 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:        eval time =    8356.03 ms /    12 runs   (  696.34 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9834.43 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    12 runs   (    0.37 ms per token,  2689.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.34 ms /    17 tokens (   73.08 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    7503.19 ms /    11 runs   (  682.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8777.61 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2646.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.25 ms /    16 tokens (   83.02 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =    7522.74 ms /    11 runs   (  683.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8883.30 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2650.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.73 ms /    16 tokens (   72.17 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    7481.23 ms /    11 runs   (  680.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8668.61 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    13 runs   (    0.38 ms per token,  2643.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.98 ms /    17 tokens (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:        eval time =    8205.65 ms /    12 runs   (  683.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9603.76 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    13 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.84 ms /    17 tokens (   74.23 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =    8116.54 ms /    12 runs   (  676.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9413.44 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    13 runs   (    0.37 ms per token,  2691.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.53 ms /    17 tokens (   75.03 ms per token,    13.33 tokens per second)\n",
      "llama_print_timings:        eval time =    8114.77 ms /    12 runs   (  676.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9425.42 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    13 runs   (    0.38 ms per token,  2643.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.79 ms /    17 tokens (   72.93 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =    8184.71 ms /    12 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9460.12 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    12 runs   (    0.39 ms per token,  2571.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.65 ms /    17 tokens (   84.80 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:        eval time =    7423.16 ms /    11 runs   (  674.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8898.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2643.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.30 ms /    17 tokens (   74.49 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =    7523.86 ms /    11 runs   (  683.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8823.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    13 runs   (    0.38 ms per token,  2642.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1459.96 ms /    17 tokens (   85.88 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:        eval time =    8185.02 ms /    12 runs   (  682.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9680.36 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    13 runs   (    0.38 ms per token,  2648.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.54 ms /    17 tokens (   79.50 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8114.65 ms /    12 runs   (  676.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9503.95 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    13 runs   (    0.38 ms per token,  2613.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.25 ms /    16 tokens (   70.58 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =    8153.26 ms /    12 runs   (  679.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9318.13 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    13 runs   (    0.38 ms per token,  2643.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.80 ms /    17 tokens (   84.64 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8249.60 ms /    12 runs   (  687.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9722.91 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    12 runs   (    0.37 ms per token,  2667.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.52 ms /    17 tokens (   74.62 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =    7592.60 ms /    11 runs   (  690.24 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8893.57 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.39 ms per token,  2594.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.02 ms /    17 tokens (   82.06 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:        eval time =    7534.25 ms /    11 runs   (  684.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8962.11 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /    13 runs   (    0.39 ms per token,  2596.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.66 ms /    17 tokens (   73.04 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =    8182.62 ms /    12 runs   (  681.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9459.92 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    13 runs   (    0.37 ms per token,  2728.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.54 ms /    16 tokens (   82.47 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:        eval time =    8233.77 ms /    12 runs   (  686.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9588.08 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    12 runs   (    0.37 ms per token,  2717.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.78 ms /    17 tokens (   77.05 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:        eval time =    7505.49 ms /    11 runs   (  682.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8847.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2604.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.47 ms /    17 tokens (   72.15 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    7438.84 ms /    11 runs   (  676.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8699.23 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    12 runs   (    0.40 ms per token,  2476.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.67 ms /    17 tokens (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =    7598.79 ms /    11 runs   (  690.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8995.84 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    13 runs   (    0.37 ms per token,  2690.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.10 ms /    17 tokens (   83.48 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =    7964.54 ms /    12 runs   (  663.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    9418.82 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    13 runs   (    0.38 ms per token,  2615.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.29 ms /    17 tokens (   74.25 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =    8152.36 ms /    12 runs   (  679.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9449.89 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    12 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.91 ms /    17 tokens (   73.99 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:        eval time =    7524.20 ms /    11 runs   (  684.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8815.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    13 runs   (    0.39 ms per token,  2574.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.32 ms /    17 tokens (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:        eval time =    8315.01 ms /    12 runs   (  692.92 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9727.32 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    13 runs   (    0.38 ms per token,  2644.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.00 ms /    16 tokens (   74.69 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:        eval time =    8137.77 ms /    12 runs   (  678.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9368.60 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    12 runs   (    0.39 ms per token,  2547.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.47 ms /    17 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =    7428.68 ms /    11 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8691.33 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    12 runs   (    0.37 ms per token,  2694.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.12 ms /    17 tokens (   75.48 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    7470.56 ms /    11 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8786.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.02 ms /    13 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.50 ms /    16 tokens (   78.09 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:        eval time =    8113.04 ms /    12 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9397.52 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    12 runs   (    0.47 ms per token,  2109.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.84 ms /    17 tokens (   73.81 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    7383.52 ms /    11 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8676.69 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    13 runs   (    0.37 ms per token,  2685.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.91 ms /    16 tokens (   71.37 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8214.64 ms /    12 runs   (  684.55 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9392.23 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    12 runs   (    0.37 ms per token,  2705.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.28 ms /    17 tokens (   84.49 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7352.60 ms /    11 runs   (  668.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8821.09 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    13 runs   (    0.37 ms per token,  2675.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.71 ms /    17 tokens (   85.45 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8199.62 ms /    12 runs   (  683.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9687.79 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    13 runs   (    0.37 ms per token,  2717.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.27 ms /    17 tokens (   85.96 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =    8163.95 ms /    12 runs   (  680.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9661.03 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    13 runs   (    0.38 ms per token,  2636.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.19 ms /    16 tokens (   73.57 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8110.79 ms /    12 runs   (  675.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9323.91 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    12 runs   (    0.37 ms per token,  2721.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.93 ms /    17 tokens (   74.41 ms per token,    13.44 tokens per second)\n",
      "llama_print_timings:        eval time =    7456.67 ms /    11 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8753.36 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2616.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.30 ms /    16 tokens (   71.58 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =    7430.87 ms /    11 runs   (  675.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8608.51 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.87 ms /    16 tokens (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:        eval time =    7345.79 ms /    11 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8693.44 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    13 runs   (    0.40 ms per token,  2486.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.26 ms /    17 tokens (   78.66 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:        eval time =    8065.10 ms /    12 runs   (  672.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9439.83 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /    13 runs   (    0.39 ms per token,  2596.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.00 ms /    17 tokens (   74.12 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    8069.92 ms /    12 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9366.45 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    13 runs   (    0.38 ms per token,  2646.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.45 ms /    17 tokens (   74.73 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8106.36 ms /    12 runs   (  675.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9411.80 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    11 runs   (    0.38 ms per token,  2635.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.81 ms /    17 tokens (   72.17 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6707.49 ms /    10 runs   (  670.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7964.52 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    12 runs   (    0.37 ms per token,  2672.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.40 ms /    17 tokens (   58.85 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =    7312.93 ms /    11 runs   (  664.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8345.15 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2633.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.31 ms /    17 tokens (   73.96 ms per token,    13.52 tokens per second)\n",
      "llama_print_timings:        eval time =    7371.81 ms /    11 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8663.07 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    13 runs   (    0.39 ms per token,  2565.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.63 ms /    17 tokens (   72.27 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    8309.91 ms /    12 runs   (  692.49 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    9574.46 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    13 runs   (    0.38 ms per token,  2627.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.27 ms /    17 tokens (   73.43 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8160.81 ms /    12 runs   (  680.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9445.53 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    13 runs   (    0.38 ms per token,  2612.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.66 ms /    17 tokens (   86.22 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:        eval time =    8206.61 ms /    12 runs   (  683.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9707.99 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    12 runs   (    0.38 ms per token,  2658.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.38 ms /    17 tokens (   74.49 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =    7441.58 ms /    11 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8741.07 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    13 runs   (    0.38 ms per token,  2627.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.20 ms /    17 tokens (   73.89 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    8090.32 ms /    12 runs   (  674.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9381.73 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    13 runs   (    0.37 ms per token,  2682.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.40 ms /    16 tokens (   71.53 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =    8149.63 ms /    12 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9329.86 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2603.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.32 ms /    17 tokens (   84.96 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:        eval time =    7502.40 ms /    11 runs   (  682.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8980.25 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    13 runs   (    0.38 ms per token,  2621.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.38 ms /    17 tokens (   84.08 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =    8205.93 ms /    12 runs   (  683.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9671.78 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    13 runs   (    0.39 ms per token,  2568.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.13 ms /    16 tokens (   77.70 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8147.11 ms /    12 runs   (  678.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9426.80 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    13 runs   (    0.38 ms per token,  2656.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.93 ms /    17 tokens (   82.11 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:        eval time =    8204.24 ms /    12 runs   (  683.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9635.88 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    12 runs   (    0.37 ms per token,  2687.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.05 ms /    17 tokens (   73.77 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =    7476.81 ms /    11 runs   (  679.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8764.35 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    12 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.15 ms /    17 tokens (   77.01 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:        eval time =    7494.70 ms /    11 runs   (  681.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8836.62 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.00 ms /    13 runs   (    0.38 ms per token,  2602.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.54 ms /    17 tokens (   77.09 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8004.29 ms /    12 runs   (  667.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9350.49 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    13 runs   (    0.38 ms per token,  2663.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.59 ms /    17 tokens (   85.33 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8147.67 ms /    12 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9634.14 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    13 runs   (    0.38 ms per token,  2616.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.58 ms /    17 tokens (   72.33 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =    8205.00 ms /    12 runs   (  683.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9469.81 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    11 runs   (    0.37 ms per token,  2671.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.69 ms /    17 tokens (   72.33 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    6905.66 ms /    10 runs   (  690.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    8166.29 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    13 runs   (    0.38 ms per token,  2635.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.21 ms /    17 tokens (   74.07 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:        eval time =    8134.64 ms /    12 runs   (  677.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9429.88 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    13 runs   (    0.37 ms per token,  2677.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.14 ms /    17 tokens (   79.30 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8233.94 ms /    12 runs   (  686.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9618.12 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    13 runs   (    0.38 ms per token,  2620.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.01 ms /    16 tokens (   75.88 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =    7993.76 ms /    12 runs   (  666.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9243.76 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    13 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.62 ms /    16 tokens (   72.98 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8096.89 ms /    12 runs   (  674.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9300.44 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    12 runs   (    0.38 ms per token,  2602.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.07 ms /    17 tokens (   78.59 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7453.41 ms /    11 runs   (  677.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8823.67 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    12 runs   (    0.37 ms per token,  2681.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.55 ms /    17 tokens (   75.80 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:        eval time =    7475.98 ms /    11 runs   (  679.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8797.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.00 ms /    13 runs   (    0.38 ms per token,  2597.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.75 ms /    17 tokens (   72.28 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    7912.44 ms /    12 runs   (  659.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9177.49 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    13 runs   (    0.46 ms per token,  2165.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.60 ms /    17 tokens (   76.21 ms per token,    13.12 tokens per second)\n",
      "llama_print_timings:        eval time =    8158.69 ms /    12 runs   (  679.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9495.47 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    12 runs   (    0.37 ms per token,  2700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.32 ms /    17 tokens (   83.37 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    7466.34 ms /    11 runs   (  678.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    8916.56 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    13 runs   (    0.37 ms per token,  2696.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.80 ms /    16 tokens (   74.24 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =    8091.16 ms /    12 runs   (  674.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9314.50 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    12 runs   (    0.38 ms per token,  2651.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.22 ms /    17 tokens (   83.72 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =    7535.55 ms /    11 runs   (  685.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8990.68 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    13 runs   (    0.38 ms per token,  2613.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.91 ms /    17 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =    8174.86 ms /    12 runs   (  681.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9142.00 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    13 runs   (    0.37 ms per token,  2685.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.82 ms /    17 tokens (   74.81 ms per token,    13.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8113.83 ms /    12 runs   (  676.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9420.71 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    13 runs   (    0.38 ms per token,  2632.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.84 ms /    17 tokens (   72.99 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8091.61 ms /    12 runs   (  674.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9367.40 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2625.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.16 ms /    17 tokens (   77.54 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:        eval time =    7418.60 ms /    11 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8768.78 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    13 runs   (    0.38 ms per token,  2628.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.44 ms /    17 tokens (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8060.00 ms /    12 runs   (  671.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9468.61 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 800th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.25 ms /    14 runs   (    0.37 ms per token,  2667.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.41 ms /    20 tokens (   71.82 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8844.75 ms /    13 runs   (  680.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10319.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    14 runs   (    0.37 ms per token,  2686.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.61 ms /    18 tokens (   74.20 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =    8830.47 ms /    13 runs   (  679.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10203.99 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2630.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.99 ms /    19 tokens (   72.05 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9486.22 ms /    14 runs   (  677.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10896.29 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    15 runs   (    0.37 ms per token,  2706.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.57 ms /    19 tokens (   75.40 ms per token,    13.26 tokens per second)\n",
      "llama_print_timings:        eval time =    9673.02 ms /    14 runs   (  690.93 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11147.23 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    14 runs   (    0.37 ms per token,  2674.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.31 ms /    19 tokens (   72.96 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =    8829.19 ms /    13 runs   (  679.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10254.02 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2603.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.35 ms /    19 tokens (   73.76 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =    9378.59 ms /    14 runs   (  669.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10821.65 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    14 runs   (    0.38 ms per token,  2657.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1640.84 ms /    19 tokens (   86.36 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8740.62 ms /    13 runs   (  672.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10419.02 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    14 runs   (    0.38 ms per token,  2616.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.02 ms /    19 tokens (   72.26 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    8822.41 ms /    13 runs   (  678.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10234.06 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /    14 runs   (    0.37 ms per token,  2725.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.83 ms /    18 tokens (   71.88 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =    8661.11 ms /    13 runs   (  666.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    9992.86 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2653.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1610.20 ms /    19 tokens (   84.75 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:        eval time =    9533.28 ms /    14 runs   (  680.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11184.75 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    15 runs   (    0.36 ms per token,  2740.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.28 ms /    19 tokens (   74.65 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =    9415.33 ms /    14 runs   (  672.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10875.25 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    14 runs   (    0.38 ms per token,  2624.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.76 ms /    18 tokens (   72.88 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8785.33 ms /    13 runs   (  675.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10134.79 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1531.92 ms /    19 tokens (   80.63 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:        eval time =    9483.04 ms /    14 runs   (  677.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11055.66 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2680.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1467.60 ms /    18 tokens (   81.53 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:        eval time =    9407.40 ms /    14 runs   (  671.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10916.94 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    15 runs   (    0.37 ms per token,  2738.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.77 ms /    19 tokens (   71.72 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9529.24 ms /    14 runs   (  680.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10932.41 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    15 runs   (    0.37 ms per token,  2697.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.33 ms /    19 tokens (   74.96 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =    9407.95 ms /    14 runs   (  672.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10873.51 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    14 runs   (    0.38 ms per token,  2649.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.13 ms /    19 tokens (   71.85 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8816.86 ms /    13 runs   (  678.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10220.48 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2683.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.52 ms /    19 tokens (   75.61 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =    9533.52 ms /    14 runs   (  680.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11010.99 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    15 runs   (    0.45 ms per token,  2226.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.25 ms /    19 tokens (   79.80 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:        eval time =    9551.61 ms /    14 runs   (  682.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11115.02 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.18 ms /    14 runs   (    0.37 ms per token,  2701.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.96 ms /    19 tokens (   73.00 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8857.27 ms /    13 runs   (  681.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10281.03 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    14 runs   (    0.38 ms per token,  2607.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.52 ms /    19 tokens (   65.87 ms per token,    15.18 tokens per second)\n",
      "llama_print_timings:        eval time =    8913.26 ms /    13 runs   (  685.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10202.65 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2677.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1364.70 ms /    19 tokens (   71.83 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    9601.64 ms /    14 runs   (  685.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11006.78 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    16 runs   (    0.37 ms per token,  2713.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1532.40 ms /    19 tokens (   80.65 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10194.51 ms /    15 runs   (  679.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11770.57 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2667.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1536.86 ms /    19 tokens (   80.89 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:        eval time =    9467.32 ms /    14 runs   (  676.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11045.67 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    14 runs   (    0.36 ms per token,  2770.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.62 ms /    19 tokens (   85.77 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =    8701.34 ms /    13 runs   (  669.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10371.24 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    14 runs   (    0.38 ms per token,  2629.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.64 ms /    19 tokens (   76.30 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =    8852.07 ms /    13 runs   (  680.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10339.40 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    15 runs   (    0.37 ms per token,  2734.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.81 ms /    19 tokens (   72.20 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =    9557.72 ms /    14 runs   (  682.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10971.26 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.01 ms /    15 runs   (    0.40 ms per token,  2495.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.52 ms /    19 tokens (   72.66 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =    9543.38 ms /    14 runs   (  681.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10966.90 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1364.08 ms /    19 tokens (   71.79 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =    9571.80 ms /    14 runs   (  683.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10977.10 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.18 ms /    14 runs   (    0.37 ms per token,  2704.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.57 ms /    19 tokens (   71.14 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =    8887.85 ms /    13 runs   (  683.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10278.73 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2680.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.20 ms /    19 tokens (   76.59 ms per token,    13.06 tokens per second)\n",
      "llama_print_timings:        eval time =    9507.70 ms /    14 runs   (  679.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11006.04 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    14 runs   (    0.37 ms per token,  2671.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.69 ms /    19 tokens (   72.88 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8803.99 ms /    13 runs   (  677.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10227.53 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    14 runs   (    0.37 ms per token,  2686.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.93 ms /    19 tokens (   73.10 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    8546.25 ms /    13 runs   (  657.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    9973.05 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    15 runs   (    0.37 ms per token,  2696.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.39 ms /    19 tokens (   73.23 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =    9568.54 ms /    14 runs   (  683.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11000.43 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2642.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.80 ms /    19 tokens (   73.67 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    9414.89 ms /    14 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10854.44 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    15 runs   (    0.38 ms per token,  2635.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.20 ms /    19 tokens (   74.96 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =    9246.09 ms /    14 runs   (  660.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10711.25 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2603.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.90 ms /    19 tokens (   77.31 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =    9306.02 ms /    14 runs   (  664.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10816.52 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    15 runs   (    0.37 ms per token,  2734.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.95 ms /    19 tokens (   73.05 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =    9367.40 ms /    14 runs   (  669.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10796.02 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    14 runs   (    0.37 ms per token,  2669.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.43 ms /    19 tokens (   73.34 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =    8696.64 ms /    13 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10127.67 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    15 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.50 ms /    18 tokens (   77.08 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:        eval time =    9360.88 ms /    14 runs   (  668.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10789.47 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    14 runs   (    0.44 ms per token,  2251.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.47 ms /    19 tokens (   71.50 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =    8647.21 ms /    13 runs   (  665.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10048.69 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2683.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.93 ms /    19 tokens (   74.26 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =    9458.42 ms /    14 runs   (  675.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10911.28 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2683.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.36 ms /    19 tokens (   72.44 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =    9409.94 ms /    14 runs   (  672.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10826.42 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    15 runs   (    0.37 ms per token,  2708.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1558.58 ms /    19 tokens (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:        eval time =    9477.31 ms /    14 runs   (  676.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11077.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2690.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.74 ms /    17 tokens (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:        eval time =    9538.90 ms /    14 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10905.29 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    14 runs   (    0.37 ms per token,  2689.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.66 ms /    19 tokens (   63.46 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8733.56 ms /    13 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9978.38 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    14 runs   (    0.38 ms per token,  2647.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.54 ms /    19 tokens (   70.55 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =    8771.92 ms /    13 runs   (  674.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10150.48 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1474.91 ms /    19 tokens (   77.63 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9454.27 ms /    14 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10970.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.32 ms /    14 runs   (    0.38 ms per token,  2633.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.40 ms /    19 tokens (   75.28 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8701.85 ms /    13 runs   (  669.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10170.78 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    14 runs   (    0.37 ms per token,  2711.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.46 ms /    18 tokens (   76.30 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =    8797.86 ms /    13 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10208.90 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2639.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.49 ms /    19 tokens (   72.71 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =    9183.53 ms /    14 runs   (  655.97 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   10607.47 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    15 runs   (    0.38 ms per token,  2601.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.18 ms /    19 tokens (   71.75 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9353.36 ms /    14 runs   (  668.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10757.45 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2703.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.91 ms /    19 tokens (   71.73 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9353.72 ms /    14 runs   (  668.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10757.58 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    15 runs   (    0.38 ms per token,  2628.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1352.69 ms /    19 tokens (   71.19 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =    9242.22 ms /    14 runs   (  660.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10636.58 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.02 ms /    14 runs   (    0.36 ms per token,  2786.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.80 ms /    19 tokens (   77.15 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:        eval time =    8802.98 ms /    13 runs   (  677.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10306.80 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2687.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.22 ms /    19 tokens (   76.17 ms per token,    13.13 tokens per second)\n",
      "llama_print_timings:        eval time =    9450.36 ms /    14 runs   (  675.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10937.76 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    14 runs   (    0.39 ms per token,  2586.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.59 ms /    19 tokens (   71.40 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8751.77 ms /    13 runs   (  673.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10146.27 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2689.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.66 ms /    19 tokens (   73.40 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =    9535.74 ms /    14 runs   (  681.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10971.43 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2681.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.75 ms /    19 tokens (   78.20 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:        eval time =    9415.16 ms /    14 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10942.59 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    15 runs   (    0.38 ms per token,  2625.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.94 ms /    19 tokens (   72.89 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    9398.40 ms /    14 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10825.09 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    14 runs   (    0.37 ms per token,  2739.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1522.61 ms /    19 tokens (   80.14 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:        eval time =    8846.60 ms /    13 runs   (  680.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10407.74 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    16 runs   (    0.37 ms per token,  2698.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1552.66 ms /    19 tokens (   81.72 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10128.98 ms /    15 runs   (  675.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11724.35 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2701.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.80 ms /    19 tokens (   73.57 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =    9491.65 ms /    14 runs   (  677.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10930.35 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.32 ms /    14 runs   (    0.38 ms per token,  2633.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1467.53 ms /    19 tokens (   77.24 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:        eval time =    8737.39 ms /    13 runs   (  672.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10243.66 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2669.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.91 ms /    19 tokens (   77.31 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =    9427.09 ms /    14 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10936.64 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.53 ms /    15 runs   (    0.37 ms per token,  2712.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1361.31 ms /    19 tokens (   71.65 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =    9476.29 ms /    14 runs   (  676.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10879.41 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2703.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1464.20 ms /    19 tokens (   77.06 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:        eval time =    9492.05 ms /    14 runs   (  678.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10996.79 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    14 runs   (    0.38 ms per token,  2646.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.13 ms /    19 tokens (   73.11 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    8754.06 ms /    13 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10181.21 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    14 runs   (    0.37 ms per token,  2709.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.98 ms /    19 tokens (   84.42 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8798.57 ms /    13 runs   (  676.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10439.67 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2684.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1523.02 ms /    19 tokens (   80.16 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:        eval time =    9653.09 ms /    14 runs   (  689.51 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11215.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    14 runs   (    0.37 ms per token,  2711.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.49 ms /    19 tokens (   73.13 ms per token,    13.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8793.62 ms /    13 runs   (  676.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10222.03 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    15 runs   (    0.37 ms per token,  2696.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.67 ms /    19 tokens (   76.46 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =    9485.22 ms /    14 runs   (  677.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10979.03 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    14 runs   (    0.39 ms per token,  2593.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.91 ms /    19 tokens (   73.63 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8800.54 ms /    13 runs   (  676.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10237.44 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    14 runs   (    0.37 ms per token,  2677.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.16 ms /    18 tokens (   71.62 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =    8761.82 ms /    13 runs   (  673.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10088.95 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2624.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.88 ms /    19 tokens (   79.78 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:        eval time =    9461.31 ms /    14 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11018.31 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    15 runs   (    0.36 ms per token,  2756.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.92 ms /    18 tokens (   72.94 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =    9516.07 ms /    14 runs   (  679.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10870.08 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.45 ms /    15 runs   (    0.36 ms per token,  2753.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1626.04 ms /    19 tokens (   85.58 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:        eval time =    9449.89 ms /    14 runs   (  674.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11116.74 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2633.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.98 ms /    19 tokens (   76.42 ms per token,    13.09 tokens per second)\n",
      "llama_print_timings:        eval time =    9489.52 ms /    14 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10982.45 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    14 runs   (    0.39 ms per token,  2565.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1569.50 ms /    19 tokens (   82.61 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:        eval time =    8865.66 ms /    13 runs   (  681.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10474.47 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    14 runs   (    0.38 ms per token,  2614.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1547.33 ms /    19 tokens (   81.44 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8883.51 ms /    13 runs   (  683.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10470.87 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.18 ms /    14 runs   (    0.37 ms per token,  2703.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.95 ms /    19 tokens (   74.63 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =    8800.76 ms /    13 runs   (  676.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10256.24 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    14 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.36 ms /    19 tokens (   73.07 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =    8770.04 ms /    13 runs   (  674.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10197.81 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2669.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.41 ms /    19 tokens (   75.76 ms per token,    13.20 tokens per second)\n",
      "llama_print_timings:        eval time =    9455.73 ms /    14 runs   (  675.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10936.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2684.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.29 ms /    19 tokens (   77.49 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9473.22 ms /    14 runs   (  676.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10986.67 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    14 runs   (    0.38 ms per token,  2649.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.66 ms /    19 tokens (   71.09 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =    8926.32 ms /    13 runs   (  686.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10315.97 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2651.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1609.02 ms /    19 tokens (   84.69 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:        eval time =    9512.93 ms /    14 runs   (  679.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11163.02 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    15 runs   (    0.38 ms per token,  2664.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.02 ms /    19 tokens (   73.37 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9584.84 ms /    14 runs   (  684.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11019.71 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    14 runs   (    0.37 ms per token,  2693.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1527.80 ms /    18 tokens (   84.88 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8820.57 ms /    13 runs   (  678.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10386.52 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    15 runs   (    0.37 ms per token,  2672.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.07 ms /    19 tokens (   73.32 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =    9388.58 ms /    14 runs   (  670.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10823.38 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.88 ms /    19 tokens (   76.52 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:        eval time =    9557.90 ms /    14 runs   (  682.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11052.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2686.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.74 ms /    19 tokens (   72.78 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =    9371.21 ms /    14 runs   (  669.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10796.89 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.18 ms /    14 runs   (    0.37 ms per token,  2704.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.78 ms /    19 tokens (   81.41 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8919.37 ms /    13 runs   (  686.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10504.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    15 runs   (    0.37 ms per token,  2698.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.22 ms /    19 tokens (   75.27 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =    9428.97 ms /    14 runs   (  673.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10899.85 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.09 ms /    14 runs   (    0.36 ms per token,  2747.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.16 ms /    19 tokens (   72.22 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8861.55 ms /    13 runs   (  681.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10270.72 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2653.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.44 ms /    19 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =    9478.96 ms /    14 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10521.04 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    15 runs   (    0.37 ms per token,  2673.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.73 ms /    18 tokens (   73.71 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    9506.78 ms /    14 runs   (  679.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10874.75 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.45 ms /    15 runs   (    0.36 ms per token,  2752.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.62 ms /    19 tokens (   74.87 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =    9372.03 ms /    14 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10835.18 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.32 ms /    14 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.43 ms /    19 tokens (   72.34 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8825.11 ms /    13 runs   (  678.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10238.00 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    14 runs   (    0.38 ms per token,  2651.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1464.50 ms /    19 tokens (   77.08 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8795.80 ms /    13 runs   (  676.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10299.55 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    14 runs   (    0.37 ms per token,  2706.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1509.60 ms /    19 tokens (   79.45 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8793.29 ms /    13 runs   (  676.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10341.64 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 900th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    15 runs   (    0.38 ms per token,  2635.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1469.11 ms /    19 tokens (   77.32 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =    9444.02 ms /    14 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10954.96 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2656.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.66 ms /    19 tokens (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9505.05 ms /    14 runs   (  678.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11023.58 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2589.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.46 ms /    19 tokens (   83.55 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =    9501.73 ms /    14 runs   (  678.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11130.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    15 runs   (    0.38 ms per token,  2625.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.59 ms /    19 tokens (   77.45 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9435.05 ms /    14 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10947.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.81 ms /    15 runs   (    0.39 ms per token,  2583.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.30 ms /    18 tokens (   76.29 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =    9463.70 ms /    14 runs   (  675.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10877.08 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.13 ms /    19 tokens (   71.11 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =    9449.35 ms /    14 runs   (  674.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10841.64 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2620.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1536.53 ms /    19 tokens (   80.87 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9433.66 ms /    14 runs   (  673.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11011.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2654.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.23 ms /    19 tokens (   73.28 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =    9507.97 ms /    14 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10941.57 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2605.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.21 ms /    19 tokens (   79.91 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:        eval time =    9452.50 ms /    14 runs   (  675.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11012.33 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2612.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.86 ms /    19 tokens (   75.57 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =    9400.53 ms /    14 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10878.54 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2643.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.24 ms /    19 tokens (   73.91 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    9488.15 ms /    14 runs   (  677.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10934.45 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2611.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.58 ms /    19 tokens (   72.66 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =    9499.30 ms /    14 runs   (  678.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10921.73 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2616.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.77 ms /    19 tokens (   79.36 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:        eval time =    9475.25 ms /    14 runs   (  676.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11023.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    15 runs   (    0.39 ms per token,  2561.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.61 ms /    18 tokens (   73.26 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =    9513.15 ms /    14 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10873.89 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    15 runs   (    0.40 ms per token,  2531.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.50 ms /    19 tokens (   72.45 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =    9451.31 ms /    14 runs   (  675.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10869.16 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2609.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.63 ms /    19 tokens (   72.98 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    9369.91 ms /    14 runs   (  669.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10797.25 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    15 runs   (    0.39 ms per token,  2596.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.53 ms /    19 tokens (   75.50 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =    9401.51 ms /    14 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10876.93 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    13 runs   (    0.37 ms per token,  2678.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.22 ms /    19 tokens (   73.54 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    8060.99 ms /    12 runs   (  671.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9494.70 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2640.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.38 ms /    19 tokens (   60.91 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =    9532.49 ms /    14 runs   (  680.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10730.00 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2612.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.25 ms /    19 tokens (   72.86 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =    9424.73 ms /    14 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10850.37 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2612.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.22 ms /    19 tokens (   73.12 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    9335.70 ms /    14 runs   (  666.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10765.89 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    15 runs   (    0.39 ms per token,  2575.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.41 ms /    19 tokens (   71.44 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =    9424.17 ms /    14 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10822.84 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2639.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1476.49 ms /    19 tokens (   77.71 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:        eval time =    9386.91 ms /    14 runs   (  670.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10904.40 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    13 runs   (    0.45 ms per token,  2201.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.29 ms /    19 tokens (   73.65 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8056.95 ms /    12 runs   (  671.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    9496.98 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    15 runs   (    0.38 ms per token,  2635.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.55 ms /    19 tokens (   72.19 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =    9441.78 ms /    14 runs   (  674.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10855.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    15 runs   (    0.39 ms per token,  2586.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.53 ms /    19 tokens (   74.76 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =    9423.97 ms /    14 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10885.51 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    15 runs   (    0.44 ms per token,  2268.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.13 ms /    19 tokens (   76.06 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =    9320.00 ms /    14 runs   (  665.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10811.75 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2610.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1503.95 ms /    19 tokens (   79.16 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9539.40 ms /    14 runs   (  681.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11084.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    14 runs   (    0.38 ms per token,  2637.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1522.89 ms /    19 tokens (   80.15 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:        eval time =    8833.46 ms /    13 runs   (  679.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10395.74 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2631.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.63 ms /    19 tokens (   84.93 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:        eval time =    9522.12 ms /    14 runs   (  680.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11176.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    15 runs   (    0.39 ms per token,  2568.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.95 ms /    19 tokens (   73.10 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =    9505.96 ms /    14 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10936.15 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.00 ms /    19 tokens (   73.21 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =    9401.87 ms /    14 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10834.02 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    15 runs   (    0.39 ms per token,  2576.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.22 ms /    19 tokens (   71.91 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9399.20 ms /    14 runs   (  671.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10806.34 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.89 ms /    15 runs   (    0.39 ms per token,  2546.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.31 ms /    19 tokens (   71.38 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =    9473.33 ms /    14 runs   (  676.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10870.02 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2622.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1503.19 ms /    19 tokens (   79.12 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:        eval time =    9506.94 ms /    14 runs   (  679.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11052.82 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    15 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.50 ms /    19 tokens (   71.34 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =    9517.59 ms /    14 runs   (  679.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10915.25 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    15 runs   (    0.38 ms per token,  2625.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.27 ms /    19 tokens (   74.96 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =    9479.58 ms /    14 runs   (  677.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10946.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    15 runs   (    0.39 ms per token,  2552.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.59 ms /    19 tokens (   71.56 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =    9484.48 ms /    14 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10886.14 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2592.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.23 ms /    19 tokens (   73.22 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =    9448.16 ms /    14 runs   (  674.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10881.14 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2622.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.16 ms /    19 tokens (   78.43 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:        eval time =    9442.98 ms /    14 runs   (  674.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10974.03 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2650.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1595.73 ms /    19 tokens (   83.99 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9536.55 ms /    14 runs   (  681.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11174.27 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    14 runs   (    0.39 ms per token,  2585.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.58 ms /    19 tokens (   72.77 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8851.20 ms /    13 runs   (  680.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10271.72 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2654.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.05 ms /    18 tokens (   85.28 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:        eval time =    9677.38 ms /    14 runs   (  691.24 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11251.99 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    15 runs   (    0.39 ms per token,  2564.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.22 ms /    19 tokens (   73.54 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    9413.43 ms /    14 runs   (  672.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10851.75 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2610.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.22 ms /    19 tokens (   75.54 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =    9552.36 ms /    14 runs   (  682.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11028.88 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.81 ms /    15 runs   (    0.39 ms per token,  2581.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.11 ms /    19 tokens (   72.53 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =    9439.29 ms /    14 runs   (  674.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10858.54 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    15 runs   (    0.38 ms per token,  2627.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.18 ms /    19 tokens (   76.22 ms per token,    13.12 tokens per second)\n",
      "llama_print_timings:        eval time =    9453.87 ms /    14 runs   (  675.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10942.57 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    15 runs   (    0.37 ms per token,  2676.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.98 ms /    18 tokens (   73.39 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9439.05 ms /    14 runs   (  674.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10800.98 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2620.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.37 ms /    19 tokens (   74.12 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    9425.57 ms /    14 runs   (  673.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10876.32 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2632.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.82 ms /    19 tokens (   72.52 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =    9482.56 ms /    14 runs   (  677.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10901.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2651.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.08 ms /    19 tokens (   71.90 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9387.07 ms /    14 runs   (  670.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10793.72 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2624.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.96 ms /    17 tokens (   76.76 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9345.14 ms /    14 runs   (  667.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10690.39 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1538.45 ms /    19 tokens (   80.97 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:        eval time =    9483.18 ms /    14 runs   (  677.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11063.04 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2670.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.56 ms /    19 tokens (   77.19 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:        eval time =    9480.36 ms /    14 runs   (  677.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10988.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.28 ms /    16 runs   (    0.39 ms per token,  2548.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.35 ms /    19 tokens (   73.33 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10194.01 ms /    15 runs   (  679.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11632.28 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    15 runs   (    0.39 ms per token,  2595.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1364.53 ms /    19 tokens (   71.82 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    9541.57 ms /    14 runs   (  681.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10946.91 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2689.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1460.00 ms /    19 tokens (   76.84 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:        eval time =    9386.16 ms /    14 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10886.64 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    15 runs   (    0.39 ms per token,  2579.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.00 ms /    19 tokens (   71.84 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    9410.14 ms /    14 runs   (  672.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10816.21 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2669.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.79 ms /    19 tokens (   72.73 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =    9372.45 ms /    14 runs   (  669.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10795.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2592.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1591.39 ms /    19 tokens (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9507.85 ms /    14 runs   (  679.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11141.10 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    14 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.36 ms /    19 tokens (   73.91 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    8696.84 ms /    13 runs   (  668.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10139.90 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    15 runs   (    0.38 ms per token,  2658.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.06 ms /    19 tokens (   84.21 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:        eval time =    9557.97 ms /    14 runs   (  682.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11200.00 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2622.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.05 ms /    19 tokens (   75.69 ms per token,    13.21 tokens per second)\n",
      "llama_print_timings:        eval time =    9540.33 ms /    14 runs   (  681.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11020.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    15 runs   (    0.39 ms per token,  2553.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.33 ms /    19 tokens (   73.33 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =    9592.53 ms /    14 runs   (  685.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11027.17 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2619.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.55 ms /    19 tokens (   72.34 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    9573.39 ms /    14 runs   (  683.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10988.37 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /    14 runs   (    0.38 ms per token,  2610.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1469.70 ms /    19 tokens (   77.35 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =    8864.54 ms /    13 runs   (  681.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10372.13 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2592.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1615.94 ms /    19 tokens (   85.05 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =    9547.55 ms /    14 runs   (  681.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11203.89 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    15 runs   (    0.39 ms per token,  2584.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.27 ms /    19 tokens (   78.91 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:        eval time =    9485.68 ms /    14 runs   (  677.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11025.43 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2642.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.63 ms /    18 tokens (   72.15 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9489.15 ms /    14 runs   (  677.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10828.65 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    14 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1542.14 ms /    18 tokens (   85.67 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8875.52 ms /    13 runs   (  682.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10455.90 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2624.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.48 ms /    19 tokens (   71.60 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =    9450.71 ms /    14 runs   (  675.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10853.21 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    13 runs   (    0.39 ms per token,  2569.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.07 ms /    19 tokens (   76.90 ms per token,    13.00 tokens per second)\n",
      "llama_print_timings:        eval time =    8111.95 ms /    12 runs   (  676.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9608.48 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    15 runs   (    0.39 ms per token,  2576.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1475.59 ms /    19 tokens (   77.66 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9515.17 ms /    14 runs   (  679.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11032.44 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2606.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.44 ms /    19 tokens (   71.97 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =    9543.33 ms /    14 runs   (  681.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10952.28 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    15 runs   (    0.38 ms per token,  2600.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.23 ms /    19 tokens (   75.49 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    9517.39 ms /    14 runs   (  679.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10993.40 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    15 runs   (    0.39 ms per token,  2567.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.32 ms /    18 tokens (   70.91 ms per token,    14.10 tokens per second)\n",
      "llama_print_timings:        eval time =    9544.26 ms /    14 runs   (  681.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10861.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2687.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.36 ms /    19 tokens (   75.49 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    9565.42 ms /    14 runs   (  683.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11040.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2647.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.82 ms /    19 tokens (   85.89 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:        eval time =    9490.14 ms /    14 runs   (  677.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11163.08 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.34 ms /    19 tokens (   72.81 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =    9385.75 ms /    14 runs   (  670.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10810.62 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    15 runs   (    0.38 ms per token,  2662.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.73 ms /    19 tokens (   72.99 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    9431.71 ms /    14 runs   (  673.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10859.13 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2639.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1610.38 ms /    19 tokens (   84.76 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:        eval time =    9488.31 ms /    14 runs   (  677.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11139.26 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    15 runs   (    0.39 ms per token,  2541.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.46 ms /    19 tokens (   72.34 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =    9381.13 ms /    14 runs   (  670.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10797.90 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.56 ms /    19 tokens (   71.71 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9539.31 ms /    14 runs   (  681.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10943.21 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    15 runs   (    0.38 ms per token,  2597.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.55 ms /    19 tokens (   76.40 ms per token,    13.09 tokens per second)\n",
      "llama_print_timings:        eval time =    9428.60 ms /    14 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10921.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    15 runs   (    0.38 ms per token,  2600.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.27 ms /    19 tokens (   73.38 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9470.77 ms /    14 runs   (  676.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10906.11 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2621.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.37 ms /    19 tokens (   71.49 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =    9500.23 ms /    14 runs   (  678.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10899.14 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    13 runs   (    0.38 ms per token,  2623.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.91 ms /    18 tokens (   73.49 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8169.97 ms /    12 runs   (  680.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9529.02 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    14 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.62 ms /    19 tokens (   72.14 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =    8797.48 ms /    13 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10205.27 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2629.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.80 ms /    18 tokens (   77.16 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:        eval time =    9568.33 ms /    14 runs   (  683.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10998.57 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2591.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.56 ms /    19 tokens (   84.50 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:        eval time =    9355.26 ms /    14 runs   (  668.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11002.51 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    15 runs   (    0.37 ms per token,  2708.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1590.94 ms /    19 tokens (   83.73 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9513.58 ms /    14 runs   (  679.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11145.02 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2671.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.47 ms /    19 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =    9443.99 ms /    14 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10493.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2683.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.30 ms /    19 tokens (   71.54 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =    9445.55 ms /    14 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10845.97 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    13 runs   (    0.42 ms per token,  2408.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1602.53 ms /    19 tokens (   84.34 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =    8085.96 ms /    12 runs   (  673.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9725.75 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.66 ms /    18 tokens (   72.43 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =    9425.89 ms /    14 runs   (  673.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10770.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    14 runs   (    0.38 ms per token,  2645.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.05 ms /    19 tokens (   77.42 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8766.63 ms /    13 runs   (  674.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10276.69 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    14 runs   (    0.38 ms per token,  2644.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.13 ms /    19 tokens (   75.11 ms per token,    13.31 tokens per second)\n",
      "llama_print_timings:        eval time =    8780.97 ms /    13 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10246.50 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2645.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.71 ms /    19 tokens (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:        eval time =    9489.03 ms /    14 runs   (  677.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11138.36 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    14 runs   (    0.39 ms per token,  2573.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.55 ms /    19 tokens (   70.66 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =    8720.69 ms /    13 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10102.70 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2623.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.94 ms /    19 tokens (   74.10 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    9454.83 ms /    14 runs   (  675.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10904.82 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1000th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    12 runs   (    0.39 ms per token,  2596.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.08 ms /    20 tokens (   71.80 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =    7421.13 ms /    11 runs   (  674.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8889.84 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    12 runs   (    0.38 ms per token,  2623.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1610.36 ms /    19 tokens (   84.76 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:        eval time =    7521.11 ms /    11 runs   (  683.74 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9163.98 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    14 runs   (    0.39 ms per token,  2595.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.12 ms /    19 tokens (   76.06 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =    8854.16 ms /    13 runs   (  681.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10337.33 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    14 runs   (    0.38 ms per token,  2635.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1459.60 ms /    19 tokens (   76.82 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =    8855.41 ms /    13 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10353.08 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    12 runs   (    0.38 ms per token,  2616.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.02 ms /    19 tokens (   76.63 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:        eval time =    7406.72 ms /    11 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8895.26 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2640.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1579.22 ms /    19 tokens (   83.12 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9345.61 ms /    14 runs   (  667.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10965.69 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2688.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.41 ms /    19 tokens (   71.86 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    9491.95 ms /    14 runs   (  678.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10898.22 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    15 runs   (    0.37 ms per token,  2705.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.59 ms /    19 tokens (   74.77 ms per token,    13.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9488.00 ms /    14 runs   (  677.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10949.44 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    15 runs   (    0.39 ms per token,  2578.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1595.21 ms /    19 tokens (   83.96 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9568.95 ms /    14 runs   (  683.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11205.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    14 runs   (    0.37 ms per token,  2675.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.79 ms /    19 tokens (   74.62 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =    8816.56 ms /    13 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10272.89 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    14 runs   (    0.37 ms per token,  2681.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1506.80 ms /    19 tokens (   79.31 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8810.20 ms /    13 runs   (  677.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10355.58 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    14 runs   (    0.38 ms per token,  2615.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.14 ms /    19 tokens (   85.74 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =    8773.96 ms /    13 runs   (  674.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10441.53 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    14 runs   (    0.39 ms per token,  2595.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.29 ms /    19 tokens (   73.59 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8826.39 ms /    13 runs   (  678.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10263.35 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2676.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1595.87 ms /    19 tokens (   83.99 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9547.02 ms /    14 runs   (  681.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11183.75 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2647.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.61 ms /    19 tokens (   73.14 ms per token,    13.67 tokens per second)\n",
      "llama_print_timings:        eval time =    9633.49 ms /    14 runs   (  688.11 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11064.21 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    12 runs   (    0.39 ms per token,  2535.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.06 ms /    19 tokens (   79.74 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7517.79 ms /    11 runs   (  683.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    9065.60 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    14 runs   (    0.38 ms per token,  2607.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.60 ms /    19 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =    8844.20 ms /    13 runs   (  680.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9883.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    14 runs   (    0.38 ms per token,  2599.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.54 ms /    19 tokens (   77.45 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:        eval time =    8722.36 ms /    13 runs   (  670.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10232.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.91 ms /    19 tokens (   84.42 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =    7448.10 ms /    11 runs   (  677.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    9085.04 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    15 runs   (    0.37 ms per token,  2693.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.93 ms /    18 tokens (   75.50 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    9428.70 ms /    14 runs   (  673.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10828.68 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    15 runs   (    0.39 ms per token,  2593.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.27 ms /    19 tokens (   72.49 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =    9462.22 ms /    14 runs   (  675.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10881.01 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    12 runs   (    0.37 ms per token,  2677.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.87 ms /    19 tokens (   72.57 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =    7449.85 ms /    11 runs   (  677.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8861.09 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    14 runs   (    0.38 ms per token,  2653.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.18 ms /    19 tokens (   71.54 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =    8634.37 ms /    13 runs   (  664.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10031.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2677.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.32 ms /    19 tokens (   72.23 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =    9494.16 ms /    14 runs   (  678.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10908.72 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    14 runs   (    0.37 ms per token,  2711.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.66 ms /    19 tokens (   72.25 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    8852.11 ms /    13 runs   (  680.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10263.76 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    14 runs   (    0.40 ms per token,  2493.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.99 ms /    19 tokens (   72.63 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =    8794.41 ms /    13 runs   (  676.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10214.64 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    15 runs   (    0.41 ms per token,  2447.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.99 ms /    18 tokens (   73.50 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =    9533.57 ms /    14 runs   (  680.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10900.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2591.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1594.46 ms /    19 tokens (   83.92 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =    7320.80 ms /    11 runs   (  665.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    8948.45 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    15 runs   (    0.37 ms per token,  2720.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1364.87 ms /    19 tokens (   71.84 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    9471.08 ms /    14 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10876.82 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2588.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.88 ms /    19 tokens (   73.63 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    9475.91 ms /    14 runs   (  676.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10917.14 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2680.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.14 ms /    19 tokens (   72.06 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9466.76 ms /    14 runs   (  676.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10876.47 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.01 ms /    16 runs   (    0.38 ms per token,  2664.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.86 ms /    19 tokens (   77.15 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10091.78 ms /    15 runs   (  672.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11601.48 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2621.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.27 ms /    19 tokens (   73.01 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    9441.05 ms /    14 runs   (  674.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10870.56 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    14 runs   (    0.38 ms per token,  2646.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.79 ms /    19 tokens (   72.52 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =    8897.51 ms /    13 runs   (  684.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10313.86 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.19 ms /    19 tokens (   71.38 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =    9445.01 ms /    14 runs   (  674.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10842.17 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.08 ms /    18 tokens (   84.39 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =    9447.39 ms /    14 runs   (  674.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11007.77 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.43 ms /    14 runs   (    0.39 ms per token,  2579.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.45 ms /    19 tokens (   72.55 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8745.27 ms /    13 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10162.66 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2613.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1602.74 ms /    19 tokens (   84.35 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =    9386.50 ms /    14 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11030.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2639.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.79 ms /    19 tokens (   72.88 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    9256.05 ms /    14 runs   (  661.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10681.72 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    14 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.90 ms /    19 tokens (   79.78 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:        eval time =    8771.33 ms /    13 runs   (  674.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10324.62 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    15 runs   (    0.38 ms per token,  2661.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.48 ms /    19 tokens (   71.29 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9404.80 ms /    14 runs   (  671.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10800.34 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.26 ms /    18 tokens (   63.13 ms per token,    15.84 tokens per second)\n",
      "llama_print_timings:        eval time =    9530.36 ms /    14 runs   (  680.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10706.79 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    15 runs   (    0.37 ms per token,  2673.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.16 ms /    18 tokens (   74.45 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =    9404.03 ms /    14 runs   (  671.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10785.23 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    14 runs   (    0.37 ms per token,  2685.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.55 ms /    19 tokens (   73.34 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    8910.12 ms /    13 runs   (  685.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10342.30 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    14 runs   (    0.38 ms per token,  2620.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.85 ms /    18 tokens (   72.10 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =    8848.22 ms /    13 runs   (  680.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10184.49 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.89 ms /    15 runs   (    0.39 ms per token,  2548.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1476.60 ms /    19 tokens (   77.72 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:        eval time =    9473.84 ms /    14 runs   (  676.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10992.78 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2611.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.57 ms /    19 tokens (   75.61 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =    9516.24 ms /    14 runs   (  679.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10994.22 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    14 runs   (    0.38 ms per token,  2640.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.72 ms /    19 tokens (   73.20 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =    8818.52 ms /    13 runs   (  678.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10248.74 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2669.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.55 ms /    19 tokens (   72.61 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =    9513.81 ms /    14 runs   (  679.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10936.11 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    12 runs   (    0.39 ms per token,  2589.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.21 ms /    19 tokens (   70.96 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =    7403.59 ms /    11 runs   (  673.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8785.28 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2633.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.67 ms /    19 tokens (   71.98 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =    9397.93 ms /    14 runs   (  671.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10806.77 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2644.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.06 ms /    19 tokens (   73.27 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =    7435.57 ms /    11 runs   (  675.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8860.86 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2683.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.69 ms /    19 tokens (   74.51 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =    9525.09 ms /    14 runs   (  680.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10981.44 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.58 ms /    19 tokens (   73.82 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =    9577.90 ms /    14 runs   (  684.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11023.27 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    24 runs   (    0.38 ms per token,  2656.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.15 ms /    19 tokens (   75.32 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =   15566.57 ms /    23 runs   (  676.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17063.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.82 ms /    19 tokens (   76.36 ms per token,    13.10 tokens per second)\n",
      "llama_print_timings:        eval time =    9524.95 ms /    14 runs   (  680.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11017.28 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2588.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.64 ms /    19 tokens (   71.77 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =    9480.57 ms /    14 runs   (  677.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10884.96 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    16 runs   (    0.37 ms per token,  2685.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.29 ms /    19 tokens (   73.91 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10086.24 ms /    15 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11534.35 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    16 runs   (    0.37 ms per token,  2675.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.51 ms /    18 tokens (   76.53 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10157.51 ms /    15 runs   (  677.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11578.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.68 ms /    28 runs   (    0.38 ms per token,  2621.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1589.43 ms /    19 tokens (   83.65 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:        eval time =   18357.90 ms /    27 runs   (  679.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20025.85 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    15 runs   (    0.39 ms per token,  2587.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.90 ms /    18 tokens (   71.66 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =    9501.88 ms /    14 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10833.37 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.50 ms /    19 tokens (   78.13 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:        eval time =    9456.50 ms /    14 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10982.21 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    15 runs   (    0.37 ms per token,  2705.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1325.71 ms /    18 tokens (   73.65 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    9442.30 ms /    14 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10809.64 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2608.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.49 ms /    19 tokens (   72.03 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9492.37 ms /    14 runs   (  678.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10902.82 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2607.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.85 ms /    19 tokens (   66.68 ms per token,    15.00 tokens per second)\n",
      "llama_print_timings:        eval time =    9530.25 ms /    14 runs   (  680.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10838.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2602.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.16 ms /    18 tokens (   72.68 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =    5447.85 ms /     8 runs   (  680.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    6781.27 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2641.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.85 ms /    18 tokens (   78.83 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:        eval time =    7520.08 ms /    11 runs   (  683.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    8971.91 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2633.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.27 ms /    19 tokens (   73.01 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =    9383.03 ms /    14 runs   (  670.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10811.41 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.13 ms /    19 tokens (   72.80 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =    9337.59 ms /    14 runs   (  666.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10762.31 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2652.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.13 ms /    19 tokens (   71.38 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =    9409.28 ms /    14 runs   (  672.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10807.83 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2678.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.66 ms /    19 tokens (   71.35 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =    9446.16 ms /    14 runs   (  674.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10843.01 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    15 runs   (    0.39 ms per token,  2574.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1524.04 ms /    19 tokens (   80.21 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =    9444.15 ms /    14 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11010.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    15 runs   (    0.39 ms per token,  2586.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1514.80 ms /    19 tokens (   79.73 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:        eval time =    9429.98 ms /    14 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10986.83 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.35 ms /    19 tokens (   78.02 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:        eval time =    9475.95 ms /    14 runs   (  676.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11000.40 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2670.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.16 ms /    19 tokens (   85.90 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:        eval time =    9279.58 ms /    14 runs   (  662.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10953.19 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2681.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.55 ms /    19 tokens (   73.45 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =    9539.83 ms /    14 runs   (  681.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10977.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    15 runs   (    0.38 ms per token,  2610.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1571.86 ms /    19 tokens (   82.73 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =    9561.07 ms /    14 runs   (  682.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11174.59 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2653.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.62 ms /    19 tokens (   72.03 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9363.33 ms /    14 runs   (  668.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10772.64 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2609.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.50 ms /    19 tokens (   84.24 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6037.86 ms /     9 runs   (  670.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    7665.82 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2651.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.90 ms /    19 tokens (   72.73 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =    9482.09 ms /    14 runs   (  677.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10905.81 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2668.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.28 ms /    18 tokens (   82.40 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:        eval time =    9330.19 ms /    14 runs   (  666.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10854.97 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2640.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.88 ms /    19 tokens (   74.15 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =    9525.93 ms /    14 runs   (  680.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10976.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /    10 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.23 ms /    19 tokens (   73.22 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6010.92 ms /     9 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    7429.71 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    15 runs   (    0.37 ms per token,  2719.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.76 ms /    19 tokens (   74.83 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =    9440.71 ms /    14 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10903.34 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    14 runs   (    0.39 ms per token,  2595.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1625.65 ms /    19 tokens (   85.56 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:        eval time =    8875.59 ms /    13 runs   (  682.74 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10540.55 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2655.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.92 ms /    19 tokens (   73.68 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    9528.33 ms /    14 runs   (  680.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10969.95 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    12 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.32 ms /    19 tokens (   75.54 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =    7562.12 ms /    11 runs   (  687.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    9031.34 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2676.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1554.52 ms /    19 tokens (   81.82 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:        eval time =    9544.33 ms /    14 runs   (  681.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11141.38 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2656.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.44 ms /    19 tokens (   72.76 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =    9400.46 ms /    14 runs   (  671.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10825.03 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2680.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.41 ms /    19 tokens (   72.23 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =    9570.01 ms /    14 runs   (  683.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10982.97 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    12 runs   (    0.37 ms per token,  2679.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.13 ms /    19 tokens (   67.80 ms per token,    14.75 tokens per second)\n",
      "llama_print_timings:        eval time =    7435.66 ms /    11 runs   (  675.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    8757.02 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2611.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.15 ms /    19 tokens (   74.48 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =    9514.18 ms /    14 runs   (  679.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10970.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    15 runs   (    0.39 ms per token,  2533.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.58 ms /    19 tokens (   71.87 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9440.49 ms /    14 runs   (  674.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10847.47 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    15 runs   (    0.37 ms per token,  2671.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.72 ms /    19 tokens (   73.51 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    9501.89 ms /    14 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10940.04 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    15 runs   (    0.38 ms per token,  2635.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.83 ms /    19 tokens (   71.99 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =    9627.10 ms /    14 runs   (  687.65 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11036.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    15 runs   (    0.39 ms per token,  2540.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.98 ms /    19 tokens (   85.53 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:        eval time =    9780.35 ms /    14 runs   (  698.60 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   11447.43 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2611.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.97 ms /    19 tokens (   74.68 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:        eval time =    9694.75 ms /    14 runs   (  692.48 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   11156.48 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2613.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.08 ms /    19 tokens (   76.37 ms per token,    13.09 tokens per second)\n",
      "llama_print_timings:        eval time =    9509.39 ms /    14 runs   (  679.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11002.35 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    15 runs   (    0.38 ms per token,  2601.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.52 ms /    19 tokens (   74.40 ms per token,    13.44 tokens per second)\n",
      "llama_print_timings:        eval time =    9639.19 ms /    14 runs   (  688.51 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11094.73 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2671.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.65 ms /    19 tokens (   73.67 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    9482.21 ms /    14 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10922.76 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1100th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    17 runs   (    0.38 ms per token,  2608.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1575.46 ms /    19 tokens (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10793.49 ms /    16 runs   (  674.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12416.60 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    16 runs   (    0.39 ms per token,  2543.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.40 ms /    19 tokens (   76.71 ms per token,    13.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10217.85 ms /    15 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11720.10 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2688.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1599.74 ms /    19 tokens (   84.20 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9507.26 ms /    14 runs   (  679.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11147.99 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.07 ms /    16 runs   (    0.38 ms per token,  2635.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.33 ms /    19 tokens (   78.81 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10244.56 ms /    15 runs   (  682.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11786.31 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2638.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.33 ms /    19 tokens (   74.33 ms per token,    13.45 tokens per second)\n",
      "llama_print_timings:        eval time =    9486.04 ms /    14 runs   (  677.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10939.52 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.06 ms /    16 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.91 ms /    19 tokens (   84.42 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10224.53 ms /    15 runs   (  681.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11872.96 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    15 runs   (    0.38 ms per token,  2625.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1609.64 ms /    19 tokens (   84.72 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:        eval time =    9479.72 ms /    14 runs   (  677.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11130.51 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.14 ms /    16 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.86 ms /    19 tokens (   74.10 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10073.62 ms /    15 runs   (  671.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11525.77 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    13 runs   (    0.38 ms per token,  2610.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.01 ms /    19 tokens (   72.79 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8185.85 ms /    12 runs   (  682.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9605.30 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2689.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.03 ms /    18 tokens (   74.06 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:        eval time =    9525.47 ms /    14 runs   (  680.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10900.25 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    16 runs   (    0.37 ms per token,  2690.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.19 ms /    19 tokens (   75.54 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10238.51 ms /    15 runs   (  682.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11717.75 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    15 runs   (    0.38 ms per token,  2653.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.72 ms /    18 tokens (   79.87 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:        eval time =    9670.22 ms /    14 runs   (  690.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11149.43 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    16 runs   (    0.38 ms per token,  2610.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.40 ms /    19 tokens (   72.71 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10172.10 ms /    15 runs   (  678.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11597.47 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    16 runs   (    0.37 ms per token,  2704.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.73 ms /    19 tokens (   59.83 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10202.89 ms /    15 runs   (  680.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11383.16 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    15 runs   (    0.38 ms per token,  2660.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.17 ms /    19 tokens (   84.22 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:        eval time =    9553.88 ms /    14 runs   (  682.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11195.78 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    15 runs   (    0.37 ms per token,  2671.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.96 ms /    19 tokens (   76.10 ms per token,    13.14 tokens per second)\n",
      "llama_print_timings:        eval time =    9523.68 ms /    14 runs   (  680.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11010.36 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.09 ms /    16 runs   (    0.38 ms per token,  2626.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.21 ms /    19 tokens (   85.38 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10181.09 ms /    15 runs   (  678.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11847.41 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2671.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.74 ms /    19 tokens (   75.14 ms per token,    13.31 tokens per second)\n",
      "llama_print_timings:        eval time =    9631.45 ms /    14 runs   (  687.96 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11101.86 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2680.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.41 ms /    19 tokens (   74.86 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10937.94 ms /    16 runs   (  683.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12407.47 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2658.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1599.72 ms /    19 tokens (   84.20 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10767.48 ms /    16 runs   (  672.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12414.00 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    17 runs   (    0.38 ms per token,  2631.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.82 ms /    19 tokens (   74.25 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10768.73 ms /    16 runs   (  673.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12227.43 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2645.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.12 ms /    19 tokens (   79.90 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:        eval time =    9696.61 ms /    14 runs   (  692.62 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   11256.36 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2671.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.37 ms /    19 tokens (   72.49 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =    9591.77 ms /    14 runs   (  685.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11011.61 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    16 runs   (    0.38 ms per token,  2645.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.02 ms /    19 tokens (   71.74 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10163.31 ms /    15 runs   (  677.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11570.97 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1621.45 ms /    19 tokens (   85.34 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =    9482.89 ms /    14 runs   (  677.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11145.90 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.14 ms /    16 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1475.72 ms /    19 tokens (   77.67 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10182.59 ms /    15 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11705.43 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    16 runs   (    0.39 ms per token,  2591.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.98 ms /    19 tokens (   78.10 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10272.59 ms /    15 runs   (  684.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11801.51 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2291.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.13 ms /    19 tokens (   71.27 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9606.13 ms /    14 runs   (  686.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11003.90 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    16 runs   (    0.37 ms per token,  2677.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.61 ms /    18 tokens (   74.48 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10153.59 ms /    15 runs   (  676.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11538.50 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    15 runs   (    0.39 ms per token,  2574.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.94 ms /    19 tokens (   73.37 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9554.66 ms /    14 runs   (  682.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10990.65 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2680.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.38 ms /    19 tokens (   72.86 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =    9600.83 ms /    14 runs   (  685.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11026.65 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    16 runs   (    0.38 ms per token,  2632.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.07 ms /    19 tokens (   72.74 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10112.86 ms /    15 runs   (  674.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11540.11 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2673.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.00 ms /    19 tokens (   73.42 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10992.85 ms /    16 runs   (  687.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12434.67 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    15 runs   (    0.40 ms per token,  2513.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.19 ms /    19 tokens (   79.64 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:        eval time =    9535.98 ms /    14 runs   (  681.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11091.31 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    15 runs   (    0.39 ms per token,  2563.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.18 ms /    18 tokens (   76.07 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =    9462.00 ms /    14 runs   (  675.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10873.30 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    16 runs   (    0.38 ms per token,  2665.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.34 ms /    19 tokens (   72.75 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10271.08 ms /    15 runs   (  684.74 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11699.40 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2657.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.25 ms /    19 tokens (   59.75 ms per token,    16.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11012.88 ms /    16 runs   (  688.31 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12194.80 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    17 runs   (    0.38 ms per token,  2662.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.32 ms /    19 tokens (   75.02 ms per token,    13.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10948.79 ms /    16 runs   (  684.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12421.31 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    16 runs   (    0.37 ms per token,  2672.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.83 ms /    19 tokens (   73.20 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10277.34 ms /    15 runs   (  685.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11712.43 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    13 runs   (    0.38 ms per token,  2627.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1630.35 ms /    19 tokens (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:        eval time =    8162.09 ms /    12 runs   (  680.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    9828.82 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2618.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.40 ms /    19 tokens (   73.60 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10938.41 ms /    16 runs   (  683.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12384.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    16 runs   (    0.37 ms per token,  2701.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.61 ms /    19 tokens (   73.77 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10230.91 ms /    15 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11676.79 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.06 ms /    16 runs   (    0.38 ms per token,  2639.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.39 ms /    19 tokens (   76.60 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10131.84 ms /    15 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11630.87 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    17 runs   (    0.38 ms per token,  2623.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.52 ms /    19 tokens (   71.50 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10720.53 ms /    16 runs   (  670.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12126.96 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    16 runs   (    0.39 ms per token,  2572.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1531.12 ms /    18 tokens (   85.06 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.77 ms /    15 runs   (  710.32 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   12231.37 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    17 runs   (    0.39 ms per token,  2562.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1702.89 ms /    19 tokens (   89.63 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11502.20 ms /    16 runs   (  718.89 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   13252.86 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.42 ms /    19 tokens (   87.76 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11203.37 ms /    16 runs   (  700.21 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12918.49 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    16 runs   (    0.38 ms per token,  2603.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1364.74 ms /    19 tokens (   71.83 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10184.45 ms /    15 runs   (  678.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11593.94 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    15 runs   (    0.37 ms per token,  2699.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.69 ms /    19 tokens (   86.56 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:        eval time =    9519.52 ms /    14 runs   (  679.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11205.85 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2622.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.53 ms /    19 tokens (   71.92 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =    9566.21 ms /    14 runs   (  683.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10974.40 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.06 ms /    16 runs   (    0.38 ms per token,  2641.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1443.19 ms /    19 tokens (   75.96 ms per token,    13.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10288.10 ms /    15 runs   (  685.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11775.21 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    16 runs   (    0.37 ms per token,  2672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.34 ms /    19 tokens (   71.86 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10281.10 ms /    15 runs   (  685.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11690.47 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    16 runs   (    0.38 ms per token,  2613.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.44 ms /    19 tokens (   76.76 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10162.56 ms /    15 runs   (  677.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11666.27 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2630.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.04 ms /    19 tokens (   73.05 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =    9552.35 ms /    14 runs   (  682.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10982.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2615.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1481.32 ms /    19 tokens (   77.96 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:        eval time =    9443.99 ms /    14 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10967.37 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    15 runs   (    0.38 ms per token,  2600.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.00 ms /    19 tokens (   71.95 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =    9526.96 ms /    14 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10935.64 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    16 runs   (    0.39 ms per token,  2595.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.59 ms /    18 tokens (   73.87 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10196.84 ms /    15 runs   (  679.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11571.55 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2677.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.74 ms /    19 tokens (   78.20 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:        eval time =    9513.67 ms /    14 runs   (  679.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11041.55 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    16 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.86 ms /    19 tokens (   72.99 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10272.61 ms /    15 runs   (  684.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11706.09 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.19 ms /    16 runs   (    0.39 ms per token,  2585.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.29 ms /    19 tokens (   75.02 ms per token,    13.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10260.92 ms /    15 runs   (  684.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11731.07 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2589.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.91 ms /    19 tokens (   55.00 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =    9633.82 ms /    14 runs   (  688.13 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   10719.79 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2676.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1449.22 ms /    19 tokens (   76.27 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =    9530.47 ms /    14 runs   (  680.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11021.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    16 runs   (    0.38 ms per token,  2645.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.66 ms /    19 tokens (   73.30 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10153.28 ms /    15 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11590.05 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    15 runs   (    0.37 ms per token,  2675.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.77 ms /    19 tokens (   75.09 ms per token,    13.32 tokens per second)\n",
      "llama_print_timings:        eval time =    9525.40 ms /    14 runs   (  680.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10995.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    16 runs   (    0.37 ms per token,  2712.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.11 ms /    19 tokens (   72.90 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10217.88 ms /    15 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11647.82 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    17 runs   (    0.37 ms per token,  2704.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1333.56 ms /    18 tokens (   74.09 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10989.48 ms /    16 runs   (  686.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12370.22 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    16 runs   (    0.38 ms per token,  2618.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.22 ms /    19 tokens (   71.54 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10337.26 ms /    15 runs   (  689.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11741.56 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2630.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1341.97 ms /    18 tokens (   74.55 ms per token,    13.41 tokens per second)\n",
      "llama_print_timings:        eval time =    9583.57 ms /    14 runs   (  684.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   10968.63 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    15 runs   (    0.38 ms per token,  2660.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.28 ms /    19 tokens (   72.01 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =    9546.61 ms /    14 runs   (  681.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10957.41 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2667.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.80 ms /    19 tokens (   72.20 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =    9399.38 ms /    14 runs   (  671.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10813.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    16 runs   (    0.37 ms per token,  2695.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.72 ms /    18 tokens (   73.26 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10273.84 ms /    15 runs   (  684.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11638.17 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2647.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1554.83 ms /    19 tokens (   81.83 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10976.30 ms /    16 runs   (  686.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12578.75 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.56 ms /    19 tokens (   72.87 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10906.53 ms /    16 runs   (  681.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12337.70 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    16 runs   (    0.38 ms per token,  2648.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.69 ms /    19 tokens (   75.93 ms per token,    13.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10444.40 ms /    15 runs   (  696.29 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   11931.39 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    15 runs   (    0.39 ms per token,  2596.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.64 ms /    19 tokens (   77.19 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:        eval time =    9575.04 ms /    14 runs   (  683.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11084.04 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2652.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1602.51 ms /    19 tokens (   84.34 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9486.88 ms /    14 runs   (  677.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11131.08 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    16 runs   (    0.37 ms per token,  2728.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.57 ms /    19 tokens (   72.45 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10341.71 ms /    15 runs   (  689.45 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11762.94 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.20 ms /    16 runs   (    0.39 ms per token,  2581.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1598.59 ms /    19 tokens (   84.14 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10230.93 ms /    15 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11874.44 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /    15 runs   (    0.37 ms per token,  2718.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.80 ms /    19 tokens (   71.94 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =    9522.33 ms /    14 runs   (  680.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10931.42 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    15 runs   (    0.36 ms per token,  2748.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.14 ms /    19 tokens (   73.90 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =    9640.41 ms /    14 runs   (  688.60 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11086.99 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    16 runs   (    0.39 ms per token,  2562.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.71 ms /    19 tokens (   74.04 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10328.47 ms /    15 runs   (  688.56 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11779.93 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    16 runs   (    0.37 ms per token,  2688.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.89 ms /    18 tokens (   72.61 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10192.28 ms /    15 runs   (  679.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11543.21 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.33 ms /    19 tokens (   76.02 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =    9578.94 ms /    14 runs   (  684.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11064.15 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2674.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.04 ms /    19 tokens (   67.79 ms per token,    14.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10947.48 ms /    16 runs   (  684.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12282.13 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    16 runs   (    0.37 ms per token,  2689.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1539.38 ms /    18 tokens (   85.52 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10168.23 ms /    15 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11751.14 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    16 runs   (    0.38 ms per token,  2613.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1566.65 ms /    19 tokens (   82.46 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10211.70 ms /    15 runs   (  680.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11822.72 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    16 runs   (    0.38 ms per token,  2642.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.74 ms /    19 tokens (   73.78 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10263.66 ms /    15 runs   (  684.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11709.08 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    17 runs   (    0.38 ms per token,  2636.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.15 ms /    18 tokens (   72.23 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10772.97 ms /    16 runs   (  673.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12119.63 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2613.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.40 ms /    19 tokens (   73.71 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =    9486.95 ms /    14 runs   (  677.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10928.66 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    16 runs   (    0.38 ms per token,  2620.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.20 ms /    19 tokens (   72.22 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10194.50 ms /    15 runs   (  679.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11611.05 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2623.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.84 ms /    19 tokens (   72.31 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =    9605.92 ms /    14 runs   (  686.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11020.55 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    14 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.07 ms /    19 tokens (   71.58 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8743.48 ms /    13 runs   (  672.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10142.55 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2620.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.51 ms /    19 tokens (   76.18 ms per token,    13.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10918.74 ms /    16 runs   (  682.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12413.81 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    16 runs   (    0.39 ms per token,  2569.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.14 ms /    19 tokens (   72.90 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10179.83 ms /    15 runs   (  678.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11609.96 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2650.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1611.19 ms /    19 tokens (   84.80 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10784.33 ms /    16 runs   (  674.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12442.25 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2617.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1487.32 ms /    19 tokens (   78.28 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:        eval time =    9455.83 ms /    14 runs   (  675.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10984.93 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    15 runs   (    0.38 ms per token,  2643.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.63 ms /    19 tokens (   71.72 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9394.86 ms /    14 runs   (  671.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10798.14 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /    15 runs   (    0.37 ms per token,  2718.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.52 ms /    19 tokens (   73.55 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =    9518.45 ms /    14 runs   (  679.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   10956.96 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    15 runs   (    0.38 ms per token,  2639.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.71 ms /    19 tokens (   72.04 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9470.73 ms /    14 runs   (  676.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10881.13 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    16 runs   (    0.37 ms per token,  2672.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.21 ms /    19 tokens (   76.70 ms per token,    13.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10132.93 ms /    15 runs   (  675.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11633.49 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1200th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    18 runs   (    0.37 ms per token,  2735.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1590.98 ms /    22 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11622.13 ms /    17 runs   (  683.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13263.06 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1573.03 ms /    21 tokens (   74.91 ms per token,    13.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11530.66 ms /    17 runs   (  678.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13153.64 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2656.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.96 ms /    21 tokens (   72.38 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10854.27 ms /    16 runs   (  678.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12421.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.22 ms /    21 tokens (   71.49 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11486.08 ms /    17 runs   (  675.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13037.91 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2593.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.22 ms /    21 tokens (   75.58 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11524.83 ms /    17 runs   (  677.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13163.56 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2674.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.08 ms /    21 tokens (   62.48 ms per token,    16.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10797.63 ms /    16 runs   (  674.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12154.85 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.42 ms /    21 tokens (   78.83 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11506.06 ms /    17 runs   (  676.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13210.72 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    18 runs   (    0.37 ms per token,  2709.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1749.08 ms /    21 tokens (   83.29 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11466.59 ms /    17 runs   (  674.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13264.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2704.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.23 ms /    21 tokens (   70.96 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11554.52 ms /    17 runs   (  679.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13094.41 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    18 runs   (    0.37 ms per token,  2731.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1793.40 ms /    21 tokens (   85.40 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11428.20 ms /    17 runs   (  672.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13270.43 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    18 runs   (    0.37 ms per token,  2716.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.19 ms /    21 tokens (   71.44 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11555.04 ms /    17 runs   (  679.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13105.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2663.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.79 ms /    21 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11498.42 ms /    17 runs   (  676.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13068.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2613.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.86 ms /    21 tokens (   71.04 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10866.32 ms /    16 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12405.02 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2703.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1533.13 ms /    21 tokens (   73.01 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11453.64 ms /    17 runs   (  673.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13036.79 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    17 runs   (    0.37 ms per token,  2703.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1489.15 ms /    21 tokens (   70.91 ms per token,    14.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10779.47 ms /    16 runs   (  673.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12315.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2623.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.18 ms /    21 tokens (   71.01 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11457.60 ms /    17 runs   (  673.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12998.31 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2663.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1671.63 ms /    21 tokens (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11460.51 ms /    17 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13181.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2619.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1559.77 ms /    21 tokens (   74.27 ms per token,    13.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11463.36 ms /    17 runs   (  674.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13072.97 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    17 runs   (    0.37 ms per token,  2739.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.48 ms /    21 tokens (   77.36 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10823.69 ms /    16 runs   (  676.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12494.94 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2656.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1541.86 ms /    21 tokens (   73.42 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10773.85 ms /    16 runs   (  673.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12363.32 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    18 runs   (    0.37 ms per token,  2732.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1522.42 ms /    21 tokens (   72.50 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11562.26 ms /    17 runs   (  680.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13133.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    17 runs   (    0.37 ms per token,  2713.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.75 ms /    21 tokens (   71.08 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10977.02 ms /    16 runs   (  686.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12517.60 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1532.18 ms /    21 tokens (   72.96 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11584.42 ms /    17 runs   (  681.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13166.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2682.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.31 ms /    21 tokens (   70.97 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11581.03 ms /    17 runs   (  681.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13121.76 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1529.70 ms /    21 tokens (   72.84 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11703.14 ms /    17 runs   (  688.42 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13282.59 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2691.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.15 ms /    21 tokens (   72.63 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11750.41 ms /    17 runs   (  691.20 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13324.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.56 ms /    20 tokens (   74.98 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11634.57 ms /    17 runs   (  684.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13184.24 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    17 runs   (    0.37 ms per token,  2716.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1538.31 ms /    21 tokens (   73.25 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10912.26 ms /    16 runs   (  682.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12498.46 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    17 runs   (    0.37 ms per token,  2700.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1570.40 ms /    21 tokens (   74.78 ms per token,    13.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10977.07 ms /    16 runs   (  686.07 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12594.59 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2686.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1656.80 ms /    21 tokens (   78.90 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10974.83 ms /    16 runs   (  685.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12678.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    18 runs   (    0.37 ms per token,  2716.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1547.40 ms /    21 tokens (   73.69 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11487.63 ms /    17 runs   (  675.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13084.13 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2651.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1488.48 ms /    21 tokens (   70.88 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11574.66 ms /    17 runs   (  680.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13112.67 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    18 runs   (    0.37 ms per token,  2723.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1558.94 ms /    21 tokens (   74.24 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11552.50 ms /    17 runs   (  679.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13162.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    18 runs   (    0.37 ms per token,  2678.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1543.27 ms /    21 tokens (   73.49 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11409.15 ms /    17 runs   (  671.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13002.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    17 runs   (    0.36 ms per token,  2754.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1718.35 ms /    21 tokens (   81.83 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10804.95 ms /    16 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12570.14 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    17 runs   (    0.37 ms per token,  2697.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.36 ms /    21 tokens (   72.30 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10831.74 ms /    16 runs   (  676.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12397.47 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    17 runs   (    0.37 ms per token,  2731.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1767.75 ms /    21 tokens (   84.18 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10920.79 ms /    16 runs   (  682.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12735.36 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.07 ms /    21 tokens (   71.77 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11619.28 ms /    17 runs   (  683.49 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13177.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.27 ms /    17 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1580.58 ms /    21 tokens (   75.27 ms per token,    13.29 tokens per second)\n",
      "llama_print_timings:        eval time =   10991.01 ms /    16 runs   (  686.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12619.30 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2657.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1508.44 ms /    21 tokens (   71.83 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10823.20 ms /    16 runs   (  676.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12380.20 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2647.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.18 ms /    21 tokens (   72.63 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11625.72 ms /    17 runs   (  683.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13201.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2651.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.56 ms /    20 tokens (   76.78 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11547.65 ms /    17 runs   (  679.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13132.98 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2679.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1756.83 ms /    21 tokens (   83.66 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10911.24 ms /    16 runs   (  681.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12715.55 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.20 ms /    17 runs   (    0.36 ms per token,  2741.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1656.64 ms /    21 tokens (   78.89 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10928.08 ms /    16 runs   (  683.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12632.11 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2639.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1758.90 ms /    21 tokens (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11631.12 ms /    17 runs   (  684.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13440.02 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    17 runs   (    0.36 ms per token,  2753.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.91 ms /    21 tokens (   71.52 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10984.25 ms /    16 runs   (  686.52 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12532.37 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2689.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.13 ms /    21 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10948.59 ms /    16 runs   (  684.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12116.01 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    17 runs   (    0.37 ms per token,  2714.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1562.16 ms /    21 tokens (   74.39 ms per token,    13.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10977.23 ms /    16 runs   (  686.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12586.54 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    17 runs   (    0.37 ms per token,  2678.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1594.78 ms /    20 tokens (   79.74 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10943.67 ms /    16 runs   (  683.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12585.40 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2652.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1528.11 ms /    21 tokens (   72.77 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10814.69 ms /    16 runs   (  675.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12390.56 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2619.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.08 ms /    21 tokens (   70.72 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11471.51 ms /    17 runs   (  674.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13007.09 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    17 runs   (    0.37 ms per token,  2677.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1780.99 ms /    21 tokens (   84.81 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10907.20 ms /    16 runs   (  681.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12735.86 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    18 runs   (    0.37 ms per token,  2721.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1758.87 ms /    21 tokens (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11569.03 ms /    17 runs   (  680.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13377.10 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    17 runs   (    0.37 ms per token,  2729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.01 ms /    21 tokens (   71.48 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10935.27 ms /    16 runs   (  683.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12483.54 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.22 ms /    21 tokens (   71.25 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11519.38 ms /    17 runs   (  677.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13066.46 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    18 runs   (    0.37 ms per token,  2717.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.21 ms /    21 tokens (   75.82 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11445.55 ms /    17 runs   (  673.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13087.14 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    18 runs   (    0.36 ms per token,  2746.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.14 ms /    21 tokens (   73.10 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11556.20 ms /    17 runs   (  679.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13142.17 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2667.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.00 ms /    21 tokens (   72.05 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10867.93 ms /    16 runs   (  679.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12427.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2701.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1758.15 ms /    21 tokens (   83.72 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11622.79 ms /    17 runs   (  683.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13431.25 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2640.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.03 ms /    21 tokens (   78.81 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11554.41 ms /    17 runs   (  679.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13259.90 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    17 runs   (    0.39 ms per token,  2589.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1556.32 ms /    21 tokens (   74.11 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10877.24 ms /    16 runs   (  679.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12481.55 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    18 runs   (    0.36 ms per token,  2750.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1502.60 ms /    21 tokens (   71.55 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11539.82 ms /    17 runs   (  678.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13092.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    18 runs   (    0.36 ms per token,  2743.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1562.58 ms /    21 tokens (   74.41 ms per token,    13.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11443.71 ms /    17 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13055.34 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2613.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.52 ms /    21 tokens (   76.45 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11512.21 ms /    17 runs   (  677.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13167.36 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    17 runs   (    0.37 ms per token,  2678.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1494.84 ms /    21 tokens (   71.18 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =   10856.34 ms /    16 runs   (  678.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12398.82 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    17 runs   (    0.37 ms per token,  2713.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1761.11 ms /    21 tokens (   83.86 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10914.51 ms /    16 runs   (  682.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12723.27 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2703.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.96 ms /    21 tokens (   75.47 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11546.84 ms /    17 runs   (  679.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13180.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    18 runs   (    0.37 ms per token,  2676.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1616.67 ms /    21 tokens (   76.98 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11647.28 ms /    17 runs   (  685.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13313.99 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.19 ms /    17 runs   (    0.36 ms per token,  2748.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1549.84 ms /    21 tokens (   73.80 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10845.36 ms /    16 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12441.73 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2692.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1498.37 ms /    21 tokens (   71.35 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11556.57 ms /    17 runs   (  679.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13104.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    18 runs   (    0.37 ms per token,  2705.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1590.92 ms /    21 tokens (   75.76 ms per token,    13.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11494.26 ms /    17 runs   (  676.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13135.17 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    17 runs   (    0.37 ms per token,  2695.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1691.89 ms /    21 tokens (   80.57 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10827.39 ms /    16 runs   (  676.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12566.87 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2665.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1754.50 ms /    21 tokens (   83.55 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11571.03 ms /    17 runs   (  680.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13375.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    17 runs   (    0.37 ms per token,  2732.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1792.78 ms /    21 tokens (   85.37 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10812.91 ms /    16 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12652.37 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    17 runs   (    0.36 ms per token,  2753.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1524.78 ms /    21 tokens (   72.61 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10893.87 ms /    16 runs   (  680.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12466.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1505.04 ms /    21 tokens (   71.67 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11568.47 ms /    17 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13124.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    18 runs   (    0.37 ms per token,  2710.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1691.57 ms /    20 tokens (   84.58 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11527.90 ms /    17 runs   (  678.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13269.34 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2628.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.40 ms /    21 tokens (   70.45 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10932.08 ms /    16 runs   (  683.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12459.10 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2666.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.90 ms /    21 tokens (   70.80 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10933.14 ms /    16 runs   (  683.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12467.08 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    17 runs   (    0.37 ms per token,  2725.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.18 ms /    21 tokens (   71.29 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10922.69 ms /    16 runs   (  682.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12466.35 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.19 ms /    17 runs   (    0.36 ms per token,  2745.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1565.89 ms /    21 tokens (   74.57 ms per token,    13.41 tokens per second)\n",
      "llama_print_timings:        eval time =   10864.01 ms /    16 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12476.81 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    18 runs   (    0.37 ms per token,  2680.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1508.85 ms /    21 tokens (   71.85 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11445.22 ms /    17 runs   (  673.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13004.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    17 runs   (    0.37 ms per token,  2715.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1481.50 ms /    21 tokens (   70.55 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10835.92 ms /    16 runs   (  677.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12364.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2673.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1615.01 ms /    21 tokens (   76.91 ms per token,    13.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10892.87 ms /    16 runs   (  680.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12556.15 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.61 ms /    21 tokens (   71.31 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10861.25 ms /    16 runs   (  678.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12407.28 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2685.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1593.52 ms /    21 tokens (   75.88 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11494.04 ms /    17 runs   (  676.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13137.23 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    18 runs   (    0.37 ms per token,  2725.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1506.41 ms /    21 tokens (   71.73 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11528.79 ms /    17 runs   (  678.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13084.91 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2576.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.86 ms /    21 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   11697.99 ms /    17 runs   (  688.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   12842.69 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    17 runs   (    0.37 ms per token,  2673.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1741.62 ms /    21 tokens (   82.93 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10990.20 ms /    16 runs   (  686.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12778.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2650.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1506.58 ms /    20 tokens (   75.33 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11641.88 ms /    17 runs   (  684.82 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13197.89 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2594.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.79 ms /    21 tokens (   76.51 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11591.25 ms /    17 runs   (  681.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13248.68 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2685.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.71 ms /    21 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10849.55 ms /    16 runs   (  678.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12416.29 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2687.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1750.83 ms /    21 tokens (   83.37 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10851.60 ms /    16 runs   (  678.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12649.98 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    17 runs   (    0.37 ms per token,  2714.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.90 ms /    20 tokens (   74.85 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10851.56 ms /    16 runs   (  678.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12396.16 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    18 runs   (    0.37 ms per token,  2696.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.80 ms /    21 tokens (   73.75 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11491.87 ms /    17 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13090.09 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    18 runs   (    0.37 ms per token,  2721.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1495.93 ms /    21 tokens (   71.23 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11516.58 ms /    17 runs   (  677.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13062.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    17 runs   (    0.37 ms per token,  2722.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.31 ms /    21 tokens (   73.11 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =   10733.19 ms /    16 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12315.88 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    18 runs   (    0.37 ms per token,  2728.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.97 ms /    20 tokens (   72.40 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11475.75 ms /    17 runs   (  675.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12972.84 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    17 runs   (    0.45 ms per token,  2213.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.26 ms /    21 tokens (   69.92 ms per token,    14.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10911.66 ms /    16 runs   (  681.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12433.02 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2663.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1565.03 ms /    21 tokens (   74.53 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10800.69 ms /    16 runs   (  675.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12413.39 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1300th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2619.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.80 ms /    21 tokens (   70.99 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11455.11 ms /    17 runs   (  673.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12995.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2691.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.41 ms /    20 tokens (   70.77 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11575.54 ms /    17 runs   (  680.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13039.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    17 runs   (    0.37 ms per token,  2676.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1664.20 ms /    21 tokens (   79.25 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10882.13 ms /    16 runs   (  680.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12593.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2647.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1617.55 ms /    21 tokens (   77.03 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11552.39 ms /    17 runs   (  679.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13219.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    17 runs   (    0.38 ms per token,  2641.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1487.24 ms /    21 tokens (   70.82 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10832.51 ms /    16 runs   (  677.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12366.51 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2603.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1506.70 ms /    20 tokens (   75.33 ms per token,    13.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11621.48 ms /    17 runs   (  683.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13178.97 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2650.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1759.96 ms /    21 tokens (   83.81 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10927.00 ms /    16 runs   (  682.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12734.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2614.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.57 ms /    20 tokens (   66.63 ms per token,    15.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11814.45 ms /    17 runs   (  694.97 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13196.12 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    18 runs   (    0.37 ms per token,  2727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.84 ms /    21 tokens (   73.66 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11514.33 ms /    17 runs   (  677.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13110.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2701.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.63 ms /    20 tokens (   74.83 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11627.52 ms /    17 runs   (  683.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13174.12 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2670.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.63 ms /    21 tokens (   70.74 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11536.52 ms /    17 runs   (  678.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13071.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    18 runs   (    0.37 ms per token,  2716.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1510.35 ms /    21 tokens (   71.92 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11448.88 ms /    17 runs   (  673.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13008.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    17 runs   (    0.36 ms per token,  2785.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1505.88 ms /    21 tokens (   71.71 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =   10761.74 ms /    16 runs   (  672.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12314.03 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    18 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.02 ms /    21 tokens (   85.00 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11462.00 ms /    17 runs   (  674.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13297.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2611.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.59 ms /    21 tokens (   71.31 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11467.93 ms /    17 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13017.69 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    17 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1530.79 ms /    21 tokens (   72.89 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10759.45 ms /    16 runs   (  672.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12338.03 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1611.39 ms /    21 tokens (   76.73 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11390.14 ms /    17 runs   (  670.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13051.76 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2684.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1550.54 ms /    21 tokens (   73.84 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =   11426.33 ms /    17 runs   (  672.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13026.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1520.06 ms /    21 tokens (   72.38 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11551.31 ms /    17 runs   (  679.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13120.35 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    16 runs   (    0.42 ms per token,  2402.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.46 ms /    21 tokens (   71.97 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10270.52 ms /    15 runs   (  684.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11829.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2603.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1575.11 ms /    21 tokens (   75.01 ms per token,    13.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11465.57 ms /    17 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13091.22 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    18 runs   (    0.38 ms per token,  2614.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1558.40 ms /    21 tokens (   74.21 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11497.45 ms /    17 runs   (  676.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13106.00 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    17 runs   (    0.37 ms per token,  2730.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1784.88 ms /    21 tokens (   84.99 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10798.08 ms /    16 runs   (  674.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12628.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.88 ms /    21 tokens (   72.66 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11551.20 ms /    17 runs   (  679.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13126.48 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2662.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.11 ms /    21 tokens (   76.34 ms per token,    13.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10842.67 ms /    16 runs   (  677.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12493.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2658.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1684.59 ms /    21 tokens (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11191.73 ms /    17 runs   (  658.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12925.28 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    17 runs   (    0.38 ms per token,  2660.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1508.15 ms /    21 tokens (   71.82 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10786.49 ms /    16 runs   (  674.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12342.81 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2690.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1568.55 ms /    21 tokens (   74.69 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10953.81 ms /    16 runs   (  684.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12568.97 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    17 runs   (    0.38 ms per token,  2647.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1488.07 ms /    21 tokens (   70.86 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10813.14 ms /    16 runs   (  675.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12348.95 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2652.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.91 ms /    21 tokens (   71.04 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11547.18 ms /    17 runs   (  679.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13088.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.81 ms /    21 tokens (   71.32 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11516.81 ms /    17 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13064.64 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    18 runs   (    0.36 ms per token,  2743.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1509.23 ms /    21 tokens (   71.87 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11399.94 ms /    17 runs   (  670.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12958.74 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2639.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1523.97 ms /    21 tokens (   72.57 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11578.47 ms /    17 runs   (  681.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13152.46 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2588.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1495.76 ms /    21 tokens (   71.23 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11647.13 ms /    17 runs   (  685.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13193.84 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2657.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1601.78 ms /    21 tokens (   76.28 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10786.77 ms /    16 runs   (  674.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12434.47 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2685.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.38 ms /    21 tokens (   75.59 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10812.60 ms /    16 runs   (  675.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12447.00 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2674.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1662.03 ms /    21 tokens (   79.14 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11617.14 ms /    17 runs   (  683.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13328.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    19 runs   (    0.38 ms per token,  2647.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1503.22 ms /    21 tokens (   71.58 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12173.19 ms /    18 runs   (  676.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13729.69 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1689.93 ms /    21 tokens (   80.47 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11527.18 ms /    17 runs   (  678.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13268.11 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2649.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.26 ms /    21 tokens (   73.73 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11382.19 ms /    17 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12980.55 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    17 runs   (    0.38 ms per token,  2619.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1650.24 ms /    21 tokens (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10756.81 ms /    16 runs   (  672.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12454.02 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2633.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.63 ms /    21 tokens (   70.74 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11526.54 ms /    17 runs   (  678.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13061.13 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    18 runs   (    0.37 ms per token,  2710.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1576.49 ms /    21 tokens (   75.07 ms per token,    13.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11438.53 ms /    17 runs   (  672.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13063.34 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2645.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1540.58 ms /    21 tokens (   73.36 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11454.23 ms /    17 runs   (  673.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13044.64 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2669.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1514.01 ms /    21 tokens (   72.10 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10899.76 ms /    16 runs   (  681.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12460.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    18 runs   (    0.39 ms per token,  2593.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.13 ms /    21 tokens (   72.05 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11386.64 ms /    17 runs   (  669.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12950.06 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2689.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.89 ms /    21 tokens (   85.04 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11496.82 ms /    17 runs   (  676.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13332.67 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1534.61 ms /    21 tokens (   73.08 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11628.78 ms /    17 runs   (  684.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13212.81 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    19 runs   (    0.37 ms per token,  2684.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.29 ms /    21 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12199.13 ms /    18 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13358.65 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1502.81 ms /    21 tokens (   71.56 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11435.28 ms /    17 runs   (  672.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12987.57 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    19 runs   (    0.39 ms per token,  2596.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.36 ms /    19 tokens (   72.91 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12143.37 ms /    18 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13581.82 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.19 ms /    21 tokens (   72.63 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11454.12 ms /    17 runs   (  673.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13028.72 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    16 runs   (    0.39 ms per token,  2570.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1542.55 ms /    21 tokens (   73.45 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10153.61 ms /    15 runs   (  676.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11741.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    17 runs   (    0.44 ms per token,  2291.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.66 ms /    19 tokens (   72.19 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10724.45 ms /    16 runs   (  670.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12146.26 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    18 runs   (    0.37 ms per token,  2694.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.14 ms /    21 tokens (   77.53 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11619.02 ms /    17 runs   (  683.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13296.27 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    19 runs   (    0.38 ms per token,  2664.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.18 ms /    21 tokens (   84.10 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11993.48 ms /    18 runs   (  666.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13812.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2649.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1680.55 ms /    21 tokens (   80.03 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:        eval time =   11499.00 ms /    17 runs   (  676.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13229.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    17 runs   (    0.39 ms per token,  2593.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.96 ms /    21 tokens (   72.66 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10856.46 ms /    16 runs   (  678.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12431.08 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2656.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.01 ms /    21 tokens (   70.95 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11485.50 ms /    17 runs   (  675.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13025.46 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    18 runs   (    0.39 ms per token,  2534.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.95 ms /    21 tokens (   70.71 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11514.09 ms /    17 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13048.91 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    18 runs   (    0.39 ms per token,  2583.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.08 ms /    21 tokens (   70.67 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11600.95 ms /    17 runs   (  682.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13134.26 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2642.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.86 ms /    21 tokens (   70.47 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11539.51 ms /    17 runs   (  678.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13069.36 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    17 runs   (    0.38 ms per token,  2612.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1523.37 ms /    21 tokens (   72.54 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   10944.97 ms /    16 runs   (  684.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12514.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    17 runs   (    0.38 ms per token,  2625.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1543.32 ms /    21 tokens (   73.49 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10876.22 ms /    16 runs   (  679.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12466.98 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    18 runs   (    0.37 ms per token,  2726.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1744.67 ms /    21 tokens (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11416.17 ms /    17 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13210.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2601.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1453.19 ms /    20 tokens (   72.66 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =   11492.84 ms /    17 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12995.98 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2618.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1520.86 ms /    21 tokens (   72.42 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11480.66 ms /    17 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13052.10 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    18 runs   (    0.39 ms per token,  2555.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.27 ms /    21 tokens (   71.01 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11502.75 ms /    17 runs   (  676.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13045.40 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2704.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.58 ms /    21 tokens (   61.93 ms per token,    16.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11615.10 ms /    17 runs   (  683.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12964.92 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.16 ms /    19 tokens (   72.53 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11481.94 ms /    17 runs   (  675.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12910.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2632.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1534.34 ms /    21 tokens (   73.06 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11521.24 ms /    17 runs   (  677.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13104.47 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    17 runs   (    0.37 ms per token,  2682.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.78 ms /    21 tokens (   70.80 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10774.15 ms /    16 runs   (  673.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12307.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2539.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.75 ms /    21 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11423.32 ms /    17 runs   (  671.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12993.23 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.15 ms /    21 tokens (   72.63 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11486.30 ms /    17 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13061.40 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.70 ms /    21 tokens (   77.56 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11572.25 ms /    17 runs   (  680.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13250.98 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.16 ms /    21 tokens (   71.39 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11419.89 ms /    17 runs   (  671.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12968.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2654.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.81 ms /    21 tokens (   71.42 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11478.34 ms /    17 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13027.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.06 ms /    20 tokens (   75.60 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11552.88 ms /    17 runs   (  679.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13115.15 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2617.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1495.28 ms /    21 tokens (   71.20 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11445.95 ms /    17 runs   (  673.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12991.71 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2685.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.84 ms /    21 tokens (   71.33 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11408.19 ms /    17 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12955.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.16 ms /    21 tokens (   78.01 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11423.42 ms /    17 runs   (  671.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13110.55 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2631.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1520.06 ms /    21 tokens (   72.38 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11432.49 ms /    17 runs   (  672.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13001.57 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2671.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1792.07 ms /    21 tokens (   85.34 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11469.62 ms /    17 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13311.47 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    18 runs   (    0.38 ms per token,  2645.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1776.72 ms /    21 tokens (   84.61 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11438.01 ms /    17 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13264.34 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2655.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1520.21 ms /    21 tokens (   72.39 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11162.36 ms /    17 runs   (  656.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12732.43 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2673.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1543.34 ms /    21 tokens (   73.49 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11488.16 ms /    17 runs   (  675.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13081.86 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2588.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1794.53 ms /    21 tokens (   85.45 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11440.14 ms /    17 runs   (  672.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13284.30 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2658.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1541.38 ms /    21 tokens (   73.40 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11524.00 ms /    17 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13115.17 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2654.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.92 ms /    21 tokens (   72.23 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11651.48 ms /    17 runs   (  685.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13216.98 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    15 runs   (    0.39 ms per token,  2567.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1627.17 ms /    21 tokens (   77.48 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9334.69 ms /    14 runs   (  666.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11003.62 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2666.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1685.70 ms /    21 tokens (   80.27 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11610.16 ms /    17 runs   (  682.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13345.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2653.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.35 ms /    20 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11524.16 ms /    17 runs   (  677.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13019.78 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2652.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1649.53 ms /    21 tokens (   78.55 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11543.23 ms /    17 runs   (  679.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13242.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1529.54 ms /    21 tokens (   72.84 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11632.09 ms /    17 runs   (  684.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13211.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.89 ms /    21 tokens (   77.57 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11434.91 ms /    17 runs   (  672.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13114.07 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    17 runs   (    0.38 ms per token,  2642.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1540.08 ms /    21 tokens (   73.34 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10865.78 ms /    16 runs   (  679.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12453.28 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2642.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.88 ms /    21 tokens (   72.38 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11539.60 ms /    17 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13109.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    18 runs   (    0.37 ms per token,  2718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.67 ms /    20 tokens (   74.23 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11583.55 ms /    17 runs   (  681.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13119.59 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    17 runs   (    0.37 ms per token,  2696.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1777.72 ms /    21 tokens (   84.65 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10912.31 ms /    16 runs   (  682.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12737.73 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    17 runs   (    0.37 ms per token,  2694.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1559.09 ms /    21 tokens (   74.24 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10857.62 ms /    16 runs   (  678.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12463.98 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1400th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2702.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1573.78 ms /    22 tokens (   71.54 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11395.96 ms /    17 runs   (  670.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13019.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1589.75 ms /    21 tokens (   75.70 ms per token,    13.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11440.51 ms /    17 runs   (  672.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13080.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    18 runs   (    0.37 ms per token,  2715.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.20 ms /    21 tokens (   71.25 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11541.45 ms /    17 runs   (  678.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13087.35 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2681.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1533.90 ms /    21 tokens (   73.04 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11458.52 ms /    17 runs   (  674.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13042.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    18 runs   (    0.37 ms per token,  2720.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1541.99 ms /    21 tokens (   73.43 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11465.54 ms /    17 runs   (  674.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13057.01 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    18 runs   (    0.37 ms per token,  2712.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1465.17 ms /    20 tokens (   73.26 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11484.15 ms /    17 runs   (  675.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12999.11 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2619.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.00 ms /    21 tokens (   71.76 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11582.92 ms /    17 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13140.84 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    18 runs   (    0.39 ms per token,  2575.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1539.10 ms /    21 tokens (   73.29 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11534.56 ms /    17 runs   (  678.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13124.16 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.86 ms /    21 tokens (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11808.45 ms /    17 runs   (  694.62 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13496.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    18 runs   (    0.37 ms per token,  2695.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.63 ms /    21 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11643.75 ms /    17 runs   (  684.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13212.12 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    18 runs   (    0.39 ms per token,  2567.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1586.44 ms /    21 tokens (   75.54 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11451.46 ms /    17 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13089.67 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    27 runs   (    0.37 ms per token,  2687.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.38 ms /    21 tokens (   72.16 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =   17914.45 ms /    26 runs   (  689.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   19504.39 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.55 ms /    21 tokens (   72.45 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11369.84 ms /    17 runs   (  668.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12940.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    19 runs   (    0.37 ms per token,  2703.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.47 ms /    21 tokens (   76.21 ms per token,    13.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12210.70 ms /    18 runs   (  678.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13862.63 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2603.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1487.72 ms /    21 tokens (   70.84 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11534.06 ms /    17 runs   (  678.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13072.35 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2673.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.56 ms /    21 tokens (   71.12 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11487.18 ms /    17 runs   (  675.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13030.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2688.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1549.74 ms /    20 tokens (   77.49 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11521.01 ms /    17 runs   (  677.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13121.71 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    32 runs   (    0.37 ms per token,  2693.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1637.89 ms /    21 tokens (   77.99 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:        eval time =   21010.52 ms /    31 runs   (  677.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22738.13 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2687.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1755.71 ms /    21 tokens (   83.61 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11549.79 ms /    17 runs   (  679.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13355.21 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    18 runs   (    0.43 ms per token,  2320.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.75 ms /    21 tokens (   72.23 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11572.64 ms /    17 runs   (  680.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13142.11 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2696.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.38 ms /    21 tokens (   71.11 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11556.67 ms /    17 runs   (  679.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13100.68 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2649.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.59 ms /    21 tokens (   76.46 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11528.83 ms /    17 runs   (  678.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13183.77 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    14 runs   (    0.39 ms per token,  2575.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.41 ms /    21 tokens (   70.73 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =    8810.55 ms /    13 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10334.67 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    14 runs   (    0.38 ms per token,  2614.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1524.11 ms /    21 tokens (   72.58 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8735.90 ms /    13 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10299.05 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    27 runs   (    0.37 ms per token,  2738.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1661.54 ms /    21 tokens (   79.12 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:        eval time =   17656.09 ms /    26 runs   (  679.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19392.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    19 runs   (    0.37 ms per token,  2734.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.76 ms /    20 tokens (   73.69 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12177.00 ms /    18 runs   (  676.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13703.06 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    27 runs   (    0.37 ms per token,  2696.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1582.71 ms /    21 tokens (   75.37 ms per token,    13.27 tokens per second)\n",
      "llama_print_timings:        eval time =   17836.64 ms /    26 runs   (  686.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19494.20 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2674.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.47 ms /    20 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11533.78 ms /    17 runs   (  678.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12674.05 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2629.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1761.29 ms /    21 tokens (   83.87 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11383.21 ms /    17 runs   (  669.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13194.58 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2650.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.40 ms /    21 tokens (   71.97 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11476.90 ms /    17 runs   (  675.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13037.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    17 runs   (    0.37 ms per token,  2730.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1539.22 ms /    21 tokens (   73.30 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10827.27 ms /    16 runs   (  676.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12413.26 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1761.22 ms /    21 tokens (   83.87 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11519.19 ms /    17 runs   (  677.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13330.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    18 runs   (    0.37 ms per token,  2677.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.20 ms /    21 tokens (   71.06 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11545.57 ms /    17 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13087.64 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2649.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1654.46 ms /    21 tokens (   78.78 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11582.09 ms /    17 runs   (  681.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13286.41 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    27 runs   (    0.37 ms per token,  2697.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1581.01 ms /    21 tokens (   75.29 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =   17634.30 ms /    26 runs   (  678.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19291.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.77 ms /    32 runs   (    0.37 ms per token,  2718.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.49 ms /    21 tokens (   73.74 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =   21216.62 ms /    31 runs   (  684.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22855.79 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    18 runs   (    0.37 ms per token,  2705.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1769.50 ms /    21 tokens (   84.26 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11577.23 ms /    17 runs   (  681.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13396.24 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    27 runs   (    0.36 ms per token,  2759.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1556.42 ms /    21 tokens (   74.12 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =   17682.23 ms /    26 runs   (  680.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19313.74 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    17 runs   (    0.37 ms per token,  2693.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1495.86 ms /    21 tokens (   71.23 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10837.52 ms /    16 runs   (  677.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12380.46 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    18 runs   (    0.38 ms per token,  2649.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1527.33 ms /    21 tokens (   72.73 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11579.08 ms /    17 runs   (  681.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13155.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2641.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1758.89 ms /    21 tokens (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11534.50 ms /    17 runs   (  678.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13343.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2667.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1647.89 ms /    21 tokens (   78.47 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10545.28 ms /    16 runs   (  659.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12240.23 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2657.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1737.52 ms /    21 tokens (   82.74 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11543.46 ms /    17 runs   (  679.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13330.71 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2686.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1768.85 ms /    21 tokens (   84.23 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10886.70 ms /    16 runs   (  680.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12702.06 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.97 ms /    27 runs   (    0.37 ms per token,  2708.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.09 ms /    21 tokens (   72.00 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   17843.23 ms /    26 runs   (  686.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19429.16 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    16 runs   (    0.38 ms per token,  2613.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.45 ms /    21 tokens (   70.59 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10100.61 ms /    15 runs   (  673.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11627.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    17 runs   (    0.38 ms per token,  2614.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.72 ms /    20 tokens (   75.69 ms per token,    13.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10875.96 ms /    16 runs   (  679.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12436.50 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    27 runs   (    0.36 ms per token,  2761.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.20 ms /    21 tokens (   70.44 ms per token,    14.20 tokens per second)\n",
      "llama_print_timings:        eval time =   17774.05 ms /    26 runs   (  683.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19327.55 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    18 runs   (    0.43 ms per token,  2325.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1647.47 ms /    21 tokens (   78.45 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11532.23 ms /    17 runs   (  678.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13235.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.87 ms /    32 runs   (    0.37 ms per token,  2695.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.86 ms /    21 tokens (   76.47 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =   20850.82 ms /    31 runs   (  672.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22547.49 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    18 runs   (    0.36 ms per token,  2746.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1502.19 ms /    21 tokens (   71.53 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11504.81 ms /    17 runs   (  676.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13056.13 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2673.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1530.09 ms /    21 tokens (   72.86 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11655.18 ms /    17 runs   (  685.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13236.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    18 runs   (    0.37 ms per token,  2695.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1597.41 ms /    21 tokens (   76.07 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11626.10 ms /    17 runs   (  683.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13273.44 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2675.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1681.10 ms /    21 tokens (   80.05 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:        eval time =   11452.93 ms /    17 runs   (  673.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13184.83 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    17 runs   (    0.38 ms per token,  2651.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1583.68 ms /    21 tokens (   75.41 ms per token,    13.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10836.10 ms /    16 runs   (  677.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12466.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2665.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1514.02 ms /    21 tokens (   72.10 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10747.55 ms /    16 runs   (  671.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12309.22 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    18 runs   (    0.40 ms per token,  2514.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1580.52 ms /    21 tokens (   75.26 ms per token,    13.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11524.59 ms /    17 runs   (  677.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13157.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.94 ms /    27 runs   (    0.37 ms per token,  2716.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.05 ms /    21 tokens (   70.62 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   17578.60 ms /    26 runs   (  676.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19136.69 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2623.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.29 ms /    21 tokens (   73.73 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11512.62 ms /    17 runs   (  677.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13109.99 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    18 runs   (    0.37 ms per token,  2678.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1588.33 ms /    21 tokens (   75.63 ms per token,    13.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11540.85 ms /    17 runs   (  678.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13179.42 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    17 runs   (    0.40 ms per token,  2524.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.42 ms /    20 tokens (   73.32 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10847.00 ms /    16 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12361.88 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    17 runs   (    0.37 ms per token,  2703.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1593.91 ms /    21 tokens (   75.90 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10751.67 ms /    16 runs   (  671.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12392.35 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2687.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.32 ms /    21 tokens (   71.97 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11430.32 ms /    17 runs   (  672.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12991.71 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    18 runs   (    0.39 ms per token,  2540.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.61 ms /    20 tokens (   73.88 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =   11596.25 ms /    17 runs   (  682.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13123.21 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    18 runs   (    0.38 ms per token,  2609.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1544.42 ms /    21 tokens (   73.54 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11561.34 ms /    17 runs   (  680.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13155.66 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.37 ms per token,  2667.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1634.17 ms /    20 tokens (   81.71 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:        eval time =   11415.99 ms /    17 runs   (  671.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13101.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    16 runs   (    0.38 ms per token,  2666.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1601.67 ms /    21 tokens (   76.27 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10161.77 ms /    15 runs   (  677.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11807.76 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    14 runs   (    0.38 ms per token,  2635.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.37 ms /    20 tokens (   72.42 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =    8708.69 ms /    13 runs   (  669.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10195.31 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2634.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1683.64 ms /    21 tokens (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11335.42 ms /    17 runs   (  666.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13069.00 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    17 runs   (    0.37 ms per token,  2719.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1684.10 ms /    21 tokens (   80.20 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10730.32 ms /    16 runs   (  670.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12461.48 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    18 runs   (    0.39 ms per token,  2585.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1539.06 ms /    21 tokens (   73.29 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11517.81 ms /    17 runs   (  677.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13107.04 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.96 ms /    27 runs   (    0.37 ms per token,  2712.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1780.82 ms /    21 tokens (   84.80 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:        eval time =   17632.49 ms /    26 runs   (  678.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19487.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.26 ms /    21 tokens (   71.11 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11502.18 ms /    17 runs   (  676.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13046.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    27 runs   (    0.37 ms per token,  2726.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1534.25 ms /    21 tokens (   73.06 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =   17604.21 ms /    26 runs   (  677.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19214.66 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    18 runs   (    0.36 ms per token,  2763.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1573.68 ms /    21 tokens (   74.94 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11482.55 ms /    17 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13106.27 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2654.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.71 ms /    21 tokens (   72.18 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11566.05 ms /    17 runs   (  680.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13132.03 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2675.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.88 ms /    21 tokens (   72.04 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11474.97 ms /    17 runs   (  675.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13037.39 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.41 ms /    33 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1593.72 ms /    21 tokens (   75.89 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =   21882.05 ms /    32 runs   (  683.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23568.39 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    18 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1560.16 ms /    21 tokens (   74.29 ms per token,    13.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11485.69 ms /    17 runs   (  675.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13095.66 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2633.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.67 ms /    21 tokens (   71.03 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11202.63 ms /    17 runs   (  658.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12744.06 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    26 runs   (    0.37 ms per token,  2706.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.43 ms /    21 tokens (   71.40 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   16896.05 ms /    25 runs   (  675.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18467.43 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2656.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1577.28 ms /    21 tokens (   75.11 ms per token,    13.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11634.32 ms /    17 runs   (  684.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13261.49 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    18 runs   (    0.38 ms per token,  2642.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.63 ms /    21 tokens (   71.03 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11600.93 ms /    17 runs   (  682.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13143.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2673.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1682.82 ms /    20 tokens (   84.14 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11298.05 ms /    17 runs   (  664.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13031.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.66 ms /    32 runs   (    0.36 ms per token,  2745.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.37 ms /    21 tokens (   78.21 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:        eval time =   20972.65 ms /    31 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22704.86 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2670.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.59 ms /    21 tokens (   72.08 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11431.58 ms /    17 runs   (  672.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12993.89 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2666.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1609.57 ms /    19 tokens (   84.71 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11454.14 ms /    17 runs   (  673.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13113.26 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.37 ms per token,  2667.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1527.12 ms /    21 tokens (   72.72 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11507.51 ms /    17 runs   (  676.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13084.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    14 runs   (    0.37 ms per token,  2672.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1569.47 ms /    21 tokens (   74.74 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8789.72 ms /    13 runs   (  676.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   10397.22 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2698.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.45 ms /    21 tokens (   70.45 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11457.89 ms /    17 runs   (  673.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12987.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    18 runs   (    0.37 ms per token,  2709.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1579.05 ms /    20 tokens (   78.95 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11501.08 ms /    17 runs   (  676.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13129.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    18 runs   (    0.38 ms per token,  2656.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1800.40 ms /    21 tokens (   85.73 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11520.68 ms /    17 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13371.87 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2672.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.95 ms /    20 tokens (   71.00 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11521.05 ms /    17 runs   (  677.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12990.84 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    26 runs   (    0.37 ms per token,  2672.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1566.13 ms /    21 tokens (   74.58 ms per token,    13.41 tokens per second)\n",
      "llama_print_timings:        eval time =   17052.96 ms /    25 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18692.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    18 runs   (    0.39 ms per token,  2579.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.80 ms /    21 tokens (   73.66 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11547.93 ms /    17 runs   (  679.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13145.49 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2700.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.22 ms /    21 tokens (   73.11 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11557.81 ms /    17 runs   (  679.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13142.76 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2676.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1662.79 ms /    21 tokens (   79.18 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11410.73 ms /    17 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13123.45 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2633.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.40 ms /    21 tokens (   71.02 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11432.78 ms /    17 runs   (  672.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12974.78 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.35 ms /    33 runs   (    0.37 ms per token,  2671.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1470.91 ms /    19 tokens (   77.42 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21489.86 ms /    32 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23051.50 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2599.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.98 ms /    21 tokens (   71.52 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11638.39 ms /    17 runs   (  684.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13190.24 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1500th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2636.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.70 ms /    21 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12225.95 ms /    18 runs   (  679.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13396.03 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.28 ms /    21 tokens (   76.82 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12076.20 ms /    18 runs   (  670.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13742.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    19 runs   (    0.38 ms per token,  2663.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1486.55 ms /    21 tokens (   70.79 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12216.79 ms /    18 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13756.13 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2654.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.03 ms /    21 tokens (   71.95 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12280.51 ms /    18 runs   (  682.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13844.78 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    18 runs   (    0.38 ms per token,  2602.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.53 ms /    21 tokens (   72.17 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11583.31 ms /    17 runs   (  681.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13149.32 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2648.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.49 ms /    21 tokens (   70.98 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12282.42 ms /    18 runs   (  682.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13826.03 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    19 runs   (    0.38 ms per token,  2652.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.15 ms /    20 tokens (   72.36 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12391.59 ms /    18 runs   (  688.42 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13892.61 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    16 runs   (    0.38 ms per token,  2649.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.73 ms /    21 tokens (   76.23 ms per token,    13.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10196.48 ms /    15 runs   (  679.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11842.06 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2670.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.45 ms /    21 tokens (   76.50 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11455.27 ms /    17 runs   (  673.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13111.81 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    19 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.71 ms /    21 tokens (   72.37 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12357.80 ms /    18 runs   (  686.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13930.99 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    18 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1671.54 ms /    21 tokens (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11393.18 ms /    17 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13115.27 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2634.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1487.30 ms /    21 tokens (   70.82 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12178.74 ms /    18 runs   (  676.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13719.04 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    19 runs   (    0.36 ms per token,  2744.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.39 ms /    21 tokens (   85.02 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12229.25 ms /    18 runs   (  679.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14067.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2616.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.54 ms /    21 tokens (   71.07 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11524.11 ms /    17 runs   (  677.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13065.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    19 runs   (    0.37 ms per token,  2712.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.28 ms /    21 tokens (   72.44 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12238.99 ms /    18 runs   (  679.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13813.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    19 runs   (    0.37 ms per token,  2694.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1549.22 ms /    21 tokens (   73.77 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12108.64 ms /    18 runs   (  672.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13710.27 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    18 runs   (    0.43 ms per token,  2302.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1765.42 ms /    21 tokens (   84.07 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11499.88 ms /    17 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13321.01 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    19 runs   (    0.37 ms per token,  2694.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.22 ms /    21 tokens (   76.44 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12251.74 ms /    18 runs   (  680.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13909.51 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2634.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1540.66 ms /    21 tokens (   73.36 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11988.08 ms /    18 runs   (  666.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13581.41 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    19 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.41 ms /    21 tokens (   57.54 ms per token,    17.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12276.32 ms /    18 runs   (  682.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13536.80 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    19 runs   (    0.37 ms per token,  2695.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1533.55 ms /    21 tokens (   73.03 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12112.02 ms /    18 runs   (  672.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13697.69 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2697.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1762.80 ms /    21 tokens (   83.94 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11620.93 ms /    17 runs   (  683.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13433.69 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2656.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.71 ms /    21 tokens (   71.08 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10900.99 ms /    16 runs   (  681.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12441.03 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    19 runs   (    0.37 ms per token,  2687.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1518.57 ms /    21 tokens (   72.31 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12098.51 ms /    18 runs   (  672.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13669.50 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    20 runs   (    0.38 ms per token,  2653.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.20 ms /    21 tokens (   73.72 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12777.16 ms /    19 runs   (  672.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14380.17 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    19 runs   (    0.37 ms per token,  2676.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.47 ms /    20 tokens (   71.17 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12271.19 ms /    18 runs   (  681.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13747.45 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    19 runs   (    0.37 ms per token,  2703.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.75 ms /    21 tokens (   72.04 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12084.26 ms /    18 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13649.20 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    19 runs   (    0.38 ms per token,  2656.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1621.72 ms /    21 tokens (   77.22 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12224.74 ms /    18 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13899.03 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    19 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1727.96 ms /    21 tokens (   82.28 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12226.05 ms /    18 runs   (  679.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14006.48 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2672.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1534.61 ms /    21 tokens (   73.08 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11607.70 ms /    17 runs   (  682.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13191.82 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    19 runs   (    0.37 ms per token,  2728.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1482.29 ms /    21 tokens (   70.59 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12162.75 ms /    18 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13697.60 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    19 runs   (    0.36 ms per token,  2748.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1567.48 ms /    21 tokens (   74.64 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12266.31 ms /    18 runs   (  681.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13886.09 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2669.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1723.25 ms /    21 tokens (   82.06 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11454.63 ms /    17 runs   (  673.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13228.43 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    19 runs   (    0.38 ms per token,  2646.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1497.83 ms /    21 tokens (   71.33 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12138.57 ms /    18 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13691.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2634.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.70 ms /    21 tokens (   69.94 ms per token,    14.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12143.53 ms /    18 runs   (  674.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13664.67 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    19 runs   (    0.37 ms per token,  2711.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1658.25 ms /    21 tokens (   78.96 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:        eval time =   12130.74 ms /    18 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13840.90 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    19 runs   (    0.43 ms per token,  2334.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.79 ms /    21 tokens (   70.99 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12153.29 ms /    18 runs   (  675.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13702.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    18 runs   (    0.38 ms per token,  2663.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1528.26 ms /    21 tokens (   72.77 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11457.23 ms /    17 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13035.56 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2701.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1520.36 ms /    21 tokens (   72.40 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11557.13 ms /    17 runs   (  679.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13126.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2702.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.10 ms /    20 tokens (   71.50 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11468.77 ms /    17 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12949.01 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    19 runs   (    0.37 ms per token,  2707.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1531.50 ms /    21 tokens (   72.93 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12151.34 ms /    18 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13735.30 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    19 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.93 ms /    21 tokens (   72.47 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12070.44 ms /    18 runs   (  670.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13645.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    20 runs   (    0.37 ms per token,  2691.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1627.23 ms /    21 tokens (   77.49 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:        eval time =   13043.01 ms /    19 runs   (  686.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14726.38 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2626.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.46 ms /    21 tokens (   71.45 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12857.99 ms /    19 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14414.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    19 runs   (    0.38 ms per token,  2659.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.09 ms /    21 tokens (   73.72 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12133.20 ms /    18 runs   (  674.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13733.67 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    18 runs   (    0.37 ms per token,  2733.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.94 ms /    21 tokens (   71.28 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =   11529.04 ms /    17 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13075.54 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2689.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1495.48 ms /    21 tokens (   71.21 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11427.75 ms /    17 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12974.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    19 runs   (    0.37 ms per token,  2667.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.06 ms /    21 tokens (   70.72 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12257.92 ms /    18 runs   (  681.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13795.91 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    19 runs   (    0.37 ms per token,  2728.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1759.16 ms /    21 tokens (   83.77 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12018.74 ms /    18 runs   (  667.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13829.78 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    19 runs   (    0.37 ms per token,  2721.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1541.86 ms /    21 tokens (   73.42 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12184.01 ms /    18 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13778.50 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2684.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1557.15 ms /    21 tokens (   74.15 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =   11260.18 ms /    17 runs   (  662.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12867.84 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    19 runs   (    0.37 ms per token,  2721.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1503.50 ms /    21 tokens (   71.60 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12206.57 ms /    18 runs   (  678.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13762.01 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2698.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1527.94 ms /    21 tokens (   72.76 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11448.63 ms /    17 runs   (  673.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13026.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2669.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.00 ms /    21 tokens (   76.19 ms per token,    13.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11586.62 ms /    17 runs   (  681.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13236.41 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2604.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.22 ms /    20 tokens (   72.11 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11460.07 ms /    17 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12952.44 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2650.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1561.06 ms /    21 tokens (   74.34 ms per token,    13.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12079.91 ms /    18 runs   (  671.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13693.89 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    18 runs   (    0.37 ms per token,  2714.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.05 ms /    21 tokens (   78.91 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:        eval time =   11507.83 ms /    17 runs   (  676.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13213.74 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1540.59 ms /    21 tokens (   73.36 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11567.16 ms /    17 runs   (  680.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13157.82 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.30 ms /    21 tokens (   55.40 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11476.11 ms /    17 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12689.29 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    19 runs   (    0.37 ms per token,  2703.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1509.22 ms /    21 tokens (   71.87 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11955.52 ms /    18 runs   (  664.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13516.96 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    19 runs   (    0.38 ms per token,  2647.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.77 ms /    20 tokens (   71.19 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12062.60 ms /    18 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13539.28 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    19 runs   (    0.40 ms per token,  2507.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.93 ms /    21 tokens (   70.76 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12259.33 ms /    18 runs   (  681.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13799.73 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2628.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.04 ms /    21 tokens (   71.95 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12199.25 ms /    18 runs   (  677.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13763.88 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    19 runs   (    0.37 ms per token,  2699.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1683.38 ms /    21 tokens (   80.16 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12143.95 ms /    18 runs   (  674.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13880.66 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    19 runs   (    0.37 ms per token,  2688.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.98 ms /    20 tokens (   73.70 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12160.40 ms /    18 runs   (  675.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13687.00 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    20 runs   (    0.39 ms per token,  2537.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1509.00 ms /    21 tokens (   71.86 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12927.52 ms /    19 runs   (  680.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14494.04 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    19 runs   (    0.38 ms per token,  2630.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1539.34 ms /    21 tokens (   73.30 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12238.98 ms /    18 runs   (  679.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13832.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    18 runs   (    0.38 ms per token,  2603.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.11 ms /    21 tokens (   78.01 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11552.17 ms /    17 runs   (  679.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13240.58 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    19 runs   (    0.37 ms per token,  2667.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1534.06 ms /    21 tokens (   73.05 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12238.84 ms /    18 runs   (  679.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13825.47 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2657.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.78 ms /    21 tokens (   75.85 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =   11579.87 ms /    17 runs   (  681.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13224.12 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2636.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1575.12 ms /    21 tokens (   75.01 ms per token,    13.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11534.46 ms /    17 runs   (  678.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13159.58 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    19 runs   (    0.37 ms per token,  2693.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1498.37 ms /    21 tokens (   71.35 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12309.75 ms /    18 runs   (  683.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13861.22 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    19 runs   (    0.37 ms per token,  2668.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.43 ms /    21 tokens (   71.40 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12139.03 ms /    18 runs   (  674.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13691.63 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    19 runs   (    0.37 ms per token,  2734.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1695.32 ms /    21 tokens (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12141.91 ms /    18 runs   (  674.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13889.61 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    19 runs   (    0.37 ms per token,  2667.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1561.98 ms /    21 tokens (   74.38 ms per token,    13.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12196.02 ms /    18 runs   (  677.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13810.20 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2650.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.15 ms /    21 tokens (   75.15 ms per token,    13.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12149.59 ms /    18 runs   (  674.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13779.94 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    18 runs   (    0.38 ms per token,  2630.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.41 ms /    21 tokens (   72.16 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11576.41 ms /    17 runs   (  680.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13142.10 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    20 runs   (    0.38 ms per token,  2606.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.01 ms /    21 tokens (   64.05 ms per token,    15.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12976.41 ms /    19 runs   (  682.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14376.86 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2687.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1627.95 ms /    21 tokens (   77.52 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10896.67 ms /    16 runs   (  681.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12572.02 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    19 runs   (    0.38 ms per token,  2614.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1498.05 ms /    21 tokens (   71.34 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12271.97 ms /    18 runs   (  681.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13824.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    19 runs   (    0.37 ms per token,  2674.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1541.43 ms /    21 tokens (   73.40 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12175.72 ms /    18 runs   (  676.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13769.18 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    18 runs   (    0.37 ms per token,  2719.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1526.79 ms /    21 tokens (   72.70 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11451.60 ms /    17 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13029.01 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    18 runs   (    0.37 ms per token,  2676.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1528.24 ms /    21 tokens (   72.77 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11514.77 ms /    17 runs   (  677.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13093.74 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.01 ms /    16 runs   (    0.38 ms per token,  2662.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1753.08 ms /    21 tokens (   83.48 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =   10163.33 ms /    15 runs   (  677.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11960.34 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2688.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1574.43 ms /    21 tokens (   74.97 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11524.29 ms /    17 runs   (  677.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13147.97 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2618.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.45 ms /    21 tokens (   71.50 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12396.17 ms /    18 runs   (  688.68 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13949.92 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    20 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1500.57 ms /    21 tokens (   71.46 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12829.42 ms /    19 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14385.45 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    19 runs   (    0.38 ms per token,  2628.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1735.47 ms /    21 tokens (   82.64 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12084.16 ms /    18 runs   (  671.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13872.49 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    19 runs   (    0.37 ms per token,  2679.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1558.42 ms /    21 tokens (   74.21 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12131.34 ms /    18 runs   (  673.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13743.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    18 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1558.66 ms /    21 tokens (   74.22 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11502.73 ms /    17 runs   (  676.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13112.74 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2636.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.98 ms /    20 tokens (   76.00 ms per token,    13.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11433.65 ms /    17 runs   (  672.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13003.35 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2635.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1508.36 ms /    21 tokens (   71.83 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12150.30 ms /    18 runs   (  675.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13712.01 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2528.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1532.79 ms /    21 tokens (   72.99 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11458.66 ms /    17 runs   (  674.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13042.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    19 runs   (    0.38 ms per token,  2648.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1604.73 ms /    21 tokens (   76.42 ms per token,    13.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12041.03 ms /    18 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13697.98 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    18 runs   (    0.38 ms per token,  2660.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.88 ms /    21 tokens (   75.47 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11427.47 ms /    17 runs   (  672.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13061.83 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2644.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1545.68 ms /    21 tokens (   73.60 ms per token,    13.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12248.21 ms /    18 runs   (  680.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13846.91 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    19 runs   (    0.38 ms per token,  2610.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1673.15 ms /    21 tokens (   79.67 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12376.02 ms /    18 runs   (  687.56 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14100.95 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    18 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1505.25 ms /    21 tokens (   71.68 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11531.83 ms /    17 runs   (  678.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13086.95 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    18 runs   (    0.37 ms per token,  2702.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1504.76 ms /    21 tokens (   71.66 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11581.98 ms /    17 runs   (  681.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13135.79 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    18 runs   (    0.38 ms per token,  2625.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.22 ms /    20 tokens (   71.51 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11414.41 ms /    17 runs   (  671.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12894.59 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1600th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    21 runs   (    0.37 ms per token,  2683.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1704.34 ms /    24 tokens (   71.01 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   13429.15 ms /    20 runs   (  671.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15191.64 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    21 runs   (    0.37 ms per token,  2731.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1725.18 ms /    22 tokens (   78.42 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13189.24 ms /    20 runs   (  659.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14972.81 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    20 runs   (    0.37 ms per token,  2724.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1849.31 ms /    23 tokens (   80.40 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12879.24 ms /    19 runs   (  677.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14785.03 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    21 runs   (    0.37 ms per token,  2691.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1704.28 ms /    23 tokens (   74.10 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13543.27 ms /    20 runs   (  677.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15305.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    20 runs   (    0.38 ms per token,  2660.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.48 ms /    23 tokens (   70.85 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12878.91 ms /    19 runs   (  677.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14563.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    21 runs   (    0.41 ms per token,  2443.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1757.25 ms /    23 tokens (   76.40 ms per token,    13.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13720.01 ms /    20 runs   (  686.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15539.48 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    20 runs   (    0.36 ms per token,  2765.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1595.17 ms /    22 tokens (   72.51 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12834.42 ms /    19 runs   (  675.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14484.43 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2669.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.68 ms /    23 tokens (   71.99 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13184.95 ms /    20 runs   (  659.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14897.90 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    21 runs   (    0.37 ms per token,  2674.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1666.73 ms /    23 tokens (   72.47 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13502.16 ms /    20 runs   (  675.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15227.56 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    20 runs   (    0.38 ms per token,  2652.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1718.28 ms /    23 tokens (   74.71 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12801.18 ms /    19 runs   (  673.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14575.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    20 runs   (    0.37 ms per token,  2726.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.27 ms /    23 tokens (   70.62 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   13069.00 ms /    19 runs   (  687.84 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14748.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2710.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1720.98 ms /    23 tokens (   74.83 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =   13484.87 ms /    20 runs   (  674.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15265.60 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    20 runs   (    0.36 ms per token,  2752.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1650.10 ms /    23 tokens (   71.74 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12806.64 ms /    19 runs   (  674.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14512.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    20 runs   (    0.37 ms per token,  2737.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.18 ms /    23 tokens (   70.62 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12896.28 ms /    19 runs   (  678.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14575.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    20 runs   (    0.36 ms per token,  2741.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1691.57 ms /    23 tokens (   73.55 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12967.09 ms /    19 runs   (  682.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14712.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    21 runs   (    0.37 ms per token,  2675.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.79 ms /    23 tokens (   71.25 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13084.66 ms /    20 runs   (  654.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14781.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    21 runs   (    0.39 ms per token,  2577.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.95 ms /    23 tokens (   72.52 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13329.71 ms /    20 runs   (  666.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15056.31 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    21 runs   (    0.38 ms per token,  2660.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1941.33 ms /    23 tokens (   84.41 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:        eval time =   13215.50 ms /    20 runs   (  660.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15214.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    21 runs   (    0.37 ms per token,  2694.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1615.31 ms /    22 tokens (   73.42 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   13160.99 ms /    20 runs   (  658.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14835.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    20 runs   (    0.37 ms per token,  2731.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1681.23 ms /    23 tokens (   73.10 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12508.36 ms /    19 runs   (  658.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14245.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    20 runs   (    0.37 ms per token,  2678.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1689.14 ms /    23 tokens (   73.44 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12407.07 ms /    19 runs   (  653.00 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14152.36 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    21 runs   (    0.40 ms per token,  2469.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1651.80 ms /    23 tokens (   71.82 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   13471.08 ms /    20 runs   (  673.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15185.40 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    20 runs   (    0.38 ms per token,  2663.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.74 ms /    23 tokens (   72.73 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12949.95 ms /    19 runs   (  681.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14678.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2667.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1695.87 ms /    23 tokens (   73.73 ms per token,    13.56 tokens per second)\n",
      "llama_print_timings:        eval time =   13473.46 ms /    20 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15228.06 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    21 runs   (    0.36 ms per token,  2751.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.67 ms /    23 tokens (   70.99 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13563.96 ms /    20 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15254.61 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    21 runs   (    0.38 ms per token,  2664.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.70 ms /    23 tokens (   71.16 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13613.21 ms /    20 runs   (  680.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15308.90 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2705.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.48 ms /    23 tokens (   72.72 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13523.34 ms /    20 runs   (  676.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15255.63 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2602.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.22 ms /    23 tokens (   71.49 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12844.48 ms /    19 runs   (  676.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14546.95 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    20 runs   (    0.37 ms per token,  2669.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1769.12 ms /    23 tokens (   76.92 ms per token,    13.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12696.22 ms /    19 runs   (  668.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14521.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    20 runs   (    0.36 ms per token,  2761.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1626.42 ms /    23 tokens (   70.71 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12831.15 ms /    19 runs   (  675.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14513.85 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2706.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1710.09 ms /    23 tokens (   74.35 ms per token,    13.45 tokens per second)\n",
      "llama_print_timings:        eval time =   13466.66 ms /    20 runs   (  673.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15235.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    21 runs   (    0.37 ms per token,  2725.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1633.09 ms /    23 tokens (   71.00 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   13482.18 ms /    20 runs   (  674.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15172.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2634.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.09 ms /    23 tokens (   82.70 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13135.16 ms /    19 runs   (  691.32 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15091.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    21 runs   (    0.36 ms per token,  2757.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.20 ms /    23 tokens (   70.83 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13684.43 ms /    20 runs   (  684.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15371.13 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2686.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.97 ms /    23 tokens (   71.43 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13485.01 ms /    20 runs   (  674.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15186.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2685.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1618.38 ms /    23 tokens (   70.36 ms per token,    14.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13641.26 ms /    20 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15319.16 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2671.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.77 ms /    23 tokens (   70.99 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13620.43 ms /    20 runs   (  681.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15312.25 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    21 runs   (    0.37 ms per token,  2687.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.16 ms /    23 tokens (   71.40 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   13682.36 ms /    20 runs   (  684.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15383.02 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    20 runs   (    0.37 ms per token,  2713.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.92 ms /    23 tokens (   70.95 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12849.43 ms /    19 runs   (  676.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14536.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    20 runs   (    0.37 ms per token,  2706.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1634.72 ms /    23 tokens (   71.07 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12963.17 ms /    19 runs   (  682.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14653.61 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    21 runs   (    0.38 ms per token,  2647.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1675.19 ms /    23 tokens (   72.83 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13291.64 ms /    20 runs   (  664.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15024.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    21 runs   (    0.37 ms per token,  2713.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1679.64 ms /    23 tokens (   73.03 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =   13511.42 ms /    20 runs   (  675.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15249.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    20 runs   (    0.37 ms per token,  2692.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.73 ms /    23 tokens (   71.12 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12781.78 ms /    19 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14472.92 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    21 runs   (    0.37 ms per token,  2674.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1625.20 ms /    23 tokens (   70.66 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =   13518.79 ms /    20 runs   (  675.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15202.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    21 runs   (    0.36 ms per token,  2742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1944.99 ms /    23 tokens (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13410.17 ms /    20 runs   (  670.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15413.43 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2671.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1911.11 ms /    23 tokens (   83.09 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13535.64 ms /    20 runs   (  676.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15505.67 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    20 runs   (    0.37 ms per token,  2718.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.68 ms /    23 tokens (   70.46 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12833.64 ms /    19 runs   (  675.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14509.12 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    20 runs   (    0.37 ms per token,  2734.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1616.83 ms /    23 tokens (   70.30 ms per token,    14.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12793.77 ms /    19 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14466.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    21 runs   (    0.42 ms per token,  2382.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.39 ms /    23 tokens (   70.93 ms per token,    14.10 tokens per second)\n",
      "llama_print_timings:        eval time =   13558.75 ms /    20 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15253.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    21 runs   (    0.36 ms per token,  2792.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1724.71 ms /    22 tokens (   78.40 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13599.31 ms /    20 runs   (  679.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15381.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    21 runs   (    0.36 ms per token,  2754.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.58 ms /    23 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13533.59 ms /    20 runs   (  676.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14783.64 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    21 runs   (    0.36 ms per token,  2744.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1625.96 ms /    23 tokens (   70.69 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =   13631.00 ms /    20 runs   (  681.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15315.95 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    21 runs   (    0.36 ms per token,  2750.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1669.83 ms /    23 tokens (   72.60 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13643.56 ms /    20 runs   (  682.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15371.12 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    21 runs   (    0.37 ms per token,  2715.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1788.48 ms /    23 tokens (   77.76 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13560.21 ms /    20 runs   (  678.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15406.53 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    21 runs   (    0.40 ms per token,  2499.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.38 ms /    23 tokens (   70.58 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   13481.52 ms /    20 runs   (  674.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15167.07 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    21 runs   (    0.38 ms per token,  2665.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1699.01 ms /    23 tokens (   73.87 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =   13549.15 ms /    20 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15307.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    21 runs   (    0.37 ms per token,  2718.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.07 ms /    23 tokens (   70.57 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   13466.39 ms /    20 runs   (  673.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15148.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    20 runs   (    0.37 ms per token,  2711.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.40 ms /    23 tokens (   71.97 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12819.63 ms /    19 runs   (  674.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14531.57 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    21 runs   (    0.36 ms per token,  2787.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1641.81 ms /    23 tokens (   71.38 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   13633.96 ms /    20 runs   (  681.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15333.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    21 runs   (    0.39 ms per token,  2593.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1726.96 ms /    23 tokens (   75.09 ms per token,    13.32 tokens per second)\n",
      "llama_print_timings:        eval time =   13825.75 ms /    20 runs   (  691.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15612.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    21 runs   (    0.37 ms per token,  2725.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1832.05 ms /    22 tokens (   83.27 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:        eval time =   13660.86 ms /    20 runs   (  683.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15550.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    20 runs   (    0.37 ms per token,  2699.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1707.58 ms /    23 tokens (   74.24 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12906.90 ms /    19 runs   (  679.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14669.19 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2709.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1999.45 ms /    23 tokens (   86.93 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13770.01 ms /    20 runs   (  688.50 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15827.73 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    20 runs   (    0.37 ms per token,  2716.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1923.85 ms /    23 tokens (   83.65 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12842.00 ms /    19 runs   (  675.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14821.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    20 runs   (    0.36 ms per token,  2801.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.07 ms /    22 tokens (   73.00 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12820.10 ms /    19 runs   (  674.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14481.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    21 runs   (    0.37 ms per token,  2731.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.66 ms /    23 tokens (   71.25 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13528.51 ms /    20 runs   (  676.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15224.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    21 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1617.96 ms /    23 tokens (   70.35 ms per token,    14.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13226.80 ms /    20 runs   (  661.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14902.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    21 runs   (    0.36 ms per token,  2754.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1721.94 ms /    23 tokens (   74.87 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =   13657.85 ms /    20 runs   (  682.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15435.87 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    20 runs   (    0.36 ms per token,  2749.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1544.44 ms /    22 tokens (   70.20 ms per token,    14.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12859.74 ms /    19 runs   (  676.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14458.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    21 runs   (    0.36 ms per token,  2761.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1934.20 ms /    23 tokens (   84.10 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13505.48 ms /    20 runs   (  675.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15498.19 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    20 runs   (    0.36 ms per token,  2757.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1649.12 ms /    23 tokens (   71.70 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12754.05 ms /    19 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14458.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2686.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1803.34 ms /    23 tokens (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13526.45 ms /    20 runs   (  676.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15388.14 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    20 runs   (    0.37 ms per token,  2689.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1749.19 ms /    23 tokens (   76.05 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12894.81 ms /    19 runs   (  678.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14700.13 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    20 runs   (    0.37 ms per token,  2706.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.51 ms /    23 tokens (   71.50 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12788.62 ms /    19 runs   (  673.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14490.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    20 runs   (    0.37 ms per token,  2709.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.41 ms /    22 tokens (   80.29 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12608.56 ms /    19 runs   (  663.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14431.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    20 runs   (    0.37 ms per token,  2683.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.64 ms /    23 tokens (   70.94 ms per token,    14.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12876.76 ms /    19 runs   (  677.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14565.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    21 runs   (    0.36 ms per token,  2763.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1955.88 ms /    23 tokens (   85.04 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13586.04 ms /    20 runs   (  679.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15599.86 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    21 runs   (    0.38 ms per token,  2659.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1760.09 ms /    23 tokens (   76.53 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13554.56 ms /    20 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15372.94 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    21 runs   (    0.37 ms per token,  2721.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1773.07 ms /    23 tokens (   77.09 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:        eval time =   13475.84 ms /    20 runs   (  673.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15306.47 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2707.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.06 ms /    23 tokens (   72.48 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13611.50 ms /    20 runs   (  680.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15336.59 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    21 runs   (    0.37 ms per token,  2712.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.85 ms /    23 tokens (   77.65 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13307.17 ms /    20 runs   (  665.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15151.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    21 runs   (    0.37 ms per token,  2725.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.10 ms /    23 tokens (   71.22 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13481.01 ms /    20 runs   (  674.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15177.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    21 runs   (    0.37 ms per token,  2702.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.40 ms /    23 tokens (   71.15 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13473.07 ms /    20 runs   (  673.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15168.77 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    20 runs   (    0.38 ms per token,  2653.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1637.12 ms /    23 tokens (   71.18 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12794.77 ms /    19 runs   (  673.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14488.05 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2707.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1793.55 ms /    23 tokens (   77.98 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13466.82 ms /    20 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15317.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    20 runs   (    0.37 ms per token,  2728.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1647.05 ms /    23 tokens (   71.61 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12807.21 ms /    19 runs   (  674.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14508.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    20 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1612.45 ms /    23 tokens (   70.11 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12815.27 ms /    19 runs   (  674.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14482.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    20 runs   (    0.37 ms per token,  2696.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1663.78 ms /    23 tokens (   72.34 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12852.43 ms /    19 runs   (  676.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14572.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    21 runs   (    0.36 ms per token,  2753.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1719.80 ms /    23 tokens (   74.77 ms per token,    13.37 tokens per second)\n",
      "llama_print_timings:        eval time =   13617.10 ms /    20 runs   (  680.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15395.31 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2706.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1806.78 ms /    23 tokens (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13504.97 ms /    20 runs   (  675.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15370.11 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    21 runs   (    0.37 ms per token,  2695.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1739.01 ms /    23 tokens (   75.61 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =   13460.65 ms /    20 runs   (  673.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15258.15 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    21 runs   (    0.36 ms per token,  2773.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1614.14 ms /    23 tokens (   70.18 ms per token,    14.25 tokens per second)\n",
      "llama_print_timings:        eval time =   13574.97 ms /    20 runs   (  678.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15247.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    21 runs   (    0.37 ms per token,  2690.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1767.56 ms /    23 tokens (   76.85 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:        eval time =   13378.29 ms /    20 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15204.95 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    21 runs   (    0.38 ms per token,  2613.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1570.73 ms /    22 tokens (   71.40 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   13410.50 ms /    20 runs   (  670.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15040.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    21 runs   (    0.36 ms per token,  2769.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1744.01 ms /    23 tokens (   75.83 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13510.00 ms /    20 runs   (  675.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15312.12 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2673.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.24 ms /    23 tokens (   72.05 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13484.45 ms /    20 runs   (  674.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15200.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    21 runs   (    0.37 ms per token,  2700.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.49 ms /    23 tokens (   70.46 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13455.67 ms /    20 runs   (  672.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15133.62 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    20 runs   (    0.37 ms per token,  2722.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1986.70 ms /    23 tokens (   86.38 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12849.68 ms /    19 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14892.16 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2686.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1839.47 ms /    23 tokens (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13449.79 ms /    20 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15348.56 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2711.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1625.28 ms /    23 tokens (   70.66 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =   13557.58 ms /    20 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15241.93 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1700th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    20 runs   (    0.37 ms per token,  2688.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.05 ms /    23 tokens (   70.96 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13059.22 ms /    19 runs   (  687.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14746.58 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2626.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1951.66 ms /    23 tokens (   84.85 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:        eval time =   13516.62 ms /    20 runs   (  675.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15526.03 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    21 runs   (    0.37 ms per token,  2698.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1653.37 ms /    23 tokens (   71.89 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =   13560.11 ms /    20 runs   (  678.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15269.07 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    20 runs   (    0.37 ms per token,  2690.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1732.71 ms /    23 tokens (   75.34 ms per token,    13.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12781.63 ms /    19 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14569.10 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    21 runs   (    0.38 ms per token,  2652.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1715.83 ms /    23 tokens (   74.60 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =   13410.47 ms /    20 runs   (  670.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15184.95 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    20 runs   (    0.37 ms per token,  2701.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.06 ms /    23 tokens (   70.52 ms per token,    14.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13052.78 ms /    19 runs   (  686.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14730.29 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    21 runs   (    0.38 ms per token,  2639.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1616.32 ms /    23 tokens (   70.27 ms per token,    14.23 tokens per second)\n",
      "llama_print_timings:        eval time =   13462.44 ms /    20 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15137.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2687.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.45 ms /    23 tokens (   80.54 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13498.56 ms /    20 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15409.57 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    21 runs   (    0.37 ms per token,  2680.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.02 ms /    23 tokens (   70.52 ms per token,    14.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13593.11 ms /    20 runs   (  679.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15274.93 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1737.17 ms /    23 tokens (   75.53 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =   13454.59 ms /    20 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15250.19 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.89 ms /    16 runs   (    0.37 ms per token,  2715.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1727.65 ms /    23 tokens (   75.12 ms per token,    13.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10164.99 ms /    15 runs   (  677.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11937.26 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    21 runs   (    0.38 ms per token,  2661.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.08 ms /    23 tokens (   71.39 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   13503.26 ms /    20 runs   (  675.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15203.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    21 runs   (    0.38 ms per token,  2618.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1595.14 ms /    23 tokens (   69.35 ms per token,    14.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13427.94 ms /    20 runs   (  671.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15081.90 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    20 runs   (    0.42 ms per token,  2388.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.07 ms /    23 tokens (   71.48 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12976.13 ms /    19 runs   (  682.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14680.30 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    20 runs   (    0.37 ms per token,  2681.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1976.95 ms /    23 tokens (   85.95 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12882.03 ms /    19 runs   (  678.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14915.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    21 runs   (    0.37 ms per token,  2687.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1693.08 ms /    23 tokens (   73.61 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =   13494.04 ms /    20 runs   (  674.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15245.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2667.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.81 ms /    23 tokens (   70.17 ms per token,    14.25 tokens per second)\n",
      "llama_print_timings:        eval time =   13497.79 ms /    20 runs   (  674.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15169.57 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    20 runs   (    0.37 ms per token,  2714.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.62 ms /    23 tokens (   70.55 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12910.69 ms /    19 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14589.79 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    20 runs   (    0.37 ms per token,  2681.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1618.78 ms /    23 tokens (   70.38 ms per token,    14.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12831.18 ms /    19 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14505.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    20 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1935.44 ms /    23 tokens (   84.15 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12864.21 ms /    19 runs   (  677.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14855.99 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    20 runs   (    0.37 ms per token,  2700.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1651.71 ms /    23 tokens (   71.81 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12813.68 ms /    19 runs   (  674.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14518.49 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    21 runs   (    0.37 ms per token,  2704.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.40 ms /    23 tokens (   71.15 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13549.78 ms /    20 runs   (  677.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15244.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    21 runs   (    0.38 ms per token,  2648.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1630.27 ms /    23 tokens (   70.88 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13845.70 ms /    20 runs   (  692.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15533.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    21 runs   (    0.38 ms per token,  2646.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1639.99 ms /    23 tokens (   71.30 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13643.23 ms /    20 runs   (  682.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15341.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    21 runs   (    0.38 ms per token,  2618.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1793.85 ms /    23 tokens (   77.99 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13535.71 ms /    20 runs   (  676.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15390.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    21 runs   (    0.38 ms per token,  2652.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1617.08 ms /    23 tokens (   70.31 ms per token,    14.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13688.47 ms /    20 runs   (  684.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15364.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    20 runs   (    0.38 ms per token,  2653.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1685.88 ms /    23 tokens (   73.30 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12862.66 ms /    19 runs   (  676.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14605.17 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.86 ms /    23 tokens (   70.82 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13607.36 ms /    20 runs   (  680.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15295.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    20 runs   (    0.37 ms per token,  2697.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1772.30 ms /    23 tokens (   77.06 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12930.32 ms /    19 runs   (  680.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14759.48 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2668.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.59 ms /    23 tokens (   70.63 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   13521.73 ms /    20 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15204.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    20 runs   (    0.37 ms per token,  2713.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.55 ms /    23 tokens (   70.85 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12716.29 ms /    19 runs   (  669.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14401.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    20 runs   (    0.37 ms per token,  2732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1650.28 ms /    23 tokens (   71.75 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12745.28 ms /    19 runs   (  670.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14450.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    21 runs   (    0.38 ms per token,  2620.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1621.94 ms /    23 tokens (   70.52 ms per token,    14.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13487.89 ms /    20 runs   (  674.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15168.20 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    21 runs   (    0.37 ms per token,  2690.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.36 ms /    23 tokens (   77.62 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13581.13 ms /    20 runs   (  679.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15424.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2706.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.67 ms /    23 tokens (   76.81 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13523.38 ms /    20 runs   (  676.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15348.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2612.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1639.66 ms /    23 tokens (   71.29 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12769.26 ms /    19 runs   (  672.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14465.27 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    21 runs   (    0.38 ms per token,  2655.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1787.27 ms /    23 tokens (   77.71 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:        eval time =   13587.45 ms /    20 runs   (  679.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15434.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    21 runs   (    0.38 ms per token,  2630.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1739.99 ms /    23 tokens (   75.65 ms per token,    13.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13560.62 ms /    20 runs   (  678.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15359.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    20 runs   (    0.37 ms per token,  2693.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.50 ms /    23 tokens (   71.41 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12903.59 ms /    19 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14601.79 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    21 runs   (    0.37 ms per token,  2694.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.63 ms /    23 tokens (   83.16 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13581.03 ms /    20 runs   (  679.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15551.60 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    20 runs   (    0.37 ms per token,  2712.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1529.58 ms /    22 tokens (   69.53 ms per token,    14.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12620.68 ms /    19 runs   (  664.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14204.99 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    21 runs   (    0.38 ms per token,  2661.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1897.12 ms /    23 tokens (   82.48 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13448.88 ms /    20 runs   (  672.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15403.63 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    20 runs   (    0.42 ms per token,  2402.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1706.04 ms /    23 tokens (   74.18 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12926.19 ms /    19 runs   (  680.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14692.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    20 runs   (    0.37 ms per token,  2715.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1627.94 ms /    23 tokens (   70.78 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12835.68 ms /    19 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14519.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    20 runs   (    0.36 ms per token,  2751.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1619.72 ms /    23 tokens (   70.42 ms per token,    14.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12863.27 ms /    19 runs   (  677.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14539.12 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    21 runs   (    0.38 ms per token,  2635.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1666.10 ms /    23 tokens (   72.44 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13394.39 ms /    20 runs   (  669.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15119.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    21 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1790.79 ms /    23 tokens (   77.86 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:        eval time =   13406.85 ms /    20 runs   (  670.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15256.30 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2708.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1698.22 ms /    23 tokens (   73.84 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =   13421.41 ms /    20 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15177.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2685.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1913.31 ms /    23 tokens (   83.19 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13560.83 ms /    20 runs   (  678.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15532.88 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    20 runs   (    0.37 ms per token,  2705.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1700.94 ms /    23 tokens (   73.95 ms per token,    13.52 tokens per second)\n",
      "llama_print_timings:        eval time =   12915.25 ms /    19 runs   (  679.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14671.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    21 runs   (    0.38 ms per token,  2664.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1654.33 ms /    23 tokens (   71.93 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =   13579.97 ms /    20 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15293.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    21 runs   (    0.38 ms per token,  2666.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1659.05 ms /    23 tokens (   72.13 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13360.36 ms /    20 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15077.29 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2628.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.37 ms /    22 tokens (   73.65 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12952.86 ms /    19 runs   (  681.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14629.78 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    20 runs   (    0.37 ms per token,  2677.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.15 ms /    23 tokens (   70.96 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12980.79 ms /    19 runs   (  683.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14668.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    21 runs   (    0.38 ms per token,  2658.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1874.71 ms /    23 tokens (   81.51 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:        eval time =   13466.46 ms /    20 runs   (  673.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15401.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    21 runs   (    0.38 ms per token,  2658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1761.54 ms /    23 tokens (   76.59 ms per token,    13.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13632.68 ms /    20 runs   (  681.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15452.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    20 runs   (    0.37 ms per token,  2698.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.88 ms /    23 tokens (   72.52 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12810.93 ms /    19 runs   (  674.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14534.36 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2679.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1630.12 ms /    23 tokens (   70.87 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13547.95 ms /    20 runs   (  677.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15236.29 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.88 ms /    21 runs   (    0.42 ms per token,  2364.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1717.29 ms /    23 tokens (   74.66 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:        eval time =   13627.77 ms /    20 runs   (  681.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15406.94 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    21 runs   (    0.37 ms per token,  2681.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1645.76 ms /    23 tokens (   71.55 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13485.04 ms /    20 runs   (  674.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15188.02 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    20 runs   (    0.38 ms per token,  2604.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.04 ms /    23 tokens (   71.13 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12823.25 ms /    19 runs   (  674.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14517.47 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    20 runs   (    0.38 ms per token,  2630.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.27 ms /    23 tokens (   72.71 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12828.09 ms /    19 runs   (  675.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14556.21 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    21 runs   (    0.37 ms per token,  2697.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1708.55 ms /    23 tokens (   74.28 ms per token,    13.46 tokens per second)\n",
      "llama_print_timings:        eval time =   13221.10 ms /    20 runs   (  661.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14987.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    21 runs   (    0.38 ms per token,  2647.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1669.77 ms /    23 tokens (   72.60 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13341.72 ms /    20 runs   (  667.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15070.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2669.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1633.56 ms /    23 tokens (   71.02 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   13454.72 ms /    20 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15147.63 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    20 runs   (    0.38 ms per token,  2637.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1686.59 ms /    23 tokens (   73.33 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12801.21 ms /    19 runs   (  673.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14543.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    20 runs   (    0.37 ms per token,  2667.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1573.69 ms /    22 tokens (   71.53 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12790.34 ms /    19 runs   (  673.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14419.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2679.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1725.92 ms /    23 tokens (   75.04 ms per token,    13.33 tokens per second)\n",
      "llama_print_timings:        eval time =   13567.54 ms /    20 runs   (  678.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15351.69 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2623.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1693.10 ms /    23 tokens (   73.61 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12993.43 ms /    19 runs   (  683.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14742.92 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1598.03 ms /    22 tokens (   72.64 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13417.01 ms /    20 runs   (  670.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15072.79 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    20 runs   (    0.37 ms per token,  2691.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1663.63 ms /    23 tokens (   72.33 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12783.95 ms /    19 runs   (  672.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14502.57 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    20 runs   (    0.38 ms per token,  2642.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.12 ms /    23 tokens (   70.53 ms per token,    14.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12804.36 ms /    19 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14482.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    21 runs   (    0.38 ms per token,  2603.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1609.29 ms /    23 tokens (   69.97 ms per token,    14.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13503.70 ms /    20 runs   (  675.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15171.90 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    21 runs   (    0.38 ms per token,  2640.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1553.78 ms /    22 tokens (   70.63 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   13560.11 ms /    20 runs   (  678.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15172.83 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    19 runs   (    0.37 ms per token,  2706.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.63 ms /    23 tokens (   70.55 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12336.91 ms /    18 runs   (  685.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14012.26 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    20 runs   (    0.37 ms per token,  2719.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1676.80 ms /    23 tokens (   72.90 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12796.24 ms /    19 runs   (  673.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14528.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    20 runs   (    0.38 ms per token,  2665.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.88 ms /    23 tokens (   70.47 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13003.06 ms /    19 runs   (  684.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14679.80 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    20 runs   (    0.37 ms per token,  2713.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1626.86 ms /    23 tokens (   70.73 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12831.32 ms /    19 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14513.00 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    21 runs   (    0.38 ms per token,  2652.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1616.92 ms /    23 tokens (   70.30 ms per token,    14.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13552.83 ms /    20 runs   (  677.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15227.93 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    20 runs   (    0.38 ms per token,  2619.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.69 ms /    23 tokens (   72.07 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =   12909.02 ms /    19 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14622.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    21 runs   (    0.38 ms per token,  2660.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1688.37 ms /    23 tokens (   73.41 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   13520.08 ms /    20 runs   (  676.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15266.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    20 runs   (    0.38 ms per token,  2643.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1722.55 ms /    23 tokens (   74.89 ms per token,    13.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12764.40 ms /    19 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14543.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    20 runs   (    0.38 ms per token,  2600.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1643.39 ms /    23 tokens (   71.45 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12903.78 ms /    19 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14604.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2668.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.54 ms /    22 tokens (   74.16 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =   13401.37 ms /    20 runs   (  670.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15090.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2711.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1762.24 ms /    23 tokens (   76.62 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13613.25 ms /    20 runs   (  680.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15433.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    20 runs   (    0.37 ms per token,  2684.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1690.12 ms /    23 tokens (   73.48 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12968.06 ms /    19 runs   (  682.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14713.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    21 runs   (    0.39 ms per token,  2592.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1637.00 ms /    23 tokens (   71.17 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13470.95 ms /    20 runs   (  673.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15166.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    21 runs   (    0.37 ms per token,  2700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1602.38 ms /    22 tokens (   72.84 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13475.54 ms /    20 runs   (  673.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15135.99 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    21 runs   (    0.37 ms per token,  2697.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.18 ms /    23 tokens (   71.09 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13604.85 ms /    20 runs   (  680.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15298.57 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    20 runs   (    0.37 ms per token,  2670.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1756.98 ms /    21 tokens (   83.67 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13034.52 ms /    19 runs   (  686.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14847.22 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    21 runs   (    0.38 ms per token,  2638.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1691.42 ms /    23 tokens (   73.54 ms per token,    13.60 tokens per second)\n",
      "llama_print_timings:        eval time =   13462.25 ms /    20 runs   (  673.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15212.79 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    21 runs   (    0.38 ms per token,  2598.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1614.43 ms /    23 tokens (   70.19 ms per token,    14.25 tokens per second)\n",
      "llama_print_timings:        eval time =   13728.42 ms /    20 runs   (  686.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15401.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    21 runs   (    0.38 ms per token,  2653.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1679.15 ms /    23 tokens (   73.01 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =   13478.43 ms /    20 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15215.89 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    21 runs   (    0.37 ms per token,  2675.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1656.43 ms /    23 tokens (   72.02 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13495.76 ms /    20 runs   (  674.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15209.86 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    20 runs   (    0.38 ms per token,  2618.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1706.54 ms /    23 tokens (   74.20 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12701.31 ms /    19 runs   (  668.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14463.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2704.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1909.34 ms /    23 tokens (   83.01 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13600.52 ms /    20 runs   (  680.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15567.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    21 runs   (    0.37 ms per token,  2696.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.28 ms /    23 tokens (   71.23 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13650.59 ms /    20 runs   (  682.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15346.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    21 runs   (    0.38 ms per token,  2639.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1776.33 ms /    23 tokens (   77.23 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13490.36 ms /    20 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15325.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    22 runs   (    0.36 ms per token,  2742.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1787.57 ms /    23 tokens (   77.72 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14101.11 ms /    21 runs   (  671.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15950.07 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    20 runs   (    0.38 ms per token,  2649.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1662.13 ms /    23 tokens (   72.27 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12777.44 ms /    19 runs   (  672.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14496.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1800th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2710.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1968.40 ms /    24 tokens (   82.02 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13491.26 ms /    20 runs   (  674.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15518.42 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    21 runs   (    0.37 ms per token,  2680.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1836.24 ms /    23 tokens (   79.84 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13492.60 ms /    20 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15387.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    21 runs   (    0.38 ms per token,  2652.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1832.77 ms /    22 tokens (   83.31 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13483.25 ms /    20 runs   (  674.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15374.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    21 runs   (    0.38 ms per token,  2639.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.43 ms /    23 tokens (   70.84 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13640.10 ms /    20 runs   (  682.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15327.27 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    21 runs   (    0.37 ms per token,  2682.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1678.43 ms /    23 tokens (   72.98 ms per token,    13.70 tokens per second)\n",
      "llama_print_timings:        eval time =   13442.45 ms /    20 runs   (  672.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15179.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    20 runs   (    0.38 ms per token,  2656.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1830.94 ms /    23 tokens (   79.61 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12876.82 ms /    19 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14764.44 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    20 runs   (    0.37 ms per token,  2669.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1651.35 ms /    23 tokens (   71.80 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12981.38 ms /    19 runs   (  683.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14687.42 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    21 runs   (    0.37 ms per token,  2673.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1627.22 ms /    23 tokens (   70.75 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13746.71 ms /    20 runs   (  687.34 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15433.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    21 runs   (    0.38 ms per token,  2633.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1685.31 ms /    23 tokens (   73.27 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13713.72 ms /    20 runs   (  685.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15458.37 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    30 runs   (    0.36 ms per token,  2751.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.29 ms /    22 tokens (   71.74 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19608.07 ms /    29 runs   (  676.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21270.92 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    20 runs   (    0.38 ms per token,  2623.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1614.26 ms /    23 tokens (   70.19 ms per token,    14.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12582.28 ms /    19 runs   (  662.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14251.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.86 ms /    23 tokens (   71.99 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13531.96 ms /    20 runs   (  676.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15245.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    22 runs   (    0.37 ms per token,  2679.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.43 ms /    23 tokens (   71.15 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =   14172.13 ms /    21 runs   (  674.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15870.33 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    21 runs   (    0.37 ms per token,  2691.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1694.57 ms /    23 tokens (   73.68 ms per token,    13.57 tokens per second)\n",
      "llama_print_timings:        eval time =   13442.28 ms /    20 runs   (  672.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15194.88 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    21 runs   (    0.38 ms per token,  2638.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1643.25 ms /    23 tokens (   71.45 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13451.06 ms /    20 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15153.23 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      19.26 ms /    50 runs   (    0.39 ms per token,  2595.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1742.33 ms /    23 tokens (   75.75 ms per token,    13.20 tokens per second)\n",
      "llama_print_timings:        eval time =   33237.47 ms /    49 runs   (  678.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   35121.01 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.05 ms /    30 runs   (    0.37 ms per token,  2713.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.26 ms /    23 tokens (   70.97 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   19603.05 ms /    29 runs   (  675.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21320.28 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.19 ms /    30 runs   (    0.37 ms per token,  2680.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1840.19 ms /    23 tokens (   80.01 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19653.93 ms /    29 runs   (  677.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21577.87 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    16 runs   (    0.37 ms per token,  2688.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1654.19 ms /    23 tokens (   71.92 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10103.66 ms /    15 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11802.02 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    21 runs   (    0.37 ms per token,  2690.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1630.46 ms /    23 tokens (   70.89 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13579.41 ms /    20 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15268.59 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2705.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1659.13 ms /    23 tokens (   72.14 ms per token,    13.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13519.81 ms /    20 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15236.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      13.97 ms /    37 runs   (    0.38 ms per token,  2647.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1920.27 ms /    23 tokens (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =   24454.66 ms /    36 runs   (  679.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26478.59 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    20 runs   (    0.38 ms per token,  2660.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1627.68 ms /    23 tokens (   70.77 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12862.69 ms /    19 runs   (  676.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14546.12 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    21 runs   (    0.37 ms per token,  2719.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1617.39 ms /    23 tokens (   70.32 ms per token,    14.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13534.35 ms /    20 runs   (  676.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15209.94 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    21 runs   (    0.38 ms per token,  2621.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1595.22 ms /    23 tokens (   69.36 ms per token,    14.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13563.93 ms /    20 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15218.51 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    21 runs   (    0.38 ms per token,  2650.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1650.67 ms /    23 tokens (   71.77 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   13490.77 ms /    20 runs   (  674.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15200.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    20 runs   (    0.37 ms per token,  2669.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.73 ms /    23 tokens (   71.12 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12894.13 ms /    19 runs   (  678.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14585.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1843.52 ms /    23 tokens (   80.15 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:        eval time =   13642.32 ms /    20 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15543.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      30.16 ms /    77 runs   (    0.39 ms per token,  2553.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1768.66 ms /    23 tokens (   76.90 ms per token,    13.00 tokens per second)\n",
      "llama_print_timings:        eval time =   51791.41 ms /    76 runs   (  681.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   53778.79 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    21 runs   (    0.38 ms per token,  2625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.41 ms /    23 tokens (   71.41 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13467.19 ms /    20 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15167.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    21 runs   (    0.38 ms per token,  2649.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1894.93 ms /    23 tokens (   82.39 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:        eval time =   13591.77 ms /    20 runs   (  679.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15545.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2672.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1712.71 ms /    23 tokens (   74.47 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:        eval time =   13420.29 ms /    20 runs   (  671.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15190.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    20 runs   (    0.37 ms per token,  2711.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1651.43 ms /    23 tokens (   71.80 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12905.95 ms /    19 runs   (  679.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14612.69 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    30 runs   (    0.37 ms per token,  2737.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1866.65 ms /    23 tokens (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:        eval time =   19404.15 ms /    29 runs   (  669.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21353.43 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    21 runs   (    0.37 ms per token,  2680.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1643.70 ms /    23 tokens (   71.47 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   13609.45 ms /    20 runs   (  680.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15313.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    20 runs   (    0.37 ms per token,  2700.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1869.52 ms /    23 tokens (   81.28 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:        eval time =   13064.21 ms /    19 runs   (  687.59 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14989.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    21 runs   (    0.37 ms per token,  2732.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.41 ms /    23 tokens (   71.41 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13380.68 ms /    20 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15082.18 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.06 ms /    16 runs   (    0.38 ms per token,  2641.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1573.07 ms /    22 tokens (   71.50 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10253.21 ms /    15 runs   (  683.55 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11870.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    20 runs   (    0.37 ms per token,  2697.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1775.91 ms /    23 tokens (   77.21 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13030.80 ms /    19 runs   (  685.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14862.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    21 runs   (    0.38 ms per token,  2615.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.10 ms /    23 tokens (   71.09 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13636.89 ms /    20 runs   (  681.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15331.42 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    21 runs   (    0.38 ms per token,  2626.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1916.65 ms /    23 tokens (   83.33 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13554.58 ms /    20 runs   (  677.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15528.86 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    20 runs   (    0.37 ms per token,  2726.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.66 ms /    23 tokens (   72.51 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12572.26 ms /    19 runs   (  661.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14295.57 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /     6 runs   (    0.38 ms per token,  2613.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1681.96 ms /    23 tokens (   73.13 ms per token,    13.67 tokens per second)\n",
      "llama_print_timings:        eval time =    3370.44 ms /     5 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    5068.95 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2671.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1744.49 ms /    23 tokens (   75.85 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13403.50 ms /    20 runs   (  670.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15206.16 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    21 runs   (    0.38 ms per token,  2662.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1935.74 ms /    23 tokens (   84.16 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13298.42 ms /    20 runs   (  664.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15291.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    30 runs   (    0.37 ms per token,  2719.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.10 ms /    23 tokens (   79.31 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19196.22 ms /    29 runs   (  661.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21102.51 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    21 runs   (    0.38 ms per token,  2645.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1679.62 ms /    23 tokens (   73.03 ms per token,    13.69 tokens per second)\n",
      "llama_print_timings:        eval time =   13139.98 ms /    20 runs   (  657.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14877.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    21 runs   (    0.42 ms per token,  2387.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.06 ms /    22 tokens (   72.37 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13369.62 ms /    20 runs   (  668.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15021.57 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.11 ms /    30 runs   (    0.37 ms per token,  2701.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1951.43 ms /    23 tokens (   84.84 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19550.10 ms /    29 runs   (  674.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21586.28 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    16 runs   (    0.37 ms per token,  2720.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1654.08 ms /    23 tokens (   71.92 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9925.09 ms /    15 runs   (  661.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11623.12 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    30 runs   (    0.37 ms per token,  2707.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1708.34 ms /    23 tokens (   74.28 ms per token,    13.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19397.63 ms /    29 runs   (  668.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21190.14 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1555.22 ms /    22 tokens (   70.69 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =   13504.83 ms /    20 runs   (  675.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15118.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    20 runs   (    0.37 ms per token,  2667.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1641.82 ms /    23 tokens (   71.38 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12798.97 ms /    19 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14496.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    21 runs   (    0.38 ms per token,  2643.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1895.91 ms /    23 tokens (   82.43 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13408.75 ms /    20 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15362.37 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2679.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1685.12 ms /    23 tokens (   73.27 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13469.75 ms /    20 runs   (  673.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15213.53 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    16 runs   (    0.38 ms per token,  2629.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1666.91 ms /    23 tokens (   72.47 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10149.72 ms /    15 runs   (  676.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11860.75 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    20 runs   (    0.38 ms per token,  2664.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1670.23 ms /    23 tokens (   72.62 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12894.34 ms /    19 runs   (  678.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14620.29 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    21 runs   (    0.37 ms per token,  2704.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1737.36 ms /    22 tokens (   78.97 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:        eval time =   13445.36 ms /    20 runs   (  672.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15242.44 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.05 ms /    30 runs   (    0.37 ms per token,  2713.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1714.18 ms /    23 tokens (   74.53 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =   19516.35 ms /    29 runs   (  672.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21315.23 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2686.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1614.10 ms /    23 tokens (   70.18 ms per token,    14.25 tokens per second)\n",
      "llama_print_timings:        eval time =   13496.43 ms /    20 runs   (  674.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15169.06 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.07 ms /    16 runs   (    0.38 ms per token,  2635.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1693.47 ms /    23 tokens (   73.63 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10154.28 ms /    15 runs   (  676.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11892.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    21 runs   (    0.37 ms per token,  2675.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1650.59 ms /    23 tokens (   71.76 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   13620.69 ms /    20 runs   (  681.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15328.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    21 runs   (    0.37 ms per token,  2700.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1604.39 ms /    23 tokens (   69.76 ms per token,    14.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13446.31 ms /    20 runs   (  672.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15107.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    20 runs   (    0.37 ms per token,  2668.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.81 ms /    23 tokens (   72.73 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12856.99 ms /    19 runs   (  676.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14585.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    21 runs   (    0.37 ms per token,  2689.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1699.52 ms /    23 tokens (   73.89 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13512.52 ms /    20 runs   (  675.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15272.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    21 runs   (    0.37 ms per token,  2731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1646.52 ms /    23 tokens (   71.59 ms per token,    13.97 tokens per second)\n",
      "llama_print_timings:        eval time =   13422.84 ms /    20 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15127.42 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    21 runs   (    0.37 ms per token,  2726.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1807.63 ms /    22 tokens (   82.16 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:        eval time =   13537.19 ms /    20 runs   (  676.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15403.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    21 runs   (    0.38 ms per token,  2649.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1639.21 ms /    23 tokens (   71.27 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13450.28 ms /    20 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15147.26 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    21 runs   (    0.37 ms per token,  2688.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1627.19 ms /    23 tokens (   70.75 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13573.43 ms /    20 runs   (  678.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15258.73 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    21 runs   (    0.36 ms per token,  2755.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1645.22 ms /    23 tokens (   71.53 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13573.53 ms /    20 runs   (  678.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15276.43 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    21 runs   (    0.38 ms per token,  2662.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1590.55 ms /    22 tokens (   72.30 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13536.06 ms /    20 runs   (  676.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15185.13 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    20 runs   (    0.38 ms per token,  2609.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1615.16 ms /    23 tokens (   70.22 ms per token,    14.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12711.60 ms /    19 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14383.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.01 ms /    16 runs   (    0.38 ms per token,  2664.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1658.04 ms /    23 tokens (   72.09 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10019.80 ms /    15 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11722.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    21 runs   (    0.37 ms per token,  2700.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1651.10 ms /    23 tokens (   71.79 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   13497.99 ms /    20 runs   (  674.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15206.43 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    21 runs   (    0.37 ms per token,  2675.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1651.60 ms /    23 tokens (   71.81 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   13424.57 ms /    20 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15136.11 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    21 runs   (    0.37 ms per token,  2698.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1619.00 ms /    23 tokens (   70.39 ms per token,    14.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13415.80 ms /    20 runs   (  670.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15094.26 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    20 runs   (    0.37 ms per token,  2689.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1648.81 ms /    23 tokens (   71.69 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12907.82 ms /    19 runs   (  679.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14612.69 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2684.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1703.36 ms /    23 tokens (   74.06 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13509.55 ms /    20 runs   (  675.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15271.39 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    16 runs   (    0.37 ms per token,  2699.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1618.90 ms /    23 tokens (   70.39 ms per token,    14.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10222.94 ms /    15 runs   (  681.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11887.25 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    20 runs   (    0.37 ms per token,  2694.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1772.61 ms /    23 tokens (   77.07 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12959.89 ms /    19 runs   (  682.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14787.42 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2634.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.37 ms /    23 tokens (   70.97 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12848.80 ms /    19 runs   (  676.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14537.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    21 runs   (    0.37 ms per token,  2717.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1675.27 ms /    23 tokens (   72.84 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13590.77 ms /    20 runs   (  679.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15324.94 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    21 runs   (    0.37 ms per token,  2680.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1920.29 ms /    23 tokens (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13611.91 ms /    20 runs   (  680.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15590.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.78 ms /    23 tokens (   71.12 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13510.15 ms /    20 runs   (  675.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15205.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2671.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1653.74 ms /    23 tokens (   71.90 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =   13421.29 ms /    20 runs   (  671.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15133.77 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    21 runs   (    0.37 ms per token,  2692.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1663.70 ms /    23 tokens (   72.33 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13035.68 ms /    20 runs   (  651.78 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14757.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    21 runs   (    0.38 ms per token,  2630.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1909.48 ms /    23 tokens (   83.02 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13537.72 ms /    20 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15505.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    20 runs   (    0.37 ms per token,  2696.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.27 ms /    23 tokens (   70.92 ms per token,    14.10 tokens per second)\n",
      "llama_print_timings:        eval time =   12796.85 ms /    19 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14483.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.82 ms /    29 runs   (    0.37 ms per token,  2681.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1710.12 ms /    23 tokens (   74.35 ms per token,    13.45 tokens per second)\n",
      "llama_print_timings:        eval time =   18863.09 ms /    28 runs   (  673.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20652.76 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2672.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.44 ms /    23 tokens (   70.15 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13430.61 ms /    20 runs   (  671.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15102.60 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    21 runs   (    0.38 ms per token,  2639.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.72 ms /    23 tokens (   72.51 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13479.84 ms /    20 runs   (  673.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15207.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    21 runs   (    0.37 ms per token,  2703.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1666.26 ms /    23 tokens (   72.45 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13530.20 ms /    20 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15255.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2673.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.28 ms /    23 tokens (   70.62 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   13468.57 ms /    20 runs   (  673.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15152.24 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2672.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1864.01 ms /    23 tokens (   81.04 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13556.38 ms /    20 runs   (  677.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15479.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    21 runs   (    0.38 ms per token,  2664.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1703.66 ms /    23 tokens (   74.07 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13683.01 ms /    20 runs   (  684.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15445.13 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    16 runs   (    0.38 ms per token,  2651.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.02 ms /    23 tokens (   71.13 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10215.12 ms /    15 runs   (  681.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11896.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2667.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1718.49 ms /    23 tokens (   74.72 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:        eval time =   13467.25 ms /    20 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15243.27 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    21 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.26 ms /    23 tokens (   70.97 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13537.24 ms /    20 runs   (  676.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15228.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    16 runs   (    0.38 ms per token,  2599.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1664.15 ms /    23 tokens (   72.35 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10224.44 ms /    15 runs   (  681.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11933.41 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    16 runs   (    0.37 ms per token,  2681.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1721.58 ms /    23 tokens (   74.85 ms per token,    13.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10125.83 ms /    15 runs   (  675.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11891.89 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1900th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    21 runs   (    0.37 ms per token,  2703.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1639.95 ms /    23 tokens (   71.30 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13661.25 ms /    20 runs   (  683.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15359.37 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2670.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.79 ms /    23 tokens (   70.95 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   13456.41 ms /    20 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15147.01 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    22 runs   (    0.37 ms per token,  2736.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1648.12 ms /    23 tokens (   71.66 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14151.93 ms /    21 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15861.51 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    21 runs   (    0.38 ms per token,  2665.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.04 ms /    23 tokens (   83.13 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13566.10 ms /    20 runs   (  678.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15537.47 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    22 runs   (    0.37 ms per token,  2671.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1673.62 ms /    23 tokens (   72.77 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14117.15 ms /    21 runs   (  672.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15851.70 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    22 runs   (    0.37 ms per token,  2702.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1633.41 ms /    23 tokens (   71.02 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   14106.01 ms /    21 runs   (  671.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15800.91 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    22 runs   (    0.37 ms per token,  2727.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1817.73 ms /    23 tokens (   79.03 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:        eval time =   14189.56 ms /    21 runs   (  675.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16068.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    22 runs   (    0.37 ms per token,  2707.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1735.00 ms /    23 tokens (   75.43 ms per token,    13.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13975.85 ms /    21 runs   (  665.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15771.48 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    21 runs   (    0.36 ms per token,  2740.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1616.97 ms /    23 tokens (   70.30 ms per token,    14.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13547.95 ms /    20 runs   (  677.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15223.88 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2685.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1926.05 ms /    23 tokens (   83.74 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =   13424.52 ms /    20 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15411.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    22 runs   (    0.37 ms per token,  2679.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1889.26 ms /    23 tokens (   82.14 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14168.66 ms /    21 runs   (  674.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16119.75 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    21 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.26 ms /    23 tokens (   71.49 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   13498.55 ms /    20 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15205.86 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    22 runs   (    0.37 ms per token,  2689.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.96 ms /    22 tokens (   74.09 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:        eval time =   14132.67 ms /    21 runs   (  672.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15825.41 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    22 runs   (    0.37 ms per token,  2729.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1626.08 ms /    23 tokens (   70.70 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   14196.45 ms /    21 runs   (  676.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15883.67 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    22 runs   (    0.37 ms per token,  2679.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1750.11 ms /    23 tokens (   76.09 ms per token,    13.14 tokens per second)\n",
      "llama_print_timings:        eval time =   14283.11 ms /    21 runs   (  680.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16095.15 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    21 runs   (    0.37 ms per token,  2695.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1707.07 ms /    23 tokens (   74.22 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13555.19 ms /    20 runs   (  677.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15320.03 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2678.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1597.03 ms /    22 tokens (   72.59 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =   13592.75 ms /    20 runs   (  679.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15248.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    22 runs   (    0.38 ms per token,  2661.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1843.91 ms /    23 tokens (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14151.70 ms /    21 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16057.09 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2705.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1938.65 ms /    23 tokens (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13626.90 ms /    20 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15623.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    21 runs   (    0.37 ms per token,  2671.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1713.66 ms /    23 tokens (   74.51 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13641.71 ms /    20 runs   (  682.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15414.64 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    21 runs   (    0.37 ms per token,  2719.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.22 ms /    23 tokens (   72.05 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13499.95 ms /    20 runs   (  675.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15215.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2667.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1868.64 ms /    23 tokens (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:        eval time =   13529.25 ms /    20 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15455.85 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    22 runs   (    0.37 ms per token,  2701.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.07 ms /    23 tokens (   71.13 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14206.02 ms /    21 runs   (  676.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15902.38 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    22 runs   (    0.38 ms per token,  2658.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1689.55 ms /    23 tokens (   73.46 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =   14268.06 ms /    21 runs   (  679.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16018.85 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    22 runs   (    0.36 ms per token,  2792.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1652.57 ms /    23 tokens (   71.85 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   14357.81 ms /    21 runs   (  683.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16071.37 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    21 runs   (    0.38 ms per token,  2662.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1811.57 ms /    23 tokens (   78.76 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:        eval time =   13577.85 ms /    20 runs   (  678.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15448.30 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    22 runs   (    0.37 ms per token,  2716.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1633.47 ms /    23 tokens (   71.02 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   14197.76 ms /    21 runs   (  676.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15892.55 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    21 runs   (    0.38 ms per token,  2660.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.21 ms /    23 tokens (   70.14 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13580.45 ms /    20 runs   (  679.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15252.32 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    20 runs   (    0.37 ms per token,  2688.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.55 ms /    23 tokens (   70.85 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12986.67 ms /    19 runs   (  683.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14673.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2707.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.54 ms /    22 tokens (   73.66 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =   13514.40 ms /    20 runs   (  675.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15193.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    21 runs   (    0.37 ms per token,  2730.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1973.39 ms /    23 tokens (   85.80 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =   13468.20 ms /    20 runs   (  673.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15499.44 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1708.04 ms /    23 tokens (   74.26 ms per token,    13.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13613.71 ms /    20 runs   (  680.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15379.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    22 runs   (    0.38 ms per token,  2609.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1668.82 ms /    23 tokens (   72.56 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =   14115.78 ms /    21 runs   (  672.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15846.74 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    21 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1567.11 ms /    22 tokens (   71.23 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13525.22 ms /    20 runs   (  676.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15150.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    21 runs   (    0.38 ms per token,  2632.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1651.64 ms /    23 tokens (   71.81 ms per token,    13.93 tokens per second)\n",
      "llama_print_timings:        eval time =   13427.06 ms /    20 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15137.86 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    21 runs   (    0.38 ms per token,  2653.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1743.96 ms /    23 tokens (   75.82 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13424.90 ms /    20 runs   (  671.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15227.18 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    22 runs   (    0.37 ms per token,  2676.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1673.50 ms /    23 tokens (   72.76 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14122.71 ms /    21 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15857.79 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    20 runs   (    0.38 ms per token,  2636.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1661.78 ms /    23 tokens (   72.25 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12946.73 ms /    19 runs   (  681.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14664.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    22 runs   (    0.37 ms per token,  2728.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1611.90 ms /    23 tokens (   70.08 ms per token,    14.27 tokens per second)\n",
      "llama_print_timings:        eval time =   14017.96 ms /    21 runs   (  667.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15690.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    21 runs   (    0.38 ms per token,  2640.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1641.72 ms /    22 tokens (   74.62 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =   13550.50 ms /    20 runs   (  677.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15250.44 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    22 runs   (    0.38 ms per token,  2649.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.64 ms /    23 tokens (   70.55 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14099.85 ms /    21 runs   (  671.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15784.54 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    21 runs   (    0.38 ms per token,  2655.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1626.51 ms /    23 tokens (   70.72 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   13107.93 ms /    20 runs   (  655.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14792.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    21 runs   (    0.37 ms per token,  2704.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1634.95 ms /    23 tokens (   71.08 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13511.83 ms /    20 runs   (  675.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15204.47 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    21 runs   (    0.38 ms per token,  2628.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1612.93 ms /    23 tokens (   70.13 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13419.52 ms /    20 runs   (  670.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15091.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    21 runs   (    0.37 ms per token,  2669.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1648.87 ms /    23 tokens (   71.69 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13558.96 ms /    20 runs   (  677.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15265.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    22 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.98 ms /    23 tokens (   70.48 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =   14204.15 ms /    21 runs   (  676.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15886.36 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    22 runs   (    0.37 ms per token,  2700.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1610.38 ms /    23 tokens (   70.02 ms per token,    14.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14102.86 ms /    21 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15775.08 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    22 runs   (    0.37 ms per token,  2726.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1558.58 ms /    22 tokens (   70.84 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   14227.18 ms /    21 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15846.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    21 runs   (    0.38 ms per token,  2623.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1662.80 ms /    23 tokens (   72.30 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13508.81 ms /    20 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15229.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    22 runs   (    0.38 ms per token,  2613.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.78 ms /    23 tokens (   70.82 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   14237.21 ms /    21 runs   (  677.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15927.31 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    22 runs   (    0.38 ms per token,  2630.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.17 ms /    23 tokens (   70.79 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   14179.61 ms /    21 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15871.82 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2679.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.94 ms /    23 tokens (   71.17 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13415.56 ms /    20 runs   (  670.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15110.62 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    21 runs   (    0.37 ms per token,  2724.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1730.80 ms /    23 tokens (   75.25 ms per token,    13.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13590.14 ms /    20 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15381.53 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    22 runs   (    0.39 ms per token,  2582.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1737.03 ms /    23 tokens (   75.52 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =   14211.23 ms /    21 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16010.79 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    21 runs   (    0.37 ms per token,  2718.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1627.31 ms /    23 tokens (   70.75 ms per token,    14.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13444.38 ms /    20 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15129.64 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    22 runs   (    0.37 ms per token,  2701.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1926.40 ms /    23 tokens (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =   14177.68 ms /    21 runs   (  675.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16165.00 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    22 runs   (    0.39 ms per token,  2583.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1615.28 ms /    22 tokens (   73.42 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14190.94 ms /    21 runs   (  675.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15868.48 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    22 runs   (    0.36 ms per token,  2750.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1591.11 ms /    22 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =   14127.83 ms /    21 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15780.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    21 runs   (    0.39 ms per token,  2567.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1764.35 ms /    23 tokens (   76.71 ms per token,    13.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13239.47 ms /    20 runs   (  661.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15064.24 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    22 runs   (    0.37 ms per token,  2691.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1788.94 ms /    23 tokens (   77.78 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14201.75 ms /    21 runs   (  676.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16052.28 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    22 runs   (    0.37 ms per token,  2667.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1554.78 ms /    22 tokens (   70.67 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =   14273.85 ms /    21 runs   (  679.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15886.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    21 runs   (    0.36 ms per token,  2743.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.87 ms /    23 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13389.22 ms /    20 runs   (  669.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14602.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    22 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.62 ms /    23 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14020.02 ms /    21 runs   (  667.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15250.06 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    21 runs   (    0.36 ms per token,  2796.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.38 ms /    23 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13615.51 ms /    20 runs   (  680.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14844.64 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    21 runs   (    0.36 ms per token,  2782.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.21 ms /    23 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13100.89 ms /    20 runs   (  655.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14315.96 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    21 runs   (    0.35 ms per token,  2827.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.25 ms /    23 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13535.83 ms /    20 runs   (  676.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14756.57 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    22 runs   (    0.37 ms per token,  2739.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.83 ms /    23 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14154.34 ms /    21 runs   (  674.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15365.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    22 runs   (    0.36 ms per token,  2815.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.50 ms /    23 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14255.62 ms /    21 runs   (  678.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15485.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    21 runs   (    0.36 ms per token,  2777.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.58 ms /    23 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   13640.78 ms /    20 runs   (  682.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14876.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    22 runs   (    0.36 ms per token,  2744.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.48 ms /    23 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   14170.44 ms /    21 runs   (  674.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15388.55 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    21 runs   (    0.36 ms per token,  2808.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.39 ms /    23 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   13543.91 ms /    20 runs   (  677.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14781.73 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    22 runs   (    0.36 ms per token,  2747.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.15 ms /    23 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   14293.03 ms /    21 runs   (  680.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15503.22 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    21 runs   (    0.36 ms per token,  2770.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.07 ms /    23 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13651.46 ms /    20 runs   (  682.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14860.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    22 runs   (    0.36 ms per token,  2769.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.88 ms /    23 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   14251.98 ms /    21 runs   (  678.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15470.17 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    21 runs   (    0.37 ms per token,  2721.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.92 ms /    23 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   13428.01 ms /    20 runs   (  671.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14654.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    22 runs   (    0.35 ms per token,  2851.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.57 ms /    23 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   14157.10 ms /    21 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15372.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    22 runs   (    0.36 ms per token,  2763.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.79 ms /    23 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14223.45 ms /    21 runs   (  677.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15444.07 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    21 runs   (    0.36 ms per token,  2791.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.34 ms /    23 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13502.69 ms /    20 runs   (  675.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14716.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    21 runs   (    0.35 ms per token,  2816.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.02 ms /    23 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13450.46 ms /    20 runs   (  672.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14659.69 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    21 runs   (    0.36 ms per token,  2750.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.38 ms /    23 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13383.82 ms /    20 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14595.26 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    22 runs   (    0.36 ms per token,  2753.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.30 ms /    23 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14093.52 ms /    21 runs   (  671.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15313.55 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    22 runs   (    0.37 ms per token,  2728.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.53 ms /    23 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14061.25 ms /    21 runs   (  669.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15289.59 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    22 runs   (    0.36 ms per token,  2804.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.66 ms /    23 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14002.99 ms /    21 runs   (  666.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15230.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    21 runs   (    0.36 ms per token,  2781.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.26 ms /    22 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   13457.97 ms /    20 runs   (  672.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14638.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    21 runs   (    0.36 ms per token,  2795.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.63 ms /    22 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13365.46 ms /    20 runs   (  668.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14572.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    22 runs   (    0.36 ms per token,  2742.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.42 ms /    23 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   14175.88 ms /    21 runs   (  675.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15392.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    22 runs   (    0.36 ms per token,  2794.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.70 ms /    23 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14001.60 ms /    21 runs   (  666.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15231.16 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    22 runs   (    0.36 ms per token,  2742.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.38 ms /    23 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14060.49 ms /    21 runs   (  669.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15280.53 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    22 runs   (    0.35 ms per token,  2849.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.69 ms /    23 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14277.85 ms /    21 runs   (  679.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15488.81 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    21 runs   (    0.36 ms per token,  2766.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.80 ms /    23 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13603.48 ms /    20 runs   (  680.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14811.05 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    21 runs   (    0.37 ms per token,  2736.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.57 ms /    23 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13597.02 ms /    20 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14809.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    19 runs   (    0.37 ms per token,  2725.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.48 ms /    23 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12173.59 ms /    18 runs   (  676.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13385.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    20 runs   (    0.37 ms per token,  2725.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.28 ms /    22 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12819.10 ms /    19 runs   (  674.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14020.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    21 runs   (    0.36 ms per token,  2815.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.02 ms /    23 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   13543.57 ms /    20 runs   (  677.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14761.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    21 runs   (    0.35 ms per token,  2862.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.91 ms /    23 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13407.82 ms /    20 runs   (  670.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14672.02 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    22 runs   (    0.36 ms per token,  2813.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.05 ms /    23 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14157.81 ms /    21 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15392.87 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    21 runs   (    0.36 ms per token,  2758.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.64 ms /    23 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13713.37 ms /    20 runs   (  685.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14930.77 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    21 runs   (    0.36 ms per token,  2791.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.97 ms /    23 tokens (   51.69 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13622.56 ms /    20 runs   (  681.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14863.01 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    22 runs   (    0.35 ms per token,  2848.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.54 ms /    23 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14224.85 ms /    21 runs   (  677.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15453.59 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    22 runs   (    0.36 ms per token,  2745.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.53 ms /    23 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14291.17 ms /    21 runs   (  680.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15519.87 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2000th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    23 runs   (    0.35 ms per token,  2823.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.20 ms /    26 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   14991.93 ms /    22 runs   (  681.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16360.53 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    24 runs   (    0.35 ms per token,  2864.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1242.96 ms /    24 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   15661.09 ms /    23 runs   (  680.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16963.16 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    24 runs   (    0.35 ms per token,  2880.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.07 ms /    25 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   15590.79 ms /    23 runs   (  677.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16910.08 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    23 runs   (    0.36 ms per token,  2779.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.22 ms /    25 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   14881.97 ms /    22 runs   (  676.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16210.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    23 runs   (    0.35 ms per token,  2869.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.88 ms /    25 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   14919.92 ms /    22 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16225.04 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    23 runs   (    0.36 ms per token,  2801.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.10 ms /    25 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   14871.96 ms /    22 runs   (  676.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16183.21 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    24 runs   (    0.35 ms per token,  2869.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.71 ms /    25 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   15479.42 ms /    23 runs   (  673.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16832.20 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    24 runs   (    0.35 ms per token,  2817.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.13 ms /    25 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15540.21 ms /    23 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16848.31 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    24 runs   (    0.35 ms per token,  2820.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.00 ms /    25 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   15312.34 ms /    23 runs   (  665.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16657.86 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    24 runs   (    0.35 ms per token,  2869.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.69 ms /    25 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15408.93 ms /    23 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16736.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    24 runs   (    0.35 ms per token,  2823.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.89 ms /    25 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15450.46 ms /    23 runs   (  671.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16776.31 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    24 runs   (    0.35 ms per token,  2831.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.98 ms /    25 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15390.42 ms /    23 runs   (  669.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16708.12 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    24 runs   (    0.35 ms per token,  2840.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.50 ms /    25 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   15560.36 ms /    23 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16903.50 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    24 runs   (    0.35 ms per token,  2869.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.22 ms /    24 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   15564.90 ms /    23 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16830.09 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    23 runs   (    0.35 ms per token,  2822.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.49 ms /    25 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14818.70 ms /    22 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16153.58 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    24 runs   (    0.35 ms per token,  2858.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.18 ms /    25 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   15473.65 ms /    23 runs   (  672.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16875.60 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    23 runs   (    0.34 ms per token,  2902.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.90 ms /    25 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14714.12 ms /    22 runs   (  668.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16047.47 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    23 runs   (    0.35 ms per token,  2836.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.87 ms /    25 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   14800.59 ms /    22 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16110.83 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    23 runs   (    0.35 ms per token,  2858.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.57 ms /    25 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   14742.27 ms /    22 runs   (  670.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16083.46 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    24 runs   (    0.36 ms per token,  2797.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.59 ms /    25 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   15471.65 ms /    23 runs   (  672.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16803.27 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    23 runs   (    0.36 ms per token,  2798.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.28 ms /    25 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   14914.14 ms /    22 runs   (  677.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16240.45 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    24 runs   (    0.35 ms per token,  2856.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.72 ms /    25 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15529.74 ms /    23 runs   (  675.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16854.06 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.65 ms /    24 runs   (    0.36 ms per token,  2773.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.98 ms /    25 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   15535.69 ms /    23 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16885.67 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    24 runs   (    0.35 ms per token,  2847.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.87 ms /    25 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15594.52 ms /    23 runs   (  678.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16923.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    24 runs   (    0.36 ms per token,  2814.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.00 ms /    25 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   15491.32 ms /    23 runs   (  673.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16823.22 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2827.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.53 ms /    25 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14984.73 ms /    22 runs   (  681.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16298.42 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    23 runs   (    0.36 ms per token,  2812.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.14 ms /    24 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   14819.07 ms /    22 runs   (  673.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16083.76 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    24 runs   (    0.36 ms per token,  2748.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.36 ms /    25 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   15601.27 ms /    23 runs   (  678.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16914.31 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    23 runs   (    0.35 ms per token,  2861.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.98 ms /    25 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   14966.47 ms /    22 runs   (  680.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16303.15 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    23 runs   (    0.36 ms per token,  2802.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.00 ms /    25 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14870.08 ms /    22 runs   (  675.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16201.31 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    24 runs   (    0.35 ms per token,  2844.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.39 ms /    25 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   15522.55 ms /    23 runs   (  674.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16852.70 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    24 runs   (    0.36 ms per token,  2797.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.92 ms /    25 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   15515.02 ms /    23 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16866.82 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    23 runs   (    0.37 ms per token,  2722.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.52 ms /    25 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14924.00 ms /    22 runs   (  678.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16232.47 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    24 runs   (    0.35 ms per token,  2861.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.52 ms /    25 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   15632.49 ms /    23 runs   (  679.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16974.73 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    23 runs   (    0.35 ms per token,  2847.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.37 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14803.64 ms /    22 runs   (  672.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16136.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    24 runs   (    0.36 ms per token,  2780.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.83 ms /    24 tokens (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   15609.36 ms /    23 runs   (  678.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16879.46 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    23 runs   (    0.35 ms per token,  2824.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.34 ms /    25 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14928.78 ms /    22 runs   (  678.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16265.64 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    23 runs   (    0.35 ms per token,  2881.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.17 ms /    25 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14928.18 ms /    22 runs   (  678.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16250.55 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    24 runs   (    0.35 ms per token,  2835.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.87 ms /    25 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   15598.64 ms /    23 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16931.93 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    23 runs   (    0.36 ms per token,  2793.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.71 ms /    25 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   14874.32 ms /    22 runs   (  676.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16189.09 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    23 runs   (    0.35 ms per token,  2819.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.56 ms /    25 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   14892.26 ms /    22 runs   (  676.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16214.55 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    24 runs   (    0.35 ms per token,  2849.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.82 ms /    25 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15681.53 ms /    23 runs   (  681.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16995.50 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    23 runs   (    0.35 ms per token,  2838.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.23 ms /    25 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14932.89 ms /    22 runs   (  678.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16304.90 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    24 runs   (    0.35 ms per token,  2863.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.49 ms /    25 tokens (   50.34 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15515.22 ms /    23 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16831.63 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    23 runs   (    0.35 ms per token,  2848.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.05 ms /    25 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14952.90 ms /    22 runs   (  679.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16390.80 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    24 runs   (    0.35 ms per token,  2844.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.79 ms /    25 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15636.50 ms /    23 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16944.94 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    24 runs   (    0.35 ms per token,  2880.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.35 ms /    25 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   15698.50 ms /    23 runs   (  682.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17034.55 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    24 runs   (    0.35 ms per token,  2856.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.92 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15570.25 ms /    23 runs   (  676.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16878.46 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    23 runs   (    0.36 ms per token,  2778.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.61 ms /    25 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14821.45 ms /    22 runs   (  673.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16145.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    24 runs   (    0.35 ms per token,  2833.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.84 ms /    25 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   15732.48 ms /    23 runs   (  684.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17053.41 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    24 runs   (    0.35 ms per token,  2867.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.07 ms /    25 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15624.26 ms /    23 runs   (  679.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16942.56 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    24 runs   (    0.35 ms per token,  2826.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.15 ms /    24 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15742.06 ms /    23 runs   (  684.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17009.72 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    23 runs   (    0.35 ms per token,  2858.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.54 ms /    25 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   15007.86 ms /    22 runs   (  682.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16318.80 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    23 runs   (    0.36 ms per token,  2784.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.59 ms /    25 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14940.61 ms /    22 runs   (  679.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16247.40 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    24 runs   (    0.35 ms per token,  2835.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.77 ms /    25 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15593.75 ms /    23 runs   (  677.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16908.87 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2830.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.42 ms /    25 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   14836.43 ms /    22 runs   (  674.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16190.67 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    24 runs   (    0.35 ms per token,  2865.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.79 ms /    25 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   15494.85 ms /    23 runs   (  673.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16818.00 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    24 runs   (    0.36 ms per token,  2764.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.74 ms /    25 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15483.64 ms /    23 runs   (  673.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16797.44 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    23 runs   (    0.35 ms per token,  2847.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.76 ms /    25 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   14905.34 ms /    22 runs   (  677.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16213.97 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    23 runs   (    0.35 ms per token,  2889.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.64 ms /    23 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14732.42 ms /    22 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15994.69 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    24 runs   (    0.35 ms per token,  2830.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.07 ms /    25 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   15558.59 ms /    23 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16872.04 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    23 runs   (    0.36 ms per token,  2780.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.61 ms /    25 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   14799.53 ms /    22 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16117.29 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    24 runs   (    0.35 ms per token,  2830.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.40 ms /    25 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   15430.79 ms /    23 runs   (  670.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16754.04 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2830.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.15 ms /    25 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   14779.73 ms /    22 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16102.37 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    23 runs   (    0.36 ms per token,  2777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.53 ms /    25 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14852.90 ms /    22 runs   (  675.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16176.61 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    24 runs   (    0.35 ms per token,  2871.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.42 ms /    25 tokens (   50.14 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   15545.72 ms /    23 runs   (  675.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16857.97 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    24 runs   (    0.35 ms per token,  2897.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.14 ms /    24 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   15450.55 ms /    23 runs   (  671.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16726.53 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    24 runs   (    0.35 ms per token,  2868.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.16 ms /    25 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   15422.45 ms /    23 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16733.97 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    23 runs   (    0.35 ms per token,  2860.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.66 ms /    24 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   14820.94 ms /    22 runs   (  673.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16113.24 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    24 runs   (    0.35 ms per token,  2824.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.52 ms /    25 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   15562.66 ms /    23 runs   (  676.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16885.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    26 runs   (    0.35 ms per token,  2834.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.53 ms /    25 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   16829.08 ms /    25 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18150.88 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    24 runs   (    0.35 ms per token,  2840.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.95 ms /    25 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   15446.42 ms /    23 runs   (  671.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16787.65 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    24 runs   (    0.36 ms per token,  2779.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.14 ms /    25 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   15571.49 ms /    23 runs   (  677.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16882.33 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    23 runs   (    0.35 ms per token,  2837.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.14 ms /    25 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   14842.83 ms /    22 runs   (  674.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16163.51 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    24 runs   (    0.35 ms per token,  2846.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.12 ms /    25 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   15505.47 ms /    23 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16847.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    23 runs   (    0.36 ms per token,  2790.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.92 ms /    25 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   14699.86 ms /    22 runs   (  668.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16018.03 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    24 runs   (    0.36 ms per token,  2779.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.19 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   15526.62 ms /    23 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16861.96 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    24 runs   (    0.35 ms per token,  2846.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.80 ms /    25 tokens (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   15493.69 ms /    23 runs   (  673.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16801.30 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    24 runs   (    0.35 ms per token,  2867.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.04 ms /    25 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   15446.65 ms /    23 runs   (  671.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16787.88 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    23 runs   (    0.35 ms per token,  2841.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.93 ms /    25 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14669.47 ms /    22 runs   (  666.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16001.08 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    23 runs   (    0.35 ms per token,  2853.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.80 ms /    25 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   14767.99 ms /    22 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16116.09 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2829.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.57 ms /    25 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   14900.25 ms /    22 runs   (  677.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16247.48 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    24 runs   (    0.36 ms per token,  2814.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.79 ms /    25 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15457.23 ms /    23 runs   (  672.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16784.90 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    24 runs   (    0.35 ms per token,  2832.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.25 ms /    24 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   15517.14 ms /    23 runs   (  674.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16789.76 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    23 runs   (    0.35 ms per token,  2872.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.16 ms /    25 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14729.26 ms /    22 runs   (  669.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16069.56 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    24 runs   (    0.35 ms per token,  2858.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.88 ms /    25 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   15412.62 ms /    23 runs   (  670.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16730.15 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    23 runs   (    0.35 ms per token,  2873.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.19 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14742.30 ms /    22 runs   (  670.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16074.06 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    24 runs   (    0.36 ms per token,  2797.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.23 ms /    24 tokens (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15514.07 ms /    23 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16772.22 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    24 runs   (    0.35 ms per token,  2852.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.14 ms /    25 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   15442.15 ms /    23 runs   (  671.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16767.67 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    24 runs   (    0.35 ms per token,  2822.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.88 ms /    25 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15492.74 ms /    23 runs   (  673.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16817.58 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    24 runs   (    0.36 ms per token,  2779.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.37 ms /    25 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   15431.69 ms /    23 runs   (  670.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16738.57 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    24 runs   (    0.34 ms per token,  2911.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.77 ms /    24 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   15360.08 ms /    23 runs   (  667.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16687.86 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    24 runs   (    0.35 ms per token,  2843.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.01 ms /    24 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   15437.95 ms /    23 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16707.92 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    23 runs   (    0.36 ms per token,  2780.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.36 ms /    25 tokens (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14838.03 ms /    22 runs   (  674.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16157.03 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    24 runs   (    0.35 ms per token,  2823.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.73 ms /    25 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   15646.57 ms /    23 runs   (  680.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16978.85 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.72 ms /    24 runs   (    0.36 ms per token,  2750.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.98 ms /    25 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   15421.54 ms /    23 runs   (  670.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16733.83 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    24 runs   (    0.35 ms per token,  2821.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.54 ms /    25 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15463.17 ms /    23 runs   (  672.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16787.51 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    24 runs   (    0.36 ms per token,  2776.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.47 ms /    25 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   15413.18 ms /    23 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16750.52 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    24 runs   (    0.36 ms per token,  2805.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.89 ms /    25 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15605.89 ms /    23 runs   (  678.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16924.31 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    23 runs   (    0.36 ms per token,  2808.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.59 ms /    25 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14750.39 ms /    22 runs   (  670.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16065.07 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2100th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    24 runs   (    0.36 ms per token,  2785.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.36 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   15243.05 ms /    23 runs   (  662.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16577.75 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    24 runs   (    0.36 ms per token,  2781.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.56 ms /    24 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   15542.27 ms /    23 runs   (  675.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16832.82 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2828.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.89 ms /    25 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14854.33 ms /    22 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16167.86 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.55 ms /    24 runs   (    0.36 ms per token,  2807.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.54 ms /    25 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   15610.45 ms /    23 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16936.03 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    23 runs   (    0.36 ms per token,  2746.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.87 ms /    25 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   14836.59 ms /    22 runs   (  674.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16146.32 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    23 runs   (    0.37 ms per token,  2734.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.27 ms /    25 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   15051.17 ms /    22 runs   (  684.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16353.63 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    23 runs   (    0.36 ms per token,  2780.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.37 ms /    25 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14822.10 ms /    22 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16136.79 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    24 runs   (    0.36 ms per token,  2804.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.38 ms /    25 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   15438.93 ms /    23 runs   (  671.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16759.26 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    23 runs   (    0.36 ms per token,  2751.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.49 ms /    25 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   14883.49 ms /    22 runs   (  676.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16199.73 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    24 runs   (    0.35 ms per token,  2828.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.55 ms /    24 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   15610.72 ms /    23 runs   (  678.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16882.68 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    23 runs   (    0.36 ms per token,  2770.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.69 ms /    23 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   14924.53 ms /    22 runs   (  678.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16177.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    24 runs   (    0.37 ms per token,  2692.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.88 ms /    23 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   15568.44 ms /    23 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16818.82 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    23 runs   (    0.36 ms per token,  2786.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.74 ms /    25 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   14977.70 ms /    22 runs   (  680.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16300.18 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    23 runs   (    0.36 ms per token,  2766.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.94 ms /    25 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   14811.00 ms /    22 runs   (  673.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16141.51 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    22 runs   (    0.35 ms per token,  2839.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.57 ms /    25 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   14135.10 ms /    21 runs   (  673.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15441.66 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    23 runs   (    0.36 ms per token,  2813.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.46 ms /    25 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   14779.36 ms /    22 runs   (  671.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16084.49 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    24 runs   (    0.37 ms per token,  2729.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.55 ms /    25 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   15558.60 ms /    23 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16870.39 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    23 runs   (    0.35 ms per token,  2823.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.83 ms /    25 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   14785.31 ms /    22 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16098.23 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    23 runs   (    0.36 ms per token,  2781.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.46 ms /    25 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14787.09 ms /    22 runs   (  672.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16139.08 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    23 runs   (    0.36 ms per token,  2792.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.30 ms /    25 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   14812.48 ms /    22 runs   (  673.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16181.47 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    24 runs   (    0.35 ms per token,  2831.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.52 ms /    25 tokens (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   15581.50 ms /    23 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16883.90 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    23 runs   (    0.35 ms per token,  2825.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.22 ms /    25 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   14861.45 ms /    22 runs   (  675.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16176.99 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    23 runs   (    0.35 ms per token,  2841.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.48 ms /    25 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14805.52 ms /    22 runs   (  672.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16123.91 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    24 runs   (    0.37 ms per token,  2682.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.18 ms /    25 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   15564.54 ms /    23 runs   (  676.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16885.77 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2828.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.50 ms /    25 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   14744.28 ms /    22 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16063.39 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    23 runs   (    0.36 ms per token,  2782.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.57 ms /    25 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   14885.76 ms /    22 runs   (  676.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16229.53 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    24 runs   (    0.37 ms per token,  2731.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.12 ms /    25 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15521.45 ms /    23 runs   (  674.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16836.97 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    23 runs   (    0.35 ms per token,  2856.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.15 ms /    25 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14860.39 ms /    22 runs   (  675.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16185.48 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    23 runs   (    0.35 ms per token,  2844.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.12 ms /    25 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14737.52 ms /    22 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16076.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    23 runs   (    0.36 ms per token,  2811.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.43 ms /    24 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14780.97 ms /    22 runs   (  671.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16059.83 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.55 ms /    24 runs   (    0.36 ms per token,  2805.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.78 ms /    25 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   15461.03 ms /    23 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16776.21 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    24 runs   (    0.37 ms per token,  2716.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.31 ms /    24 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   15394.43 ms /    23 runs   (  669.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16682.64 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    24 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.77 ms /    25 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15347.03 ms /    23 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16677.82 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    23 runs   (    0.37 ms per token,  2669.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.98 ms /    25 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   14722.67 ms /    22 runs   (  669.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16110.06 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    24 runs   (    0.35 ms per token,  2822.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.07 ms /    25 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   15321.22 ms /    23 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16632.75 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    23 runs   (    0.36 ms per token,  2766.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.40 ms /    25 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   14729.69 ms /    22 runs   (  669.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16068.09 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    23 runs   (    0.35 ms per token,  2822.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.33 ms /    24 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   14681.50 ms /    22 runs   (  667.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15989.05 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    23 runs   (    0.36 ms per token,  2761.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.39 ms /    25 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   14705.71 ms /    22 runs   (  668.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16027.36 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    23 runs   (    0.35 ms per token,  2843.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.68 ms /    25 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14758.00 ms /    22 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16076.68 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    23 runs   (    0.36 ms per token,  2763.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.26 ms /    25 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   14814.88 ms /    22 runs   (  673.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16134.77 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    22 runs   (    0.35 ms per token,  2894.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.13 ms /    23 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   14140.13 ms /    21 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15384.56 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    23 runs   (    0.36 ms per token,  2767.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.86 ms /    24 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   14836.93 ms /    22 runs   (  674.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16154.22 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    23 runs   (    0.37 ms per token,  2711.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.59 ms /    25 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   14710.57 ms /    22 runs   (  668.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16021.71 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    23 runs   (    0.36 ms per token,  2753.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.51 ms /    25 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14782.22 ms /    22 runs   (  671.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16105.74 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    22 runs   (    0.36 ms per token,  2804.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.93 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   14056.80 ms /    21 runs   (  669.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15359.16 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    23 runs   (    0.37 ms per token,  2678.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.78 ms /    25 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   14627.43 ms /    22 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15934.84 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    24 runs   (    0.36 ms per token,  2787.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.91 ms /    25 tokens (   57.48 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   15219.61 ms /    23 runs   (  661.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16714.94 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    23 runs   (    0.35 ms per token,  2871.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.82 ms /    24 tokens (   51.03 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14629.13 ms /    22 runs   (  664.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15909.49 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    23 runs   (    0.36 ms per token,  2763.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.80 ms /    25 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   14691.26 ms /    22 runs   (  667.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16021.88 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    24 runs   (    0.35 ms per token,  2819.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.69 ms /    25 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15340.44 ms /    23 runs   (  666.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16666.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    23 runs   (    0.35 ms per token,  2841.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.89 ms /    25 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14745.24 ms /    22 runs   (  670.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16080.10 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    23 runs   (    0.35 ms per token,  2826.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.71 ms /    25 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14732.06 ms /    22 runs   (  669.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16049.60 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    23 runs   (    0.36 ms per token,  2816.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.99 ms /    25 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14706.33 ms /    22 runs   (  668.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16041.29 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    23 runs   (    0.37 ms per token,  2718.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.02 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   14713.27 ms /    22 runs   (  668.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16019.90 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    24 runs   (    0.35 ms per token,  2818.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.87 ms /    25 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15485.20 ms /    23 runs   (  673.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16803.05 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    23 runs   (    0.36 ms per token,  2806.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.23 ms /    25 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14656.08 ms /    22 runs   (  666.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15978.47 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    24 runs   (    0.36 ms per token,  2779.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.52 ms /    25 tokens (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   15396.29 ms /    23 runs   (  669.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16707.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    24 runs   (    0.36 ms per token,  2784.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.49 ms /    25 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   15426.78 ms /    23 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16749.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    24 runs   (    0.36 ms per token,  2762.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.30 ms /    25 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   15398.73 ms /    23 runs   (  669.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16722.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    23 runs   (    0.36 ms per token,  2745.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.36 ms /    25 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   14695.18 ms /    22 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16038.16 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    24 runs   (    0.36 ms per token,  2809.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.43 ms /    25 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15476.56 ms /    23 runs   (  672.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16802.86 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    23 runs   (    0.35 ms per token,  2838.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.42 ms /    25 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   14657.46 ms /    22 runs   (  666.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15987.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2827.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.03 ms /    25 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   14726.67 ms /    22 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16054.75 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    23 runs   (    0.36 ms per token,  2772.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.34 ms /    25 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14695.35 ms /    22 runs   (  667.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16018.98 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    23 runs   (    0.35 ms per token,  2833.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.91 ms /    24 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   14844.17 ms /    22 runs   (  674.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16139.91 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    24 runs   (    0.37 ms per token,  2725.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.27 ms /    25 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   15507.24 ms /    23 runs   (  674.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16839.94 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    23 runs   (    0.36 ms per token,  2812.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.00 ms /    24 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   14947.71 ms /    22 runs   (  679.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16237.66 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    24 runs   (    0.37 ms per token,  2734.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.25 ms /    25 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   15517.14 ms /    23 runs   (  674.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16845.84 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    24 runs   (    0.36 ms per token,  2787.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.33 ms /    25 tokens (   51.77 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   15474.03 ms /    23 runs   (  672.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16826.79 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    23 runs   (    0.36 ms per token,  2760.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.41 ms /    25 tokens (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   14787.47 ms /    22 runs   (  672.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16094.91 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    23 runs   (    0.36 ms per token,  2778.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.98 ms /    25 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14809.23 ms /    22 runs   (  673.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16133.55 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    23 runs   (    0.36 ms per token,  2801.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.67 ms /    25 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14764.98 ms /    22 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16089.54 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    23 runs   (    0.35 ms per token,  2843.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.30 ms /    25 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   14842.31 ms /    22 runs   (  674.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16151.63 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    23 runs   (    0.36 ms per token,  2770.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.41 ms /    25 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14672.89 ms /    22 runs   (  666.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16006.56 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    22 runs   (    0.35 ms per token,  2842.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.79 ms /    25 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   13974.36 ms /    21 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15281.31 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    23 runs   (    0.35 ms per token,  2866.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.59 ms /    25 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   14917.70 ms /    22 runs   (  678.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16233.23 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    24 runs   (    0.36 ms per token,  2794.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.26 ms /    25 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   15516.59 ms /    23 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16852.15 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    23 runs   (    0.36 ms per token,  2743.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.51 ms /    25 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   14733.99 ms /    22 runs   (  669.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16075.92 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    23 runs   (    0.36 ms per token,  2740.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1203.11 ms /    24 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   14767.77 ms /    22 runs   (  671.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16027.81 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    24 runs   (    0.36 ms per token,  2767.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.42 ms /    25 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   15479.10 ms /    23 runs   (  673.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16817.76 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    23 runs   (    0.36 ms per token,  2759.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.53 ms /    25 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   14773.21 ms /    22 runs   (  671.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16084.03 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    24 runs   (    0.36 ms per token,  2801.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.43 ms /    25 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   15402.76 ms /    23 runs   (  669.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16735.69 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    23 runs   (    0.35 ms per token,  2821.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.22 ms /    25 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   14907.66 ms /    22 runs   (  677.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16251.78 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2827.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.87 ms /    25 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14750.22 ms /    22 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16074.19 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.88 ms /    24 runs   (    0.37 ms per token,  2702.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.65 ms /    25 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15268.06 ms /    23 runs   (  663.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16592.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    24 runs   (    0.35 ms per token,  2838.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.86 ms /    25 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   15275.46 ms /    23 runs   (  664.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16594.09 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    23 runs   (    0.35 ms per token,  2837.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.84 ms /    24 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   14584.32 ms /    22 runs   (  662.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15863.20 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    23 runs   (    0.36 ms per token,  2777.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.66 ms /    25 tokens (   50.19 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   14617.13 ms /    22 runs   (  664.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15927.57 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    24 runs   (    0.37 ms per token,  2677.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.24 ms /    25 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   15498.15 ms /    23 runs   (  673.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16813.05 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    23 runs   (    0.35 ms per token,  2817.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.12 ms /    25 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   14712.06 ms /    22 runs   (  668.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16073.75 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    18 runs   (    0.36 ms per token,  2800.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.02 ms /    25 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   11354.37 ms /    17 runs   (  667.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12681.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    23 runs   (    0.36 ms per token,  2790.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.51 ms /    25 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14685.28 ms /    22 runs   (  667.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16049.60 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    18 runs   (    0.36 ms per token,  2784.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.79 ms /    25 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11324.32 ms /    17 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12629.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2830.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.10 ms /    25 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14628.95 ms /    22 runs   (  664.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15942.36 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    24 runs   (    0.35 ms per token,  2829.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.15 ms /    25 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   15391.37 ms /    23 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16764.23 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2829.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.29 ms /    25 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   14691.98 ms /    22 runs   (  667.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15999.33 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.86 ms /    24 runs   (    0.37 ms per token,  2709.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.37 ms /    25 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   15559.25 ms /    23 runs   (  676.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16870.90 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    24 runs   (    0.37 ms per token,  2732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.49 ms /    25 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   15477.13 ms /    23 runs   (  672.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16792.69 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    24 runs   (    0.36 ms per token,  2809.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.04 ms /    24 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   15222.43 ms /    23 runs   (  661.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16590.59 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    23 runs   (    0.35 ms per token,  2877.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.20 ms /    25 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   14813.15 ms /    22 runs   (  673.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16152.67 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2200th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    24 runs   (    0.35 ms per token,  2834.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.30 ms /    26 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   15586.96 ms /    23 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16960.07 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    18 runs   (    0.37 ms per token,  2729.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.40 ms /    25 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11505.56 ms /    17 runs   (  676.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12817.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    33 runs   (    0.36 ms per token,  2777.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.63 ms /    25 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21378.05 ms /    32 runs   (  668.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22731.72 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    24 runs   (    0.35 ms per token,  2827.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.60 ms /    25 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   15439.76 ms /    23 runs   (  671.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16748.91 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    24 runs   (    0.36 ms per token,  2762.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.38 ms /    25 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   15468.15 ms /    23 runs   (  672.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16777.88 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    23 runs   (    0.36 ms per token,  2804.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.13 ms /    25 tokens (   53.21 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14687.34 ms /    22 runs   (  667.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16073.90 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    18 runs   (    0.35 ms per token,  2821.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.45 ms /    25 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   11348.28 ms /    17 runs   (  667.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12692.36 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    36 runs   (    0.37 ms per token,  2722.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.21 ms /    25 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   23449.61 ms /    35 runs   (  669.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24827.98 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    18 runs   (    0.36 ms per token,  2746.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.14 ms /    25 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11406.79 ms /    17 runs   (  670.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12699.84 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    23 runs   (    0.35 ms per token,  2831.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.58 ms /    25 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   14618.52 ms /    22 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15933.77 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    18 runs   (    0.37 ms per token,  2715.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.89 ms /    25 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11317.05 ms /    17 runs   (  665.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12626.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    24 runs   (    0.36 ms per token,  2815.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.06 ms /    25 tokens (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   15513.48 ms /    23 runs   (  674.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16826.01 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    24 runs   (    0.36 ms per token,  2811.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.07 ms /    25 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   15322.38 ms /    23 runs   (  666.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16645.91 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      15.72 ms /    42 runs   (    0.37 ms per token,  2671.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.53 ms /    25 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   27361.47 ms /    41 runs   (  667.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28719.05 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    33 runs   (    0.36 ms per token,  2777.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.67 ms /    25 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   21286.90 ms /    32 runs   (  665.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22636.15 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.80 ms /    33 runs   (    0.36 ms per token,  2795.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.63 ms /    25 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   21526.14 ms /    32 runs   (  672.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22866.52 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    23 runs   (    0.36 ms per token,  2749.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.43 ms /    25 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   14682.99 ms /    22 runs   (  667.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15999.31 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    24 runs   (    0.36 ms per token,  2798.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.27 ms /    25 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   15476.33 ms /    23 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16783.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    33 runs   (    0.37 ms per token,  2739.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.70 ms /    24 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   21349.28 ms /    32 runs   (  667.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22699.67 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    23 runs   (    0.36 ms per token,  2812.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.74 ms /    24 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14626.35 ms /    22 runs   (  664.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15915.89 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    18 runs   (    0.35 ms per token,  2834.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.07 ms /    25 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11407.56 ms /    17 runs   (  671.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12718.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    24 runs   (    0.36 ms per token,  2761.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.60 ms /    25 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   15475.48 ms /    23 runs   (  672.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16797.11 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    33 runs   (    0.36 ms per token,  2743.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.52 ms /    25 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   21438.12 ms /    32 runs   (  669.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22775.29 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    23 runs   (    0.35 ms per token,  2847.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.37 ms /    25 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   14790.16 ms /    22 runs   (  672.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16111.63 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    33 runs   (    0.37 ms per token,  2723.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.88 ms /    24 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   21669.87 ms /    32 runs   (  677.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22964.28 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    24 runs   (    0.35 ms per token,  2839.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.40 ms /    25 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   15268.01 ms /    23 runs   (  663.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16595.86 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    24 runs   (    0.36 ms per token,  2757.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.30 ms /    25 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   15236.26 ms /    23 runs   (  662.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16558.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    24 runs   (    0.36 ms per token,  2765.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.04 ms /    23 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   15281.21 ms /    23 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16495.44 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.60 ms /    32 runs   (    0.36 ms per token,  2758.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.08 ms /    25 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   20700.66 ms /    31 runs   (  667.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22034.69 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    23 runs   (    0.36 ms per token,  2812.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.24 ms /    25 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   14641.21 ms /    22 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15952.62 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    24 runs   (    0.35 ms per token,  2874.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.52 ms /    25 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15190.42 ms /    23 runs   (  660.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16503.24 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    24 runs   (    0.36 ms per token,  2810.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.14 ms /    25 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   15302.01 ms /    23 runs   (  665.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16620.85 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    18 runs   (    0.36 ms per token,  2791.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1307.04 ms /    25 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11325.46 ms /    17 runs   (  666.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12675.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    18 runs   (    0.36 ms per token,  2765.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.55 ms /    25 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11210.27 ms /    17 runs   (  659.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12507.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    23 runs   (    0.37 ms per token,  2720.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1247.50 ms /    25 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   14580.11 ms /    22 runs   (  662.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15883.73 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    24 runs   (    0.35 ms per token,  2818.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.96 ms /    25 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15390.94 ms /    23 runs   (  669.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16709.15 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    33 runs   (    0.36 ms per token,  2760.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.04 ms /    25 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   21337.55 ms /    32 runs   (  666.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22714.58 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    23 runs   (    0.35 ms per token,  2882.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.94 ms /    25 tokens (   49.84 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   14760.34 ms /    22 runs   (  670.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16061.86 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    33 runs   (    0.37 ms per token,  2738.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.43 ms /    25 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   21465.84 ms /    32 runs   (  670.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22796.99 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    24 runs   (    0.35 ms per token,  2832.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.21 ms /    25 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   15360.85 ms /    23 runs   (  667.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16680.21 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    23 runs   (    0.36 ms per token,  2805.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.16 ms /    25 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   14759.57 ms /    22 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16125.61 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    25 runs   (    0.36 ms per token,  2794.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.12 ms /    24 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   16087.57 ms /    24 runs   (  670.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17354.53 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    24 runs   (    0.35 ms per token,  2839.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.02 ms /    25 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   15395.12 ms /    23 runs   (  669.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16735.77 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    24 runs   (    0.36 ms per token,  2767.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.54 ms /    25 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   15472.69 ms /    23 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16794.38 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    24 runs   (    0.35 ms per token,  2818.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.42 ms /    25 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15499.40 ms /    23 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16813.02 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    24 runs   (    0.37 ms per token,  2716.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.86 ms /    25 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   15535.93 ms /    23 runs   (  675.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16847.24 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    24 runs   (    0.35 ms per token,  2857.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.57 ms /    25 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   15386.71 ms /    23 runs   (  668.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16707.01 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    23 runs   (    0.36 ms per token,  2795.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.67 ms /    25 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14971.30 ms /    22 runs   (  680.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16279.46 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      15.71 ms /    43 runs   (    0.37 ms per token,  2737.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.91 ms /    25 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   28509.47 ms /    42 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29888.58 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    18 runs   (    0.35 ms per token,  2823.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.60 ms /    25 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11255.78 ms /    17 runs   (  662.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12561.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    23 runs   (    0.36 ms per token,  2751.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.80 ms /    25 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14533.02 ms /    22 runs   (  660.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15872.48 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    23 runs   (    0.35 ms per token,  2844.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.47 ms /    25 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   14733.31 ms /    22 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16086.86 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      15.77 ms /    43 runs   (    0.37 ms per token,  2726.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.93 ms /    25 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   27995.62 ms /    42 runs   (  666.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29359.85 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    24 runs   (    0.36 ms per token,  2813.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.81 ms /    25 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15234.81 ms /    23 runs   (  662.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16565.01 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    24 runs   (    0.36 ms per token,  2801.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.38 ms /    25 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   15253.67 ms /    23 runs   (  663.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16565.99 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    24 runs   (    0.37 ms per token,  2728.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.97 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15380.48 ms /    23 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16688.44 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    33 runs   (    0.36 ms per token,  2750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.95 ms /    25 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   21310.70 ms /    32 runs   (  665.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22639.02 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.78 ms /    33 runs   (    0.36 ms per token,  2802.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.60 ms /    25 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   21141.32 ms /    32 runs   (  660.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22511.61 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    18 runs   (    0.36 ms per token,  2753.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.89 ms /    25 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11422.19 ms /    17 runs   (  671.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12730.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    24 runs   (    0.35 ms per token,  2856.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.52 ms /    25 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   15388.28 ms /    23 runs   (  669.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16695.90 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    29 runs   (    0.35 ms per token,  2839.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.19 ms /    25 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   18718.38 ms /    28 runs   (  668.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20042.45 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    23 runs   (    0.36 ms per token,  2805.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.84 ms /    25 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   14859.35 ms /    22 runs   (  675.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16172.38 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    24 runs   (    0.37 ms per token,  2739.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1460.64 ms /    25 tokens (   58.43 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:        eval time =   15442.32 ms /    23 runs   (  671.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16962.15 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      15.22 ms /    42 runs   (    0.36 ms per token,  2758.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.66 ms /    25 tokens (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   27878.58 ms /    41 runs   (  679.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29232.17 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    18 runs   (    0.37 ms per token,  2730.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.21 ms /    24 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11581.79 ms /    17 runs   (  681.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12834.22 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    33 runs   (    0.36 ms per token,  2768.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.42 ms /    25 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   21655.42 ms /    32 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23000.96 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    33 runs   (    0.36 ms per token,  2777.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.06 ms /    25 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   21600.24 ms /    32 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22943.62 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    23 runs   (    0.35 ms per token,  2819.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.60 ms /    25 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14821.51 ms /    22 runs   (  673.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16156.09 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    33 runs   (    0.35 ms per token,  2826.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.44 ms /    25 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   21562.22 ms /    32 runs   (  673.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22911.15 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    18 runs   (    0.36 ms per token,  2798.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.62 ms /    25 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11528.02 ms /    17 runs   (  678.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12822.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      15.30 ms /    42 runs   (    0.36 ms per token,  2744.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.68 ms /    24 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   27657.97 ms /    41 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28967.81 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    24 runs   (    0.36 ms per token,  2799.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.37 ms /    25 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   15292.54 ms /    23 runs   (  664.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16607.50 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    18 runs   (    0.36 ms per token,  2793.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.71 ms /    25 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11429.47 ms /    17 runs   (  672.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12764.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    18 runs   (    0.37 ms per token,  2723.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.74 ms /    25 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11442.07 ms /    17 runs   (  673.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12741.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    24 runs   (    0.36 ms per token,  2808.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.09 ms /    25 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15441.03 ms /    23 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16759.45 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    23 runs   (    0.36 ms per token,  2813.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.18 ms /    25 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   14856.39 ms /    22 runs   (  675.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16185.98 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    33 runs   (    0.36 ms per token,  2783.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.27 ms /    25 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   21306.42 ms /    32 runs   (  665.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22666.43 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    23 runs   (    0.35 ms per token,  2877.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.92 ms /    25 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14804.91 ms /    22 runs   (  672.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16140.06 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    24 runs   (    0.36 ms per token,  2797.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.58 ms /    25 tokens (   55.42 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   15414.93 ms /    23 runs   (  670.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16859.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.55 ms /    24 runs   (    0.36 ms per token,  2807.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.94 ms /    25 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   15409.99 ms /    23 runs   (  670.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16763.43 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    23 runs   (    0.36 ms per token,  2754.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.41 ms /    25 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14687.94 ms /    22 runs   (  667.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16009.56 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      15.64 ms /    43 runs   (    0.36 ms per token,  2749.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.37 ms /    25 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   28346.08 ms /    42 runs   (  674.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29738.63 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    18 runs   (    0.36 ms per token,  2761.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.17 ms /    25 tokens (   50.29 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   11384.38 ms /    17 runs   (  669.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12684.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    24 runs   (    0.36 ms per token,  2791.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.26 ms /    25 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   15578.85 ms /    23 runs   (  677.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16922.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    34 runs   (    0.36 ms per token,  2762.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.37 ms /    25 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   22340.31 ms /    33 runs   (  676.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23680.82 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    18 runs   (    0.36 ms per token,  2740.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.74 ms /    24 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11458.10 ms /    17 runs   (  674.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12719.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    18 runs   (    0.36 ms per token,  2787.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1222.54 ms /    24 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11484.55 ms /    17 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12750.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    24 runs   (    0.35 ms per token,  2819.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.58 ms /    25 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   15530.28 ms /    23 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16877.89 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    18 runs   (    0.36 ms per token,  2798.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.99 ms /    25 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11456.45 ms /    17 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12762.90 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    18 runs   (    0.35 ms per token,  2849.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.80 ms /    25 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11447.10 ms /    17 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12744.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    37 runs   (    0.36 ms per token,  2758.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.21 ms /    25 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   24300.81 ms /    36 runs   (  675.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25653.61 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    33 runs   (    0.36 ms per token,  2788.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.81 ms /    25 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   21524.90 ms /    32 runs   (  672.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22888.08 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    24 runs   (    0.35 ms per token,  2841.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.21 ms /    25 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15444.61 ms /    23 runs   (  671.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16763.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    24 runs   (    0.36 ms per token,  2801.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.56 ms /    25 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   15328.89 ms /    23 runs   (  666.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16701.39 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    33 runs   (    0.36 ms per token,  2767.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.24 ms /    24 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   21552.57 ms /    32 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22872.66 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    24 runs   (    0.36 ms per token,  2780.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.44 ms /    25 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   15450.93 ms /    23 runs   (  671.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16775.93 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    24 runs   (    0.35 ms per token,  2861.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.62 ms /    25 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   15350.80 ms /    23 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16686.06 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    33 runs   (    0.37 ms per token,  2668.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.23 ms /    25 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   21563.49 ms /    32 runs   (  673.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22903.02 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    33 runs   (    0.35 ms per token,  2827.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.94 ms /    24 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   21575.85 ms /    32 runs   (  674.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22864.27 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    24 runs   (    0.36 ms per token,  2810.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.08 ms /    25 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15479.67 ms /    23 runs   (  673.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16787.58 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2300th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    25 runs   (    0.35 ms per token,  2844.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.11 ms /    25 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   16170.29 ms /    24 runs   (  673.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17513.62 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.55 ms /    24 runs   (    0.36 ms per token,  2806.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.16 ms /    25 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   15446.44 ms /    23 runs   (  671.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16769.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    24 runs   (    0.34 ms per token,  2909.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.57 ms /    25 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   15353.30 ms /    23 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16685.97 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    25 runs   (    0.35 ms per token,  2865.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.41 ms /    25 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   16184.02 ms /    24 runs   (  674.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17528.73 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    25 runs   (    0.36 ms per token,  2807.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.57 ms /    25 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15954.25 ms /    24 runs   (  664.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17274.13 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    25 runs   (    0.35 ms per token,  2829.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.46 ms /    25 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   15976.84 ms /    24 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17328.86 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    23 runs   (    0.35 ms per token,  2873.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.37 ms /    25 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   14592.22 ms /    22 runs   (  663.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15896.65 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    24 runs   (    0.35 ms per token,  2853.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.09 ms /    25 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   15495.70 ms /    23 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16833.42 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    25 runs   (    0.36 ms per token,  2792.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1300.83 ms /    25 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   16207.12 ms /    24 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17569.23 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    22 runs   (    0.35 ms per token,  2833.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.82 ms /    25 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14004.39 ms /    21 runs   (  666.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15367.26 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    24 runs   (    0.35 ms per token,  2858.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.90 ms /    25 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   15457.76 ms /    23 runs   (  672.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16790.50 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    24 runs   (    0.36 ms per token,  2786.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.24 ms /    25 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   15573.15 ms /    23 runs   (  677.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16896.93 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    25 runs   (    0.35 ms per token,  2831.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.93 ms /    24 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   16103.25 ms /    24 runs   (  670.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17385.57 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    25 runs   (    0.36 ms per token,  2803.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1227.60 ms /    24 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   16034.86 ms /    24 runs   (  668.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17324.44 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    25 runs   (    0.35 ms per token,  2870.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.13 ms /    25 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   16060.17 ms /    24 runs   (  669.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17406.14 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    19 runs   (    0.37 ms per token,  2729.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.76 ms /    25 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12010.79 ms /    18 runs   (  667.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13349.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    23 runs   (    0.35 ms per token,  2832.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.07 ms /    25 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   14702.63 ms /    22 runs   (  668.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16039.20 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    24 runs   (    0.36 ms per token,  2814.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.21 ms /    25 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   15372.41 ms /    23 runs   (  668.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16705.16 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    25 runs   (    0.35 ms per token,  2841.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.02 ms /    25 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   16079.54 ms /    24 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17409.44 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    25 runs   (    0.36 ms per token,  2789.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.42 ms /    25 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   16008.83 ms /    24 runs   (  667.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17335.18 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    18 runs   (    0.37 ms per token,  2723.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.48 ms /    25 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11384.97 ms /    17 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12724.38 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    24 runs   (    0.36 ms per token,  2786.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.60 ms /    25 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   15557.62 ms /    23 runs   (  676.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16873.74 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    25 runs   (    0.36 ms per token,  2809.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.24 ms /    25 tokens (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_print_timings:        eval time =   15995.73 ms /    24 runs   (  666.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17307.65 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    23 runs   (    0.36 ms per token,  2771.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.71 ms /    25 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14617.03 ms /    22 runs   (  664.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15949.80 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    24 runs   (    0.35 ms per token,  2827.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.82 ms /    25 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   15357.09 ms /    23 runs   (  667.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16682.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.75 ms /    25 runs   (    0.35 ms per token,  2858.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.50 ms /    24 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   16063.77 ms /    24 runs   (  669.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17379.04 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    27 runs   (    0.35 ms per token,  2848.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.07 ms /    24 tokens (   50.09 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   17389.37 ms /    26 runs   (  668.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18656.72 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    25 runs   (    0.35 ms per token,  2868.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.93 ms /    25 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   15993.96 ms /    24 runs   (  666.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17336.21 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.91 ms /    25 runs   (    0.36 ms per token,  2806.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.67 ms /    25 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15943.75 ms /    24 runs   (  664.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17272.30 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    24 runs   (    0.35 ms per token,  2828.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.04 ms /    25 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   15350.98 ms /    23 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16695.12 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.74 ms /    25 runs   (    0.35 ms per token,  2861.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.81 ms /    25 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15991.17 ms /    24 runs   (  666.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17307.81 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    24 runs   (    0.36 ms per token,  2792.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.99 ms /    25 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15291.41 ms /    23 runs   (  664.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16609.65 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    24 runs   (    0.35 ms per token,  2883.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.26 ms /    25 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   15343.06 ms /    23 runs   (  667.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16657.42 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    25 runs   (    0.36 ms per token,  2766.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.53 ms /    25 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15994.08 ms /    24 runs   (  666.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17321.68 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    25 runs   (    0.36 ms per token,  2811.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.97 ms /    25 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15888.56 ms /    24 runs   (  662.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17216.58 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    24 runs   (    0.36 ms per token,  2798.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.22 ms /    23 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   15309.69 ms /    23 runs   (  665.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16542.91 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    23 runs   (    0.35 ms per token,  2862.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1219.57 ms /    24 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   14644.74 ms /    22 runs   (  665.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15919.42 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    24 runs   (    0.35 ms per token,  2839.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.42 ms /    25 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   15390.84 ms /    23 runs   (  669.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16745.52 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    24 runs   (    0.35 ms per token,  2837.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.15 ms /    25 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15311.32 ms /    23 runs   (  665.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16627.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    25 runs   (    0.35 ms per token,  2826.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.03 ms /    24 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   15921.54 ms /    24 runs   (  663.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17223.31 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    24 runs   (    0.36 ms per token,  2803.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.34 ms /    25 tokens (   50.21 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15356.17 ms /    23 runs   (  667.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16669.55 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    24 runs   (    0.35 ms per token,  2871.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.98 ms /    25 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   15361.57 ms /    23 runs   (  667.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16697.80 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    24 runs   (    0.35 ms per token,  2841.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.03 ms /    25 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15375.91 ms /    23 runs   (  668.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16701.82 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    25 runs   (    0.35 ms per token,  2831.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.17 ms /    25 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15958.40 ms /    24 runs   (  664.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17276.39 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    24 runs   (    0.35 ms per token,  2821.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.48 ms /    25 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   15298.72 ms /    23 runs   (  665.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16629.18 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    18 runs   (    0.35 ms per token,  2820.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.86 ms /    24 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11351.65 ms /    17 runs   (  667.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12624.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    25 runs   (    0.35 ms per token,  2884.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.36 ms /    23 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   16077.44 ms /    24 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17303.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    24 runs   (    0.35 ms per token,  2859.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.58 ms /    25 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   15361.40 ms /    23 runs   (  667.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16683.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    24 runs   (    0.35 ms per token,  2838.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.94 ms /    24 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   15244.63 ms /    23 runs   (  662.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16531.22 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    24 runs   (    0.35 ms per token,  2818.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.16 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   15215.72 ms /    23 runs   (  661.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16549.26 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    25 runs   (    0.36 ms per token,  2767.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.67 ms /    25 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   15982.71 ms /    24 runs   (  665.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17315.67 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    25 runs   (    0.34 ms per token,  2898.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.05 ms /    25 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   15931.19 ms /    24 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17270.06 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    25 runs   (    0.35 ms per token,  2862.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.62 ms /    25 tokens (   50.26 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15955.59 ms /    24 runs   (  664.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17272.23 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.72 ms /    25 runs   (    0.35 ms per token,  2865.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.76 ms /    25 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   15934.67 ms /    24 runs   (  663.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17265.23 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    24 runs   (    0.36 ms per token,  2759.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.49 ms /    25 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   15368.43 ms /    23 runs   (  668.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16691.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    24 runs   (    0.36 ms per token,  2813.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.41 ms /    25 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15276.40 ms /    23 runs   (  664.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16603.20 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    24 runs   (    0.35 ms per token,  2877.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.21 ms /    25 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   15408.78 ms /    23 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16751.63 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    24 runs   (    0.35 ms per token,  2842.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.23 ms /    25 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   15362.75 ms /    23 runs   (  667.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16696.73 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    24 runs   (    0.36 ms per token,  2802.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.83 ms /    24 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15351.98 ms /    23 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16617.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    25 runs   (    0.35 ms per token,  2884.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.22 ms /    25 tokens (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   16001.80 ms /    24 runs   (  666.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17326.11 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    24 runs   (    0.35 ms per token,  2857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.85 ms /    25 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   15398.57 ms /    23 runs   (  669.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16720.80 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    24 runs   (    0.35 ms per token,  2854.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1280.56 ms /    25 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   15298.94 ms /    23 runs   (  665.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16637.77 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.67 ms /    27 runs   (    0.36 ms per token,  2791.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.81 ms /    25 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   17178.67 ms /    26 runs   (  660.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18523.51 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    23 runs   (    0.35 ms per token,  2829.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.09 ms /    25 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   14672.77 ms /    22 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15980.29 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    25 runs   (    0.36 ms per token,  2812.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.67 ms /    25 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   16023.89 ms /    24 runs   (  667.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17369.72 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    25 runs   (    0.35 ms per token,  2848.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.60 ms /    24 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   15994.25 ms /    24 runs   (  666.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17281.49 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    24 runs   (    0.35 ms per token,  2894.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.43 ms /    25 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   15320.82 ms /    23 runs   (  666.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16645.86 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    24 runs   (    0.35 ms per token,  2827.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.06 ms /    25 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   15459.26 ms /    23 runs   (  672.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16789.05 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    25 runs   (    0.36 ms per token,  2809.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.98 ms /    25 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   16071.50 ms /    24 runs   (  669.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17401.83 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    23 runs   (    0.36 ms per token,  2754.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.75 ms /    25 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14881.34 ms /    22 runs   (  676.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16196.61 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    27 runs   (    0.35 ms per token,  2872.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.92 ms /    25 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   17257.28 ms /    26 runs   (  663.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18588.01 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    24 runs   (    0.35 ms per token,  2825.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.02 ms /    25 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   15366.32 ms /    23 runs   (  668.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16724.54 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    24 runs   (    0.36 ms per token,  2803.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.55 ms /    25 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   15492.23 ms /    23 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16832.69 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    25 runs   (    0.35 ms per token,  2841.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.84 ms /    25 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   15947.40 ms /    24 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17281.99 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    24 runs   (    0.36 ms per token,  2809.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.85 ms /    25 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15261.10 ms /    23 runs   (  663.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16569.77 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    24 runs   (    0.35 ms per token,  2819.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.33 ms /    25 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   15377.98 ms /    23 runs   (  668.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16709.89 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    24 runs   (    0.35 ms per token,  2834.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.35 ms /    24 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15395.80 ms /    23 runs   (  669.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16663.04 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    27 runs   (    0.36 ms per token,  2811.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.83 ms /    25 tokens (   50.11 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   17444.95 ms /    26 runs   (  670.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18762.65 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    18 runs   (    0.36 ms per token,  2762.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.91 ms /    25 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11401.11 ms /    17 runs   (  670.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12708.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    25 runs   (    0.35 ms per token,  2847.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.44 ms /    25 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   16266.49 ms /    24 runs   (  677.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17603.67 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    25 runs   (    0.36 ms per token,  2795.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1329.62 ms /    25 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   16210.88 ms /    24 runs   (  675.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17601.55 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    24 runs   (    0.36 ms per token,  2786.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.33 ms /    24 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15540.07 ms /    23 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16815.98 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    24 runs   (    0.35 ms per token,  2851.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.15 ms /    25 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   15372.30 ms /    23 runs   (  668.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16699.12 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    24 runs   (    0.35 ms per token,  2853.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1260.53 ms /    25 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   15483.90 ms /    23 runs   (  673.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16802.39 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    24 runs   (    0.35 ms per token,  2845.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.60 ms /    25 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   15300.09 ms /    23 runs   (  665.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16639.47 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    24 runs   (    0.36 ms per token,  2789.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.52 ms /    25 tokens (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   15370.42 ms /    23 runs   (  668.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16673.77 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    24 runs   (    0.36 ms per token,  2804.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.32 ms /    25 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   15432.00 ms /    23 runs   (  670.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16747.62 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    24 runs   (    0.37 ms per token,  2736.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1252.89 ms /    25 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   15388.58 ms /    23 runs   (  669.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16700.09 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    18 runs   (    0.36 ms per token,  2807.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1246.40 ms /    24 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   10997.93 ms /    17 runs   (  646.94 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12287.76 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    25 runs   (    0.36 ms per token,  2791.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.92 ms /    25 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   15598.94 ms /    24 runs   (  649.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   16922.50 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.86 ms /    25 runs   (    0.35 ms per token,  2820.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.82 ms /    25 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   16031.06 ms /    24 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17356.56 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    25 runs   (    0.35 ms per token,  2835.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.91 ms /    25 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   16153.48 ms /    24 runs   (  673.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17504.77 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    24 runs   (    0.35 ms per token,  2879.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.53 ms /    25 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   15531.00 ms /    23 runs   (  675.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16873.66 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    25 runs   (    0.35 ms per token,  2846.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.73 ms /    25 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   16195.35 ms /    24 runs   (  674.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17521.43 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    24 runs   (    0.35 ms per token,  2866.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.05 ms /    25 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15408.20 ms /    23 runs   (  669.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16724.22 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    24 runs   (    0.36 ms per token,  2803.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.38 ms /    25 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   15558.49 ms /    23 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16870.73 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.75 ms /    25 runs   (    0.35 ms per token,  2856.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.79 ms /    25 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   16179.60 ms /    24 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17511.12 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    24 runs   (    0.35 ms per token,  2827.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.72 ms /    25 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   15442.97 ms /    23 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16767.98 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    24 runs   (    0.36 ms per token,  2748.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.40 ms /    25 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   15445.28 ms /    23 runs   (  671.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16782.23 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.57 ms /    24 runs   (    0.40 ms per token,  2508.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.82 ms /    24 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15417.79 ms /    23 runs   (  670.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16689.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2400th element\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    26 runs   (    0.35 ms per token,  2872.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.06 ms /    28 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   16834.42 ms /    25 runs   (  673.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18282.68 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    26 runs   (    0.35 ms per token,  2860.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.51 ms /    27 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   16593.36 ms /    25 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18005.61 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    27 runs   (    0.36 ms per token,  2794.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.27 ms /    27 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   16968.44 ms /    26 runs   (  652.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   18376.99 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.81 ms /    27 runs   (    0.36 ms per token,  2751.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.40 ms /    27 tokens (   50.16 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   17309.03 ms /    26 runs   (  665.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18729.64 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    27 runs   (    0.35 ms per token,  2870.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.78 ms /    27 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:        eval time =   17457.09 ms /    26 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18863.15 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    26 runs   (    0.36 ms per token,  2812.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.58 ms /    27 tokens (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_print_timings:        eval time =   16696.82 ms /    25 runs   (  667.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18097.97 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.77 ms /    27 runs   (    0.36 ms per token,  2763.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.37 ms /    27 tokens (   49.64 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   17356.03 ms /    26 runs   (  667.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18762.44 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    27 runs   (    0.35 ms per token,  2872.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.63 ms /    27 tokens (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_print_timings:        eval time =   17506.93 ms /    26 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18907.07 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    26 runs   (    0.36 ms per token,  2789.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.91 ms /    25 tokens (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   16324.45 ms /    25 runs   (  652.98 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17638.28 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    26 runs   (    0.35 ms per token,  2872.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.55 ms /    26 tokens (   50.21 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   16667.94 ms /    25 runs   (  666.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18036.76 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.33 ms /    27 runs   (    0.35 ms per token,  2892.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1340.77 ms /    27 tokens (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:        eval time =   17347.32 ms /    26 runs   (  667.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18753.42 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    26 runs   (    0.35 ms per token,  2845.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.09 ms /    26 tokens (   57.39 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =   16622.74 ms /    25 runs   (  664.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18177.56 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    26 runs   (    0.34 ms per token,  2920.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.29 ms /    27 tokens (   49.42 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:        eval time =   16757.56 ms /    25 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18154.88 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    26 runs   (    0.35 ms per token,  2867.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1363.45 ms /    27 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   16828.45 ms /    25 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18255.05 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.25 ms /    27 runs   (    0.38 ms per token,  2633.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.50 ms /    27 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   18153.10 ms /    26 runs   (  698.20 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   19584.17 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    26 runs   (    0.35 ms per token,  2856.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2023.20 ms /    27 tokens (   74.93 ms per token,    13.35 tokens per second)\n",
      "llama_print_timings:        eval time =   16965.76 ms /    25 runs   (  678.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19053.73 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    26 runs   (    0.36 ms per token,  2760.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.19 ms /    27 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   17184.30 ms /    25 runs   (  687.37 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   18669.28 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.82 ms /    27 runs   (    0.36 ms per token,  2750.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1505.89 ms /    27 tokens (   55.77 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   17629.26 ms /    26 runs   (  678.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19207.47 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    27 runs   (    0.36 ms per token,  2760.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.35 ms /    26 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   17430.36 ms /    26 runs   (  670.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18829.33 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    27 runs   (    0.38 ms per token,  2659.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1360.33 ms /    27 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   17679.19 ms /    26 runs   (  679.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19108.10 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4574.21 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    26 runs   (    0.35 ms per token,  2819.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.05 ms /    27 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   16855.42 ms /    25 runs   (  674.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18288.92 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "#time sleep to avoid rate limit\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if i%100==0:\n",
    "      print(f'processing {i}th element')\n",
    "    try:\n",
    "\n",
    "\n",
    "        prompt = f\"{data[i][0]} + {data[i][1]} ?\"\n",
    "        prompt_template=f'''SYSTEM: You are a math assistant. I will ask you some addition questions. For example, if I ask 'What is 2 + 3?', you should answer '2 + 3 = 5'. Each question is in a separate line. Please return each answer in a separate line.\n",
    "        USER: {prompt}\n",
    "\n",
    "        ASSISTANT:\n",
    "        '''\n",
    "\n",
    "        response=lcpp_llm(prompt=prompt_template, max_tokens=100, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)\n",
    "        #for each response extract the answer and write it to a file\n",
    "        with open('int_addition.txt', 'a') as f:\n",
    "            answer = response[\"choices\"][0][\"text\"]\n",
    "            \n",
    "            f.write(f'{data[i]} = {answer}\\n')\n",
    "    except:\n",
    "        print('rate limit reached. Sleeping for 2 minutes')\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viveksdmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
