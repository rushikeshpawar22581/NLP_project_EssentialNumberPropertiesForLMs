{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required libraries\n",
    "# %pip install transformers\n",
    "# %pip install torchtext\n",
    "# %pip install sentencepiece\n",
    "# %pip install datasets\n",
    "# %pip install torchmetrics\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# #huggiface download\n",
    "# %pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/viveksdmlenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the model llama 2 7b\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is in bin format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viveksd/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "#print toal path\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/root/.cache': Permission denied\n"
     ]
    }
   ],
   "source": [
    "#do ls for viveksd/.cache\n",
    "!ls /root/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /home/viveksd/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.36 GiB (5.51 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  8555.93 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   400.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    85.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '16'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"1000 + -2300?\"\n",
    "prompt_template=f'''SYSTEM: You are a math assistant. I will ask you some addition questions. For example, if I ask 'What is 2 + 3?', you should answer '2 + 3 = 5'. Each question is in a separate line. Please return each answer in a separate line.\n",
    "        USER: {prompt}\n",
    "\n",
    "        ASSISTANT:\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt= f\"Find the maximum number in the list [2, 0, -4, 5, 8]\"\n",
    "\n",
    "prompt_template=f'''SYSTEM: You are a math assistant.I will ask you to find the minimum number in a list. Please answer in the correct format. For example, if I ask 'Find the maximum number in the list [1, 2, 3]', you should answer 'Max([1, 2, 3]) = 3'\n",
    "\n",
    "        USER: {prompt}\n",
    "        \n",
    "        ASSISTANT:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    20 runs   (    0.35 ms per token,  2823.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5396.91 ms /   110 tokens (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_print_timings:        eval time =   13022.63 ms /    19 runs   (  685.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18465.44 ms /   129 tokens\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Max([2, 0, -4, 5, 8]) = 8\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file in data folder int_addition.json\n",
    "with open('lists.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len iof data\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_437656/812915592.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lists_size_3_pos</th>\n",
       "      <th>lists_size_5_pos</th>\n",
       "      <th>lists_size_10_pos</th>\n",
       "      <th>lists_size_3_neg</th>\n",
       "      <th>lists_size_5_neg</th>\n",
       "      <th>lists_size_10_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[27222, 90204, 63001]</td>\n",
       "      <td>[27222, 90204, 63001, 43332, 30737]</td>\n",
       "      <td>[27222, 90204, 63001, 43332, 30737, 358, 1671,...</td>\n",
       "      <td>[-27222, 90204, -63001]</td>\n",
       "      <td>[-27222, -90204, -63001, 43332, 30737]</td>\n",
       "      <td>[-27222, -90204, -63001, 43332, -30737, 358, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>[75255, 87690, 64763]</td>\n",
       "      <td>[75255, 87690, 64763, 19548, 11807]</td>\n",
       "      <td>[75255, 87690, 64763, 19548, 11807, 67070, 983...</td>\n",
       "      <td>[-75255, 87690, 64763]</td>\n",
       "      <td>[-75255, 87690, 64763, 19548, -11807]</td>\n",
       "      <td>[75255, -87690, -64763, 19548, -11807, 67070, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[33540, 84454, 30298]</td>\n",
       "      <td>[33540, 84454, 30298, 59867, 38800]</td>\n",
       "      <td>[33540, 84454, 30298, 59867, 38800, 34619, 608...</td>\n",
       "      <td>[-33540, -84454, 30298]</td>\n",
       "      <td>[-33540, -84454, 30298, 59867, 38800]</td>\n",
       "      <td>[33540, -84454, 30298, -59867, -38800, -34619,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[5170, 38085, 47214]</td>\n",
       "      <td>[5170, 38085, 47214, 88705, 40987]</td>\n",
       "      <td>[5170, 38085, 47214, 88705, 40987, 55836, 9680...</td>\n",
       "      <td>[5170, -38085, 47214]</td>\n",
       "      <td>[-5170, -38085, 47214, -88705, -40987]</td>\n",
       "      <td>[-5170, -38085, -47214, 88705, -40987, 55836, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[6014, 1267, 18139]</td>\n",
       "      <td>[6014, 1267, 18139, 86947, 84829]</td>\n",
       "      <td>[6014, 1267, 18139, 86947, 84829, 22349, 43078...</td>\n",
       "      <td>[-6014, -1267, -18139]</td>\n",
       "      <td>[-6014, 1267, -18139, -86947, 84829]</td>\n",
       "      <td>[6014, -1267, -18139, -86947, 84829, -22349, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lists_size_3_pos                     lists_size_5_pos  \\\n",
       "495  [27222, 90204, 63001]  [27222, 90204, 63001, 43332, 30737]   \n",
       "496  [75255, 87690, 64763]  [75255, 87690, 64763, 19548, 11807]   \n",
       "497  [33540, 84454, 30298]  [33540, 84454, 30298, 59867, 38800]   \n",
       "498   [5170, 38085, 47214]   [5170, 38085, 47214, 88705, 40987]   \n",
       "499    [6014, 1267, 18139]    [6014, 1267, 18139, 86947, 84829]   \n",
       "\n",
       "                                     lists_size_10_pos  \\\n",
       "495  [27222, 90204, 63001, 43332, 30737, 358, 1671,...   \n",
       "496  [75255, 87690, 64763, 19548, 11807, 67070, 983...   \n",
       "497  [33540, 84454, 30298, 59867, 38800, 34619, 608...   \n",
       "498  [5170, 38085, 47214, 88705, 40987, 55836, 9680...   \n",
       "499  [6014, 1267, 18139, 86947, 84829, 22349, 43078...   \n",
       "\n",
       "            lists_size_3_neg                        lists_size_5_neg  \\\n",
       "495  [-27222, 90204, -63001]  [-27222, -90204, -63001, 43332, 30737]   \n",
       "496   [-75255, 87690, 64763]   [-75255, 87690, 64763, 19548, -11807]   \n",
       "497  [-33540, -84454, 30298]   [-33540, -84454, 30298, 59867, 38800]   \n",
       "498    [5170, -38085, 47214]  [-5170, -38085, 47214, -88705, -40987]   \n",
       "499   [-6014, -1267, -18139]    [-6014, 1267, -18139, -86947, 84829]   \n",
       "\n",
       "                                     lists_size_10_neg  \n",
       "495  [-27222, -90204, -63001, 43332, -30737, 358, -...  \n",
       "496  [75255, -87690, -64763, 19548, -11807, 67070, ...  \n",
       "497  [33540, -84454, 30298, -59867, -38800, -34619,...  \n",
       "498  [-5170, -38085, -47214, 88705, -40987, 55836, ...  \n",
       "499  [6014, -1267, -18139, -86947, 84829, -22349, -...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data as pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "#last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len of df\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    20 runs   (    0.36 ms per token,  2792.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3376.82 ms /    67 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12850.32 ms /    19 runs   (  676.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16272.36 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    21 runs   (    0.36 ms per token,  2740.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.69 ms /    22 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13697.03 ms /    20 runs   (  684.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14856.80 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    21 runs   (    0.36 ms per token,  2791.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.75 ms /    21 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   13625.41 ms /    20 runs   (  681.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14744.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    21 runs   (    0.35 ms per token,  2822.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.68 ms /    21 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   13579.42 ms /    20 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14690.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    20 runs   (    0.37 ms per token,  2731.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.96 ms /    22 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =   12846.64 ms /    19 runs   (  676.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13999.55 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    21 runs   (    0.36 ms per token,  2747.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.95 ms /    22 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   13632.61 ms /    20 runs   (  681.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14813.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    20 runs   (    0.37 ms per token,  2722.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.28 ms /    22 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12740.93 ms /    19 runs   (  670.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13940.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    20 runs   (    0.36 ms per token,  2754.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.65 ms /    21 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13058.60 ms /    19 runs   (  687.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14188.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    20 runs   (    0.36 ms per token,  2753.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.91 ms /    21 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   13058.00 ms /    19 runs   (  687.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14168.02 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    20 runs   (    0.36 ms per token,  2802.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.54 ms /    22 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12880.83 ms /    19 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14054.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    20 runs   (    0.36 ms per token,  2787.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.95 ms /    22 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12865.11 ms /    19 runs   (  677.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14020.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    20 runs   (    0.36 ms per token,  2778.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.91 ms /    21 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12866.87 ms /    19 runs   (  677.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13989.79 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    21 runs   (    0.37 ms per token,  2698.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.04 ms /    22 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   13631.01 ms /    20 runs   (  681.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14831.35 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    21 runs   (    0.36 ms per token,  2805.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.54 ms /    21 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   13513.31 ms /    20 runs   (  675.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14630.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    20 runs   (    0.35 ms per token,  2826.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.17 ms /    19 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12841.96 ms /    19 runs   (  675.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13864.31 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    20 runs   (    0.36 ms per token,  2747.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.89 ms /    22 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12770.96 ms /    19 runs   (  672.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13937.58 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    21 runs   (    0.37 ms per token,  2718.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.21 ms /    22 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13515.41 ms /    20 runs   (  675.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14688.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    20 runs   (    0.36 ms per token,  2798.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.89 ms /    22 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12822.93 ms /    19 runs   (  674.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13990.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    20 runs   (    0.36 ms per token,  2769.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.50 ms /    21 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12988.24 ms /    19 runs   (  683.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14114.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    20 runs   (    0.36 ms per token,  2796.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.27 ms /    21 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12930.44 ms /    19 runs   (  680.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14043.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    21 runs   (    0.36 ms per token,  2813.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.45 ms /    22 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13636.93 ms /    20 runs   (  681.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14828.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    21 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.05 ms /    21 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   13611.52 ms /    20 runs   (  680.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14743.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    20 runs   (    0.37 ms per token,  2723.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.86 ms /    22 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12791.18 ms /    19 runs   (  673.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13958.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    20 runs   (    0.36 ms per token,  2764.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.26 ms /    21 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12791.53 ms /    19 runs   (  673.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13916.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    20 runs   (    0.36 ms per token,  2798.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.96 ms /    21 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12705.74 ms /    19 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13848.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    21 runs   (    0.37 ms per token,  2689.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.11 ms /    22 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13521.09 ms /    20 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14720.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    20 runs   (    0.36 ms per token,  2814.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.82 ms /    22 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12875.74 ms /    19 runs   (  677.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14055.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    21 runs   (    0.35 ms per token,  2826.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.73 ms /    22 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13483.23 ms /    20 runs   (  674.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14645.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    20 runs   (    0.37 ms per token,  2734.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.54 ms /    22 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12852.93 ms /    19 runs   (  676.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14005.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    21 runs   (    0.36 ms per token,  2807.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.24 ms /    22 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   13437.36 ms /    20 runs   (  671.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14618.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    21 runs   (    0.37 ms per token,  2692.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.00 ms /    21 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   13509.17 ms /    20 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14627.81 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    21 runs   (    0.37 ms per token,  2732.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.59 ms /    21 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13525.60 ms /    20 runs   (  676.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14638.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    20 runs   (    0.36 ms per token,  2800.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.65 ms /    22 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12767.69 ms /    19 runs   (  671.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13924.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    21 runs   (    0.37 ms per token,  2734.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.70 ms /    22 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13430.31 ms /    20 runs   (  671.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14608.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    21 runs   (    0.36 ms per token,  2770.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.37 ms /    21 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   13378.96 ms /    20 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14552.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.42 ms /    21 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13455.96 ms /    20 runs   (  672.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14582.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    21 runs   (    0.37 ms per token,  2732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.36 ms /    21 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13383.77 ms /    20 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14517.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    21 runs   (    0.37 ms per token,  2677.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.40 ms /    21 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   13598.89 ms /    20 runs   (  679.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14739.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    20 runs   (    0.37 ms per token,  2728.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.51 ms /    22 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12825.27 ms /    19 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13986.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    20 runs   (    0.36 ms per token,  2756.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.51 ms /    21 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12945.82 ms /    19 runs   (  681.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14086.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    21 runs   (    0.35 ms per token,  2847.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1132.62 ms /    22 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13550.75 ms /    20 runs   (  677.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14731.85 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    21 runs   (    0.38 ms per token,  2616.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.28 ms /    21 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   13518.22 ms /    20 runs   (  675.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14638.96 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    20 runs   (    0.36 ms per token,  2771.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.70 ms /    22 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12816.87 ms /    19 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13994.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    20 runs   (    0.37 ms per token,  2708.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.75 ms /    21 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12797.98 ms /    19 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13904.84 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    20 runs   (    0.36 ms per token,  2764.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.64 ms /    21 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12833.97 ms /    19 runs   (  675.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13951.46 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    21 runs   (    0.38 ms per token,  2651.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.29 ms /    22 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13519.68 ms /    20 runs   (  675.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14722.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    21 runs   (    0.38 ms per token,  2664.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.70 ms /    21 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   13458.99 ms /    20 runs   (  672.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14590.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    20 runs   (    0.37 ms per token,  2679.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.06 ms /    22 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12774.41 ms /    19 runs   (  672.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13931.15 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2685.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.42 ms /    22 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   13500.59 ms /    20 runs   (  675.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14697.19 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    21 runs   (    0.37 ms per token,  2719.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.34 ms /    21 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13469.02 ms /    20 runs   (  673.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14596.10 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    21 runs   (    0.37 ms per token,  2702.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.66 ms /    21 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13533.89 ms /    20 runs   (  676.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14685.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    20 runs   (    0.37 ms per token,  2726.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.30 ms /    22 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12984.03 ms /    19 runs   (  683.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14164.23 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    21 runs   (    0.37 ms per token,  2721.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.14 ms /    22 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   13534.03 ms /    20 runs   (  676.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14730.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    20 runs   (    0.36 ms per token,  2771.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.79 ms /    22 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12878.48 ms /    19 runs   (  677.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14045.22 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    20 runs   (    0.37 ms per token,  2717.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.86 ms /    21 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12945.40 ms /    19 runs   (  681.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14058.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    20 runs   (    0.36 ms per token,  2758.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.84 ms /    22 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12970.19 ms /    19 runs   (  682.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14129.82 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    20 runs   (    0.36 ms per token,  2801.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.13 ms /    22 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12834.69 ms /    19 runs   (  675.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14005.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    20 runs   (    0.37 ms per token,  2696.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.85 ms /    21 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12826.81 ms /    19 runs   (  675.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13982.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    20 runs   (    0.38 ms per token,  2627.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.47 ms /    21 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12918.63 ms /    19 runs   (  679.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14038.34 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2686.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.78 ms /    22 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   13484.49 ms /    20 runs   (  674.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14645.43 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    21 runs   (    0.37 ms per token,  2710.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.76 ms /    21 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   13496.50 ms /    20 runs   (  674.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14636.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    20 runs   (    0.37 ms per token,  2734.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.72 ms /    22 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12835.60 ms /    19 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13992.79 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    20 runs   (    0.37 ms per token,  2718.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.78 ms /    21 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12827.10 ms /    19 runs   (  675.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13950.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    20 runs   (    0.37 ms per token,  2734.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.98 ms /    21 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12929.55 ms /    19 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14087.55 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    21 runs   (    0.36 ms per token,  2759.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.60 ms /    22 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   13463.87 ms /    20 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14630.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    20 runs   (    0.36 ms per token,  2783.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.61 ms /    22 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12988.23 ms /    19 runs   (  683.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14153.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    21 runs   (    0.37 ms per token,  2691.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.43 ms /    22 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13546.10 ms /    20 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14709.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    21 runs   (    0.37 ms per token,  2695.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.46 ms /    21 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   13557.63 ms /    20 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14676.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    21 runs   (    0.38 ms per token,  2648.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.44 ms /    21 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13517.96 ms /    20 runs   (  675.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14632.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    21 runs   (    0.35 ms per token,  2825.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.61 ms /    21 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   13605.71 ms /    20 runs   (  680.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14722.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    20 runs   (    0.36 ms per token,  2766.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.50 ms /    22 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12898.21 ms /    19 runs   (  678.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14076.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    20 runs   (    0.36 ms per token,  2750.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.21 ms /    22 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12715.98 ms /    19 runs   (  669.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13898.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    20 runs   (    0.36 ms per token,  2794.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.56 ms /    22 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12855.57 ms /    19 runs   (  676.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14031.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    21 runs   (    0.36 ms per token,  2762.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.38 ms /    22 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   13635.71 ms /    20 runs   (  681.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14812.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    20 runs   (    0.36 ms per token,  2805.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.22 ms /    22 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12479.86 ms /    19 runs   (  656.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13644.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    20 runs   (    0.37 ms per token,  2728.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.65 ms /    21 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12733.60 ms /    19 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13861.06 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    21 runs   (    0.37 ms per token,  2714.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.61 ms /    22 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   13446.50 ms /    20 runs   (  672.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14617.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    20 runs   (    0.37 ms per token,  2715.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.38 ms /    22 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12930.33 ms /    19 runs   (  680.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14155.05 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    21 runs   (    0.35 ms per token,  2838.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.00 ms /    22 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   13542.47 ms /    20 runs   (  677.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14767.55 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    21 runs   (    0.36 ms per token,  2797.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.30 ms /    21 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   13486.19 ms /    20 runs   (  674.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14604.01 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    20 runs   (    0.37 ms per token,  2694.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.30 ms /    22 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12884.68 ms /    19 runs   (  678.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14068.98 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    20 runs   (    0.35 ms per token,  2825.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.63 ms /    21 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12815.35 ms /    19 runs   (  674.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13940.00 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    21 runs   (    0.36 ms per token,  2755.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.94 ms /    22 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   13429.61 ms /    20 runs   (  671.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14598.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    21 runs   (    0.36 ms per token,  2792.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.48 ms /    21 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13572.44 ms /    20 runs   (  678.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14720.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    20 runs   (    0.36 ms per token,  2791.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.59 ms /    22 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12864.34 ms /    19 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14031.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    21 runs   (    0.36 ms per token,  2784.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.80 ms /    22 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13370.40 ms /    20 runs   (  668.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14574.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    20 runs   (    0.37 ms per token,  2720.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.12 ms /    22 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   12751.90 ms /    19 runs   (  671.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13947.43 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    20 runs   (    0.36 ms per token,  2785.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.91 ms /    21 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12851.83 ms /    19 runs   (  676.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13971.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    20 runs   (    0.36 ms per token,  2778.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.43 ms /    21 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12823.40 ms /    19 runs   (  674.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13943.06 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    21 runs   (    0.35 ms per token,  2819.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.86 ms /    22 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13393.17 ms /    20 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14598.86 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    21 runs   (    0.36 ms per token,  2805.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.30 ms /    21 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13397.23 ms /    20 runs   (  669.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14510.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    21 runs   (    0.37 ms per token,  2684.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.79 ms /    21 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   13482.12 ms /    20 runs   (  674.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14599.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    20 runs   (    0.37 ms per token,  2706.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.40 ms /    22 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12762.03 ms /    19 runs   (  671.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13934.25 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    21 runs   (    0.39 ms per token,  2586.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.17 ms /    22 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   13547.39 ms /    20 runs   (  677.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14742.24 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    20 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.66 ms /    22 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   13135.19 ms /    19 runs   (  691.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14301.03 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    20 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.09 ms /    21 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12895.70 ms /    19 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14059.74 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    20 runs   (    0.36 ms per token,  2772.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.12 ms /    21 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12785.55 ms /    19 runs   (  672.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13902.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    21 runs   (    0.36 ms per token,  2742.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.84 ms /    22 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   13446.69 ms /    20 runs   (  672.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14628.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    20 runs   (    0.37 ms per token,  2731.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.94 ms /    22 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12774.56 ms /    19 runs   (  672.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13935.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    20 runs   (    0.37 ms per token,  2686.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.67 ms /    21 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12930.85 ms /    19 runs   (  680.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14070.86 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    26 runs   (    0.37 ms per token,  2733.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.58 ms /    26 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   16943.47 ms /    25 runs   (  677.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18374.49 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.72 ms /    27 runs   (    0.36 ms per token,  2776.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.26 ms /    27 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:        eval time =   17459.35 ms /    26 runs   (  671.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18871.36 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    27 runs   (    0.36 ms per token,  2798.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1328.82 ms /    26 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17535.72 ms /    26 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18928.22 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.75 ms /    27 runs   (    0.36 ms per token,  2769.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1311.99 ms /    26 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =   17650.46 ms /    26 runs   (  678.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19026.46 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.34 ms /    26 runs   (    0.36 ms per token,  2782.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.98 ms /    27 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   16840.44 ms /    25 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18282.36 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.67 ms /    26 runs   (    0.37 ms per token,  2687.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.62 ms /    26 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   16907.34 ms /    25 runs   (  676.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18281.03 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.93 ms /    27 runs   (    0.37 ms per token,  2719.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1320.82 ms /    26 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17544.76 ms /    26 runs   (  674.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18930.21 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.50 ms /    26 runs   (    0.37 ms per token,  2737.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.83 ms /    25 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   16824.72 ms /    25 runs   (  672.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18152.15 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    27 runs   (    0.37 ms per token,  2735.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.64 ms /    26 tokens (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   17605.92 ms /    26 runs   (  677.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18966.61 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    24 runs   (    0.36 ms per token,  2749.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.49 ms /    25 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   15695.25 ms /    23 runs   (  682.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17016.83 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    26 runs   (    0.36 ms per token,  2791.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.30 ms /    27 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   16983.38 ms /    25 runs   (  679.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18404.12 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    27 runs   (    0.36 ms per token,  2795.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.42 ms /    26 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   17494.66 ms /    26 runs   (  672.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18864.16 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.23 ms /    26 runs   (    0.36 ms per token,  2816.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.00 ms /    27 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   16829.61 ms /    25 runs   (  673.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18258.68 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    24 runs   (    0.36 ms per token,  2778.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.02 ms /    25 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   15597.70 ms /    23 runs   (  678.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16921.60 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    27 runs   (    0.36 ms per token,  2808.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.70 ms /    27 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   17642.14 ms /    26 runs   (  678.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19075.03 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.96 ms /    27 runs   (    0.37 ms per token,  2711.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1324.77 ms /    26 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   17588.68 ms /    26 runs   (  676.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18979.41 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    26 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.10 ms /    25 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   16905.99 ms /    25 runs   (  676.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18240.95 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    26 runs   (    0.36 ms per token,  2805.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.89 ms /    26 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   16881.58 ms /    25 runs   (  675.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18245.40 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    26 runs   (    0.37 ms per token,  2723.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.40 ms /    27 tokens (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:        eval time =   16896.61 ms /    25 runs   (  675.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18293.27 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    24 runs   (    0.37 ms per token,  2705.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1271.55 ms /    25 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15529.83 ms /    23 runs   (  675.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16858.57 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.77 ms /    27 runs   (    0.36 ms per token,  2763.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.40 ms /    27 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   17575.56 ms /    26 runs   (  675.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19082.07 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    26 runs   (    0.36 ms per token,  2813.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.76 ms /    26 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   16776.31 ms /    25 runs   (  671.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18182.54 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.69 ms /    26 runs   (    0.37 ms per token,  2684.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1347.70 ms /    27 tokens (   49.91 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   16827.28 ms /    25 runs   (  673.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18237.37 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    25 runs   (    0.36 ms per token,  2793.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.91 ms /    25 tokens (   49.84 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:        eval time =   16274.32 ms /    24 runs   (  678.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17580.43 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    27 runs   (    0.40 ms per token,  2522.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.71 ms /    27 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   17477.07 ms /    26 runs   (  672.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18928.62 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.80 ms /    27 runs   (    0.36 ms per token,  2753.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.42 ms /    25 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   17565.84 ms /    26 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18920.35 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    24 runs   (    0.36 ms per token,  2786.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.69 ms /    26 tokens (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   15520.24 ms /    23 runs   (  674.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16874.37 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    26 runs   (    0.38 ms per token,  2658.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1297.00 ms /    26 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:        eval time =   16840.12 ms /    25 runs   (  673.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18199.50 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.57 ms /    26 runs   (    0.37 ms per token,  2715.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.28 ms /    26 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   16835.99 ms /    25 runs   (  673.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18211.10 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    25 runs   (    0.37 ms per token,  2738.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.80 ms /    24 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   16117.88 ms /    24 runs   (  671.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17435.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    26 runs   (    0.36 ms per token,  2766.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.77 ms /    27 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   17007.40 ms /    25 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18438.29 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    26 runs   (    0.37 ms per token,  2719.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.25 ms /    25 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   16977.94 ms /    25 runs   (  679.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18302.84 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    26 runs   (    0.36 ms per token,  2799.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.18 ms /    27 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   17037.69 ms /    25 runs   (  681.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18509.51 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    27 runs   (    0.36 ms per token,  2796.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.29 ms /    27 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =   17715.02 ms /    26 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19112.44 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    27 runs   (    0.36 ms per token,  2741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.18 ms /    26 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   17684.98 ms /    26 runs   (  680.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19064.30 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    25 runs   (    0.36 ms per token,  2746.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.89 ms /    25 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16436.12 ms /    24 runs   (  684.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17776.63 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    24 runs   (    0.38 ms per token,  2652.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.57 ms /    26 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   15923.08 ms /    23 runs   (  692.31 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   17381.80 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.43 ms /    25 runs   (    0.38 ms per token,  2651.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.36 ms /    25 tokens (   51.85 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   16382.21 ms /    24 runs   (  682.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17739.79 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    23 runs   (    0.36 ms per token,  2752.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.33 ms /    24 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14806.34 ms /    22 runs   (  673.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16074.15 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    25 runs   (    0.36 ms per token,  2802.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.10 ms /    25 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   16327.14 ms /    24 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17650.91 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.91 ms /    27 runs   (    0.37 ms per token,  2724.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.13 ms /    27 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   17654.16 ms /    26 runs   (  679.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19093.17 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    18 runs   (    0.38 ms per token,  2640.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.47 ms /    26 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11530.24 ms /    17 runs   (  678.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12886.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    27 runs   (    0.36 ms per token,  2774.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.74 ms /    26 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   17723.73 ms /    26 runs   (  681.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19125.27 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    27 runs   (    0.35 ms per token,  2826.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.09 ms /    25 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   17855.47 ms /    26 runs   (  686.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19233.91 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    26 runs   (    0.35 ms per token,  2828.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.98 ms /    25 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   16994.03 ms /    25 runs   (  679.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18313.82 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    25 runs   (    0.37 ms per token,  2723.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.13 ms /    26 tokens (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   16326.46 ms /    24 runs   (  680.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17690.01 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    26 runs   (    0.36 ms per token,  2778.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.84 ms /    27 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   16970.63 ms /    25 runs   (  678.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18393.75 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    26 runs   (    0.36 ms per token,  2805.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.19 ms /    27 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   16913.00 ms /    25 runs   (  676.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18332.30 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    26 runs   (    0.36 ms per token,  2777.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.63 ms /    27 tokens (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:        eval time =   16908.20 ms /    25 runs   (  676.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18307.59 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    27 runs   (    0.37 ms per token,  2733.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.29 ms /    25 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17798.72 ms /    26 runs   (  684.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19135.04 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    24 runs   (    0.36 ms per token,  2788.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.74 ms /    25 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   15776.39 ms /    23 runs   (  685.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17094.26 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    26 runs   (    0.37 ms per token,  2723.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.13 ms /    25 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   17014.37 ms /    25 runs   (  680.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18358.94 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    26 runs   (    0.37 ms per token,  2731.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.39 ms /    27 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:        eval time =   17053.98 ms /    25 runs   (  682.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18449.28 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.47 ms /    26 runs   (    0.36 ms per token,  2744.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.39 ms /    25 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17075.83 ms /    25 runs   (  683.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18457.01 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    26 runs   (    0.38 ms per token,  2655.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.31 ms /    26 tokens (   51.67 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   17104.78 ms /    25 runs   (  684.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18510.75 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    26 runs   (    0.37 ms per token,  2708.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.02 ms /    27 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   17115.05 ms /    25 runs   (  684.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18555.64 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    27 runs   (    0.36 ms per token,  2766.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.75 ms /    27 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   17900.47 ms /    26 runs   (  688.48 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   19336.68 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    25 runs   (    0.36 ms per token,  2745.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.86 ms /    24 tokens (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   16205.48 ms /    24 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17472.59 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    26 runs   (    0.36 ms per token,  2775.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.20 ms /    25 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   16958.53 ms /    25 runs   (  678.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18295.71 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    27 runs   (    0.36 ms per token,  2809.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.46 ms /    26 tokens (   50.59 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   17722.30 ms /    26 runs   (  681.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19104.15 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    25 runs   (    0.36 ms per token,  2749.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.54 ms /    24 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   16200.63 ms /    24 runs   (  675.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17473.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    27 runs   (    0.36 ms per token,  2740.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.30 ms /    26 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17728.00 ms /    26 runs   (  681.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19115.46 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    26 runs   (    0.37 ms per token,  2692.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.25 ms /    27 tokens (   49.79 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:        eval time =   17003.19 ms /    25 runs   (  680.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18411.12 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    26 runs   (    0.36 ms per token,  2804.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.83 ms /    26 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   17105.25 ms /    25 runs   (  684.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18476.30 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    24 runs   (    0.36 ms per token,  2788.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.11 ms /    25 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   15729.39 ms /    23 runs   (  683.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17041.44 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.71 ms /    27 runs   (    0.36 ms per token,  2782.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.44 ms /    27 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   17670.79 ms /    26 runs   (  679.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19121.97 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    26 runs   (    0.37 ms per token,  2708.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.50 ms /    26 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   16882.66 ms /    25 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18257.04 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    26 runs   (    0.37 ms per token,  2732.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.28 ms /    27 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   16990.85 ms /    25 runs   (  679.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18442.23 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    27 runs   (    0.36 ms per token,  2798.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.14 ms /    27 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   17730.13 ms /    26 runs   (  681.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19188.48 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    24 runs   (    0.36 ms per token,  2769.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.62 ms /    26 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15649.16 ms /    23 runs   (  680.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17018.45 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    23 runs   (    0.36 ms per token,  2766.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.72 ms /    23 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14932.33 ms /    22 runs   (  678.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16218.09 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    27 runs   (    0.36 ms per token,  2782.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.09 ms /    27 tokens (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   17601.15 ms /    26 runs   (  676.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19020.68 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    26 runs   (    0.36 ms per token,  2749.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.04 ms /    27 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   16973.33 ms /    25 runs   (  678.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18412.82 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    24 runs   (    0.37 ms per token,  2705.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.01 ms /    25 tokens (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   15541.40 ms /    23 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16849.02 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    26 runs   (    0.36 ms per token,  2747.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.97 ms /    27 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   16855.78 ms /    25 runs   (  674.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18322.60 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    25 runs   (    0.36 ms per token,  2743.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.59 ms /    25 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   16222.67 ms /    24 runs   (  675.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17533.10 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    26 runs   (    0.36 ms per token,  2743.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.33 ms /    27 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   16821.47 ms /    25 runs   (  672.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18256.23 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    27 runs   (    0.37 ms per token,  2720.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.71 ms /    27 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   17503.35 ms /    26 runs   (  673.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18943.00 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    27 runs   (    0.36 ms per token,  2782.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.39 ms /    25 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   17586.44 ms /    26 runs   (  676.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18920.16 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    25 runs   (    0.36 ms per token,  2810.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.05 ms /    27 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   16127.06 ms /    24 runs   (  671.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17561.02 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    25 runs   (    0.36 ms per token,  2763.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1278.30 ms /    25 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16407.81 ms /    24 runs   (  683.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17746.36 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.65 ms /    25 runs   (    0.35 ms per token,  2890.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.41 ms /    26 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:        eval time =   16257.81 ms /    24 runs   (  677.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17611.41 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    25 runs   (    0.37 ms per token,  2725.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.20 ms /    26 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   16109.18 ms /    24 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17501.85 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.77 ms /    27 runs   (    0.36 ms per token,  2764.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1338.53 ms /    27 tokens (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:        eval time =   17585.49 ms /    26 runs   (  676.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18990.44 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    26 runs   (    0.37 ms per token,  2723.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.41 ms /    27 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   16873.08 ms /    25 runs   (  674.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18346.43 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.45 ms /    26 runs   (    0.36 ms per token,  2750.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.97 ms /    26 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   16873.90 ms /    25 runs   (  674.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18271.76 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    26 runs   (    0.37 ms per token,  2735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.26 ms /    26 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   16853.16 ms /    25 runs   (  674.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18227.19 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    24 runs   (    0.36 ms per token,  2796.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.92 ms /    25 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   15612.46 ms /    23 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16975.77 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    26 runs   (    0.36 ms per token,  2815.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.95 ms /    25 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   16955.67 ms /    25 runs   (  678.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18279.05 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    25 runs   (    0.35 ms per token,  2828.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.12 ms /    24 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   16274.85 ms /    24 runs   (  678.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17538.19 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    26 runs   (    0.35 ms per token,  2866.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.65 ms /    26 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   16939.18 ms /    25 runs   (  677.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18326.04 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    25 runs   (    0.36 ms per token,  2810.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.12 ms /    25 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:        eval time =   16271.53 ms /    24 runs   (  677.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17579.99 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    25 runs   (    0.35 ms per token,  2827.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1301.16 ms /    25 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   16276.56 ms /    24 runs   (  678.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17638.74 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    27 runs   (    0.36 ms per token,  2741.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.53 ms /    27 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   17687.92 ms /    26 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19135.67 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    25 runs   (    0.36 ms per token,  2755.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.87 ms /    26 tokens (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:        eval time =   16141.11 ms /    24 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17496.37 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.01 ms /    25 runs   (    0.36 ms per token,  2775.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.49 ms /    24 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   16346.38 ms /    24 runs   (  681.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17702.82 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    25 runs   (    0.36 ms per token,  2803.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.70 ms /    25 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   16341.15 ms /    24 runs   (  680.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17677.24 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       8.72 ms /    24 runs   (    0.36 ms per token,  2751.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1298.65 ms /    25 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   15600.27 ms /    23 runs   (  678.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16957.48 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    25 runs   (    0.37 ms per token,  2705.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.74 ms /    26 tokens (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =   16348.75 ms /    24 runs   (  681.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17715.54 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    26 runs   (    0.36 ms per token,  2772.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.59 ms /    27 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   16822.02 ms /    25 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18277.62 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    31 runs   (    0.38 ms per token,  2619.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1523.07 ms /    30 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   20492.09 ms /    30 runs   (  683.07 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22091.40 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    32 runs   (    0.38 ms per token,  2646.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1621.04 ms /    32 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   21066.03 ms /    31 runs   (  679.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22765.35 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.70 ms /    31 runs   (    0.38 ms per token,  2649.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1550.12 ms /    31 tokens (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:        eval time =   20341.99 ms /    30 runs   (  678.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21968.39 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    32 runs   (    0.37 ms per token,  2701.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1568.40 ms /    31 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   21247.14 ms /    31 runs   (  685.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22894.81 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    32 runs   (    0.36 ms per token,  2741.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1502.18 ms /    30 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   21121.76 ms /    31 runs   (  681.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22702.40 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    33 runs   (    0.37 ms per token,  2704.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.14 ms /    31 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   21643.06 ms /    32 runs   (  676.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23301.57 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    32 runs   (    0.37 ms per token,  2698.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.50 ms /    32 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   21295.41 ms /    31 runs   (  686.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22975.51 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.83 ms /    33 runs   (    0.39 ms per token,  2571.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.21 ms /    32 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21736.07 ms /    32 runs   (  679.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23426.36 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    31 runs   (    0.38 ms per token,  2641.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.00 ms /    31 tokens (   51.77 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   20223.70 ms /    30 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21905.41 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    32 runs   (    0.38 ms per token,  2601.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1574.09 ms /    31 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   21026.72 ms /    31 runs   (  678.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22679.81 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.44 ms /    30 runs   (    0.38 ms per token,  2623.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1539.97 ms /    30 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19869.44 ms /    29 runs   (  685.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21484.44 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.43 ms /    31 runs   (    0.37 ms per token,  2711.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1554.47 ms /    31 tokens (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:        eval time =   20395.41 ms /    30 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22026.60 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    32 runs   (    0.37 ms per token,  2689.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1595.36 ms /    32 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:        eval time =   21103.13 ms /    31 runs   (  680.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22778.47 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    31 runs   (    0.36 ms per token,  2798.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.96 ms /    30 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   20259.98 ms /    30 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21846.74 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.16 ms /    31 runs   (    0.36 ms per token,  2778.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1571.97 ms /    31 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20282.24 ms /    30 runs   (  676.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21930.87 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.73 ms /    32 runs   (    0.37 ms per token,  2727.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.42 ms /    28 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   21180.97 ms /    31 runs   (  683.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22676.99 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    32 runs   (    0.37 ms per token,  2667.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1585.81 ms /    32 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:        eval time =   21049.16 ms /    31 runs   (  679.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22714.47 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    33 runs   (    0.38 ms per token,  2658.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.30 ms /    32 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   21622.68 ms /    32 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23342.05 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    32 runs   (    0.38 ms per token,  2648.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.63 ms /    31 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   20975.62 ms /    31 runs   (  676.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22687.21 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.10 ms /    30 runs   (    0.37 ms per token,  2701.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1550.60 ms /    31 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19702.33 ms /    29 runs   (  679.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21327.26 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    32 runs   (    0.37 ms per token,  2697.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1574.15 ms /    31 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   21035.44 ms /    31 runs   (  678.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22689.04 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    32 runs   (    0.37 ms per token,  2698.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1619.76 ms /    32 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   20944.71 ms /    31 runs   (  675.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22643.02 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.61 ms /    33 runs   (    0.38 ms per token,  2616.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1558.30 ms /    30 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   21659.44 ms /    32 runs   (  676.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23299.57 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    32 runs   (    0.38 ms per token,  2621.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.34 ms /    30 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   20637.50 ms /    31 runs   (  665.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22231.81 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.45 ms /    29 runs   (    0.36 ms per token,  2776.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1512.63 ms /    30 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19066.04 ms /    28 runs   (  680.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20649.86 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    31 runs   (    0.39 ms per token,  2579.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1570.38 ms /    30 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   20527.74 ms /    30 runs   (  684.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22176.85 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    33 runs   (    0.38 ms per token,  2643.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1616.70 ms /    32 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   21829.92 ms /    32 runs   (  682.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23528.35 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    32 runs   (    0.38 ms per token,  2644.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1626.01 ms /    32 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   21064.57 ms /    31 runs   (  679.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22769.99 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    31 runs   (    0.35 ms per token,  2827.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1549.31 ms /    31 tokens (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_print_timings:        eval time =   20252.00 ms /    30 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21876.59 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.73 ms /    32 runs   (    0.37 ms per token,  2728.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1585.34 ms /    31 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20905.95 ms /    31 runs   (  674.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22570.06 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    33 runs   (    0.37 ms per token,  2674.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.42 ms /    31 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   21692.14 ms /    32 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23352.20 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    32 runs   (    0.38 ms per token,  2663.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1551.57 ms /    30 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   20991.33 ms /    31 runs   (  677.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22622.50 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    32 runs   (    0.38 ms per token,  2647.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.73 ms /    32 tokens (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   20951.92 ms /    31 runs   (  675.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22634.83 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.06 ms /    28 runs   (    0.36 ms per token,  2783.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1468.87 ms /    28 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   18547.44 ms /    27 runs   (  686.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20084.14 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.49 ms /    33 runs   (    0.38 ms per token,  2641.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.66 ms /    32 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   21633.83 ms /    32 runs   (  676.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23316.75 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    27 runs   (    0.37 ms per token,  2698.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1528.43 ms /    30 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   17648.43 ms /    26 runs   (  678.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19244.01 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    31 runs   (    0.37 ms per token,  2678.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1516.18 ms /    30 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   20448.26 ms /    30 runs   (  681.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22041.31 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    32 runs   (    0.37 ms per token,  2698.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.59 ms /    32 tokens (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21073.17 ms /    31 runs   (  679.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22759.44 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.75 ms /    32 runs   (    0.37 ms per token,  2723.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1560.84 ms /    31 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20982.24 ms /    31 runs   (  676.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22622.11 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    32 runs   (    0.37 ms per token,  2703.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1586.85 ms /    31 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   20909.63 ms /    31 runs   (  674.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22576.18 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.30 ms /    31 runs   (    0.36 ms per token,  2742.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.90 ms /    30 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   20496.47 ms /    30 runs   (  683.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22096.10 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    32 runs   (    0.38 ms per token,  2654.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.74 ms /    32 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   20977.41 ms /    31 runs   (  676.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22686.09 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    32 runs   (    0.37 ms per token,  2681.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1621.61 ms /    32 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   21165.65 ms /    31 runs   (  682.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22866.95 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    32 runs   (    0.37 ms per token,  2684.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1600.57 ms /    32 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_print_timings:        eval time =   21128.91 ms /    31 runs   (  681.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22809.80 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    30 runs   (    0.36 ms per token,  2789.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.76 ms /    30 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19754.16 ms /    29 runs   (  681.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21335.60 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    28 runs   (    0.37 ms per token,  2688.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1593.57 ms /    30 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   18329.33 ms /    27 runs   (  678.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19992.64 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    30 runs   (    0.37 ms per token,  2739.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1530.97 ms /    30 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19646.80 ms /    29 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21251.95 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    26 runs   (    0.35 ms per token,  2849.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.16 ms /    31 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   16975.42 ms /    25 runs   (  679.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18587.65 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    33 runs   (    0.37 ms per token,  2677.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.43 ms /    31 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   21841.14 ms /    32 runs   (  682.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23511.85 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.75 ms /    32 runs   (    0.37 ms per token,  2724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1560.62 ms /    31 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   21087.67 ms /    31 runs   (  680.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22726.79 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.96 ms /    28 runs   (    0.36 ms per token,  2809.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1488.38 ms /    29 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   18358.55 ms /    27 runs   (  679.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19915.35 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    32 runs   (    0.38 ms per token,  2654.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.98 ms /    32 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   21022.92 ms /    31 runs   (  678.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22725.63 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    32 runs   (    0.38 ms per token,  2658.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1603.43 ms /    32 tokens (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_print_timings:        eval time =   21051.27 ms /    31 runs   (  679.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22734.34 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    32 runs   (    0.38 ms per token,  2654.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.10 ms /    32 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21036.20 ms /    31 runs   (  678.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22721.83 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    32 runs   (    0.36 ms per token,  2746.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1574.02 ms /    31 tokens (   50.77 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   21031.54 ms /    31 runs   (  678.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22685.57 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    31 runs   (    0.37 ms per token,  2677.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.74 ms /    30 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   20695.90 ms /    30 runs   (  689.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   22293.64 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    33 runs   (    0.37 ms per token,  2721.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1552.20 ms /    30 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   21965.98 ms /    32 runs   (  686.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23599.47 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    32 runs   (    0.38 ms per token,  2665.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.86 ms /    31 tokens (   52.29 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   21193.58 ms /    31 runs   (  683.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22893.79 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.09 ms /    31 runs   (    0.36 ms per token,  2794.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1573.00 ms /    31 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   20545.74 ms /    30 runs   (  684.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22195.45 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    32 runs   (    0.38 ms per token,  2653.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.75 ms /    32 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   21259.53 ms /    31 runs   (  685.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22945.33 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.62 ms /    31 runs   (    0.37 ms per token,  2667.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1598.72 ms /    31 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   20165.64 ms /    30 runs   (  672.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21842.55 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    32 runs   (    0.38 ms per token,  2652.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1604.11 ms /    32 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   20867.90 ms /    31 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22552.09 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    32 runs   (    0.37 ms per token,  2708.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.58 ms /    32 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   21115.22 ms /    31 runs   (  681.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22817.98 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    33 runs   (    0.38 ms per token,  2653.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.38 ms /    32 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21696.72 ms /    32 runs   (  678.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23385.26 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    32 runs   (    0.38 ms per token,  2636.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1583.19 ms /    31 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   21045.98 ms /    31 runs   (  678.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22708.61 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.64 ms /    32 runs   (    0.36 ms per token,  2750.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.61 ms /    31 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   21186.12 ms /    31 runs   (  683.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22850.49 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.99 ms /    33 runs   (    0.36 ms per token,  2752.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1565.23 ms /    31 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =   21876.57 ms /    32 runs   (  683.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23522.65 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    32 runs   (    0.38 ms per token,  2615.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1602.15 ms /    32 tokens (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_print_timings:        eval time =   21104.90 ms /    31 runs   (  680.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22786.00 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.36 ms /    31 runs   (    0.37 ms per token,  2728.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.30 ms /    30 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20212.73 ms /    30 runs   (  673.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21809.07 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.50 ms /    32 runs   (    0.39 ms per token,  2559.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1558.27 ms /    30 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   21038.34 ms /    31 runs   (  678.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22676.25 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.15 ms /    31 runs   (    0.36 ms per token,  2779.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1520.18 ms /    30 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   20288.29 ms /    30 runs   (  676.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21884.37 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    31 runs   (    0.38 ms per token,  2657.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1609.06 ms /    31 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   20292.92 ms /    30 runs   (  676.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21977.88 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    30 runs   (    0.36 ms per token,  2768.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1517.54 ms /    30 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19440.25 ms /    29 runs   (  670.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21031.29 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    32 runs   (    0.37 ms per token,  2670.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.78 ms /    31 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   20768.82 ms /    31 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22440.03 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    30 runs   (    0.36 ms per token,  2760.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1543.05 ms /    30 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   19499.41 ms /    29 runs   (  672.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21115.22 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    32 runs   (    0.38 ms per token,  2639.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1511.27 ms /    30 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   20883.66 ms /    31 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22473.41 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    30 runs   (    0.36 ms per token,  2755.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1572.51 ms /    31 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   19519.48 ms /    29 runs   (  673.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21165.91 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.80 ms /    32 runs   (    0.37 ms per token,  2712.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1645.95 ms /    32 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   20882.39 ms /    31 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22606.26 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.82 ms /    32 runs   (    0.37 ms per token,  2707.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1591.14 ms /    32 tokens (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:        eval time =   21012.78 ms /    31 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22681.79 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    32 runs   (    0.38 ms per token,  2623.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.75 ms /    32 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20829.12 ms /    31 runs   (  671.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22530.47 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    32 runs   (    0.38 ms per token,  2649.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1579.04 ms /    31 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   20904.58 ms /    31 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22562.17 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    32 runs   (    0.37 ms per token,  2682.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1622.27 ms /    32 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   21010.99 ms /    31 runs   (  677.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22711.69 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    33 runs   (    0.38 ms per token,  2650.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1598.07 ms /    32 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   21782.92 ms /    32 runs   (  680.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23462.76 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.80 ms /    32 runs   (    0.37 ms per token,  2711.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1505.41 ms /    30 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   21019.59 ms /    31 runs   (  678.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22603.88 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.64 ms /    32 runs   (    0.36 ms per token,  2748.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1588.26 ms /    31 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   21039.53 ms /    31 runs   (  678.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22707.52 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.53 ms /    31 runs   (    0.37 ms per token,  2688.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1571.78 ms /    31 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20286.96 ms /    30 runs   (  676.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21934.43 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    33 runs   (    0.37 ms per token,  2698.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1598.12 ms /    32 tokens (   49.94 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:        eval time =   21753.58 ms /    32 runs   (  679.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23433.13 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    32 runs   (    0.36 ms per token,  2739.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1610.98 ms /    32 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20879.10 ms /    31 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22569.26 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    32 runs   (    0.37 ms per token,  2705.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.19 ms /    31 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   20721.68 ms /    31 runs   (  668.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22392.30 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    32 runs   (    0.37 ms per token,  2725.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1566.67 ms /    31 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =   21048.11 ms /    31 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22694.00 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    32 runs   (    0.37 ms per token,  2667.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.30 ms /    32 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   21041.89 ms /    31 runs   (  678.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22792.92 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    31 runs   (    0.38 ms per token,  2654.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1573.08 ms /    31 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   20362.93 ms /    30 runs   (  678.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22013.22 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    32 runs   (    0.38 ms per token,  2651.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1612.36 ms /    32 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   21080.72 ms /    31 runs   (  680.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22772.71 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    32 runs   (    0.37 ms per token,  2680.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.36 ms /    31 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   21082.91 ms /    31 runs   (  680.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22741.00 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.00 ms /    30 runs   (    0.37 ms per token,  2726.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.56 ms /    31 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19829.11 ms /    29 runs   (  683.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21490.67 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    33 runs   (    0.37 ms per token,  2679.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1614.03 ms /    32 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =   21794.29 ms /    32 runs   (  681.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23490.34 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    29 runs   (    0.36 ms per token,  2759.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.95 ms /    29 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19121.06 ms /    28 runs   (  682.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20690.47 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      10.66 ms /    29 runs   (    0.37 ms per token,  2720.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1488.59 ms /    29 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19011.73 ms /    28 runs   (  678.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20573.09 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    32 runs   (    0.38 ms per token,  2652.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1576.81 ms /    31 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   21169.11 ms /    31 runs   (  682.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22826.11 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.35 ms /    33 runs   (    0.37 ms per token,  2672.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.82 ms /    32 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   21929.44 ms /    32 runs   (  685.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23651.24 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.59 ms /    39 runs   (    0.37 ms per token,  2672.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1838.79 ms /    36 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   26030.89 ms /    38 runs   (  685.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27967.94 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.66 ms /    34 runs   (    0.37 ms per token,  2684.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1764.51 ms /    33 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   22681.78 ms /    33 runs   (  687.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   24530.97 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.13 ms /    38 runs   (    0.37 ms per token,  2689.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1877.50 ms /    36 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   25120.86 ms /    37 runs   (  678.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27093.99 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.20 ms /    38 runs   (    0.37 ms per token,  2676.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1787.63 ms /    35 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   24997.97 ms /    37 runs   (  675.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26880.35 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    26 runs   (    0.36 ms per token,  2791.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1877.47 ms /    36 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   16896.83 ms /    25 runs   (  675.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18838.76 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    38 runs   (    0.37 ms per token,  2703.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1923.08 ms /    37 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   25010.81 ms /    37 runs   (  675.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27027.92 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    37 runs   (    0.37 ms per token,  2678.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.77 ms /    35 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   24575.01 ms /    36 runs   (  682.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26453.18 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.38 ms /    38 runs   (    0.38 ms per token,  2642.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1849.67 ms /    36 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   25437.49 ms /    37 runs   (  687.50 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27381.39 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    38 runs   (    0.38 ms per token,  2644.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1846.12 ms /    36 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   25352.58 ms /    37 runs   (  685.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27293.07 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.53 ms /    39 runs   (    0.37 ms per token,  2684.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1860.70 ms /    36 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   26069.23 ms /    38 runs   (  686.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   28027.84 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    38 runs   (    0.37 ms per token,  2673.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1884.67 ms /    37 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   25266.83 ms /    37 runs   (  682.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27245.66 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.03 ms /    38 runs   (    0.37 ms per token,  2707.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1846.64 ms /    36 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   25139.60 ms /    37 runs   (  679.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27080.28 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.97 ms /    37 runs   (    0.38 ms per token,  2648.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1809.38 ms /    35 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   24478.08 ms /    36 runs   (  679.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26379.60 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.49 ms /    38 runs   (    0.38 ms per token,  2623.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1889.38 ms /    37 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   25136.47 ms /    37 runs   (  679.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27119.99 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.39 ms /    38 runs   (    0.38 ms per token,  2640.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1909.29 ms /    37 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   25174.34 ms /    37 runs   (  680.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27178.36 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.54 ms /    36 runs   (    0.38 ms per token,  2658.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1826.87 ms /    36 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   23918.16 ms /    35 runs   (  683.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   25834.85 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.27 ms /    38 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1829.32 ms /    35 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   25451.46 ms /    37 runs   (  687.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27376.72 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.40 ms /    38 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1890.29 ms /    37 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   25424.91 ms /    37 runs   (  687.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27411.22 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.79 ms /    37 runs   (    0.37 ms per token,  2682.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1855.54 ms /    36 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   24532.78 ms /    36 runs   (  681.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26481.37 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.44 ms /    38 runs   (    0.38 ms per token,  2631.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.60 ms /    36 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   25039.41 ms /    37 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26988.54 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.82 ms /    35 runs   (    0.37 ms per token,  2730.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1685.93 ms /    33 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   23090.77 ms /    34 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24864.34 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    38 runs   (    0.37 ms per token,  2698.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.32 ms /    36 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   25025.60 ms /    37 runs   (  676.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26973.42 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.04 ms /    38 runs   (    0.37 ms per token,  2705.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1897.63 ms /    37 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   25299.06 ms /    37 runs   (  683.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27292.68 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.38 ms /    38 runs   (    0.38 ms per token,  2642.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1813.99 ms /    36 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =   25345.14 ms /    37 runs   (  685.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27255.66 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.38 ms /    38 runs   (    0.38 ms per token,  2643.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1892.34 ms /    37 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   25558.37 ms /    37 runs   (  690.77 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27546.19 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.78 ms /    32 runs   (    0.37 ms per token,  2716.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1840.04 ms /    36 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   21123.11 ms /    31 runs   (  681.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23043.30 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    36 runs   (    0.37 ms per token,  2723.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1885.45 ms /    36 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   23844.89 ms /    35 runs   (  681.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25820.81 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.64 ms /    39 runs   (    0.38 ms per token,  2663.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1881.93 ms /    37 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   25878.03 ms /    38 runs   (  681.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27858.03 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.28 ms /    38 runs   (    0.38 ms per token,  2662.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1910.36 ms /    37 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   25562.06 ms /    37 runs   (  690.87 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27569.03 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.07 ms /    38 runs   (    0.37 ms per token,  2700.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.01 ms /    36 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   25143.88 ms /    37 runs   (  679.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27062.01 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.03 ms /    38 runs   (    0.37 ms per token,  2708.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1913.73 ms /    37 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   25182.66 ms /    37 runs   (  680.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27191.20 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.11 ms /    38 runs   (    0.37 ms per token,  2694.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1858.46 ms /    36 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   25359.87 ms /    37 runs   (  685.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27313.36 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.62 ms /    36 runs   (    0.38 ms per token,  2642.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1767.72 ms /    35 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   23749.26 ms /    35 runs   (  678.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25606.67 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    38 runs   (    0.36 ms per token,  2749.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1884.95 ms /    37 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   25124.36 ms /    37 runs   (  679.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27104.13 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.25 ms /    37 runs   (    0.39 ms per token,  2597.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1827.95 ms /    36 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   24341.73 ms /    36 runs   (  676.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26262.23 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.10 ms /    38 runs   (    0.37 ms per token,  2695.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1783.90 ms /    35 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   24979.09 ms /    37 runs   (  675.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26857.66 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.20 ms /    38 runs   (    0.37 ms per token,  2675.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1875.60 ms /    37 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   25167.33 ms /    37 runs   (  680.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27137.20 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    38 runs   (    0.37 ms per token,  2674.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1872.85 ms /    37 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   25123.75 ms /    37 runs   (  679.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27091.11 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.98 ms /    38 runs   (    0.37 ms per token,  2717.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1903.46 ms /    37 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   25177.48 ms /    37 runs   (  680.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27175.82 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    38 runs   (    0.37 ms per token,  2722.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1921.89 ms /    37 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   25044.52 ms /    37 runs   (  676.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27060.28 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.14 ms /    38 runs   (    0.37 ms per token,  2686.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.67 ms /    36 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   25403.73 ms /    37 runs   (  686.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27351.74 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.02 ms /    38 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1870.84 ms /    36 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   25363.85 ms /    37 runs   (  685.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27328.95 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    37 runs   (    0.37 ms per token,  2684.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1717.49 ms /    34 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =   24374.51 ms /    36 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26184.78 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    38 runs   (    0.37 ms per token,  2673.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1923.92 ms /    37 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   25162.92 ms /    37 runs   (  680.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27182.07 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    38 runs   (    0.37 ms per token,  2698.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1883.24 ms /    36 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   25085.00 ms /    37 runs   (  677.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27064.31 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.64 ms /    37 runs   (    0.37 ms per token,  2713.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1807.57 ms /    35 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   24533.16 ms /    36 runs   (  681.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26433.17 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.03 ms /    37 runs   (    0.38 ms per token,  2638.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1854.83 ms /    36 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   24490.52 ms /    36 runs   (  680.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26438.14 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.23 ms /    38 runs   (    0.37 ms per token,  2671.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1895.35 ms /    37 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   25264.70 ms /    37 runs   (  682.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27254.59 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.04 ms /    38 runs   (    0.37 ms per token,  2705.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1825.07 ms /    36 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =   24994.83 ms /    37 runs   (  675.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26914.03 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.56 ms /    39 runs   (    0.37 ms per token,  2677.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1838.72 ms /    36 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   25922.23 ms /    38 runs   (  682.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27858.17 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.10 ms /    35 runs   (    0.37 ms per token,  2671.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1776.13 ms /    35 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   23057.17 ms /    34 runs   (  678.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24920.43 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.98 ms /    38 runs   (    0.37 ms per token,  2718.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1918.73 ms /    37 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   25155.25 ms /    37 runs   (  679.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27169.24 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.67 ms /    37 runs   (    0.37 ms per token,  2706.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1857.76 ms /    36 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   24613.11 ms /    36 runs   (  683.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26563.15 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.14 ms /    38 runs   (    0.37 ms per token,  2687.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1840.13 ms /    36 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =   25180.35 ms /    37 runs   (  680.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27115.08 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.78 ms /    39 runs   (    0.38 ms per token,  2639.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1873.70 ms /    37 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   25741.26 ms /    38 runs   (  677.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27714.05 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    38 runs   (    0.37 ms per token,  2698.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1910.20 ms /    37 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   24982.05 ms /    37 runs   (  675.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26987.54 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.01 ms /    38 runs   (    0.37 ms per token,  2712.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1842.60 ms /    35 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   25052.15 ms /    37 runs   (  677.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26989.75 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.26 ms /    38 runs   (    0.38 ms per token,  2664.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1874.88 ms /    36 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   25294.93 ms /    37 runs   (  683.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27266.01 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.56 ms /    38 runs   (    0.38 ms per token,  2609.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1825.82 ms /    36 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   25284.59 ms /    37 runs   (  683.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27206.89 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    32 runs   (    0.38 ms per token,  2599.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1913.20 ms /    37 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   21251.80 ms /    31 runs   (  685.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23246.16 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    38 runs   (    0.37 ms per token,  2703.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1772.93 ms /    35 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   25194.17 ms /    37 runs   (  680.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27062.40 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.28 ms /    38 runs   (    0.38 ms per token,  2660.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1992.96 ms /    37 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   25279.43 ms /    37 runs   (  683.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27368.84 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    38 runs   (    0.37 ms per token,  2701.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1846.12 ms /    36 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   25321.06 ms /    37 runs   (  684.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27262.95 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.70 ms /    37 runs   (    0.37 ms per token,  2699.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1844.65 ms /    36 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   24476.73 ms /    36 runs   (  679.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26414.25 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    32 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1833.75 ms /    36 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21160.70 ms /    31 runs   (  682.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23075.28 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.76 ms /    37 runs   (    0.37 ms per token,  2689.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1836.64 ms /    36 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   24488.20 ms /    36 runs   (  680.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26418.29 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.09 ms /    38 runs   (    0.37 ms per token,  2697.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1900.62 ms /    37 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   25264.38 ms /    37 runs   (  682.82 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27260.44 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.47 ms /    38 runs   (    0.38 ms per token,  2626.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1832.83 ms /    36 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   25399.05 ms /    37 runs   (  686.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27328.69 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    38 runs   (    0.37 ms per token,  2673.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1939.76 ms /    37 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   25090.12 ms /    37 runs   (  678.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27125.50 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.93 ms /    37 runs   (    0.38 ms per token,  2655.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1775.83 ms /    35 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   24777.84 ms /    36 runs   (  688.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   26646.65 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.45 ms /    38 runs   (    0.38 ms per token,  2630.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1892.12 ms /    37 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   25232.73 ms /    37 runs   (  681.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27221.47 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.05 ms /    38 runs   (    0.37 ms per token,  2704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1827.30 ms /    36 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   25454.23 ms /    37 runs   (  687.95 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27376.57 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.92 ms /    37 runs   (    0.38 ms per token,  2658.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1778.76 ms /    35 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   24595.22 ms /    36 runs   (  683.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26466.61 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.04 ms /    38 runs   (    0.37 ms per token,  2705.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1908.17 ms /    37 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   25210.58 ms /    37 runs   (  681.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27213.51 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    36 runs   (    0.37 ms per token,  2701.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1793.16 ms /    35 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   23775.19 ms /    35 runs   (  679.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25658.06 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.94 ms /    35 runs   (    0.37 ms per token,  2704.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1809.69 ms /    35 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   22969.19 ms /    34 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24866.70 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.01 ms /    38 runs   (    0.37 ms per token,  2711.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1883.81 ms /    36 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   25041.05 ms /    37 runs   (  676.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27019.84 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.25 ms /    38 runs   (    0.37 ms per token,  2667.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1903.48 ms /    37 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =   25172.81 ms /    37 runs   (  680.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27172.02 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.43 ms /    38 runs   (    0.38 ms per token,  2633.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1878.05 ms /    37 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   25559.08 ms /    37 runs   (  690.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27532.37 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.89 ms /    32 runs   (    0.37 ms per token,  2691.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1907.77 ms /    37 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   21234.34 ms /    31 runs   (  684.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23222.73 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.46 ms /    38 runs   (    0.38 ms per token,  2628.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1876.08 ms /    37 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =   25349.89 ms /    37 runs   (  685.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27322.21 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.73 ms /    37 runs   (    0.37 ms per token,  2695.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1839.84 ms /    36 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   24408.27 ms /    36 runs   (  678.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26341.48 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.54 ms /    37 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1865.21 ms /    36 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   24558.26 ms /    36 runs   (  682.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26515.85 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.34 ms /    38 runs   (    0.38 ms per token,  2650.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1859.83 ms /    36 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   25179.67 ms /    37 runs   (  680.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27135.47 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.86 ms /    35 runs   (    0.37 ms per token,  2722.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1729.76 ms /    34 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   23057.12 ms /    34 runs   (  678.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24874.83 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.40 ms /    38 runs   (    0.38 ms per token,  2639.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1881.31 ms /    36 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   25594.15 ms /    37 runs   (  691.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27574.66 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.29 ms /    38 runs   (    0.38 ms per token,  2658.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.92 ms /    36 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =   25027.09 ms /    37 runs   (  676.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26976.36 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    37 runs   (    0.38 ms per token,  2650.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1814.78 ms /    35 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   24436.44 ms /    36 runs   (  678.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26344.86 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.46 ms /    36 runs   (    0.37 ms per token,  2674.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1837.74 ms /    35 tokens (   52.51 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   23697.92 ms /    35 runs   (  677.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25626.12 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.28 ms /    38 runs   (    0.38 ms per token,  2660.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1943.09 ms /    37 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   25122.10 ms /    37 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27160.77 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.45 ms /    38 runs   (    0.38 ms per token,  2630.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1885.07 ms /    36 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   25156.69 ms /    37 runs   (  679.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27137.38 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.51 ms /    38 runs   (    0.38 ms per token,  2618.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1911.66 ms /    37 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   25110.28 ms /    37 runs   (  678.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27119.28 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      11.40 ms /    31 runs   (    0.37 ms per token,  2720.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1575.15 ms /    31 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   20240.91 ms /    30 runs   (  674.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21893.31 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    37 runs   (    0.37 ms per token,  2739.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1858.21 ms /    36 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   24302.77 ms /    36 runs   (  675.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26253.72 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.57 ms /    37 runs   (    0.37 ms per token,  2727.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1815.66 ms /    35 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   24416.74 ms /    36 runs   (  678.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26323.75 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.26 ms /    38 runs   (    0.38 ms per token,  2665.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1849.68 ms /    36 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   25113.88 ms /    37 runs   (  678.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27059.12 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      14.03 ms /    38 runs   (    0.37 ms per token,  2708.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1920.98 ms /    37 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   25094.41 ms /    37 runs   (  678.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27110.32 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    37 runs   (    0.38 ms per token,  2654.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1842.02 ms /    35 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   24684.03 ms /    36 runs   (  685.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26619.43 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    34 runs   (    0.36 ms per token,  2746.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1815.37 ms /    35 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   22230.75 ms /    33 runs   (  673.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24130.58 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    36 runs   (    0.37 ms per token,  2703.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1787.67 ms /    35 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   23817.55 ms /    35 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25694.89 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.89 ms /    45 runs   (    0.38 ms per token,  2664.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2015.62 ms /    39 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =   29696.69 ms /    44 runs   (  674.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31827.61 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.68 ms /    44 runs   (    0.38 ms per token,  2637.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2034.27 ms /    40 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   29217.64 ms /    43 runs   (  679.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31364.50 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.55 ms /    44 runs   (    0.38 ms per token,  2658.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2157.49 ms /    42 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   29508.33 ms /    43 runs   (  686.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31778.28 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.58 ms /    44 runs   (    0.38 ms per token,  2653.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2114.56 ms /    41 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   28899.62 ms /    43 runs   (  672.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   31125.04 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.57 ms /    44 runs   (    0.38 ms per token,  2654.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2035.86 ms /    40 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   28909.31 ms /    43 runs   (  672.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   31055.93 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.52 ms /    44 runs   (    0.38 ms per token,  2662.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2122.46 ms /    41 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   29438.53 ms /    43 runs   (  684.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31672.63 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.52 ms /    44 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2086.11 ms /    41 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   29187.66 ms /    43 runs   (  678.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31385.88 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.00 ms /    43 runs   (    0.37 ms per token,  2687.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2107.66 ms /    41 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   28748.92 ms /    42 runs   (  684.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30965.16 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.04 ms /    42 runs   (    0.38 ms per token,  2618.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2067.97 ms /    40 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   27790.35 ms /    41 runs   (  677.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29965.02 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.45 ms /    44 runs   (    0.37 ms per token,  2674.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2093.71 ms /    41 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   29237.51 ms /    43 runs   (  679.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31442.28 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.48 ms /    44 runs   (    0.37 ms per token,  2670.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2040.24 ms /    40 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   29165.41 ms /    43 runs   (  678.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31317.47 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.94 ms /    45 runs   (    0.38 ms per token,  2656.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2145.73 ms /    42 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   29847.60 ms /    44 runs   (  678.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32107.70 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.30 ms /    45 runs   (    0.38 ms per token,  2601.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2057.49 ms /    41 tokens (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_print_timings:        eval time =   29713.50 ms /    44 runs   (  675.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31886.23 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.00 ms /    45 runs   (    0.38 ms per token,  2647.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2094.37 ms /    41 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   29941.78 ms /    44 runs   (  680.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32150.52 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.28 ms /    45 runs   (    0.38 ms per token,  2604.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2057.85 ms /    41 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:        eval time =   30010.92 ms /    44 runs   (  682.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32183.99 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.79 ms /    44 runs   (    0.38 ms per token,  2621.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2078.13 ms /    40 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   29375.12 ms /    43 runs   (  683.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31565.99 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.12 ms /    43 runs   (    0.37 ms per token,  2667.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2107.24 ms /    41 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   28473.56 ms /    42 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30688.86 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.96 ms /    43 runs   (    0.39 ms per token,  2535.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2073.98 ms /    40 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   28511.91 ms /    42 runs   (  678.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30698.41 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.91 ms /    44 runs   (    0.38 ms per token,  2602.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2081.96 ms /    41 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =   29201.23 ms /    43 runs   (  679.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31395.75 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.80 ms /    44 runs   (    0.38 ms per token,  2619.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2185.14 ms /    42 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   29061.40 ms /    43 runs   (  675.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31358.00 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.88 ms /    44 runs   (    0.38 ms per token,  2606.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2115.06 ms /    41 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =   29378.58 ms /    43 runs   (  683.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31605.33 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.06 ms /    43 runs   (    0.37 ms per token,  2676.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2040.20 ms /    40 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   28723.70 ms /    42 runs   (  683.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30872.35 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.11 ms /    42 runs   (    0.38 ms per token,  2607.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1959.59 ms /    38 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   27816.52 ms /    41 runs   (  678.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29882.57 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      15.86 ms /    42 runs   (    0.38 ms per token,  2649.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2032.37 ms /    40 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   27689.19 ms /    41 runs   (  675.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29826.75 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.05 ms /    45 runs   (    0.38 ms per token,  2638.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2157.06 ms /    42 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   29867.85 ms /    44 runs   (  678.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32138.46 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.27 ms /    45 runs   (    0.38 ms per token,  2605.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2076.91 ms /    41 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   30013.33 ms /    44 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32205.40 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.65 ms /    44 runs   (    0.38 ms per token,  2642.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2112.76 ms /    42 tokens (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =   29791.05 ms /    43 runs   (  692.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   32024.15 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.79 ms /    44 runs   (    0.38 ms per token,  2620.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2779.74 ms /    39 tokens (   71.28 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =   29874.94 ms /    43 runs   (  694.77 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   32777.44 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.41 ms /    43 runs   (    0.38 ms per token,  2621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3240.76 ms /    40 tokens (   81.02 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:        eval time =   29173.77 ms /    42 runs   (  694.61 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   32534.37 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.72 ms /    44 runs   (    0.38 ms per token,  2631.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2970.08 ms /    41 tokens (   72.44 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =   29948.87 ms /    43 runs   (  696.49 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   33041.10 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      18.26 ms /    45 runs   (    0.41 ms per token,  2464.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2887.13 ms /    42 tokens (   68.74 ms per token,    14.55 tokens per second)\n",
      "llama_print_timings:        eval time =   30037.87 ms /    44 runs   (  682.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   33051.78 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      15.74 ms /    42 runs   (    0.37 ms per token,  2668.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2099.79 ms /    41 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   28147.99 ms /    41 runs   (  686.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30355.72 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.27 ms /    44 runs   (    0.37 ms per token,  2703.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2043.76 ms /    40 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   29359.85 ms /    43 runs   (  682.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31514.49 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.73 ms /    44 runs   (    0.38 ms per token,  2629.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2090.32 ms /    41 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   29335.92 ms /    43 runs   (  682.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31538.40 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.50 ms /    43 runs   (    0.38 ms per token,  2606.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2039.87 ms /    40 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   28701.70 ms /    42 runs   (  683.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30852.27 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.56 ms /    44 runs   (    0.38 ms per token,  2657.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2087.50 ms /    41 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   29242.97 ms /    43 runs   (  680.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31442.38 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.93 ms /    45 runs   (    0.38 ms per token,  2657.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2055.21 ms /    41 tokens (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_print_timings:        eval time =   30226.62 ms /    44 runs   (  686.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32396.05 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.41 ms /    44 runs   (    0.37 ms per token,  2680.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2159.38 ms /    42 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =   29495.03 ms /    43 runs   (  685.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31766.63 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.85 ms /    44 runs   (    0.38 ms per token,  2611.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2105.88 ms /    41 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =   29680.82 ms /    43 runs   (  690.25 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   31899.15 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.14 ms /    43 runs   (    0.38 ms per token,  2664.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1996.61 ms /    39 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =   28782.25 ms /    42 runs   (  685.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30888.22 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      15.60 ms /    42 runs   (    0.37 ms per token,  2691.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2111.93 ms /    41 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   27979.60 ms /    41 runs   (  682.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30198.06 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.88 ms /    45 runs   (    0.38 ms per token,  2665.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2165.00 ms /    42 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =   30018.38 ms /    44 runs   (  682.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32297.74 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.69 ms /    44 runs   (    0.38 ms per token,  2635.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2137.10 ms /    42 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =   29323.36 ms /    43 runs   (  681.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31573.45 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.56 ms /    44 runs   (    0.38 ms per token,  2657.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2112.43 ms /    41 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   29385.23 ms /    43 runs   (  683.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31609.95 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.83 ms /    44 runs   (    0.38 ms per token,  2615.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2140.22 ms /    42 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   29207.66 ms /    43 runs   (  679.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31459.93 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.45 ms /    44 runs   (    0.37 ms per token,  2674.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2089.20 ms /    41 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =   29273.49 ms /    43 runs   (  680.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31473.41 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.68 ms /    44 runs   (    0.38 ms per token,  2638.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2106.97 ms /    41 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   29317.20 ms /    43 runs   (  681.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31535.92 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.46 ms /    44 runs   (    0.37 ms per token,  2673.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2136.43 ms /    42 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   29097.30 ms /    43 runs   (  676.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31344.59 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.56 ms /    44 runs   (    0.38 ms per token,  2656.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2063.38 ms /    40 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   29336.04 ms /    43 runs   (  682.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31510.61 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.35 ms /    43 runs   (    0.38 ms per token,  2629.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2116.89 ms /    41 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   28720.94 ms /    42 runs   (  683.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30946.40 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.56 ms /    44 runs   (    0.38 ms per token,  2656.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2034.77 ms /    40 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =   29454.14 ms /    43 runs   (  684.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31600.50 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.67 ms /    45 runs   (    0.37 ms per token,  2699.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2091.80 ms /    41 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =   30158.14 ms /    44 runs   (  685.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32364.35 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    44 runs   (    0.40 ms per token,  2523.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2112.07 ms /    42 tokens (   50.29 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =   29586.05 ms /    43 runs   (  688.05 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   31815.12 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.62 ms /    44 runs   (    0.38 ms per token,  2646.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2138.35 ms /    41 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   29396.21 ms /    43 runs   (  683.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31645.10 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.55 ms /    44 runs   (    0.38 ms per token,  2659.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2132.59 ms /    41 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   29284.45 ms /    43 runs   (  681.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31528.32 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    45 runs   (    0.39 ms per token,  2582.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.26 ms /    41 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   30076.06 ms /    44 runs   (  683.55 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32293.97 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.90 ms /    45 runs   (    0.38 ms per token,  2663.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2164.74 ms /    41 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   30319.41 ms /    44 runs   (  689.08 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   32597.89 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.06 ms /    45 runs   (    0.38 ms per token,  2638.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2075.37 ms /    41 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   30264.91 ms /    44 runs   (  687.84 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   32455.82 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      15.95 ms /    43 runs   (    0.37 ms per token,  2695.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.88 ms /    41 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   28479.43 ms /    42 runs   (  678.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30691.26 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      15.42 ms /    42 runs   (    0.37 ms per token,  2724.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2029.41 ms /    39 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   28048.41 ms /    41 runs   (  684.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30182.37 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.75 ms /    44 runs   (    0.38 ms per token,  2626.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2124.17 ms /    41 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   29223.49 ms /    43 runs   (  679.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31460.48 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.81 ms /    43 runs   (    0.39 ms per token,  2557.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2093.22 ms /    41 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   28792.15 ms /    42 runs   (  685.53 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31000.64 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.85 ms /    45 runs   (    0.37 ms per token,  2671.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2025.95 ms /    40 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   30030.18 ms /    44 runs   (  682.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32171.57 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.28 ms /    43 runs   (    0.38 ms per token,  2640.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.65 ms /    41 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =   28495.90 ms /    42 runs   (  678.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30709.03 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.45 ms /    43 runs   (    0.38 ms per token,  2614.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2075.22 ms /    40 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   28581.39 ms /    42 runs   (  680.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30765.86 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.50 ms /    44 runs   (    0.40 ms per token,  2513.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2100.26 ms /    41 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =   29516.05 ms /    43 runs   (  686.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31731.49 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.55 ms /    44 runs   (    0.38 ms per token,  2659.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2149.74 ms /    42 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   29548.07 ms /    43 runs   (  687.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31810.59 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.31 ms /    43 runs   (    0.38 ms per token,  2636.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2093.31 ms /    40 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   28792.34 ms /    42 runs   (  685.53 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30995.24 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.00 ms /    45 runs   (    0.38 ms per token,  2646.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2153.31 ms /    41 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   30191.30 ms /    44 runs   (  686.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32460.25 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.55 ms /    44 runs   (    0.38 ms per token,  2658.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2128.18 ms /    42 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =   29521.38 ms /    43 runs   (  686.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31762.59 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.34 ms /    43 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2046.34 ms /    40 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   28664.13 ms /    42 runs   (  682.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30820.17 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.37 ms /    43 runs   (    0.38 ms per token,  2627.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2083.10 ms /    41 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =   28514.12 ms /    42 runs   (  678.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30706.72 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.04 ms /    45 runs   (    0.38 ms per token,  2640.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2075.25 ms /    41 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   29827.10 ms /    44 runs   (  677.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   32017.59 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.05 ms /    45 runs   (    0.38 ms per token,  2639.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2098.44 ms /    41 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   30044.65 ms /    44 runs   (  682.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32257.40 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.65 ms /    44 runs   (    0.38 ms per token,  2643.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2141.53 ms /    42 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =   29199.41 ms /    43 runs   (  679.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31452.57 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.61 ms /    45 runs   (    0.37 ms per token,  2709.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2131.41 ms /    42 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =   30023.96 ms /    44 runs   (  682.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32269.32 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.78 ms /    45 runs   (    0.37 ms per token,  2681.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.06 ms /    41 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   29815.99 ms /    44 runs   (  677.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   32032.93 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.44 ms /    44 runs   (    0.37 ms per token,  2676.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2033.08 ms /    40 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =   29184.29 ms /    43 runs   (  678.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31328.40 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.03 ms /    43 runs   (    0.37 ms per token,  2681.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2075.77 ms /    41 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =   28424.50 ms /    42 runs   (  676.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30609.28 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.29 ms /    45 runs   (    0.38 ms per token,  2602.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2171.51 ms /    42 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   29555.04 ms /    44 runs   (  671.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   31840.72 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      15.87 ms /    42 runs   (    0.38 ms per token,  2646.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1935.24 ms /    38 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   27731.09 ms /    41 runs   (  676.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29772.41 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.56 ms /    44 runs   (    0.38 ms per token,  2657.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2132.13 ms /    42 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   29197.24 ms /    43 runs   (  679.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31442.31 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.78 ms /    42 runs   (    0.40 ms per token,  2502.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2013.17 ms /    39 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =   28285.73 ms /    41 runs   (  689.90 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   30410.50 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.52 ms /    44 runs   (    0.38 ms per token,  2662.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2050.83 ms /    40 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   29551.34 ms /    43 runs   (  687.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31713.91 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.89 ms /    45 runs   (    0.38 ms per token,  2665.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2047.25 ms /    40 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =   30129.99 ms /    44 runs   (  684.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32291.66 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      15.16 ms /    41 runs   (    0.37 ms per token,  2705.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2041.36 ms /    40 tokens (   51.03 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =   27273.16 ms /    40 runs   (  681.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29418.15 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.88 ms /    45 runs   (    0.38 ms per token,  2666.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2171.13 ms /    42 tokens (   51.69 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   30145.06 ms /    44 runs   (  685.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32430.78 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    44 runs   (    0.40 ms per token,  2524.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2070.35 ms /    40 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   29470.47 ms /    43 runs   (  685.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31655.50 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.06 ms /    45 runs   (    0.38 ms per token,  2637.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2043.13 ms /    40 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =   29964.98 ms /    44 runs   (  681.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32123.39 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      15.89 ms /    42 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2044.11 ms /    40 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =   27848.17 ms /    41 runs   (  679.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29998.82 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.02 ms /    45 runs   (    0.38 ms per token,  2643.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2154.15 ms /    42 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =   29946.71 ms /    44 runs   (  680.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32215.45 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.30 ms /    43 runs   (    0.38 ms per token,  2638.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2155.32 ms /    41 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   28559.83 ms /    42 runs   (  680.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30825.05 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.40 ms /    44 runs   (    0.37 ms per token,  2683.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2087.49 ms /    41 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   29396.83 ms /    43 runs   (  683.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31597.16 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.87 ms /    45 runs   (    0.37 ms per token,  2667.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2116.49 ms /    42 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =   30216.92 ms /    44 runs   (  686.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32448.76 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      18.71 ms /    45 runs   (    0.42 ms per token,  2404.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2073.14 ms /    41 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =   29906.21 ms /    44 runs   (  679.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32103.55 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.97 ms /    45 runs   (    0.38 ms per token,  2651.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2074.82 ms /    41 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   30038.12 ms /    44 runs   (  682.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32228.49 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      17.18 ms /    45 runs   (    0.38 ms per token,  2620.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2081.25 ms /    41 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =   30117.59 ms /    44 runs   (  684.49 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   32314.79 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.84 ms /    45 runs   (    0.37 ms per token,  2672.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2097.06 ms /    41 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   29975.35 ms /    44 runs   (  681.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32187.20 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.45 ms /    44 runs   (    0.37 ms per token,  2674.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2036.88 ms /    40 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =   29639.08 ms /    43 runs   (  689.28 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   31788.70 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5397.38 ms\n",
      "llama_print_timings:      sample time =      16.35 ms /    43 runs   (    0.38 ms per token,  2629.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2027.01 ms /    39 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   28641.97 ms /    42 runs   (  681.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30778.70 ms /    81 tokens\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#run for list_size_3_pos first column of datafram df\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(f\"Completed {i} rows\")\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        prompt = f\"Find the minimum number in the list {df.iloc[i, 4]}\"\n",
    "        prompt_template=f'''SYSTEM: You are a math assistant.I will ask you to find the minimum number in a list. Please answer in the correct format. For example, if I ask 'Find the minimum number in the list [1, 2, 3]', you should answer 'Min([1, 2, 3]) = 1'\n",
    "        USER: {prompt}\n",
    "        ASSISTANT:'''\n",
    "        \n",
    "        response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                    repeat_penalty=1.2, top_k=150,\n",
    "                    echo=False)\n",
    "        \n",
    "        with open('min_output_5_neg_1.txt', 'a') as f:\n",
    "            answer=response[\"choices\"][0][\"text\"]\n",
    "            f.write(f\"{df.iloc[i, 4]} = {answer} \\n\")\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        #write in min_output.txt'\n",
    "        with open('min_output_5_neg_1.txt', 'a') as f:\n",
    "            f.write(f\"{df.iloc[i, 4]} = Error \\n\")\n",
    "            \n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viveksdmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
