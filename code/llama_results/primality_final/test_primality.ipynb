{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required libraries\n",
    "# %pip install transformers\n",
    "# %pip install torchtext\n",
    "# %pip install sentencepiece\n",
    "# %pip install datasets\n",
    "# %pip install torchmetrics\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# #huggiface download\n",
    "# %pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/anaconda3/envs/viveksdmlenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the model llama 2 13b chat gguf\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is in gguf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf\n"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "#print toal path\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.36 GiB (5.51 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  8555.93 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   400.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    85.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '16'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= f\"is 22 prime?\"\n",
    "\n",
    "prompt_template=f'''You are a math assistant. I will ask you to find wheather given number is prime or not. Please answer in the correct format. For example, if I ask 'is 5 prime?' , you should answer 'Yes' if 5 is a prime number or 'No' if 5 is not a prime number. Do not include any other information in your answer.\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT:'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2702.45 ms /    55 tokens (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:        eval time =     677.83 ms /     1 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3386.91 ms /    56 tokens\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file in data folder int_addition.json\n",
    "with open('primality_test.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primes</th>\n",
       "      <th>composites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3187</td>\n",
       "      <td>99160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59509</td>\n",
       "      <td>12005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58787</td>\n",
       "      <td>33309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22861</td>\n",
       "      <td>73881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89519</td>\n",
       "      <td>78681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>38053</td>\n",
       "      <td>83445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>74797</td>\n",
       "      <td>35077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>78823</td>\n",
       "      <td>18386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>61751</td>\n",
       "      <td>19887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>25321</td>\n",
       "      <td>12784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      primes  composites\n",
       "0       3187       99160\n",
       "1      59509       12005\n",
       "2      58787       33309\n",
       "3      22861       73881\n",
       "4      89519       78681\n",
       "...      ...         ...\n",
       "4995   38053       83445\n",
       "4996   74797       35077\n",
       "4997   78823       18386\n",
       "4998   61751       19887\n",
       "4999   25321       12784\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data as pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "#last 5 rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59509"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2150.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3161.75 ms /    65 tokens (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_print_timings:        eval time =     676.72 ms /     1 runs   (  676.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    3844.77 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.12 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     711.51 ms /     1 runs   (  711.51 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1528.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.34 ms /    15 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     749.96 ms /     1 runs   (  749.96 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =    1537.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.90 ms /    16 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =     672.72 ms /     1 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1539.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.41 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     647.57 ms /     1 runs   (  647.57 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.81 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     726.73 ms /     1 runs   (  726.73 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1562.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.70 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     659.23 ms /     1 runs   (  659.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.80 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     646.61 ms /     1 runs   (  646.61 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.44 ms /    16 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     652.07 ms /     1 runs   (  652.07 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1492.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.97 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     697.29 ms /     1 runs   (  697.29 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1512.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.03 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     663.20 ms /     1 runs   (  663.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.54 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     656.07 ms /     1 runs   (  656.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.74 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     694.35 ms /     1 runs   (  694.35 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1515.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.82 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     652.32 ms /     1 runs   (  652.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.25 ms /    15 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     717.06 ms /     1 runs   (  717.06 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1496.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.65 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     706.87 ms /     1 runs   (  706.87 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1532.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.02 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     696.38 ms /     1 runs   (  696.38 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1522.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.81 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     666.14 ms /     1 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.05 ms /    16 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     680.47 ms /     1 runs   (  680.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1513.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.65 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     657.79 ms /     1 runs   (  657.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.28 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     686.26 ms /     1 runs   (  686.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1512.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.13 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     674.03 ms /     1 runs   (  674.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.33 ms /    16 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     698.49 ms /     1 runs   (  698.49 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1537.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.37 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     650.53 ms /     1 runs   (  650.53 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1485.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.14 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     656.72 ms /     1 runs   (  656.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.68 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     662.16 ms /     1 runs   (  662.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1442.18 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2185.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.95 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     652.72 ms /     1 runs   (  652.72 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.50 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     706.41 ms /     1 runs   (  706.41 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1535.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.07 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     662.38 ms /     1 runs   (  662.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.70 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     653.61 ms /     1 runs   (  653.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1496.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2040.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.16 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     664.77 ms /     1 runs   (  664.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.60 ms /    15 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     648.20 ms /     1 runs   (  648.20 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.27 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     666.66 ms /     1 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.98 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     666.72 ms /     1 runs   (  666.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1504.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.26 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     676.21 ms /     1 runs   (  676.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.36 ms /    16 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     651.95 ms /     1 runs   (  651.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1506.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.89 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     701.13 ms /     1 runs   (  701.13 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1517.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.29 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     667.26 ms /     1 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.90 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     661.51 ms /     1 runs   (  661.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.59 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     668.08 ms /     1 runs   (  668.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1440.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.67 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     681.38 ms /     1 runs   (  681.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1499.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.05 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     645.11 ms /     1 runs   (  645.11 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.01 ms /    15 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =     652.21 ms /     1 runs   (  652.21 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1451.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     883.10 ms /    16 tokens (   55.19 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =     717.98 ms /     1 runs   (  717.98 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1606.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.77 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     649.01 ms /     1 runs   (  649.01 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.15 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     687.88 ms /     1 runs   (  687.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1516.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.97 ms /    15 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     683.47 ms /     1 runs   (  683.47 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1454.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.89 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     650.10 ms /     1 runs   (  650.10 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.86 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     658.47 ms /     1 runs   (  658.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1435.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.71 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     644.44 ms /     1 runs   (  644.44 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1487.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.76 ms /    15 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     705.10 ms /     1 runs   (  705.10 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1491.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.08 ms /    15 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     668.76 ms /     1 runs   (  668.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1451.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.74 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     680.61 ms /     1 runs   (  680.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1505.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.42 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     669.09 ms /     1 runs   (  669.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.98 ms /    15 tokens (   51.67 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     633.56 ms /     1 runs   (  633.56 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1414.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.83 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     659.63 ms /     1 runs   (  659.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.93 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     667.49 ms /     1 runs   (  667.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2047.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.95 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     633.81 ms /     1 runs   (  633.81 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1449.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.80 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     665.81 ms /     1 runs   (  665.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.05 ms /    15 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     645.14 ms /     1 runs   (  645.14 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1421.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     868.66 ms /    16 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =     647.41 ms /     1 runs   (  647.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1521.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.14 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     649.25 ms /     1 runs   (  649.25 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.23 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     664.14 ms /     1 runs   (  664.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.80 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     675.51 ms /     1 runs   (  675.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.94 ms /    16 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     671.58 ms /     1 runs   (  671.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1506.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.78 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     711.11 ms /     1 runs   (  711.11 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1528.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.75 ms /    16 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     651.81 ms /     1 runs   (  651.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1507.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.53 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     707.34 ms /     1 runs   (  707.34 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1537.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.39 ms /    14 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =     671.83 ms /     1 runs   (  671.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1425.45 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.73 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     663.46 ms /     1 runs   (  663.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.45 ms /    16 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     654.29 ms /     1 runs   (  654.29 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1492.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.31 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     643.65 ms /     1 runs   (  643.65 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1421.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.51 ms /    15 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     655.25 ms /     1 runs   (  655.25 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1442.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.45 ms /    16 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     678.18 ms /     1 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1523.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.58 ms /    15 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     646.67 ms /     1 runs   (  646.67 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1440.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.87 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     636.48 ms /     1 runs   (  636.48 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1458.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.17 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     655.88 ms /     1 runs   (  655.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.78 ms /    15 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     659.12 ms /     1 runs   (  659.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1447.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.79 ms /    15 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     658.52 ms /     1 runs   (  658.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1452.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.72 ms /    16 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     672.00 ms /     1 runs   (  672.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1518.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.00 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     659.57 ms /     1 runs   (  659.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.39 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     655.09 ms /     1 runs   (  655.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2118.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.78 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     648.76 ms /     1 runs   (  648.76 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1480.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2089.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.11 ms /    16 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     667.91 ms /     1 runs   (  667.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1511.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.73 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     663.66 ms /     1 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2141.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.29 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     662.76 ms /     1 runs   (  662.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.11 ms /    16 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     689.03 ms /     1 runs   (  689.03 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1524.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.42 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     670.73 ms /     1 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.33 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     644.55 ms /     1 runs   (  644.55 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1482.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.66 ms /    16 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     663.30 ms /     1 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1510.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.33 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     665.32 ms /     1 runs   (  665.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.48 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     651.76 ms /     1 runs   (  651.76 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.89 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     646.96 ms /     1 runs   (  646.96 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.31 ms /    16 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     687.47 ms /     1 runs   (  687.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1528.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.74 ms /    16 tokens (   52.23 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     691.91 ms /     1 runs   (  691.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1532.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.17 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     677.81 ms /     1 runs   (  677.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.02 ms /    16 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =     644.51 ms /     1 runs   (  644.51 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1498.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.29 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     700.40 ms /     1 runs   (  700.40 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1523.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.00 ms /    16 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =     710.89 ms /     1 runs   (  710.89 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1574.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.67 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     681.09 ms /     1 runs   (  681.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1504.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.50 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     655.59 ms /     1 runs   (  655.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.65 ms /    16 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     652.45 ms /     1 runs   (  652.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1493.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.64 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     659.08 ms /     1 runs   (  659.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1496.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.41 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     678.06 ms /     1 runs   (  678.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1456.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.68 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     677.56 ms /     1 runs   (  677.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1503.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.96 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     650.27 ms /     1 runs   (  650.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.40 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     675.60 ms /     1 runs   (  675.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1499.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.16 ms /    15 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     655.94 ms /     1 runs   (  655.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1427.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.65 ms /    16 tokens (   51.67 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     651.86 ms /     1 runs   (  651.86 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.84 ms /    15 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     641.19 ms /     1 runs   (  641.19 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1416.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2125.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.24 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     673.27 ms /     1 runs   (  673.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1507.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.70 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     696.37 ms /     1 runs   (  696.37 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1527.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.28 ms /    15 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     675.08 ms /     1 runs   (  675.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1443.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.22 ms /    15 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     649.36 ms /     1 runs   (  649.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1423.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.39 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     660.82 ms /     1 runs   (  660.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.79 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     651.86 ms /     1 runs   (  651.86 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.23 ms /    16 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =     641.03 ms /     1 runs   (  641.03 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1503.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.57 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     667.78 ms /     1 runs   (  667.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.89 ms /    15 tokens (   54.13 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =     643.27 ms /     1 runs   (  643.27 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.38 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     656.40 ms /     1 runs   (  656.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.70 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     694.53 ms /     1 runs   (  694.53 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1519.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.83 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     660.89 ms /     1 runs   (  660.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.65 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     687.12 ms /     1 runs   (  687.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.24 ms /    16 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     647.01 ms /     1 runs   (  647.01 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.24 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     650.90 ms /     1 runs   (  650.90 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.60 ms /    15 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     660.48 ms /     1 runs   (  660.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1443.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     865.45 ms /    16 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =     677.43 ms /     1 runs   (  677.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1548.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.91 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     664.62 ms /     1 runs   (  664.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.27 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     690.94 ms /     1 runs   (  690.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1516.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.22 ms /    16 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     693.29 ms /     1 runs   (  693.29 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1525.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.81 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     676.49 ms /     1 runs   (  676.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1456.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.29 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     673.26 ms /     1 runs   (  673.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.49 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     668.79 ms /     1 runs   (  668.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.50 ms /    14 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     653.12 ms /     1 runs   (  653.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1383.86 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.27 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     661.14 ms /     1 runs   (  661.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.01 ms /    16 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     663.09 ms /     1 runs   (  663.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /     2 runs   (    0.65 ms per token,  1530.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.02 ms /    13 tokens (   53.69 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =     690.92 ms /     1 runs   (  690.92 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1396.40 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.93 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     661.72 ms /     1 runs   (  661.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.36 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     645.41 ms /     1 runs   (  645.41 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2109.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.95 ms /    15 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     664.07 ms /     1 runs   (  664.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1439.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.70 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     663.57 ms /     1 runs   (  663.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.39 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     666.83 ms /     1 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.41 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     656.46 ms /     1 runs   (  656.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.28 ms /    16 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     661.46 ms /     1 runs   (  661.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.19 ms /    15 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     660.51 ms /     1 runs   (  660.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1433.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.75 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     672.82 ms /     1 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.27 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     652.06 ms /     1 runs   (  652.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.25 ms /    16 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     672.22 ms /     1 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1508.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.99 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     672.11 ms /     1 runs   (  672.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.99 ms /    15 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     682.29 ms /     1 runs   (  682.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1471.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     749.23 ms /    14 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =     722.00 ms /     1 runs   (  722.00 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1476.44 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.06 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     750.63 ms /     1 runs   (  750.63 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =    1571.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.12 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     652.11 ms /     1 runs   (  652.11 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.98 ms /    15 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     666.79 ms /     1 runs   (  666.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1440.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.09 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     683.88 ms /     1 runs   (  683.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1511.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.47 ms /    13 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     666.09 ms /     1 runs   (  666.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1360.16 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.86 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     648.49 ms /     1 runs   (  648.49 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1481.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.64 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     650.88 ms /     1 runs   (  650.88 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.97 ms /    16 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =     696.20 ms /     1 runs   (  696.20 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1549.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.55 ms /    15 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     665.01 ms /     1 runs   (  665.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1450.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.76 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     682.41 ms /     1 runs   (  682.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1506.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.54 ms /    16 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     673.90 ms /     1 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1514.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.92 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     646.83 ms /     1 runs   (  646.83 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1478.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.08 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     657.81 ms /     1 runs   (  657.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     876.40 ms /    16 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =     647.73 ms /     1 runs   (  647.73 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1529.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.98 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     654.16 ms /     1 runs   (  654.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.97 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     657.59 ms /     1 runs   (  657.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.59 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     654.76 ms /     1 runs   (  654.76 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.36 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     661.04 ms /     1 runs   (  661.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.44 ms /    15 tokens (   52.56 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     656.31 ms /     1 runs   (  656.31 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1449.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.85 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     647.80 ms /     1 runs   (  647.80 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.82 ms /    14 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     645.92 ms /     1 runs   (  645.92 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1377.95 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.34 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     680.95 ms /     1 runs   (  680.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1502.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.31 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     647.46 ms /     1 runs   (  647.46 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.70 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     702.65 ms /     1 runs   (  702.65 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1522.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.46 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     651.36 ms /     1 runs   (  651.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.61 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     677.70 ms /     1 runs   (  677.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1506.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.98 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     652.95 ms /     1 runs   (  652.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1425.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.34 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     673.46 ms /     1 runs   (  673.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.81 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     672.34 ms /     1 runs   (  672.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.88 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     660.03 ms /     1 runs   (  660.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2081.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.49 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     649.06 ms /     1 runs   (  649.06 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1480.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.00 ms /    15 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     723.88 ms /     1 runs   (  723.88 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1505.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.58 ms /    14 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     670.57 ms /     1 runs   (  670.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1395.26 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.37 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     657.72 ms /     1 runs   (  657.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.83 ms /    16 tokens (   51.61 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     673.10 ms /     1 runs   (  673.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.10 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     664.69 ms /     1 runs   (  664.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.11 ms /    16 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     651.39 ms /     1 runs   (  651.39 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1490.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.36 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     657.42 ms /     1 runs   (  657.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.53 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     651.45 ms /     1 runs   (  651.45 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.54 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     679.81 ms /     1 runs   (  679.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1499.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.49 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     672.77 ms /     1 runs   (  672.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.07 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     673.08 ms /     1 runs   (  673.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.26 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     658.72 ms /     1 runs   (  658.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     872.23 ms /    16 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =     709.31 ms /     1 runs   (  709.31 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1586.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.82 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     699.18 ms /     1 runs   (  699.18 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1518.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.04 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     687.74 ms /     1 runs   (  687.74 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1509.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.11 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     662.26 ms /     1 runs   (  662.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.86 ms /    16 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     666.16 ms /     1 runs   (  666.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1502.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.50 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     663.57 ms /     1 runs   (  663.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.64 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     650.47 ms /     1 runs   (  650.47 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2136.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.99 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     661.31 ms /     1 runs   (  661.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.74 ms /    16 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     681.17 ms /     1 runs   (  681.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1512.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     872.39 ms /    16 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =     706.87 ms /     1 runs   (  706.87 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1584.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.51 ms /    16 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     655.94 ms /     1 runs   (  655.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1505.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.16 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     690.15 ms /     1 runs   (  690.15 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1505.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.96 ms /    15 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     714.27 ms /     1 runs   (  714.27 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1492.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.40 ms /    16 tokens (   51.96 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     651.62 ms /     1 runs   (  651.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1488.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.82 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     656.20 ms /     1 runs   (  656.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.25 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     669.21 ms /     1 runs   (  669.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.37 ms /    15 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     684.95 ms /     1 runs   (  684.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1476.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.52 ms /    16 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     663.42 ms /     1 runs   (  663.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1501.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.31 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     650.71 ms /     1 runs   (  650.71 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.49 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     690.22 ms /     1 runs   (  690.22 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1506.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.49 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     662.48 ms /     1 runs   (  662.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.80 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     675.91 ms /     1 runs   (  675.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.64 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     653.48 ms /     1 runs   (  653.48 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.94 ms /    15 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     657.52 ms /     1 runs   (  657.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1433.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.96 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     693.11 ms /     1 runs   (  693.11 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1516.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.20 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     682.93 ms /     1 runs   (  682.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.52 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     652.13 ms /     1 runs   (  652.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.20 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     676.54 ms /     1 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.31 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     658.02 ms /     1 runs   (  658.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.35 ms /    15 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     652.68 ms /     1 runs   (  652.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1436.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.29 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     696.53 ms /     1 runs   (  696.53 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1513.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.78 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     655.63 ms /     1 runs   (  655.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2120.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.59 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     705.39 ms /     1 runs   (  705.39 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1528.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.09 ms /    15 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     678.10 ms /     1 runs   (  678.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1451.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.95 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     683.98 ms /     1 runs   (  683.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1501.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.84 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     653.53 ms /     1 runs   (  653.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.69 ms /    16 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     657.25 ms /     1 runs   (  657.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1502.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.53 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     659.14 ms /     1 runs   (  659.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.99 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     659.07 ms /     1 runs   (  659.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.04 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     659.10 ms /     1 runs   (  659.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.47 ms /    15 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     655.96 ms /     1 runs   (  655.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1432.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.72 ms /    15 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     659.91 ms /     1 runs   (  659.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1441.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.32 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     657.63 ms /     1 runs   (  657.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.37 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     662.12 ms /     1 runs   (  662.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.47 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     666.47 ms /     1 runs   (  666.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.70 ms /    15 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     648.87 ms /     1 runs   (  648.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1433.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.57 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     647.95 ms /     1 runs   (  647.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.15 ms /    16 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     684.71 ms /     1 runs   (  684.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1514.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.16 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     664.67 ms /     1 runs   (  664.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.14 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     674.46 ms /     1 runs   (  674.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1501.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.18 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     668.80 ms /     1 runs   (  668.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.94 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     648.60 ms /     1 runs   (  648.60 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.12 ms /    15 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     699.43 ms /     1 runs   (  699.43 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1475.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.35 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     651.02 ms /     1 runs   (  651.02 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1427.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.76 ms /    15 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     654.35 ms /     1 runs   (  654.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1449.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.19 ms /    16 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =     666.56 ms /     1 runs   (  666.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1530.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.09 ms /    16 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     660.27 ms /     1 runs   (  660.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1495.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.20 ms /    16 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     653.46 ms /     1 runs   (  653.46 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.93 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     672.25 ms /     1 runs   (  672.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1489.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2103.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.49 ms /    15 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     649.28 ms /     1 runs   (  649.28 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1432.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.52 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     726.50 ms /     1 runs   (  726.50 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1561.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.79 ms /    16 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     664.98 ms /     1 runs   (  664.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1506.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.44 ms /    16 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =     661.44 ms /     1 runs   (  661.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1522.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.58 ms /    15 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     703.96 ms /     1 runs   (  703.96 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1485.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.85 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     705.06 ms /     1 runs   (  705.06 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1530.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.56 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     676.83 ms /     1 runs   (  676.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1512.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.59 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     665.60 ms /     1 runs   (  665.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2032.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.76 ms /    15 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     678.19 ms /     1 runs   (  678.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1465.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.49 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     663.39 ms /     1 runs   (  663.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1438.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.25 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     645.09 ms /     1 runs   (  645.09 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.23 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     667.45 ms /     1 runs   (  667.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1510.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.89 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     654.16 ms /     1 runs   (  654.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.16 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     688.89 ms /     1 runs   (  688.89 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1503.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.56 ms /    15 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =     723.38 ms /     1 runs   (  723.38 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1528.30 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.73 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     649.97 ms /     1 runs   (  649.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1492.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.64 ms /    16 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =     660.10 ms /     1 runs   (  660.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1523.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     881.14 ms /    16 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =     683.42 ms /     1 runs   (  683.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1570.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.99 ms /    16 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =     671.21 ms /     1 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1520.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.48 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     660.27 ms /     1 runs   (  660.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.69 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     696.38 ms /     1 runs   (  696.38 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1471.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.63 ms /    15 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     674.67 ms /     1 runs   (  674.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1443.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.23 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     657.37 ms /     1 runs   (  657.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.45 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     662.76 ms /     1 runs   (  662.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.94 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     709.77 ms /     1 runs   (  709.77 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1524.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.24 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     737.29 ms /     1 runs   (  737.29 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1557.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.32 ms /    16 tokens (   52.65 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     664.61 ms /     1 runs   (  664.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1512.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.12 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     658.88 ms /     1 runs   (  658.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.42 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     667.67 ms /     1 runs   (  667.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.64 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     646.17 ms /     1 runs   (  646.17 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.85 ms /    15 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     655.42 ms /     1 runs   (  655.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1434.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.64 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     662.32 ms /     1 runs   (  662.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.22 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     680.69 ms /     1 runs   (  680.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1499.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.23 ms /    16 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     680.85 ms /     1 runs   (  680.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1516.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.97 ms /    15 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     677.48 ms /     1 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1475.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.91 ms /    15 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     702.43 ms /     1 runs   (  702.43 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1486.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.32 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     650.19 ms /     1 runs   (  650.19 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1487.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.51 ms /    16 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     647.99 ms /     1 runs   (  647.99 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1489.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.68 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     655.30 ms /     1 runs   (  655.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.09 ms /    16 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     660.74 ms /     1 runs   (  660.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.37 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     673.47 ms /     1 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1511.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.88 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     689.27 ms /     1 runs   (  689.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1507.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.37 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     666.83 ms /     1 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1503.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.24 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     660.55 ms /     1 runs   (  660.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.48 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     662.24 ms /     1 runs   (  662.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.89 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     654.38 ms /     1 runs   (  654.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.96 ms /    15 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     658.13 ms /     1 runs   (  658.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1441.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.29 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     664.88 ms /     1 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1442.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.32 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     658.19 ms /     1 runs   (  658.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.52 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     659.76 ms /     1 runs   (  659.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.89 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     647.93 ms /     1 runs   (  647.93 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     878.77 ms /    16 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =     676.05 ms /     1 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1560.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.81 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     651.37 ms /     1 runs   (  651.37 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.97 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     660.54 ms /     1 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1430.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.49 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     650.36 ms /     1 runs   (  650.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1481.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.46 ms /    15 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     653.00 ms /     1 runs   (  653.00 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1433.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.26 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     696.30 ms /     1 runs   (  696.30 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1510.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.25 ms /    15 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =     699.29 ms /     1 runs   (  699.29 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1508.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.64 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     650.74 ms /     1 runs   (  650.74 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.28 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     646.95 ms /     1 runs   (  646.95 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1472.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.72 ms /    15 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     654.88 ms /     1 runs   (  654.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1434.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.73 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     710.11 ms /     1 runs   (  710.11 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1527.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2166.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.58 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     673.72 ms /     1 runs   (  673.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.62 ms /    15 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     695.01 ms /     1 runs   (  695.01 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1473.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.76 ms /    15 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     650.73 ms /     1 runs   (  650.73 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1424.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.12 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     669.60 ms /     1 runs   (  669.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1501.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.51 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     670.64 ms /     1 runs   (  670.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1501.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.64 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     673.05 ms /     1 runs   (  673.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.87 ms /    15 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =     655.12 ms /     1 runs   (  655.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.48 ms /    15 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =     653.06 ms /     1 runs   (  653.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1465.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.84 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     658.54 ms /     1 runs   (  658.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.05 ms /    15 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     661.43 ms /     1 runs   (  661.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1433.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.29 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     672.87 ms /     1 runs   (  672.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.94 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     647.54 ms /     1 runs   (  647.54 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.17 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     664.31 ms /     1 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.03 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     649.95 ms /     1 runs   (  649.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.41 ms /    15 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     657.76 ms /     1 runs   (  657.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1444.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.65 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     683.56 ms /     1 runs   (  683.56 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1503.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.73 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     676.37 ms /     1 runs   (  676.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1449.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.11 ms /    15 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     663.14 ms /     1 runs   (  663.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1447.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.65 ms /    15 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     681.56 ms /     1 runs   (  681.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1471.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.12 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     653.14 ms /     1 runs   (  653.14 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.27 ms /    14 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     650.56 ms /     1 runs   (  650.56 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1385.90 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.57 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     656.53 ms /     1 runs   (  656.53 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.71 ms /    16 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     670.95 ms /     1 runs   (  670.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1504.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.51 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     649.30 ms /     1 runs   (  649.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.06 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     656.28 ms /     1 runs   (  656.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.35 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     670.91 ms /     1 runs   (  670.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.29 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     670.45 ms /     1 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1500.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.96 ms /    15 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     692.10 ms /     1 runs   (  692.10 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1486.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.16 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     675.06 ms /     1 runs   (  675.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.58 ms /    15 tokens (   51.51 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     668.66 ms /     1 runs   (  668.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1446.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.02 ms /    15 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     689.42 ms /     1 runs   (  689.42 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1476.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.92 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     652.13 ms /     1 runs   (  652.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2185.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.19 ms /    13 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     652.11 ms /     1 runs   (  652.11 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1340.89 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.46 ms /    16 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     694.61 ms /     1 runs   (  694.61 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1543.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.79 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     647.31 ms /     1 runs   (  647.31 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.46 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     682.90 ms /     1 runs   (  682.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1500.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.38 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     646.16 ms /     1 runs   (  646.16 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.07 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     672.07 ms /     1 runs   (  672.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1506.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.62 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     649.49 ms /     1 runs   (  649.49 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.04 ms /    15 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     694.57 ms /     1 runs   (  694.57 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1472.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.45 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     708.85 ms /     1 runs   (  708.85 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1530.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.24 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     675.61 ms /     1 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1519.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.49 ms /    15 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     662.80 ms /     1 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1432.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.19 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     646.03 ms /     1 runs   (  646.03 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.22 ms /    15 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     659.88 ms /     1 runs   (  659.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1431.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.17 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     658.42 ms /     1 runs   (  658.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.79 ms /    15 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     655.43 ms /     1 runs   (  655.43 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1428.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.99 ms /    15 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     700.81 ms /     1 runs   (  700.81 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1475.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.10 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     733.12 ms /     1 runs   (  733.12 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1551.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.85 ms /    15 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     671.31 ms /     1 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1454.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.78 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     683.43 ms /     1 runs   (  683.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1516.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.33 ms /    16 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =     691.78 ms /     1 runs   (  691.78 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1563.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.61 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     655.19 ms /     1 runs   (  655.19 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.64 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     655.84 ms /     1 runs   (  655.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.28 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     655.63 ms /     1 runs   (  655.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.14 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     643.23 ms /     1 runs   (  643.23 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.41 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     649.42 ms /     1 runs   (  649.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.66 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     654.67 ms /     1 runs   (  654.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.33 ms /    16 tokens (   50.65 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     744.47 ms /     1 runs   (  744.47 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =    1560.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.21 ms /    15 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     653.41 ms /     1 runs   (  653.41 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1427.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.24 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     648.49 ms /     1 runs   (  648.49 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.32 ms /    15 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     661.13 ms /     1 runs   (  661.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1466.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.02 ms /    15 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     654.46 ms /     1 runs   (  654.46 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1430.10 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.05 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     663.56 ms /     1 runs   (  663.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1495.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.15 ms /    16 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     714.76 ms /     1 runs   (  714.76 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1558.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.99 ms /    15 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     671.25 ms /     1 runs   (  671.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1457.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.01 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     722.26 ms /     1 runs   (  722.26 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1542.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.53 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     650.04 ms /     1 runs   (  650.04 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.63 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     652.00 ms /     1 runs   (  652.00 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2155.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.34 ms /    15 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     669.27 ms /     1 runs   (  669.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1457.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.30 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     665.92 ms /     1 runs   (  665.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.39 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     679.55 ms /     1 runs   (  679.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1495.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.22 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     648.05 ms /     1 runs   (  648.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.54 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     647.34 ms /     1 runs   (  647.34 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.61 ms /    16 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     657.96 ms /     1 runs   (  657.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1511.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.64 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     667.26 ms /     1 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.89 ms /    16 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =     656.32 ms /     1 runs   (  656.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1515.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.39 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     701.88 ms /     1 runs   (  701.88 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1528.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.46 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     669.72 ms /     1 runs   (  669.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1484.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.97 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     657.80 ms /     1 runs   (  657.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1502.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.11 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     653.87 ms /     1 runs   (  653.87 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.62 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     659.86 ms /     1 runs   (  659.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.39 ms /    16 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     659.04 ms /     1 runs   (  659.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.00 ms /    16 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     659.59 ms /     1 runs   (  659.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     863.82 ms /    16 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =     648.76 ms /     1 runs   (  648.76 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1518.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.48 ms /    16 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     691.67 ms /     1 runs   (  691.67 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1546.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.45 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     656.56 ms /     1 runs   (  656.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.47 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     658.15 ms /     1 runs   (  658.15 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.41 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     660.00 ms /     1 runs   (  660.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2178.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.80 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     711.74 ms /     1 runs   (  711.74 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1527.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2132.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.89 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     720.86 ms /     1 runs   (  720.86 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1541.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.14 ms /    16 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     674.88 ms /     1 runs   (  674.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1513.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.12 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     680.64 ms /     1 runs   (  680.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1508.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.64 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     655.67 ms /     1 runs   (  655.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.31 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     660.40 ms /     1 runs   (  660.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1473.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.22 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     667.13 ms /     1 runs   (  667.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.52 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     679.15 ms /     1 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1510.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.55 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     666.95 ms /     1 runs   (  666.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.22 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     683.00 ms /     1 runs   (  683.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1512.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2107.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.65 ms /    14 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     716.91 ms /     1 runs   (  716.91 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1453.42 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.69 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     685.11 ms /     1 runs   (  685.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1514.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.69 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     655.70 ms /     1 runs   (  655.70 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.97 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     662.93 ms /     1 runs   (  662.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.09 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     656.95 ms /     1 runs   (  656.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.59 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     646.92 ms /     1 runs   (  646.92 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.82 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     654.21 ms /     1 runs   (  654.21 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.98 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     658.95 ms /     1 runs   (  658.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.14 ms /    16 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     657.35 ms /     1 runs   (  657.35 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1494.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.66 ms /    15 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     652.46 ms /     1 runs   (  652.46 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1442.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.30 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     672.51 ms /     1 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.37 ms /    16 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     685.20 ms /     1 runs   (  685.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1511.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.79 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     707.26 ms /     1 runs   (  707.26 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1523.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.14 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     678.60 ms /     1 runs   (  678.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1450.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.23 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     649.25 ms /     1 runs   (  649.25 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1493.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.35 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     658.72 ms /     1 runs   (  658.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.01 ms /    16 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     682.42 ms /     1 runs   (  682.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1501.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.59 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     652.84 ms /     1 runs   (  652.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.88 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     671.74 ms /     1 runs   (  671.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1505.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.70 ms /    16 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     700.59 ms /     1 runs   (  700.59 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1535.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.90 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     658.71 ms /     1 runs   (  658.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.37 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     658.09 ms /     1 runs   (  658.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.17 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     647.65 ms /     1 runs   (  647.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.19 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     641.69 ms /     1 runs   (  641.69 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1461.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.41 ms /    15 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     662.94 ms /     1 runs   (  662.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1436.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.65 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     663.82 ms /     1 runs   (  663.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1501.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.85 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     642.15 ms /     1 runs   (  642.15 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1467.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.87 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     668.49 ms /     1 runs   (  668.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.32 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     648.19 ms /     1 runs   (  648.19 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1484.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.13 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     657.85 ms /     1 runs   (  657.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.03 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     644.76 ms /     1 runs   (  644.76 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.98 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     695.28 ms /     1 runs   (  695.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1466.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.87 ms /    16 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     696.09 ms /     1 runs   (  696.09 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1542.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.60 ms /    14 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     676.16 ms /     1 runs   (  676.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1402.84 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.46 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     660.26 ms /     1 runs   (  660.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.66 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     655.94 ms /     1 runs   (  655.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1429.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.03 ms /    16 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     685.62 ms /     1 runs   (  685.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1528.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.90 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     671.16 ms /     1 runs   (  671.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.65 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     670.96 ms /     1 runs   (  670.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1489.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.96 ms /    15 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =     647.56 ms /     1 runs   (  647.56 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1449.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.13 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     711.34 ms /     1 runs   (  711.34 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1527.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.11 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     689.82 ms /     1 runs   (  689.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1507.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.40 ms /    14 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     657.09 ms /     1 runs   (  657.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1385.57 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.70 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     658.73 ms /     1 runs   (  658.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.76 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     696.84 ms /     1 runs   (  696.84 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1514.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.27 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     706.47 ms /     1 runs   (  706.47 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1541.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.25 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     659.01 ms /     1 runs   (  659.01 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.37 ms /    15 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     675.98 ms /     1 runs   (  675.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1455.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.93 ms /    14 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     659.18 ms /     1 runs   (  659.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1387.26 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.32 ms /    15 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     645.56 ms /     1 runs   (  645.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1430.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.07 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     666.03 ms /     1 runs   (  666.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.10 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     662.89 ms /     1 runs   (  662.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.83 ms /    15 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     707.91 ms /     1 runs   (  707.91 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1484.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.80 ms /    15 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     661.09 ms /     1 runs   (  661.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1451.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.41 ms /    15 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =     650.72 ms /     1 runs   (  650.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1484.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.32 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     666.61 ms /     1 runs   (  666.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.80 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     676.89 ms /     1 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1504.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.43 ms /    16 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     674.58 ms /     1 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1520.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.08 ms /    15 tokens (   55.67 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =     678.99 ms /     1 runs   (  678.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1520.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.26 ms /    16 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     735.32 ms /     1 runs   (  735.32 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1587.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.39 ms /    16 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     654.09 ms /     1 runs   (  654.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1500.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.75 ms /    15 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     724.54 ms /     1 runs   (  724.54 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1519.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.85 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     666.55 ms /     1 runs   (  666.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.72 ms /    15 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     678.50 ms /     1 runs   (  678.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1465.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.20 ms /    16 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     661.05 ms /     1 runs   (  661.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1506.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.94 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     725.00 ms /     1 runs   (  725.00 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1551.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.19 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     651.16 ms /     1 runs   (  651.16 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.85 ms /    16 tokens (   52.18 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     679.98 ms /     1 runs   (  679.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1519.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.58 ms /    13 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     669.43 ms /     1 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1352.53 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.80 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     686.94 ms /     1 runs   (  686.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1517.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.23 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     645.57 ms /     1 runs   (  645.57 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.63 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     670.92 ms /     1 runs   (  670.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     941.38 ms /    16 tokens (   58.84 ms per token,    17.00 tokens per second)\n",
      "llama_print_timings:        eval time =     686.39 ms /     1 runs   (  686.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1633.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.01 ms /    16 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     647.05 ms /     1 runs   (  647.05 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1499.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.29 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     643.45 ms /     1 runs   (  643.45 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1478.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.77 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     673.57 ms /     1 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.82 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     720.37 ms /     1 runs   (  720.37 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1538.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.10 ms /    16 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     670.04 ms /     1 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1512.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.26 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     685.36 ms /     1 runs   (  685.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.32 ms /    15 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     660.20 ms /     1 runs   (  660.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1460.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.92 ms /    15 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     661.32 ms /     1 runs   (  661.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1438.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.49 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     653.63 ms /     1 runs   (  653.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.25 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     655.06 ms /     1 runs   (  655.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.54 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     662.88 ms /     1 runs   (  662.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.59 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     650.34 ms /     1 runs   (  650.34 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.54 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     648.72 ms /     1 runs   (  648.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.82 ms /    16 tokens (   51.61 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     698.18 ms /     1 runs   (  698.18 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1529.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.24 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     643.35 ms /     1 runs   (  643.35 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.26 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     647.92 ms /     1 runs   (  647.92 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.43 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     670.90 ms /     1 runs   (  670.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2192.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.73 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     672.72 ms /     1 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1500.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.39 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     658.14 ms /     1 runs   (  658.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.90 ms /    16 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     671.92 ms /     1 runs   (  671.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1484.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.38 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     636.53 ms /     1 runs   (  636.53 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1468.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.49 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     667.23 ms /     1 runs   (  667.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     855.93 ms /    16 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =     690.34 ms /     1 runs   (  690.34 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1551.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.07 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     646.66 ms /     1 runs   (  646.66 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1481.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.57 ms /    16 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     660.85 ms /     1 runs   (  660.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1502.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.40 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     645.98 ms /     1 runs   (  645.98 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1481.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.42 ms /    15 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     734.98 ms /     1 runs   (  734.98 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1527.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.94 ms /    16 tokens (   53.43 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =     671.19 ms /     1 runs   (  671.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1531.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.91 ms /    16 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     661.28 ms /     1 runs   (  661.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.04 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     680.15 ms /     1 runs   (  680.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1508.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.20 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     692.19 ms /     1 runs   (  692.19 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1513.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.62 ms /    16 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     669.95 ms /     1 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1520.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2111.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.75 ms /    15 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     632.51 ms /     1 runs   (  632.51 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1411.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.38 ms /    15 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =     651.39 ms /     1 runs   (  651.39 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.39 ms /    15 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =     651.04 ms /     1 runs   (  651.04 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.34 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     656.94 ms /     1 runs   (  656.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.30 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     667.24 ms /     1 runs   (  667.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.30 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     668.09 ms /     1 runs   (  668.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.52 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     650.39 ms /     1 runs   (  650.39 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.61 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     647.96 ms /     1 runs   (  647.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.61 ms /    15 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     649.94 ms /     1 runs   (  649.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1438.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.83 ms /    15 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     654.61 ms /     1 runs   (  654.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1424.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.73 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     665.05 ms /     1 runs   (  665.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.29 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     660.24 ms /     1 runs   (  660.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.33 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     663.90 ms /     1 runs   (  663.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.24 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     674.65 ms /     1 runs   (  674.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1499.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.39 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     646.30 ms /     1 runs   (  646.30 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.78 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     655.23 ms /     1 runs   (  655.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.51 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     651.86 ms /     1 runs   (  651.86 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.30 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     664.72 ms /     1 runs   (  664.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.38 ms /    15 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     652.59 ms /     1 runs   (  652.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1440.74 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.88 ms /    16 tokens (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     660.70 ms /     1 runs   (  660.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.50 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     663.63 ms /     1 runs   (  663.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.76 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     673.89 ms /     1 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1503.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.97 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     659.83 ms /     1 runs   (  659.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.46 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     647.52 ms /     1 runs   (  647.52 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     755.71 ms /    14 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =     648.91 ms /     1 runs   (  648.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1410.24 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.18 ms /    16 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     658.27 ms /     1 runs   (  658.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1494.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.60 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     649.94 ms /     1 runs   (  649.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.99 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     640.82 ms /     1 runs   (  640.82 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1414.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.52 ms /    15 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     660.47 ms /     1 runs   (  660.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1432.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.54 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     649.27 ms /     1 runs   (  649.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.72 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     679.30 ms /     1 runs   (  679.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1508.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.58 ms /    14 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     662.01 ms /     1 runs   (  662.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1392.42 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.60 ms /    15 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     659.05 ms /     1 runs   (  659.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1436.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.97 ms /    15 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =     661.22 ms /     1 runs   (  661.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1472.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.68 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     658.02 ms /     1 runs   (  658.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2094.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.53 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     665.00 ms /     1 runs   (  665.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.89 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     672.74 ms /     1 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1502.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.57 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     669.13 ms /     1 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.99 ms /    16 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     686.29 ms /     1 runs   (  686.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1535.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.26 ms /    15 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     655.27 ms /     1 runs   (  655.27 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1425.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.77 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     663.59 ms /     1 runs   (  663.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.58 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     659.01 ms /     1 runs   (  659.01 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2074.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.38 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     664.57 ms /     1 runs   (  664.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1502.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.50 ms /    14 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     700.68 ms /     1 runs   (  700.68 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1438.50 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.80 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     655.89 ms /     1 runs   (  655.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.49 ms /    16 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     662.59 ms /     1 runs   (  662.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1506.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.86 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     655.30 ms /     1 runs   (  655.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.44 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     660.86 ms /     1 runs   (  660.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.85 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     686.07 ms /     1 runs   (  686.07 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1515.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.05 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     647.48 ms /     1 runs   (  647.48 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1487.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.34 ms /    16 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     662.16 ms /     1 runs   (  662.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1517.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.82 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     677.46 ms /     1 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1502.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.23 ms /    15 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     661.09 ms /     1 runs   (  661.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1440.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.60 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     652.09 ms /     1 runs   (  652.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.39 ms /    16 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     641.01 ms /     1 runs   (  641.01 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1484.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.07 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     663.75 ms /     1 runs   (  663.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.26 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     654.78 ms /     1 runs   (  654.78 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1487.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.97 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     676.73 ms /     1 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.62 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     658.37 ms /     1 runs   (  658.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.84 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     696.53 ms /     1 runs   (  696.53 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1515.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.47 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     644.09 ms /     1 runs   (  644.09 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.92 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     713.91 ms /     1 runs   (  713.91 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1489.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.17 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     677.26 ms /     1 runs   (  677.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.25 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     701.25 ms /     1 runs   (  701.25 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1527.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.73 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     672.10 ms /     1 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.66 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     686.25 ms /     1 runs   (  686.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.26 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     712.19 ms /     1 runs   (  712.19 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1555.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.20 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     666.44 ms /     1 runs   (  666.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.93 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     661.62 ms /     1 runs   (  661.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.69 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     664.38 ms /     1 runs   (  664.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.63 ms /    15 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     686.81 ms /     1 runs   (  686.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1479.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.55 ms /    15 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     698.15 ms /     1 runs   (  698.15 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1476.31 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.59 ms /    15 tokens (   51.51 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     679.12 ms /     1 runs   (  679.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1457.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.52 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     681.39 ms /     1 runs   (  681.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1495.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.32 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     682.33 ms /     1 runs   (  682.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1505.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.95 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     659.13 ms /     1 runs   (  659.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1497.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.79 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     668.91 ms /     1 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.62 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     657.79 ms /     1 runs   (  657.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.65 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     700.28 ms /     1 runs   (  700.28 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1476.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.94 ms /    15 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     665.77 ms /     1 runs   (  665.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1442.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.65 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     703.81 ms /     1 runs   (  703.81 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1528.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.46 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     652.96 ms /     1 runs   (  652.96 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.53 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     651.53 ms /     1 runs   (  651.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.16 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     649.64 ms /     1 runs   (  649.64 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.15 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     673.55 ms /     1 runs   (  673.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.49 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     656.60 ms /     1 runs   (  656.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.28 ms /    14 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     650.36 ms /     1 runs   (  650.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1386.25 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.07 ms /    14 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     654.03 ms /     1 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1382.79 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.17 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     660.43 ms /     1 runs   (  660.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.98 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     668.12 ms /     1 runs   (  668.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1440.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.61 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     699.44 ms /     1 runs   (  699.44 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1520.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.09 ms /    16 tokens (   51.51 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     646.72 ms /     1 runs   (  646.72 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1476.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.43 ms /    14 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     679.49 ms /     1 runs   (  679.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1407.37 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.76 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     670.43 ms /     1 runs   (  670.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.52 ms /    16 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     653.18 ms /     1 runs   (  653.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1501.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.16 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     697.23 ms /     1 runs   (  697.23 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1517.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.28 ms /    15 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     675.26 ms /     1 runs   (  675.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1450.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.22 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     679.08 ms /     1 runs   (  679.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1495.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.36 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     650.75 ms /     1 runs   (  650.75 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.87 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     658.17 ms /     1 runs   (  658.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.18 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     671.21 ms /     1 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.99 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     649.85 ms /     1 runs   (  649.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.10 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     647.87 ms /     1 runs   (  647.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.25 ms /    16 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     661.11 ms /     1 runs   (  661.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1514.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.51 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     671.62 ms /     1 runs   (  671.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.95 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     648.57 ms /     1 runs   (  648.57 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.31 ms /    15 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     671.30 ms /     1 runs   (  671.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1465.10 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.82 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     660.77 ms /     1 runs   (  660.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.43 ms /    15 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     645.56 ms /     1 runs   (  645.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1415.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.66 ms /    14 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     650.48 ms /     1 runs   (  650.48 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1382.16 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.02 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     663.57 ms /     1 runs   (  663.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.07 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     676.62 ms /     1 runs   (  676.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.61 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     660.35 ms /     1 runs   (  660.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.15 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     649.43 ms /     1 runs   (  649.43 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.02 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     659.26 ms /     1 runs   (  659.26 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.16 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     660.77 ms /     1 runs   (  660.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.55 ms /    16 tokens (   51.53 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     660.80 ms /     1 runs   (  660.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.27 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     658.29 ms /     1 runs   (  658.29 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.95 ms /    15 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     656.97 ms /     1 runs   (  656.97 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1456.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.89 ms /    16 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     653.70 ms /     1 runs   (  653.70 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1504.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.55 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     650.91 ms /     1 runs   (  650.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.55 ms /    16 tokens (   51.53 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     662.53 ms /     1 runs   (  662.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.63 ms /    16 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     670.16 ms /     1 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1515.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.33 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     669.14 ms /     1 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.67 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     674.35 ms /     1 runs   (  674.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1489.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.65 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     674.30 ms /     1 runs   (  674.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.18 ms /    15 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     648.89 ms /     1 runs   (  648.89 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1428.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.22 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     649.47 ms /     1 runs   (  649.47 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.50 ms /    15 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     666.39 ms /     1 runs   (  666.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1435.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.59 ms /    15 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     633.93 ms /     1 runs   (  633.93 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1423.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.64 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     649.50 ms /     1 runs   (  649.50 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.54 ms /    15 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     650.34 ms /     1 runs   (  650.34 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1435.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.15 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     640.66 ms /     1 runs   (  640.66 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1466.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.59 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     629.28 ms /     1 runs   (  629.28 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1447.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.37 ms /    14 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     687.62 ms /     1 runs   (  687.62 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1424.40 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.90 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     646.19 ms /     1 runs   (  646.19 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1475.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2178.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.27 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     654.75 ms /     1 runs   (  654.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.42 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     674.84 ms /     1 runs   (  674.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.38 ms /    16 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     651.33 ms /     1 runs   (  651.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1496.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.26 ms /    14 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     655.16 ms /     1 runs   (  655.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1380.42 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.99 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     649.30 ms /     1 runs   (  649.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.85 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     682.95 ms /     1 runs   (  682.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.46 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     671.41 ms /     1 runs   (  671.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2183.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.71 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     732.68 ms /     1 runs   (  732.68 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1506.31 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.34 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     649.90 ms /     1 runs   (  649.90 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.31 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     656.68 ms /     1 runs   (  656.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.76 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     679.52 ms /     1 runs   (  679.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1499.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.19 ms /    16 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     681.31 ms /     1 runs   (  681.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1512.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.98 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     675.22 ms /     1 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.93 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     670.22 ms /     1 runs   (  670.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.75 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     652.33 ms /     1 runs   (  652.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.26 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     653.68 ms /     1 runs   (  653.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.92 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     663.43 ms /     1 runs   (  663.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.00 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     667.43 ms /     1 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1504.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.47 ms /    16 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     684.03 ms /     1 runs   (  684.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1528.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.12 ms /    15 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     742.46 ms /     1 runs   (  742.46 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =    1534.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.05 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     670.67 ms /     1 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1515.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     886.99 ms /    16 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =     657.43 ms /     1 runs   (  657.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1549.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.59 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     700.73 ms /     1 runs   (  700.73 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1532.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.36 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     673.30 ms /     1 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.27 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     656.11 ms /     1 runs   (  656.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.36 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     658.87 ms /     1 runs   (  658.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.53 ms /    15 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     655.68 ms /     1 runs   (  655.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1448.79 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.03 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     655.84 ms /     1 runs   (  655.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.89 ms /    16 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     674.21 ms /     1 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1504.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.21 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     648.35 ms /     1 runs   (  648.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.35 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     648.94 ms /     1 runs   (  648.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.42 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     672.43 ms /     1 runs   (  672.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.86 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     648.42 ms /     1 runs   (  648.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.24 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     669.31 ms /     1 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.78 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     646.18 ms /     1 runs   (  646.18 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1475.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.75 ms /    16 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =     649.08 ms /     1 runs   (  649.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1502.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2034.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.85 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     705.54 ms /     1 runs   (  705.54 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1539.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.37 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     680.74 ms /     1 runs   (  680.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1517.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.60 ms /    15 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     637.15 ms /     1 runs   (  637.15 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1411.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.84 ms /    15 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     696.21 ms /     1 runs   (  696.21 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1487.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.09 ms /    15 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     713.66 ms /     1 runs   (  713.66 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1480.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.94 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     662.40 ms /     1 runs   (  662.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.28 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     634.31 ms /     1 runs   (  634.31 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1459.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.09 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     664.57 ms /     1 runs   (  664.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.46 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     683.86 ms /     1 runs   (  683.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1503.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.06 ms /    15 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     647.23 ms /     1 runs   (  647.23 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1423.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.68 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     641.14 ms /     1 runs   (  641.14 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1460.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.18 ms /    16 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     647.99 ms /     1 runs   (  647.99 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1500.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.23 ms /    15 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     663.41 ms /     1 runs   (  663.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1460.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.14 ms /    15 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     694.04 ms /     1 runs   (  694.04 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1471.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.78 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     665.39 ms /     1 runs   (  665.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1437.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.88 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     645.88 ms /     1 runs   (  645.88 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.92 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     658.25 ms /     1 runs   (  658.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.17 ms /    15 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     650.86 ms /     1 runs   (  650.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1432.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.54 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     663.62 ms /     1 runs   (  663.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.60 ms /    15 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     652.97 ms /     1 runs   (  652.97 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1426.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.01 ms /    16 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =     671.40 ms /     1 runs   (  671.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1528.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.93 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     662.96 ms /     1 runs   (  662.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.33 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     660.31 ms /     1 runs   (  660.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.76 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     690.30 ms /     1 runs   (  690.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1511.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.75 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     645.12 ms /     1 runs   (  645.12 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1471.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.27 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     652.95 ms /     1 runs   (  652.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1487.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.76 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     684.51 ms /     1 runs   (  684.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1505.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.82 ms /    15 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     651.36 ms /     1 runs   (  651.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.71 ms /    16 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     655.60 ms /     1 runs   (  655.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1504.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.80 ms /    15 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     658.10 ms /     1 runs   (  658.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1433.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.90 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     676.40 ms /     1 runs   (  676.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.20 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     648.47 ms /     1 runs   (  648.47 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.97 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     648.15 ms /     1 runs   (  648.15 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.52 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     651.86 ms /     1 runs   (  651.86 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1465.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.81 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     653.43 ms /     1 runs   (  653.43 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.19 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     654.28 ms /     1 runs   (  654.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.27 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     651.26 ms /     1 runs   (  651.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1494.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.65 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     655.98 ms /     1 runs   (  655.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.89 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     693.42 ms /     1 runs   (  693.42 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1509.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.30 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     666.01 ms /     1 runs   (  666.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.76 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     671.11 ms /     1 runs   (  671.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.92 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     700.87 ms /     1 runs   (  700.87 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1473.64 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.47 ms /    15 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     674.58 ms /     1 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1460.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.11 ms /    15 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     661.15 ms /     1 runs   (  661.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1435.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.59 ms /    15 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     652.80 ms /     1 runs   (  652.80 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1440.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.20 ms /    15 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =     670.16 ms /     1 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1483.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.44 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     662.42 ms /     1 runs   (  662.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.28 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     646.37 ms /     1 runs   (  646.37 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1471.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.09 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     635.56 ms /     1 runs   (  635.56 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1457.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.73 ms /    15 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     670.09 ms /     1 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1451.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.07 ms /    15 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     663.30 ms /     1 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1437.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.64 ms /    15 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     702.10 ms /     1 runs   (  702.10 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1480.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.74 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     679.78 ms /     1 runs   (  679.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1456.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.15 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     646.73 ms /     1 runs   (  646.73 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.95 ms /    15 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     659.23 ms /     1 runs   (  659.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1446.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.08 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     694.85 ms /     1 runs   (  694.85 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1511.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.67 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     695.10 ms /     1 runs   (  695.10 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1527.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.83 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     681.19 ms /     1 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1502.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.16 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     657.94 ms /     1 runs   (  657.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.07 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     661.80 ms /     1 runs   (  661.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.82 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     681.85 ms /     1 runs   (  681.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1499.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.18 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     654.96 ms /     1 runs   (  654.96 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.22 ms /    15 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     662.98 ms /     1 runs   (  662.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1437.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.72 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     662.52 ms /     1 runs   (  662.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.37 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     665.17 ms /     1 runs   (  665.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.16 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     662.60 ms /     1 runs   (  662.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.81 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     677.36 ms /     1 runs   (  677.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1457.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.24 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     652.28 ms /     1 runs   (  652.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1425.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.40 ms /    13 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     663.37 ms /     1 runs   (  663.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1350.29 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2183.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.26 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     662.76 ms /     1 runs   (  662.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.61 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     660.46 ms /     1 runs   (  660.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.63 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     650.70 ms /     1 runs   (  650.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.79 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     659.07 ms /     1 runs   (  659.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1498.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.45 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     669.60 ms /     1 runs   (  669.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.41 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     679.85 ms /     1 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1494.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.85 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     713.65 ms /     1 runs   (  713.65 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1528.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.82 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     667.65 ms /     1 runs   (  667.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     2 runs   (    0.89 ms per token,  1119.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.44 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     671.32 ms /     1 runs   (  671.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1512.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.77 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     661.28 ms /     1 runs   (  661.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.71 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     680.01 ms /     1 runs   (  680.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1508.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.91 ms /    16 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     657.07 ms /     1 runs   (  657.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1493.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.57 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     664.41 ms /     1 runs   (  664.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1495.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.90 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     660.30 ms /     1 runs   (  660.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.61 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     672.52 ms /     1 runs   (  672.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.74 ms /    14 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     656.97 ms /     1 runs   (  656.97 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1395.28 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.80 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     669.45 ms /     1 runs   (  669.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     798.28 ms /    15 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =     660.86 ms /     1 runs   (  660.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1464.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.21 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     697.03 ms /     1 runs   (  697.03 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1518.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.85 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     650.00 ms /     1 runs   (  650.00 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.35 ms /    15 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     724.14 ms /     1 runs   (  724.14 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1499.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.90 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     665.38 ms /     1 runs   (  665.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1479.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.51 ms /    15 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     659.99 ms /     1 runs   (  659.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1434.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.05 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     655.23 ms /     1 runs   (  655.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.58 ms /    14 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     663.22 ms /     1 runs   (  663.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1387.41 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.27 ms /    15 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     676.73 ms /     1 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1477.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.37 ms /    16 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     650.97 ms /     1 runs   (  650.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.49 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     651.12 ms /     1 runs   (  651.12 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.32 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     665.85 ms /     1 runs   (  665.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.53 ms /    15 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     679.86 ms /     1 runs   (  679.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1451.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.98 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     654.96 ms /     1 runs   (  654.96 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.52 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     655.04 ms /     1 runs   (  655.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.94 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     658.36 ms /     1 runs   (  658.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.25 ms /    15 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     663.21 ms /     1 runs   (  663.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1432.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.15 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     681.21 ms /     1 runs   (  681.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1505.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.81 ms /    16 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     669.98 ms /     1 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1513.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.53 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     662.96 ms /     1 runs   (  662.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.75 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     661.49 ms /     1 runs   (  661.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1435.10 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.17 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     660.00 ms /     1 runs   (  660.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.30 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     694.25 ms /     1 runs   (  694.25 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1512.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.16 ms /    15 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     668.77 ms /     1 runs   (  668.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1445.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.71 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     681.65 ms /     1 runs   (  681.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1501.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.88 ms /    15 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     672.69 ms /     1 runs   (  672.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1442.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.44 ms /    16 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     652.79 ms /     1 runs   (  652.79 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1496.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.71 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     678.20 ms /     1 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1491.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.06 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     683.62 ms /     1 runs   (  683.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1510.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.17 ms /    14 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     676.32 ms /     1 runs   (  676.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1409.14 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.99 ms /    15 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     664.45 ms /     1 runs   (  664.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1440.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.73 ms /    16 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     658.89 ms /     1 runs   (  658.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.61 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     653.40 ms /     1 runs   (  653.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.29 ms /    14 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     656.45 ms /     1 runs   (  656.45 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1383.94 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.47 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     666.55 ms /     1 runs   (  666.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.73 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     649.24 ms /     1 runs   (  649.24 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.36 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     680.87 ms /     1 runs   (  680.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1518.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.56 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     665.71 ms /     1 runs   (  665.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.71 ms /    15 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     659.49 ms /     1 runs   (  659.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1440.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.06 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     664.26 ms /     1 runs   (  664.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.58 ms /    15 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     648.10 ms /     1 runs   (  648.10 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1427.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.71 ms /    15 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     660.82 ms /     1 runs   (  660.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1441.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.59 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     640.12 ms /     1 runs   (  640.12 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1462.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.43 ms /    15 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     640.90 ms /     1 runs   (  640.90 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1417.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.57 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     661.75 ms /     1 runs   (  661.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.41 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     661.38 ms /     1 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.07 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     659.39 ms /     1 runs   (  659.39 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1484.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.93 ms /    14 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     648.41 ms /     1 runs   (  648.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1387.23 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.27 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     646.97 ms /     1 runs   (  646.97 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.08 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     664.61 ms /     1 runs   (  664.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.14 ms /    15 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     651.45 ms /     1 runs   (  651.45 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1429.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.42 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     675.85 ms /     1 runs   (  675.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.85 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     675.73 ms /     1 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.20 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     675.61 ms /     1 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.89 ms /    14 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     670.15 ms /     1 runs   (  670.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1403.74 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.12 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     644.46 ms /     1 runs   (  644.46 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.96 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     649.51 ms /     1 runs   (  649.51 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.06 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     649.76 ms /     1 runs   (  649.76 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.07 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     656.96 ms /     1 runs   (  656.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.51 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     664.83 ms /     1 runs   (  664.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.81 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     686.68 ms /     1 runs   (  686.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1509.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.28 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     672.88 ms /     1 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1445.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.05 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     674.58 ms /     1 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.44 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     705.95 ms /     1 runs   (  705.95 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1527.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2176.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     742.12 ms /    14 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     668.16 ms /     1 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1416.16 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.42 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     674.86 ms /     1 runs   (  674.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.84 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     646.93 ms /     1 runs   (  646.93 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.73 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     648.85 ms /     1 runs   (  648.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.79 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     659.61 ms /     1 runs   (  659.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.50 ms /    15 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     647.71 ms /     1 runs   (  647.71 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1428.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.17 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     664.44 ms /     1 runs   (  664.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.20 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     666.22 ms /     1 runs   (  666.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.66 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     670.89 ms /     1 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.38 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     649.54 ms /     1 runs   (  649.54 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.49 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     656.29 ms /     1 runs   (  656.29 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.29 ms /    14 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     658.83 ms /     1 runs   (  658.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1390.30 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.09 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     659.04 ms /     1 runs   (  659.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.80 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     647.17 ms /     1 runs   (  647.17 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1480.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.33 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     674.30 ms /     1 runs   (  674.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.36 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     661.38 ms /     1 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.56 ms /    16 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     678.97 ms /     1 runs   (  678.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1521.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     758.89 ms /    14 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =     658.28 ms /     1 runs   (  658.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1422.86 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.92 ms /    15 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     650.73 ms /     1 runs   (  650.73 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1438.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.88 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     676.94 ms /     1 runs   (  676.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2169.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.92 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     654.00 ms /     1 runs   (  654.00 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.29 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     656.09 ms /     1 runs   (  656.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.44 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     711.42 ms /     1 runs   (  711.42 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1532.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.79 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     640.68 ms /     1 runs   (  640.68 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1467.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.38 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     653.44 ms /     1 runs   (  653.44 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.69 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     660.51 ms /     1 runs   (  660.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.93 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     664.85 ms /     1 runs   (  664.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.04 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     658.65 ms /     1 runs   (  658.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.68 ms /    16 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     659.90 ms /     1 runs   (  659.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.96 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     650.05 ms /     1 runs   (  650.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.82 ms /    15 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     658.38 ms /     1 runs   (  658.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1431.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.52 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     662.07 ms /     1 runs   (  662.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.81 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     688.88 ms /     1 runs   (  688.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1510.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.97 ms /    16 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     646.60 ms /     1 runs   (  646.60 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1485.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2098.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     883.23 ms /    16 tokens (   55.20 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =     691.27 ms /     1 runs   (  691.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1580.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.13 ms /    15 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     654.66 ms /     1 runs   (  654.66 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1455.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.53 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     719.60 ms /     1 runs   (  719.60 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1553.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     897.81 ms /    16 tokens (   56.11 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =     714.96 ms /     1 runs   (  714.96 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1618.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     875.20 ms /    16 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =     661.89 ms /     1 runs   (  661.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1542.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.67 ms /    16 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =     658.98 ms /     1 runs   (  658.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1514.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.94 ms /    16 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =     654.71 ms /     1 runs   (  654.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1512.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.83 ms /    16 tokens (   51.61 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     732.47 ms /     1 runs   (  732.47 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1563.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.68 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     672.64 ms /     1 runs   (  672.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1511.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.41 ms /    16 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     650.29 ms /     1 runs   (  650.29 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.37 ms /    15 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     662.26 ms /     1 runs   (  662.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1443.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.56 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     648.63 ms /     1 runs   (  648.63 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.69 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     667.16 ms /     1 runs   (  667.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.66 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     646.85 ms /     1 runs   (  646.85 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.02 ms /    16 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     654.21 ms /     1 runs   (  654.21 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1487.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.82 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     646.22 ms /     1 runs   (  646.22 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.58 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     664.22 ms /     1 runs   (  664.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.50 ms /    15 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     675.88 ms /     1 runs   (  675.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1457.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.82 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     672.35 ms /     1 runs   (  672.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1452.79 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     2 runs   (    0.50 ms per token,  2006.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.83 ms /    15 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     695.20 ms /     1 runs   (  695.20 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1489.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.28 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     649.62 ms /     1 runs   (  649.62 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.07 ms /    16 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     642.86 ms /     1 runs   (  642.86 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1477.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.63 ms /    16 tokens (   51.16 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     678.13 ms /     1 runs   (  678.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1502.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.87 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     661.29 ms /     1 runs   (  661.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1436.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.55 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     649.58 ms /     1 runs   (  649.58 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.52 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     647.25 ms /     1 runs   (  647.25 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.86 ms /    16 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =     676.00 ms /     1 runs   (  676.00 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1541.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.81 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     656.51 ms /     1 runs   (  656.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.39 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     700.79 ms /     1 runs   (  700.79 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1515.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.51 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     678.05 ms /     1 runs   (  678.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1491.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.16 ms /    14 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     660.62 ms /     1 runs   (  660.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1390.63 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.26 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     658.30 ms /     1 runs   (  658.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1484.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.37 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     673.45 ms /     1 runs   (  673.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.63 ms /    15 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =     644.72 ms /     1 runs   (  644.72 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1474.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.00 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     700.59 ms /     1 runs   (  700.59 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1516.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.55 ms /    14 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     706.70 ms /     1 runs   (  706.70 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1436.65 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.29 ms /    15 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     661.48 ms /     1 runs   (  661.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1457.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.42 ms /    14 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     681.01 ms /     1 runs   (  681.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1419.35 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.41 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     679.20 ms /     1 runs   (  679.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1507.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.26 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     693.91 ms /     1 runs   (  693.91 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1514.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.84 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     694.65 ms /     1 runs   (  694.65 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1515.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.47 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     666.77 ms /     1 runs   (  666.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.32 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     684.29 ms /     1 runs   (  684.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.43 ms /    16 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =     716.75 ms /     1 runs   (  716.75 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1582.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.32 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     663.65 ms /     1 runs   (  663.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.00 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     655.61 ms /     1 runs   (  655.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1427.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.34 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     661.75 ms /     1 runs   (  661.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.93 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     657.40 ms /     1 runs   (  657.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.63 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     659.24 ms /     1 runs   (  659.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.74 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     657.82 ms /     1 runs   (  657.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1484.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.37 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     659.63 ms /     1 runs   (  659.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.48 ms /    15 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     654.97 ms /     1 runs   (  654.97 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1441.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.26 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     658.67 ms /     1 runs   (  658.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.16 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     680.58 ms /     1 runs   (  680.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1505.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.56 ms /    14 tokens (   52.40 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     651.59 ms /     1 runs   (  651.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1390.20 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.95 ms /    16 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     656.30 ms /     1 runs   (  656.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.95 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     650.33 ms /     1 runs   (  650.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.71 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     678.54 ms /     1 runs   (  678.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1459.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.00 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     657.18 ms /     1 runs   (  657.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1493.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.88 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     690.25 ms /     1 runs   (  690.25 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1509.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.98 ms /    15 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     655.24 ms /     1 runs   (  655.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1434.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.50 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     666.48 ms /     1 runs   (  666.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1500.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.14 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     665.20 ms /     1 runs   (  665.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.66 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     679.42 ms /     1 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1504.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.83 ms /    14 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     673.90 ms /     1 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1407.78 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.97 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     665.21 ms /     1 runs   (  665.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.34 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     658.59 ms /     1 runs   (  658.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.80 ms /    16 tokens (   51.99 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     664.92 ms /     1 runs   (  664.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1501.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.62 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     691.32 ms /     1 runs   (  691.32 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1506.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.80 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     692.01 ms /     1 runs   (  692.01 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1516.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.87 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     669.14 ms /     1 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1502.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.90 ms /    15 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =     665.59 ms /     1 runs   (  665.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.18 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     676.22 ms /     1 runs   (  676.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1502.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.32 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     652.44 ms /     1 runs   (  652.44 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.73 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     725.80 ms /     1 runs   (  725.80 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1542.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.85 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     656.31 ms /     1 runs   (  656.31 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.87 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     646.72 ms /     1 runs   (  646.72 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1479.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.65 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     663.12 ms /     1 runs   (  663.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1498.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.02 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     654.03 ms /     1 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.54 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     667.08 ms /     1 runs   (  667.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.58 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     701.71 ms /     1 runs   (  701.71 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1518.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.60 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     659.96 ms /     1 runs   (  659.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.66 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     665.44 ms /     1 runs   (  665.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.22 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     651.83 ms /     1 runs   (  651.83 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.87 ms /    15 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     711.19 ms /     1 runs   (  711.19 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1492.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.59 ms /    15 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     665.28 ms /     1 runs   (  665.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1457.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.58 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     672.01 ms /     1 runs   (  672.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.75 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     646.82 ms /     1 runs   (  646.82 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.20 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     656.56 ms /     1 runs   (  656.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.69 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     695.61 ms /     1 runs   (  695.61 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1512.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.17 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     645.32 ms /     1 runs   (  645.32 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1417.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.95 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     692.24 ms /     1 runs   (  692.24 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1523.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.56 ms /    16 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     651.59 ms /     1 runs   (  651.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1492.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.99 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     682.79 ms /     1 runs   (  682.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1498.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.35 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     650.06 ms /     1 runs   (  650.06 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.88 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     693.58 ms /     1 runs   (  693.58 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1516.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.70 ms /    16 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     646.71 ms /     1 runs   (  646.71 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1494.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.42 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     676.92 ms /     1 runs   (  676.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1501.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.09 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     667.74 ms /     1 runs   (  667.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.80 ms /    15 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     668.63 ms /     1 runs   (  668.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1442.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.98 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     658.89 ms /     1 runs   (  658.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1503.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.22 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     687.88 ms /     1 runs   (  687.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1505.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.49 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     687.53 ms /     1 runs   (  687.53 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1510.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.15 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     652.40 ms /     1 runs   (  652.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.01 ms /    16 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     664.00 ms /     1 runs   (  664.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1507.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.11 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     651.07 ms /     1 runs   (  651.07 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.65 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     676.35 ms /     1 runs   (  676.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1449.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.94 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     652.85 ms /     1 runs   (  652.85 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1490.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.26 ms /    15 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =     661.09 ms /     1 runs   (  661.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1457.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.77 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     650.86 ms /     1 runs   (  650.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.68 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     658.87 ms /     1 runs   (  658.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1433.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.83 ms /    16 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     652.04 ms /     1 runs   (  652.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1489.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.81 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     664.70 ms /     1 runs   (  664.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.53 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     664.41 ms /     1 runs   (  664.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.40 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     727.07 ms /     1 runs   (  727.07 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1547.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.20 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     653.14 ms /     1 runs   (  653.14 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.71 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     647.85 ms /     1 runs   (  647.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.75 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     674.48 ms /     1 runs   (  674.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1452.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.08 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     648.67 ms /     1 runs   (  648.67 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.40 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     690.55 ms /     1 runs   (  690.55 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1518.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.80 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     661.48 ms /     1 runs   (  661.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.66 ms /    16 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     648.41 ms /     1 runs   (  648.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1495.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.81 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     673.93 ms /     1 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1449.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.69 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     698.61 ms /     1 runs   (  698.61 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1514.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.32 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     649.68 ms /     1 runs   (  649.68 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.04 ms /    15 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     654.12 ms /     1 runs   (  654.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1445.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.81 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     665.02 ms /     1 runs   (  665.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1436.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.61 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     654.30 ms /     1 runs   (  654.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.16 ms /    15 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     664.03 ms /     1 runs   (  664.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1439.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.04 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     650.69 ms /     1 runs   (  650.69 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.84 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     664.02 ms /     1 runs   (  664.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1497.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.54 ms per token,  1869.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.12 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     684.27 ms /     1 runs   (  684.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1512.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2166.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.77 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     652.92 ms /     1 runs   (  652.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.75 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     648.44 ms /     1 runs   (  648.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.89 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.51 ms /     1 runs   (  659.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.59 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     668.83 ms /     1 runs   (  668.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1444.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.85 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     653.89 ms /     1 runs   (  653.89 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     878.96 ms /    16 tokens (   54.93 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =     659.81 ms /     1 runs   (  659.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1545.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.08 ms /    15 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     657.41 ms /     1 runs   (  657.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1436.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.03 ms /    15 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     683.32 ms /     1 runs   (  683.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1474.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.19 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     745.10 ms /     1 runs   (  745.10 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =    1567.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2155.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.57 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     663.80 ms /     1 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.66 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     640.98 ms /     1 runs   (  640.98 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1457.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.36 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     662.32 ms /     1 runs   (  662.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1472.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.97 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     648.26 ms /     1 runs   (  648.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1425.30 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.37 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     654.03 ms /     1 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1489.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.80 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     668.91 ms /     1 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1507.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.85 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     648.57 ms /     1 runs   (  648.57 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1420.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.22 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     648.86 ms /     1 runs   (  648.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.11 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     647.16 ms /     1 runs   (  647.16 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1478.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.59 ms /    16 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     647.52 ms /     1 runs   (  647.52 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1500.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.07 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     651.73 ms /     1 runs   (  651.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.99 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     663.35 ms /     1 runs   (  663.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.33 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     645.50 ms /     1 runs   (  645.50 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.07 ms /    16 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     659.64 ms /     1 runs   (  659.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1498.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.49 ms per token,  2057.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.43 ms /    15 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     690.55 ms /     1 runs   (  690.55 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1482.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.14 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     672.46 ms /     1 runs   (  672.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1504.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.34 ms /    16 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     669.88 ms /     1 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1519.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     877.69 ms /    16 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =     656.75 ms /     1 runs   (  656.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1539.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.75 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     648.95 ms /     1 runs   (  648.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.97 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     648.18 ms /     1 runs   (  648.18 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.14 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     657.57 ms /     1 runs   (  657.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2190.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.36 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     648.77 ms /     1 runs   (  648.77 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.46 ms /    16 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     663.14 ms /     1 runs   (  663.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.82 ms /    16 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     661.39 ms /     1 runs   (  661.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1504.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.83 ms /    15 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     642.86 ms /     1 runs   (  642.86 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1418.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.83 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     686.70 ms /     1 runs   (  686.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2166.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.79 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     646.41 ms /     1 runs   (  646.41 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1476.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2157.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.09 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     669.86 ms /     1 runs   (  669.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.19 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     657.84 ms /     1 runs   (  657.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.16 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     673.08 ms /     1 runs   (  673.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.02 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     681.14 ms /     1 runs   (  681.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1494.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.38 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     666.13 ms /     1 runs   (  666.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.19 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     653.75 ms /     1 runs   (  653.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     761.12 ms /    15 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     652.22 ms /     1 runs   (  652.22 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1419.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.45 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     658.95 ms /     1 runs   (  658.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.96 ms /    15 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     670.11 ms /     1 runs   (  670.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1443.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2038.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.56 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     633.65 ms /     1 runs   (  633.65 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1460.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.45 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     658.95 ms /     1 runs   (  658.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1494.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.84 ms /    15 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     665.50 ms /     1 runs   (  665.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1445.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.81 ms /    15 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     649.35 ms /     1 runs   (  649.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1435.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.84 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     667.26 ms /     1 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1442.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.23 ms /    15 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     647.19 ms /     1 runs   (  647.19 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1421.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.36 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     677.65 ms /     1 runs   (  677.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.72 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     666.16 ms /     1 runs   (  666.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.81 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     649.87 ms /     1 runs   (  649.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.35 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     654.67 ms /     1 runs   (  654.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.42 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     651.51 ms /     1 runs   (  651.51 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.23 ms /    15 tokens (   51.22 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     666.25 ms /     1 runs   (  666.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1440.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.69 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     651.61 ms /     1 runs   (  651.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1423.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.99 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     657.38 ms /     1 runs   (  657.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.59 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     657.20 ms /     1 runs   (  657.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.42 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     650.90 ms /     1 runs   (  650.90 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1483.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.69 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     648.47 ms /     1 runs   (  648.47 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1483.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.18 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     648.65 ms /     1 runs   (  648.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.39 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     643.55 ms /     1 runs   (  643.55 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.39 ms /    15 tokens (   56.16 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =     663.72 ms /     1 runs   (  663.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1511.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.59 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     664.97 ms /     1 runs   (  664.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.46 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     653.61 ms /     1 runs   (  653.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.81 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     675.62 ms /     1 runs   (  675.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.99 ms /    15 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     658.77 ms /     1 runs   (  658.77 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1436.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.27 ms /    16 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     662.28 ms /     1 runs   (  662.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1501.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.14 ms /    16 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =     684.18 ms /     1 runs   (  684.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1541.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.47 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     632.39 ms /     1 runs   (  632.39 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1448.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.45 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     731.68 ms /     1 runs   (  731.68 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1568.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.83 ms /    15 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =     672.56 ms /     1 runs   (  672.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.42 ms /    16 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     703.16 ms /     1 runs   (  703.16 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1561.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.68 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     666.64 ms /     1 runs   (  666.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1499.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.10 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     715.84 ms /     1 runs   (  715.84 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1541.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.00 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     658.79 ms /     1 runs   (  658.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /     2 runs   (    0.94 ms per token,  1064.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.50 ms /    16 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     674.27 ms /     1 runs   (  674.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1529.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.17 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     716.22 ms /     1 runs   (  716.22 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1536.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.63 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     725.95 ms /     1 runs   (  725.95 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1544.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.00 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     662.68 ms /     1 runs   (  662.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.00 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     688.41 ms /     1 runs   (  688.41 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1532.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.14 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     650.71 ms /     1 runs   (  650.71 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.36 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     663.35 ms /     1 runs   (  663.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.66 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     654.06 ms /     1 runs   (  654.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.94 ms /    14 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     645.57 ms /     1 runs   (  645.57 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1382.34 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.08 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     647.78 ms /     1 runs   (  647.78 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.34 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     648.11 ms /     1 runs   (  648.11 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.66 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     673.33 ms /     1 runs   (  673.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.09 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     689.26 ms /     1 runs   (  689.26 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1507.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.26 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     706.13 ms /     1 runs   (  706.13 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1525.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.71 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     667.07 ms /     1 runs   (  667.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1446.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.21 ms /    15 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     663.10 ms /     1 runs   (  663.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1434.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.70 ms /    16 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     707.57 ms /     1 runs   (  707.57 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1551.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.38 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     657.79 ms /     1 runs   (  657.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.03 ms /    16 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     670.73 ms /     1 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1489.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.62 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     655.96 ms /     1 runs   (  655.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.05 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     675.52 ms /     1 runs   (  675.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1506.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.55 ms /    15 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     664.11 ms /     1 runs   (  664.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1456.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.28 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     660.97 ms /     1 runs   (  660.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.68 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     675.23 ms /     1 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.78 ms /    15 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     658.12 ms /     1 runs   (  658.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1432.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.91 ms /    15 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     671.96 ms /     1 runs   (  671.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1442.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.39 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     689.14 ms /     1 runs   (  689.14 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1510.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.42 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     657.10 ms /     1 runs   (  657.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.09 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     647.71 ms /     1 runs   (  647.71 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.70 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     671.09 ms /     1 runs   (  671.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1444.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.93 ms /    15 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     662.25 ms /     1 runs   (  662.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1450.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.75 ms /    16 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     704.53 ms /     1 runs   (  704.53 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1540.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.28 ms /    15 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     685.53 ms /     1 runs   (  685.53 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1456.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.84 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     667.59 ms /     1 runs   (  667.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.75 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     672.02 ms /     1 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1445.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.87 ms /    16 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =     670.85 ms /     1 runs   (  670.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1533.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.09 ms /    16 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     723.68 ms /     1 runs   (  723.68 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1559.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.97 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     682.92 ms /     1 runs   (  682.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1516.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.73 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     662.12 ms /     1 runs   (  662.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1438.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.42 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     664.91 ms /     1 runs   (  664.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.33 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     666.84 ms /     1 runs   (  666.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.56 ms per token,  1773.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.66 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     680.31 ms /     1 runs   (  680.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1502.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.51 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     684.61 ms /     1 runs   (  684.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.05 ms /    15 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =     655.49 ms /     1 runs   (  655.49 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.31 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     648.20 ms /     1 runs   (  648.20 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1420.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.19 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     661.74 ms /     1 runs   (  661.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.90 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     655.40 ms /     1 runs   (  655.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.48 ms per token,  2070.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.27 ms /    16 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     670.13 ms /     1 runs   (  670.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1482.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.96 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     684.67 ms /     1 runs   (  684.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1512.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.30 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     654.53 ms /     1 runs   (  654.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.21 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     657.28 ms /     1 runs   (  657.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.89 ms /    16 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     709.73 ms /     1 runs   (  709.73 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1535.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.62 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     682.44 ms /     1 runs   (  682.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1495.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.84 ms /    16 tokens (   52.18 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     662.71 ms /     1 runs   (  662.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1502.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.26 ms /    15 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     674.45 ms /     1 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1454.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.61 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     693.15 ms /     1 runs   (  693.15 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1509.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.20 ms /    14 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     666.71 ms /     1 runs   (  666.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1400.69 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.37 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     697.47 ms /     1 runs   (  697.47 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1516.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.11 ms /    15 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     673.24 ms /     1 runs   (  673.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1464.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.20 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     664.77 ms /     1 runs   (  664.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.90 ms /    14 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     656.69 ms /     1 runs   (  656.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1389.87 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.58 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     708.56 ms /     1 runs   (  708.56 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1480.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.73 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     667.96 ms /     1 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.49 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     673.17 ms /     1 runs   (  673.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.85 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     661.73 ms /     1 runs   (  661.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.69 ms /    15 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     663.90 ms /     1 runs   (  663.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1459.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.15 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     654.23 ms /     1 runs   (  654.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.31 ms /    15 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     693.10 ms /     1 runs   (  693.10 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1463.23 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.42 ms /    15 tokens (   53.09 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =     655.13 ms /     1 runs   (  655.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1456.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.45 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     658.24 ms /     1 runs   (  658.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.50 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     663.58 ms /     1 runs   (  663.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.26 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     663.65 ms /     1 runs   (  663.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2136.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.26 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     688.48 ms /     1 runs   (  688.48 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1520.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.60 ms /    16 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     642.12 ms /     1 runs   (  642.12 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1489.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.70 ms /    16 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     667.52 ms /     1 runs   (  667.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1519.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.86 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     673.85 ms /     1 runs   (  673.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1446.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.87 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     652.69 ms /     1 runs   (  652.69 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.35 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     660.48 ms /     1 runs   (  660.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.50 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     665.33 ms /     1 runs   (  665.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.21 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     649.09 ms /     1 runs   (  649.09 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.60 ms /    16 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     708.73 ms /     1 runs   (  708.73 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1557.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.66 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     661.81 ms /     1 runs   (  661.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.01 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     657.02 ms /     1 runs   (  657.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.20 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     719.19 ms /     1 runs   (  719.19 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1537.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.02 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     672.47 ms /     1 runs   (  672.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1508.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.41 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     652.45 ms /     1 runs   (  652.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.30 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     656.76 ms /     1 runs   (  656.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.95 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     655.39 ms /     1 runs   (  655.39 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.18 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     647.17 ms /     1 runs   (  647.17 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1480.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.07 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     676.30 ms /     1 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1508.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.95 ms /    16 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     654.90 ms /     1 runs   (  654.90 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1493.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.13 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     648.01 ms /     1 runs   (  648.01 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.20 ms /    16 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     647.17 ms /     1 runs   (  647.17 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1489.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.84 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     649.08 ms /     1 runs   (  649.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1427.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.62 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     646.44 ms /     1 runs   (  646.44 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.54 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     684.70 ms /     1 runs   (  684.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.17 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     676.78 ms /     1 runs   (  676.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1502.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.34 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     663.68 ms /     1 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.41 ms /    15 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     671.24 ms /     1 runs   (  671.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1440.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.47 ms /    15 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     668.15 ms /     1 runs   (  668.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1453.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.44 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     656.36 ms /     1 runs   (  656.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1469.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.99 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     672.47 ms /     1 runs   (  672.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.64 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     651.07 ms /     1 runs   (  651.07 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1427.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.26 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     674.16 ms /     1 runs   (  674.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.38 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     638.66 ms /     1 runs   (  638.66 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1476.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.01 ms /    16 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     694.06 ms /     1 runs   (  694.06 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1533.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.16 ms /    15 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     662.92 ms /     1 runs   (  662.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1451.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.31 ms /    16 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     663.82 ms /     1 runs   (  663.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1521.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.58 ms /    15 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     675.66 ms /     1 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1452.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.28 ms /    16 tokens (   50.96 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     664.34 ms /     1 runs   (  664.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.67 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     661.83 ms /     1 runs   (  661.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.39 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     655.01 ms /     1 runs   (  655.01 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.89 ms /    15 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     668.44 ms /     1 runs   (  668.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1453.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2143.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.02 ms /    16 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     665.27 ms /     1 runs   (  665.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.30 ms /    15 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     674.29 ms /     1 runs   (  674.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1455.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.23 ms /    16 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     646.89 ms /     1 runs   (  646.89 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1485.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.32 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     649.75 ms /     1 runs   (  649.75 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.67 ms /    16 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =     650.91 ms /     1 runs   (  650.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1515.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.64 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     711.12 ms /     1 runs   (  711.12 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1526.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.12 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     651.89 ms /     1 runs   (  651.89 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.93 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     657.72 ms /     1 runs   (  657.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.28 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     645.43 ms /     1 runs   (  645.43 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1474.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.94 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     644.62 ms /     1 runs   (  644.62 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.41 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     658.81 ms /     1 runs   (  658.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.34 ms /    15 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     687.52 ms /     1 runs   (  687.52 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1462.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.32 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     649.82 ms /     1 runs   (  649.82 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.42 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     690.87 ms /     1 runs   (  690.87 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1518.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.92 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     664.99 ms /     1 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.93 ms /    15 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     661.08 ms /     1 runs   (  661.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1430.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.50 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     665.72 ms /     1 runs   (  665.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.77 ms /    15 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     675.39 ms /     1 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1457.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.56 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     657.94 ms /     1 runs   (  657.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.74 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     667.59 ms /     1 runs   (  667.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.10 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     657.03 ms /     1 runs   (  657.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.13 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     672.96 ms /     1 runs   (  672.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.24 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     657.82 ms /     1 runs   (  657.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.88 ms /    16 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     667.89 ms /     1 runs   (  667.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1511.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.50 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     658.55 ms /     1 runs   (  658.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.31 ms /    15 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     674.67 ms /     1 runs   (  674.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1446.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.74 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     674.82 ms /     1 runs   (  674.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.87 ms /    16 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     652.03 ms /     1 runs   (  652.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1489.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     761.43 ms /    15 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     685.09 ms /     1 runs   (  685.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1451.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.38 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     645.34 ms /     1 runs   (  645.34 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.16 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     741.73 ms /     1 runs   (  741.73 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =    1562.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.25 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     661.40 ms /     1 runs   (  661.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.13 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     669.35 ms /     1 runs   (  669.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1484.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.10 ms /    16 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     677.83 ms /     1 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1501.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.64 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     666.06 ms /     1 runs   (  666.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.44 ms /    14 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     671.23 ms /     1 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1400.37 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.28 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     673.62 ms /     1 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1501.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.96 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     657.90 ms /     1 runs   (  657.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.68 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     654.11 ms /     1 runs   (  654.11 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1429.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.00 ms /    16 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     654.17 ms /     1 runs   (  654.17 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1503.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.60 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     650.36 ms /     1 runs   (  650.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.95 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     670.08 ms /     1 runs   (  670.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1507.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.98 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     658.03 ms /     1 runs   (  658.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.07 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     655.87 ms /     1 runs   (  655.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.23 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     668.38 ms /     1 runs   (  668.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1499.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.20 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     680.56 ms /     1 runs   (  680.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1497.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.15 ms /    16 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     663.79 ms /     1 runs   (  663.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.71 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     679.94 ms /     1 runs   (  679.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1497.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.00 ms /    15 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     650.70 ms /     1 runs   (  650.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1440.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.01 ms /    15 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     675.38 ms /     1 runs   (  675.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1453.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.12 ms /    14 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     662.57 ms /     1 runs   (  662.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1390.76 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.25 ms /    16 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =     651.60 ms /     1 runs   (  651.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1502.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.36 ms /    15 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     647.81 ms /     1 runs   (  647.81 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1429.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.00 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     651.71 ms /     1 runs   (  651.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.22 ms /    16 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     651.13 ms /     1 runs   (  651.13 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1497.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.50 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     677.74 ms /     1 runs   (  677.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.98 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     656.02 ms /     1 runs   (  656.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.45 ms /    16 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     653.17 ms /     1 runs   (  653.17 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1508.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.59 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     688.47 ms /     1 runs   (  688.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1507.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.68 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     649.81 ms /     1 runs   (  649.81 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.25 ms /    15 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =     683.65 ms /     1 runs   (  683.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1492.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.20 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     728.09 ms /     1 runs   (  728.09 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1547.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.95 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     673.99 ms /     1 runs   (  673.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.60 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     653.97 ms /     1 runs   (  653.97 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.78 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     678.23 ms /     1 runs   (  678.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1516.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.88 ms /    15 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     647.07 ms /     1 runs   (  647.07 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1422.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.34 ms /    14 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     653.57 ms /     1 runs   (  653.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1389.39 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.63 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     658.37 ms /     1 runs   (  658.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.08 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     660.96 ms /     1 runs   (  660.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.99 ms /    15 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     670.38 ms /     1 runs   (  670.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1445.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.67 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     649.59 ms /     1 runs   (  649.59 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.02 ms /    16 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     657.49 ms /     1 runs   (  657.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1501.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.60 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     726.48 ms /     1 runs   (  726.48 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1552.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.76 ms /    14 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =     649.75 ms /     1 runs   (  649.75 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1401.63 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.11 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     723.00 ms /     1 runs   (  723.00 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1538.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.40 ms /    15 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     710.52 ms /     1 runs   (  710.52 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1483.74 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.01 ms /    15 tokens (   51.53 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     682.69 ms /     1 runs   (  682.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1461.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.65 ms /    15 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     681.19 ms /     1 runs   (  681.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1469.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.69 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     656.22 ms /     1 runs   (  656.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.31 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     650.51 ms /     1 runs   (  650.51 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.42 ms /    15 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     650.94 ms /     1 runs   (  650.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1424.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.71 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     724.37 ms /     1 runs   (  724.37 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1541.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.50 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     678.10 ms /     1 runs   (  678.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1499.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.86 ms /    15 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     693.78 ms /     1 runs   (  693.78 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1471.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     890.51 ms /    16 tokens (   55.66 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =     677.04 ms /     1 runs   (  677.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1572.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.41 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     718.62 ms /     1 runs   (  718.62 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1550.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.84 ms /    15 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     677.16 ms /     1 runs   (  677.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1450.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     878.51 ms /    16 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =     688.44 ms /     1 runs   (  688.44 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1572.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.46 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     693.40 ms /     1 runs   (  693.40 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1522.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.43 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     654.25 ms /     1 runs   (  654.25 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2164.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.11 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     670.89 ms /     1 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1483.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.25 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     695.06 ms /     1 runs   (  695.06 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1513.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.17 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     656.63 ms /     1 runs   (  656.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.29 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     642.66 ms /     1 runs   (  642.66 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1415.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.80 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     725.39 ms /     1 runs   (  725.39 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1548.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.01 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     664.48 ms /     1 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.87 ms /    15 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     688.12 ms /     1 runs   (  688.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1457.79 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.66 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     667.10 ms /     1 runs   (  667.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.93 ms /    16 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     671.27 ms /     1 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1482.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.74 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     700.70 ms /     1 runs   (  700.70 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1538.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.19 ms /    15 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     660.95 ms /     1 runs   (  660.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1451.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.72 ms /    16 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     678.89 ms /     1 runs   (  678.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1514.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.70 ms /    16 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     699.46 ms /     1 runs   (  699.46 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1531.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.59 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     649.75 ms /     1 runs   (  649.75 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.25 ms /    15 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     677.61 ms /     1 runs   (  677.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1451.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.74 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     651.59 ms /     1 runs   (  651.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.99 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     665.41 ms /     1 runs   (  665.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1436.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.79 ms /    16 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =     664.44 ms /     1 runs   (  664.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1518.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.08 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     649.18 ms /     1 runs   (  649.18 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.41 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     664.81 ms /     1 runs   (  664.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.09 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     666.29 ms /     1 runs   (  666.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.98 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     644.27 ms /     1 runs   (  644.27 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1416.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.85 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     648.37 ms /     1 runs   (  648.37 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.79 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     655.24 ms /     1 runs   (  655.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /     2 runs   (    0.95 ms per token,  1050.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.62 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     695.82 ms /     1 runs   (  695.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1524.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.94 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     674.32 ms /     1 runs   (  674.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1499.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.81 ms /    16 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     689.67 ms /     1 runs   (  689.67 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1539.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.53 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     659.46 ms /     1 runs   (  659.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.51 ms /    15 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     654.83 ms /     1 runs   (  654.83 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1422.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     883.48 ms /    16 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =     680.67 ms /     1 runs   (  680.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1569.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.84 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     648.56 ms /     1 runs   (  648.56 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.77 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     646.40 ms /     1 runs   (  646.40 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1469.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2178.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.31 ms /    16 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     650.07 ms /     1 runs   (  650.07 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1488.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.86 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     652.50 ms /     1 runs   (  652.50 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.42 ms /    16 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     649.81 ms /     1 runs   (  649.81 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1492.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.36 ms /    16 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     687.05 ms /     1 runs   (  687.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1530.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.52 ms /    15 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     650.05 ms /     1 runs   (  650.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1441.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.56 ms /    16 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     654.53 ms /     1 runs   (  654.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1510.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.74 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     649.04 ms /     1 runs   (  649.04 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.25 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     645.48 ms /     1 runs   (  645.48 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.38 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     646.86 ms /     1 runs   (  646.86 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.25 ms /    14 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     663.46 ms /     1 runs   (  663.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1398.26 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.96 ms /    15 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     670.00 ms /     1 runs   (  670.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1457.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.39 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     763.38 ms /     1 runs   (  763.38 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =    1576.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.92 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     698.40 ms /     1 runs   (  698.40 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1523.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.66 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     683.27 ms /     1 runs   (  683.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1507.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.47 ms /    15 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     674.02 ms /     1 runs   (  674.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1453.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.32 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     687.05 ms /     1 runs   (  687.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1505.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.66 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     673.88 ms /     1 runs   (  673.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.33 ms /    15 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     650.17 ms /     1 runs   (  650.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1424.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.38 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     642.62 ms /     1 runs   (  642.62 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1459.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.77 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     649.05 ms /     1 runs   (  649.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     862.74 ms /    16 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =     656.79 ms /     1 runs   (  656.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1524.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.90 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     653.88 ms /     1 runs   (  653.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.81 ms /    16 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     666.67 ms /     1 runs   (  666.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1511.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /     2 runs   (    0.49 ms per token,  2020.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.00 ms /    16 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =     672.42 ms /     1 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1530.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.68 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     720.98 ms /     1 runs   (  720.98 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1560.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.86 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     699.13 ms /     1 runs   (  699.13 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1517.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.26 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     652.77 ms /     1 runs   (  652.77 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.64 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     651.96 ms /     1 runs   (  651.96 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.84 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     669.28 ms /     1 runs   (  669.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1447.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.20 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     666.14 ms /     1 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.47 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     665.93 ms /     1 runs   (  665.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1499.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.67 ms /    15 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     677.81 ms /     1 runs   (  677.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1451.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.15 ms /    16 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     656.21 ms /     1 runs   (  656.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.54 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     654.76 ms /     1 runs   (  654.76 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.69 ms /    16 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     644.83 ms /     1 runs   (  644.83 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1486.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.32 ms /    15 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     662.66 ms /     1 runs   (  662.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1437.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.50 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     674.64 ms /     1 runs   (  674.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.43 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     700.46 ms /     1 runs   (  700.46 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1519.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2178.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.80 ms /    15 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     681.69 ms /     1 runs   (  681.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1466.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.79 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     666.53 ms /     1 runs   (  666.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2042.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.51 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     687.32 ms /     1 runs   (  687.32 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1517.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.29 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     649.77 ms /     1 runs   (  649.77 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.28 ms /    16 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     706.99 ms /     1 runs   (  706.99 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1547.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.83 ms /    15 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     693.30 ms /     1 runs   (  693.30 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1475.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.18 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     706.59 ms /     1 runs   (  706.59 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1525.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.53 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     694.77 ms /     1 runs   (  694.77 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1514.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.64 ms /    15 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     666.52 ms /     1 runs   (  666.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1464.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.57 ms /    15 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     648.94 ms /     1 runs   (  648.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1426.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.94 ms /    15 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     648.51 ms /     1 runs   (  648.51 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1427.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.11 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     657.08 ms /     1 runs   (  657.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.79 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     673.14 ms /     1 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.26 ms /    15 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     674.38 ms /     1 runs   (  674.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1448.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.74 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     668.62 ms /     1 runs   (  668.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.00 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     668.64 ms /     1 runs   (  668.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1439.10 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.30 ms /    16 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     660.05 ms /     1 runs   (  660.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1505.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.92 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     675.58 ms /     1 runs   (  675.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /     2 runs   (    0.92 ms per token,  1081.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.76 ms /    15 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     675.39 ms /     1 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1456.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.79 ms /    14 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     659.51 ms /     1 runs   (  659.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1401.53 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.53 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     686.92 ms /     1 runs   (  686.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1508.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.35 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     665.78 ms /     1 runs   (  665.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.18 ms /    16 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     646.95 ms /     1 runs   (  646.95 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.43 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     682.36 ms /     1 runs   (  682.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1499.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.63 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     678.26 ms /     1 runs   (  678.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1449.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.69 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     647.09 ms /     1 runs   (  647.09 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1476.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.08 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     650.17 ms /     1 runs   (  650.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.61 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     648.46 ms /     1 runs   (  648.46 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1480.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.73 ms /    16 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     664.88 ms /     1 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.65 ms /    16 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =     662.30 ms /     1 runs   (  662.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1522.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.95 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     668.93 ms /     1 runs   (  668.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.94 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     686.94 ms /     1 runs   (  686.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1512.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.14 ms /    16 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     668.40 ms /     1 runs   (  668.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.59 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     671.69 ms /     1 runs   (  671.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1499.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.93 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     666.90 ms /     1 runs   (  666.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.82 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     643.68 ms /     1 runs   (  643.68 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1477.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.90 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     643.57 ms /     1 runs   (  643.57 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2178.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.63 ms /    16 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     692.61 ms /     1 runs   (  692.61 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1533.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.53 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     710.11 ms /     1 runs   (  710.11 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1531.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.47 ms /    15 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     646.16 ms /     1 runs   (  646.16 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1423.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.80 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     673.47 ms /     1 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.05 ms /    16 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =     650.61 ms /     1 runs   (  650.61 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1514.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.20 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     662.95 ms /     1 runs   (  662.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.98 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     647.49 ms /     1 runs   (  647.49 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.53 ms /    16 tokens (   51.53 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     695.04 ms /     1 runs   (  695.04 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1525.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.30 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     666.52 ms /     1 runs   (  666.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.53 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     663.13 ms /     1 runs   (  663.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.01 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     661.02 ms /     1 runs   (  661.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1501.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.38 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     667.72 ms /     1 runs   (  667.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.69 ms /    15 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     659.87 ms /     1 runs   (  659.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1442.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.87 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     674.03 ms /     1 runs   (  674.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1450.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.22 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     660.18 ms /     1 runs   (  660.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.93 ms /    16 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     648.38 ms /     1 runs   (  648.38 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1488.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.02 ms /    15 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     683.11 ms /     1 runs   (  683.11 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1475.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.48 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     646.92 ms /     1 runs   (  646.92 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1475.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.34 ms /    15 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =     649.78 ms /     1 runs   (  649.78 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.69 ms /    15 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     647.67 ms /     1 runs   (  647.67 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1425.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.34 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     675.41 ms /     1 runs   (  675.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.17 ms /    15 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     646.70 ms /     1 runs   (  646.70 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1422.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.73 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     645.00 ms /     1 runs   (  645.00 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.80 ms /    15 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     644.60 ms /     1 runs   (  644.60 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1435.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.73 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     659.64 ms /     1 runs   (  659.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2185.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.66 ms /    16 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =     667.70 ms /     1 runs   (  667.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1527.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.19 ms /    15 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     667.52 ms /     1 runs   (  667.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1438.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2141.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.24 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     647.09 ms /     1 runs   (  647.09 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1475.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.79 ms /    15 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     654.84 ms /     1 runs   (  654.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1442.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.26 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     652.42 ms /     1 runs   (  652.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.75 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     648.21 ms /     1 runs   (  648.21 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.38 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     648.92 ms /     1 runs   (  648.92 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.47 ms /    15 tokens (   51.16 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     650.12 ms /     1 runs   (  650.12 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1422.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.12 ms /    15 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     656.42 ms /     1 runs   (  656.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1432.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     2 runs   (    0.96 ms per token,  1039.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.48 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     648.38 ms /     1 runs   (  648.38 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1429.18 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.18 ms /    15 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     658.12 ms /     1 runs   (  658.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1429.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.27 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     692.46 ms /     1 runs   (  692.46 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1526.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.70 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     649.03 ms /     1 runs   (  649.03 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.45 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     647.85 ms /     1 runs   (  647.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.50 ms /    16 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     656.65 ms /     1 runs   (  656.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.02 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     649.20 ms /     1 runs   (  649.20 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.91 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     635.82 ms /     1 runs   (  635.82 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1455.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.51 ms /    15 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     651.75 ms /     1 runs   (  651.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1427.49 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.46 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     659.95 ms /     1 runs   (  659.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.65 ms /    16 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =     649.58 ms /     1 runs   (  649.58 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1458.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.76 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     678.51 ms /     1 runs   (  678.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1497.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.67 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     702.18 ms /     1 runs   (  702.18 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1474.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.99 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     681.40 ms /     1 runs   (  681.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1494.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2173.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.94 ms /    15 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     642.62 ms /     1 runs   (  642.62 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1422.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.39 ms /    16 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =     661.14 ms /     1 runs   (  661.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1525.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.21 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     662.85 ms /     1 runs   (  662.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.56 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     652.94 ms /     1 runs   (  652.94 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2150.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.07 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     679.15 ms /     1 runs   (  679.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1492.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.83 ms /    15 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     669.14 ms /     1 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1449.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.53 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     650.56 ms /     1 runs   (  650.56 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.90 ms /    16 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     651.71 ms /     1 runs   (  651.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1491.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.72 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     661.11 ms /     1 runs   (  661.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.96 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     654.11 ms /     1 runs   (  654.11 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.59 ms /    14 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     671.28 ms /     1 runs   (  671.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1405.16 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.98 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     649.94 ms /     1 runs   (  649.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /     2 runs   (    0.49 ms per token,  2026.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.99 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     660.92 ms /     1 runs   (  660.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.42 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     648.66 ms /     1 runs   (  648.66 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.51 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     662.31 ms /     1 runs   (  662.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.36 ms /    15 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     653.89 ms /     1 runs   (  653.89 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1422.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.35 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     658.34 ms /     1 runs   (  658.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.55 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     664.31 ms /     1 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.60 ms /    16 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     653.40 ms /     1 runs   (  653.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1503.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.00 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     667.50 ms /     1 runs   (  667.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.27 ms /    16 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     660.60 ms /     1 runs   (  660.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1497.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.44 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     665.62 ms /     1 runs   (  665.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.15 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     647.70 ms /     1 runs   (  647.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.67 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     671.11 ms /     1 runs   (  671.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1314.07 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.21 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     673.81 ms /     1 runs   (  673.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.91 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     653.06 ms /     1 runs   (  653.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.64 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     635.96 ms /     1 runs   (  635.96 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1455.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.92 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     660.75 ms /     1 runs   (  660.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.87 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     652.39 ms /     1 runs   (  652.39 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.54 ms /    15 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     646.54 ms /     1 runs   (  646.54 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1434.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.08 ms /    16 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =     645.18 ms /     1 runs   (  645.18 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1454.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.50 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     676.03 ms /     1 runs   (  676.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.62 ms /    15 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     648.12 ms /     1 runs   (  648.12 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1428.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.21 ms /    16 tokens (   51.83 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     642.49 ms /     1 runs   (  642.49 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1477.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.53 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     647.20 ms /     1 runs   (  647.20 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.35 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     639.39 ms /     1 runs   (  639.39 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1463.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.32 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     672.57 ms /     1 runs   (  672.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1489.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.02 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     661.18 ms /     1 runs   (  661.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1497.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.13 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     648.34 ms /     1 runs   (  648.34 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.79 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     644.67 ms /     1 runs   (  644.67 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1472.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.33 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     660.27 ms /     1 runs   (  660.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.57 ms /    16 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =     647.86 ms /     1 runs   (  647.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1518.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.01 ms /    16 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     678.95 ms /     1 runs   (  678.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1521.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.39 ms /    16 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     631.72 ms /     1 runs   (  631.72 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1476.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.94 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     672.90 ms /     1 runs   (  672.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.19 ms /    15 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     634.73 ms /     1 runs   (  634.73 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1418.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.93 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     663.27 ms /     1 runs   (  663.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.76 ms /    14 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     646.59 ms /     1 runs   (  646.59 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1369.14 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.17 ms /    16 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     647.17 ms /     1 runs   (  647.17 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1483.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.38 ms /    15 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     692.74 ms /     1 runs   (  692.74 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1472.44 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.05 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     647.72 ms /     1 runs   (  647.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.48 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     645.48 ms /     1 runs   (  645.48 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.68 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     655.81 ms /     1 runs   (  655.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.80 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     654.88 ms /     1 runs   (  654.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.95 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     639.11 ms /     1 runs   (  639.11 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.27 ms /    16 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     672.15 ms /     1 runs   (  672.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1525.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.66 ms /    15 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     695.41 ms /     1 runs   (  695.41 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1478.31 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.20 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     656.83 ms /     1 runs   (  656.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.32 ms /    15 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     642.72 ms /     1 runs   (  642.72 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1432.64 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2107.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.44 ms /    16 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     651.25 ms /     1 runs   (  651.25 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1490.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.76 ms /    15 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     657.80 ms /     1 runs   (  657.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1428.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.83 ms /    16 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     666.78 ms /     1 runs   (  666.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1514.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.27 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     661.61 ms /     1 runs   (  661.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.05 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     661.48 ms /     1 runs   (  661.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.66 ms /    16 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     658.47 ms /     1 runs   (  658.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1496.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.81 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     641.60 ms /     1 runs   (  641.60 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1417.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.56 ms /    15 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     680.59 ms /     1 runs   (  680.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1449.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.21 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     654.34 ms /     1 runs   (  654.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.16 ms /    15 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     652.17 ms /     1 runs   (  652.17 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1440.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.21 ms /    16 tokens (   50.83 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     627.64 ms /     1 runs   (  627.64 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1446.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.56 ms /    15 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     673.44 ms /     1 runs   (  673.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1454.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.08 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     653.43 ms /     1 runs   (  653.43 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1465.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.38 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     646.14 ms /     1 runs   (  646.14 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.41 ms /    15 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     646.56 ms /     1 runs   (  646.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1433.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.61 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     651.60 ms /     1 runs   (  651.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.13 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     650.01 ms /     1 runs   (  650.01 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.06 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     669.09 ms /     1 runs   (  669.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.64 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     649.00 ms /     1 runs   (  649.00 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /     2 runs   (    0.94 ms per token,  1064.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.32 ms /    14 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     645.35 ms /     1 runs   (  645.35 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1381.17 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.01 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     660.29 ms /     1 runs   (  660.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.49 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     624.57 ms /     1 runs   (  624.57 ms per token,     1.60 tokens per second)\n",
      "llama_print_timings:       total time =    1443.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.42 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     657.90 ms /     1 runs   (  657.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.16 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     644.24 ms /     1 runs   (  644.24 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1416.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.57 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     660.40 ms /     1 runs   (  660.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.07 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     661.51 ms /     1 runs   (  661.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.89 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     653.47 ms /     1 runs   (  653.47 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.97 ms /    15 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     714.47 ms /     1 runs   (  714.47 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1500.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.77 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     647.08 ms /     1 runs   (  647.08 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.76 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     648.92 ms /     1 runs   (  648.92 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.26 ms /    16 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     689.99 ms /     1 runs   (  689.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1533.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     798.66 ms /    15 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =     668.16 ms /     1 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1471.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.57 ms /    14 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =     659.55 ms /     1 runs   (  659.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1430.50 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.53 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     669.24 ms /     1 runs   (  669.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.80 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     673.00 ms /     1 runs   (  673.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.00 ms /    16 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     695.73 ms /     1 runs   (  695.73 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1507.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.38 ms /    15 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     666.52 ms /     1 runs   (  666.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1435.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2129.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.39 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     660.25 ms /     1 runs   (  660.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.68 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     670.49 ms /     1 runs   (  670.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1484.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.56 ms /    16 tokens (   51.03 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     643.10 ms /     1 runs   (  643.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.20 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     651.51 ms /     1 runs   (  651.51 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.43 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     650.48 ms /     1 runs   (  650.48 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.17 ms /    15 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     669.24 ms /     1 runs   (  669.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1452.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.87 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     655.12 ms /     1 runs   (  655.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1486.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.69 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     651.48 ms /     1 runs   (  651.48 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.18 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     670.54 ms /     1 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.17 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     641.08 ms /     1 runs   (  641.08 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1470.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.96 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     659.69 ms /     1 runs   (  659.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.44 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     664.46 ms /     1 runs   (  664.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1479.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.97 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     674.81 ms /     1 runs   (  674.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1512.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.57 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     653.60 ms /     1 runs   (  653.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.20 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     674.89 ms /     1 runs   (  674.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1489.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.81 ms /    15 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     674.34 ms /     1 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1469.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.23 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     660.50 ms /     1 runs   (  660.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.88 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     640.47 ms /     1 runs   (  640.47 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1457.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2129.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.52 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     693.97 ms /     1 runs   (  693.97 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1525.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.67 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     662.41 ms /     1 runs   (  662.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.98 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     656.84 ms /     1 runs   (  656.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.35 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     670.38 ms /     1 runs   (  670.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.54 ms /    16 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     643.78 ms /     1 runs   (  643.78 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1482.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.05 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     657.51 ms /     1 runs   (  657.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.99 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     692.20 ms /     1 runs   (  692.20 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1510.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.57 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     665.73 ms /     1 runs   (  665.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.74 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     659.89 ms /     1 runs   (  659.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1496.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.84 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     649.37 ms /     1 runs   (  649.37 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.67 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     658.44 ms /     1 runs   (  658.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1433.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.93 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     687.56 ms /     1 runs   (  687.56 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1501.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.47 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     668.69 ms /     1 runs   (  668.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.39 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     690.65 ms /     1 runs   (  690.65 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1506.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.43 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     669.70 ms /     1 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.42 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     653.44 ms /     1 runs   (  653.44 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.25 ms /    16 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =     659.05 ms /     1 runs   (  659.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1516.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.76 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     649.79 ms /     1 runs   (  649.79 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1493.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.10 ms /    15 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     644.87 ms /     1 runs   (  644.87 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1429.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.70 ms /    16 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     656.55 ms /     1 runs   (  656.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.02 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     675.18 ms /     1 runs   (  675.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1499.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.65 ms /    16 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     674.60 ms /     1 runs   (  674.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1532.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.04 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     646.74 ms /     1 runs   (  646.74 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1481.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.66 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     701.35 ms /     1 runs   (  701.35 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1514.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.36 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     648.41 ms /     1 runs   (  648.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.88 ms /    16 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     689.35 ms /     1 runs   (  689.35 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1524.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.85 ms /    16 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     632.54 ms /     1 runs   (  632.54 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1469.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.06 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     658.22 ms /     1 runs   (  658.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2087.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.74 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     664.66 ms /     1 runs   (  664.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.14 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     708.65 ms /     1 runs   (  708.65 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1539.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.93 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     641.38 ms /     1 runs   (  641.38 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1463.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.15 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     649.27 ms /     1 runs   (  649.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.04 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     647.44 ms /     1 runs   (  647.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.05 ms /    15 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     714.53 ms /     1 runs   (  714.53 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1488.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.94 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     640.89 ms /     1 runs   (  640.89 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.98 ms /    15 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     663.19 ms /     1 runs   (  663.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1440.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.39 ms /    16 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     666.74 ms /     1 runs   (  666.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1521.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.98 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     672.31 ms /     1 runs   (  672.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.60 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     653.70 ms /     1 runs   (  653.70 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.52 ms /    14 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     691.63 ms /     1 runs   (  691.63 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1428.32 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.56 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     649.52 ms /     1 runs   (  649.52 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1484.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.88 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     650.51 ms /     1 runs   (  650.51 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.54 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     673.87 ms /     1 runs   (  673.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1444.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.76 ms /    14 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     647.95 ms /     1 runs   (  647.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1371.62 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.12 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     653.05 ms /     1 runs   (  653.05 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     761.22 ms /    15 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     686.84 ms /     1 runs   (  686.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1453.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.58 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     671.50 ms /     1 runs   (  671.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.63 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     645.56 ms /     1 runs   (  645.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.69 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     660.08 ms /     1 runs   (  660.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.53 ms /    16 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     647.84 ms /     1 runs   (  647.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1498.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.19 ms /    16 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     641.14 ms /     1 runs   (  641.14 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1473.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.96 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     649.58 ms /     1 runs   (  649.58 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.99 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     658.49 ms /     1 runs   (  658.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.13 ms /    15 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     680.64 ms /     1 runs   (  680.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1467.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.50 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     693.89 ms /     1 runs   (  693.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1513.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.13 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     654.68 ms /     1 runs   (  654.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.46 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     666.51 ms /     1 runs   (  666.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.74 ms /    14 tokens (   54.48 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =     651.05 ms /     1 runs   (  651.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1419.03 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.23 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     647.39 ms /     1 runs   (  647.39 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.84 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     706.30 ms /     1 runs   (  706.30 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1532.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.04 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     658.11 ms /     1 runs   (  658.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     2 runs   (    0.97 ms per token,  1032.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.05 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     640.14 ms /     1 runs   (  640.14 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1467.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     794.62 ms /    15 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     688.24 ms /     1 runs   (  688.24 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1488.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.92 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     654.59 ms /     1 runs   (  654.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1487.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.96 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     646.04 ms /     1 runs   (  646.04 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.83 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     664.02 ms /     1 runs   (  664.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.30 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     697.20 ms /     1 runs   (  697.20 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1516.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.50 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     649.50 ms /     1 runs   (  649.50 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.80 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     669.19 ms /     1 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.30 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     644.86 ms /     1 runs   (  644.86 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.58 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     641.89 ms /     1 runs   (  641.89 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1460.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.06 ms /    14 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     657.56 ms /     1 runs   (  657.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1382.64 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.01 ms /    15 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     680.12 ms /     1 runs   (  680.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1463.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.02 ms /    16 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     653.87 ms /     1 runs   (  653.87 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.39 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     673.72 ms /     1 runs   (  673.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1488.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.03 ms /    16 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     650.97 ms /     1 runs   (  650.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1496.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.73 ms /    16 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =     703.37 ms /     1 runs   (  703.37 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1558.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.03 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     663.46 ms /     1 runs   (  663.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.08 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     646.69 ms /     1 runs   (  646.69 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1418.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.55 ms /    14 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     681.42 ms /     1 runs   (  681.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1418.06 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.01 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     649.17 ms /     1 runs   (  649.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1490.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.15 ms /    16 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     662.48 ms /     1 runs   (  662.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1508.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.76 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     653.04 ms /     1 runs   (  653.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.90 ms /    15 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     654.74 ms /     1 runs   (  654.74 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1423.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.06 ms /    15 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     639.56 ms /     1 runs   (  639.56 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1424.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.16 ms /    15 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     644.72 ms /     1 runs   (  644.72 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1414.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.29 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     656.32 ms /     1 runs   (  656.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.68 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     641.31 ms /     1 runs   (  641.31 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1459.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.04 ms /    15 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     656.27 ms /     1 runs   (  656.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1438.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.01 ms /    15 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     647.85 ms /     1 runs   (  647.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1422.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2157.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.12 ms /    15 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     654.40 ms /     1 runs   (  654.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1441.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.07 ms /    16 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     653.63 ms /     1 runs   (  653.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1491.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.42 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     668.31 ms /     1 runs   (  668.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.83 ms /    16 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =     646.16 ms /     1 runs   (  646.16 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1500.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.95 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     661.84 ms /     1 runs   (  661.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.49 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     674.05 ms /     1 runs   (  674.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1500.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.42 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     656.76 ms /     1 runs   (  656.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.74 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     651.98 ms /     1 runs   (  651.98 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.95 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     654.64 ms /     1 runs   (  654.64 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.02 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     647.40 ms /     1 runs   (  647.40 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.07 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     665.22 ms /     1 runs   (  665.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1477.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.60 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     684.41 ms /     1 runs   (  684.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1458.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.80 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     682.38 ms /     1 runs   (  682.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1509.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.41 ms /    15 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     665.43 ms /     1 runs   (  665.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1455.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.73 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     646.10 ms /     1 runs   (  646.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1422.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.10 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     674.58 ms /     1 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.45 ms /    16 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     660.63 ms /     1 runs   (  660.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.82 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     660.63 ms /     1 runs   (  660.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.97 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     637.40 ms /     1 runs   (  637.40 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1465.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.66 ms /    16 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     662.09 ms /     1 runs   (  662.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1498.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.59 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     681.85 ms /     1 runs   (  681.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1452.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.61 ms /    15 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     660.45 ms /     1 runs   (  660.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1430.64 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.29 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     660.12 ms /     1 runs   (  660.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.49 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     647.09 ms /     1 runs   (  647.09 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.66 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     639.79 ms /     1 runs   (  639.79 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1455.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.95 ms /    14 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =     630.14 ms /     1 runs   (  630.14 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1384.15 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.94 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     667.69 ms /     1 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.81 ms /    15 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     656.30 ms /     1 runs   (  656.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1444.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.71 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     685.26 ms /     1 runs   (  685.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1513.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.26 ms /    16 tokens (   51.45 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     658.02 ms /     1 runs   (  658.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.21 ms /    13 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =     679.65 ms /     1 runs   (  679.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1398.51 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.83 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     654.39 ms /     1 runs   (  654.39 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.52 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     664.68 ms /     1 runs   (  664.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.63 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     614.91 ms /     1 runs   (  614.91 ms per token,     1.63 tokens per second)\n",
      "llama_print_timings:       total time =    1439.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.63 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     663.35 ms /     1 runs   (  663.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2127.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.07 ms /    16 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     655.07 ms /     1 runs   (  655.07 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1490.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.45 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     661.38 ms /     1 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.65 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     660.05 ms /     1 runs   (  660.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1493.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.27 ms /    16 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     664.49 ms /     1 runs   (  664.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1501.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.82 ms /    15 tokens (   51.45 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     633.22 ms /     1 runs   (  633.22 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1410.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.96 ms /    16 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     701.63 ms /     1 runs   (  701.63 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1541.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     800.82 ms /    15 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =     674.96 ms /     1 runs   (  674.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1482.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.14 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     680.44 ms /     1 runs   (  680.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1509.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.83 ms /    16 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =     666.07 ms /     1 runs   (  666.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1526.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.13 ms /    16 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     662.48 ms /     1 runs   (  662.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1515.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.24 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     670.35 ms /     1 runs   (  670.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.57 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     662.67 ms /     1 runs   (  662.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.45 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     671.33 ms /     1 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.85 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     665.01 ms /     1 runs   (  665.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1439.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.80 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     656.73 ms /     1 runs   (  656.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.31 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     651.79 ms /     1 runs   (  651.79 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.25 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     653.52 ms /     1 runs   (  653.52 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.23 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     661.74 ms /     1 runs   (  661.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.78 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     685.28 ms /     1 runs   (  685.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1456.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.63 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     644.88 ms /     1 runs   (  644.88 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.70 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     714.60 ms /     1 runs   (  714.60 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1546.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.35 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     661.13 ms /     1 runs   (  661.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.25 ms /    16 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     699.52 ms /     1 runs   (  699.52 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1542.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.63 ms /    15 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =     651.22 ms /     1 runs   (  651.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1486.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.04 ms /    15 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     647.54 ms /     1 runs   (  647.54 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1440.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.62 ms /    16 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     654.92 ms /     1 runs   (  654.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1489.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.55 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     693.87 ms /     1 runs   (  693.87 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1530.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.04 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     654.62 ms /     1 runs   (  654.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1491.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.05 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     661.69 ms /     1 runs   (  661.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1499.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.81 ms /    15 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     658.64 ms /     1 runs   (  658.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1437.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.11 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     670.46 ms /     1 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.48 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     647.21 ms /     1 runs   (  647.21 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.67 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     664.02 ms /     1 runs   (  664.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1436.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.51 ms /    15 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     666.88 ms /     1 runs   (  666.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1441.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.06 ms /    15 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     682.81 ms /     1 runs   (  682.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1472.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.05 ms /    15 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     645.20 ms /     1 runs   (  645.20 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1427.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.54 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     658.78 ms /     1 runs   (  658.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.18 ms /    15 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     676.85 ms /     1 runs   (  676.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1455.67 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.81 ms /    16 tokens (   51.61 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     651.41 ms /     1 runs   (  651.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.32 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     692.31 ms /     1 runs   (  692.31 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1516.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.04 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     692.43 ms /     1 runs   (  692.43 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1510.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.10 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     709.93 ms /     1 runs   (  709.93 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1522.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.78 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     758.35 ms /     1 runs   (  758.35 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =    1578.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.11 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     661.87 ms /     1 runs   (  661.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.33 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     658.24 ms /     1 runs   (  658.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.40 ms /    15 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     723.06 ms /     1 runs   (  723.06 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1495.87 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.56 ms /    16 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     700.54 ms /     1 runs   (  700.54 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1533.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.77 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     667.51 ms /     1 runs   (  667.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.64 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     699.86 ms /     1 runs   (  699.86 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1517.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.51 ms /    15 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     670.54 ms /     1 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1457.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.04 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     665.11 ms /     1 runs   (  665.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.77 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     708.06 ms /     1 runs   (  708.06 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1521.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.28 ms /    15 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     661.68 ms /     1 runs   (  661.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1440.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.88 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     647.96 ms /     1 runs   (  647.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.95 ms /    15 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     656.66 ms /     1 runs   (  656.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1437.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.55 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     673.23 ms /     1 runs   (  673.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1502.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.94 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     658.36 ms /     1 runs   (  658.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.03 ms /    15 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     650.02 ms /     1 runs   (  650.02 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1431.23 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.87 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     651.09 ms /     1 runs   (  651.09 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2143.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.06 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     661.13 ms /     1 runs   (  661.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.30 ms /    15 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     646.25 ms /     1 runs   (  646.25 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1427.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.93 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     691.82 ms /     1 runs   (  691.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1512.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.92 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     716.16 ms /     1 runs   (  716.16 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1539.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.42 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     671.04 ms /     1 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1449.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2176.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.78 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     693.50 ms /     1 runs   (  693.50 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1531.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.00 ms /    16 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     645.88 ms /     1 runs   (  645.88 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1479.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.79 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     662.97 ms /     1 runs   (  662.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.93 ms /    15 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     676.50 ms /     1 runs   (  676.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1460.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     798.66 ms /    15 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =     645.54 ms /     1 runs   (  645.54 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1449.18 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.26 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     662.99 ms /     1 runs   (  662.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.35 ms /    15 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     675.77 ms /     1 runs   (  675.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1466.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.22 ms /    15 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     659.76 ms /     1 runs   (  659.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1437.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.20 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     665.25 ms /     1 runs   (  665.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.82 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     656.06 ms /     1 runs   (  656.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.59 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     691.91 ms /     1 runs   (  691.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1509.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.88 ms /    15 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     648.64 ms /     1 runs   (  648.64 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1420.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     866.04 ms /    16 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =     655.24 ms /     1 runs   (  655.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1526.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.80 ms /    16 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =     663.22 ms /     1 runs   (  663.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1520.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.98 ms /    15 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =     648.34 ms /     1 runs   (  648.34 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.03 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     650.48 ms /     1 runs   (  650.48 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.86 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     657.34 ms /     1 runs   (  657.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.48 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     647.27 ms /     1 runs   (  647.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.01 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     680.62 ms /     1 runs   (  680.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1495.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.25 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     709.00 ms /     1 runs   (  709.00 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1526.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.13 ms /    16 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     654.88 ms /     1 runs   (  654.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1494.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.79 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     726.32 ms /     1 runs   (  726.32 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1544.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.10 ms /    16 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     666.45 ms /     1 runs   (  666.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.90 ms /    16 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     661.70 ms /     1 runs   (  661.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1501.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.92 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     662.89 ms /     1 runs   (  662.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.98 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     696.84 ms /     1 runs   (  696.84 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1467.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.60 ms /    16 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     671.73 ms /     1 runs   (  671.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1514.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.27 ms /    16 tokens (   52.45 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     648.84 ms /     1 runs   (  648.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1494.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.02 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     646.12 ms /     1 runs   (  646.12 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.61 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     649.70 ms /     1 runs   (  649.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1481.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2164.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.34 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     696.12 ms /     1 runs   (  696.12 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1521.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.14 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     693.17 ms /     1 runs   (  693.17 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1523.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.64 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     662.20 ms /     1 runs   (  662.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1501.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.74 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     661.53 ms /     1 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1439.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.91 ms /    16 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     697.30 ms /     1 runs   (  697.30 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1533.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.31 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     640.76 ms /     1 runs   (  640.76 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.52 ms /    15 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     653.87 ms /     1 runs   (  653.87 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1421.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.09 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     659.44 ms /     1 runs   (  659.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.96 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     667.28 ms /     1 runs   (  667.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.50 ms /    15 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     652.14 ms /     1 runs   (  652.14 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1436.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.67 ms /    14 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     654.05 ms /     1 runs   (  654.05 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1384.51 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.43 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     667.90 ms /     1 runs   (  667.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.66 ms /    16 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     691.24 ms /     1 runs   (  691.24 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1523.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.69 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     666.73 ms /     1 runs   (  666.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.95 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     656.89 ms /     1 runs   (  656.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.52 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     647.06 ms /     1 runs   (  647.06 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.09 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     647.65 ms /     1 runs   (  647.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.04 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     775.30 ms /     1 runs   (  775.30 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =    1609.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.83 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     699.04 ms /     1 runs   (  699.04 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1523.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.62 ms /    14 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     649.31 ms /     1 runs   (  649.31 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1377.97 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.84 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     688.07 ms /     1 runs   (  688.07 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1506.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.43 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     659.27 ms /     1 runs   (  659.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.62 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     691.56 ms /     1 runs   (  691.56 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1509.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.31 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     668.37 ms /     1 runs   (  668.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.78 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     658.57 ms /     1 runs   (  658.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2190.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.95 ms /    16 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     661.37 ms /     1 runs   (  661.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1500.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.47 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     671.10 ms /     1 runs   (  671.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.88 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     658.21 ms /     1 runs   (  658.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1496.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.94 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     659.92 ms /     1 runs   (  659.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.96 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     658.70 ms /     1 runs   (  658.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.62 ms /    16 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =     682.06 ms /     1 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1542.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.61 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     678.66 ms /     1 runs   (  678.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1500.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.62 ms /    16 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     661.62 ms /     1 runs   (  661.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1506.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.72 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     655.34 ms /     1 runs   (  655.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.92 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     665.46 ms /     1 runs   (  665.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.91 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     651.67 ms /     1 runs   (  651.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.06 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     671.85 ms /     1 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1509.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.24 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     650.79 ms /     1 runs   (  650.79 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.33 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     654.47 ms /     1 runs   (  654.47 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.85 ms /    15 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     650.87 ms /     1 runs   (  650.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1432.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.28 ms /    16 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     655.55 ms /     1 runs   (  655.55 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1503.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.18 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     656.89 ms /     1 runs   (  656.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.65 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     655.69 ms /     1 runs   (  655.69 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.25 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     649.33 ms /     1 runs   (  649.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.15 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     661.50 ms /     1 runs   (  661.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1433.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.34 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     700.15 ms /     1 runs   (  700.15 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1515.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.73 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     686.66 ms /     1 runs   (  686.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1512.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.91 ms /    16 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     675.99 ms /     1 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1511.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.36 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     646.47 ms /     1 runs   (  646.47 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1474.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.93 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     644.67 ms /     1 runs   (  644.67 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.00 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     650.39 ms /     1 runs   (  650.39 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1486.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.57 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     655.16 ms /     1 runs   (  655.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.78 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     651.90 ms /     1 runs   (  651.90 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.61 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     664.84 ms /     1 runs   (  664.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1479.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.53 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     650.21 ms /     1 runs   (  650.21 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.88 ms /    15 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     691.03 ms /     1 runs   (  691.03 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1474.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.27 ms /    16 tokens (   52.45 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     656.81 ms /     1 runs   (  656.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1501.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.11 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     660.37 ms /     1 runs   (  660.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.82 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     656.15 ms /     1 runs   (  656.15 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2185.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.23 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     657.79 ms /     1 runs   (  657.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1502.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2136.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.34 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     695.90 ms /     1 runs   (  695.90 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1513.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.95 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     659.21 ms /     1 runs   (  659.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.57 ms /    15 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     657.78 ms /     1 runs   (  657.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1432.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.20 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     651.96 ms /     1 runs   (  651.96 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1424.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.89 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     653.09 ms /     1 runs   (  653.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.26 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     665.88 ms /     1 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.31 ms /    15 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     667.11 ms /     1 runs   (  667.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1438.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.91 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     666.46 ms /     1 runs   (  666.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.54 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     659.87 ms /     1 runs   (  659.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.38 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     642.37 ms /     1 runs   (  642.37 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1457.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.11 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     675.55 ms /     1 runs   (  675.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.17 ms /    16 tokens (   51.64 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     645.15 ms /     1 runs   (  645.15 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1476.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.04 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     673.61 ms /     1 runs   (  673.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.53 ms /    16 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     657.68 ms /     1 runs   (  657.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1499.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.32 ms /    16 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =     652.90 ms /     1 runs   (  652.90 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1516.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.56 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     651.54 ms /     1 runs   (  651.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.65 ms /    16 tokens (   51.67 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     659.64 ms /     1 runs   (  659.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.94 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     660.32 ms /     1 runs   (  660.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.54 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     660.40 ms /     1 runs   (  660.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.44 ms /    14 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     660.97 ms /     1 runs   (  660.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1392.29 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.91 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     660.61 ms /     1 runs   (  660.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.36 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     655.04 ms /     1 runs   (  655.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.76 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     648.98 ms /     1 runs   (  648.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.89 ms /    16 tokens (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     650.70 ms /     1 runs   (  650.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.41 ms /    15 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     656.41 ms /     1 runs   (  656.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1432.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.21 ms /    16 tokens (   50.83 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     655.41 ms /     1 runs   (  655.41 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.15 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     661.21 ms /     1 runs   (  661.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.61 ms /    15 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     673.89 ms /     1 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1443.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.47 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     662.17 ms /     1 runs   (  662.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.48 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     644.12 ms /     1 runs   (  644.12 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.26 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     707.41 ms /     1 runs   (  707.41 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1531.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.78 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     675.20 ms /     1 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1446.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2044.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.75 ms /    16 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     648.57 ms /     1 runs   (  648.57 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.63 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     670.59 ms /     1 runs   (  670.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.15 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     653.49 ms /     1 runs   (  653.49 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.50 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     642.98 ms /     1 runs   (  642.98 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.43 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     660.27 ms /     1 runs   (  660.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.41 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     643.21 ms /     1 runs   (  643.21 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.62 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     651.43 ms /     1 runs   (  651.43 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.87 ms /    15 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     651.47 ms /     1 runs   (  651.47 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1430.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.55 ms /    16 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     671.84 ms /     1 runs   (  671.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1510.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.43 ms /    16 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =     647.61 ms /     1 runs   (  647.61 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1509.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2120.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.71 ms /    14 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     662.66 ms /     1 runs   (  662.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1406.94 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.98 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     658.55 ms /     1 runs   (  658.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.99 ms /    15 tokens (   52.87 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     640.78 ms /     1 runs   (  640.78 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1439.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.19 ms /    16 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     652.62 ms /     1 runs   (  652.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1494.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.92 ms /    15 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     658.20 ms /     1 runs   (  658.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1428.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.72 ms /    14 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =     643.48 ms /     1 runs   (  643.48 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1393.46 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.31 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     648.84 ms /     1 runs   (  648.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.59 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     647.72 ms /     1 runs   (  647.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1484.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.38 ms /    15 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     657.59 ms /     1 runs   (  657.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1431.10 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.88 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     646.42 ms /     1 runs   (  646.42 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2162.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.21 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     651.44 ms /     1 runs   (  651.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.42 ms /    16 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =     701.42 ms /     1 runs   (  701.42 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1563.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.52 ms /    16 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     699.73 ms /     1 runs   (  699.73 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1550.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /     2 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.39 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     721.38 ms /     1 runs   (  721.38 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1554.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     2 runs   (    0.64 ms per token,  1567.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.26 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     674.19 ms /     1 runs   (  674.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1513.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.06 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     664.06 ms /     1 runs   (  664.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.70 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     656.46 ms /     1 runs   (  656.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.29 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     691.13 ms /     1 runs   (  691.13 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1514.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.37 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     652.65 ms /     1 runs   (  652.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     798.23 ms /    15 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =     659.74 ms /     1 runs   (  659.74 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1463.18 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.62 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     655.72 ms /     1 runs   (  655.72 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.24 ms /    14 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     667.95 ms /     1 runs   (  667.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1403.68 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.76 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     662.55 ms /     1 runs   (  662.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.23 ms /    16 tokens (   52.70 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     653.59 ms /     1 runs   (  653.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1501.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.72 ms /    14 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     651.30 ms /     1 runs   (  651.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1384.61 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.90 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     660.54 ms /     1 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.54 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     660.80 ms /     1 runs   (  660.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.67 ms /    15 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     670.09 ms /     1 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1443.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.00 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     659.85 ms /     1 runs   (  659.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     898.47 ms /    16 tokens (   56.15 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =     643.88 ms /     1 runs   (  643.88 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1548.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.47 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     639.80 ms /     1 runs   (  639.80 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1465.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.57 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     672.68 ms /     1 runs   (  672.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.89 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     652.33 ms /     1 runs   (  652.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.11 ms /    13 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     656.22 ms /     1 runs   (  656.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1340.84 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.31 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     661.77 ms /     1 runs   (  661.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.97 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     648.11 ms /     1 runs   (  648.11 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.30 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     652.37 ms /     1 runs   (  652.37 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.74 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     648.41 ms /     1 runs   (  648.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.09 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     671.15 ms /     1 runs   (  671.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1483.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.43 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     661.38 ms /     1 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.83 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     659.30 ms /     1 runs   (  659.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1432.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.81 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     650.22 ms /     1 runs   (  650.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.44 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     656.67 ms /     1 runs   (  656.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.37 ms /    16 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     665.50 ms /     1 runs   (  665.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.61 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     653.16 ms /     1 runs   (  653.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.28 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     667.67 ms /     1 runs   (  667.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.24 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     644.37 ms /     1 runs   (  644.37 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.48 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     653.33 ms /     1 runs   (  653.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.50 ms /    15 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     656.30 ms /     1 runs   (  656.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1432.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.98 ms /    15 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     658.82 ms /     1 runs   (  658.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1436.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.83 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     655.10 ms /     1 runs   (  655.10 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.84 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     674.02 ms /     1 runs   (  674.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.08 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     657.21 ms /     1 runs   (  657.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1469.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.48 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     647.70 ms /     1 runs   (  647.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.99 ms /    15 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     652.36 ms /     1 runs   (  652.36 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1426.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.85 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     649.62 ms /     1 runs   (  649.62 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.48 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     669.18 ms /     1 runs   (  669.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.64 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     731.11 ms /     1 runs   (  731.11 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1564.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.16 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     650.09 ms /     1 runs   (  650.09 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.79 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     653.37 ms /     1 runs   (  653.37 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.47 ms /    16 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     653.04 ms /     1 runs   (  653.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1497.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.44 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     686.00 ms /     1 runs   (  686.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1501.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.94 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     649.42 ms /     1 runs   (  649.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.35 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     659.34 ms /     1 runs   (  659.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.88 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     662.15 ms /     1 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.01 ms /    16 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     678.36 ms /     1 runs   (  678.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1490.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.95 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     659.25 ms /     1 runs   (  659.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.26 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     656.12 ms /     1 runs   (  656.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.78 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     652.20 ms /     1 runs   (  652.20 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.59 ms /    16 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     655.88 ms /     1 runs   (  655.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.01 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     696.65 ms /     1 runs   (  696.65 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1513.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.02 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     650.15 ms /     1 runs   (  650.15 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.21 ms /    16 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     662.57 ms /     1 runs   (  662.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1498.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.21 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     643.81 ms /     1 runs   (  643.81 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.99 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     671.07 ms /     1 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1500.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.32 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     660.92 ms /     1 runs   (  660.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.78 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     672.76 ms /     1 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.62 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     675.02 ms /     1 runs   (  675.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.47 ms /    15 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     663.33 ms /     1 runs   (  663.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1431.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.80 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     649.70 ms /     1 runs   (  649.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1287.04 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.87 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     651.18 ms /     1 runs   (  651.18 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.37 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     665.02 ms /     1 runs   (  665.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1502.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.32 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     641.56 ms /     1 runs   (  641.56 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1470.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.49 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     666.37 ms /     1 runs   (  666.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.40 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     709.88 ms /     1 runs   (  709.88 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1528.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.10 ms /    16 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     673.47 ms /     1 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1515.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.57 ms /    16 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     671.92 ms /     1 runs   (  671.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1504.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.98 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     689.00 ms /     1 runs   (  689.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1523.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.06 ms /    15 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =     643.86 ms /     1 runs   (  643.86 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1455.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.87 ms /    16 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     696.62 ms /     1 runs   (  696.62 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1543.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.33 ms /    15 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     647.15 ms /     1 runs   (  647.15 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1422.80 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.49 ms per token,  2053.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.00 ms /    15 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     689.73 ms /     1 runs   (  689.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1474.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     794.48 ms /    15 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     642.94 ms /     1 runs   (  642.94 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1442.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.10 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     673.83 ms /     1 runs   (  673.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.55 ms /    15 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     665.32 ms /     1 runs   (  665.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1438.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.71 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     660.65 ms /     1 runs   (  660.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.90 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     671.63 ms /     1 runs   (  671.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.10 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     685.09 ms /     1 runs   (  685.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1510.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.86 ms /    14 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     640.23 ms /     1 runs   (  640.23 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1367.37 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.10 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     660.90 ms /     1 runs   (  660.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.64 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     667.06 ms /     1 runs   (  667.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.07 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     672.13 ms /     1 runs   (  672.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.26 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     656.81 ms /     1 runs   (  656.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.01 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     680.47 ms /     1 runs   (  680.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1494.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2162.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.73 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     677.07 ms /     1 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.50 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     673.19 ms /     1 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.32 ms /    16 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     661.36 ms /     1 runs   (  661.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1506.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2178.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.23 ms /    15 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     700.31 ms /     1 runs   (  700.31 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1474.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2114.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.68 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     662.26 ms /     1 runs   (  662.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.03 ms /    15 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     648.21 ms /     1 runs   (  648.21 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1428.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.60 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     658.18 ms /     1 runs   (  658.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1495.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.10 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     675.93 ms /     1 runs   (  675.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1507.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.50 ms /    15 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     635.74 ms /     1 runs   (  635.74 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1412.74 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.30 ms /    15 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =     655.88 ms /     1 runs   (  655.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.37 ms /    15 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     659.42 ms /     1 runs   (  659.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1431.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.19 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     666.32 ms /     1 runs   (  666.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.03 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     652.33 ms /     1 runs   (  652.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2105.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.91 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     646.36 ms /     1 runs   (  646.36 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2141.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     761.86 ms /    15 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     648.45 ms /     1 runs   (  648.45 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1415.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.30 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     668.19 ms /     1 runs   (  668.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.94 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     652.00 ms /     1 runs   (  652.00 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.17 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     693.68 ms /     1 runs   (  693.68 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1507.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.35 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     644.18 ms /     1 runs   (  644.18 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1458.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.76 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     670.65 ms /     1 runs   (  670.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1483.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.24 ms /    15 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     666.14 ms /     1 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1455.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.85 ms /    15 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     646.58 ms /     1 runs   (  646.58 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1419.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.22 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     649.25 ms /     1 runs   (  649.25 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     886.42 ms /    16 tokens (   55.40 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =     672.07 ms /     1 runs   (  672.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1563.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.66 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     655.62 ms /     1 runs   (  655.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.62 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     646.19 ms /     1 runs   (  646.19 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.42 ms /    16 tokens (   51.96 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     646.68 ms /     1 runs   (  646.68 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1483.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.65 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     691.32 ms /     1 runs   (  691.32 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1516.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.05 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     676.74 ms /     1 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.55 ms /    15 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     644.48 ms /     1 runs   (  644.48 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1426.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.78 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     644.56 ms /     1 runs   (  644.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.34 ms /    16 tokens (   52.40 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     652.89 ms /     1 runs   (  652.89 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1496.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.36 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     650.78 ms /     1 runs   (  650.78 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.94 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     655.90 ms /     1 runs   (  655.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.57 ms /    16 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     652.67 ms /     1 runs   (  652.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1499.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.46 ms /    16 tokens (   51.22 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     685.24 ms /     1 runs   (  685.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1509.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.62 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     647.97 ms /     1 runs   (  647.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.89 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     673.95 ms /     1 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1503.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.67 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     676.37 ms /     1 runs   (  676.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1500.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.51 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     685.50 ms /     1 runs   (  685.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1498.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.71 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     669.39 ms /     1 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.00 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     652.40 ms /     1 runs   (  652.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.18 ms /    16 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     662.86 ms /     1 runs   (  662.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.89 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     648.95 ms /     1 runs   (  648.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.77 ms /    14 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     647.86 ms /     1 runs   (  647.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1386.86 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.55 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     647.98 ms /     1 runs   (  647.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.15 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     643.82 ms /     1 runs   (  643.82 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1469.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.64 ms /    16 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     668.45 ms /     1 runs   (  668.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1520.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.02 ms /    16 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     670.55 ms /     1 runs   (  670.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1526.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.84 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     651.70 ms /     1 runs   (  651.70 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.19 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     730.17 ms /     1 runs   (  730.17 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1555.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.72 ms /    16 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     669.43 ms /     1 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1517.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2105.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.43 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     649.75 ms /     1 runs   (  649.75 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.25 ms /    16 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     664.99 ms /     1 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1504.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.84 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     664.33 ms /     1 runs   (  664.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.48 ms /    15 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     648.37 ms /     1 runs   (  648.37 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.07 ms /    16 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     658.58 ms /     1 runs   (  658.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.35 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     661.44 ms /     1 runs   (  661.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.51 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     643.19 ms /     1 runs   (  643.19 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.65 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.99 ms /     1 runs   (  652.99 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.36 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     674.82 ms /     1 runs   (  674.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1502.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.02 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     644.93 ms /     1 runs   (  644.93 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.55 ms /    15 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     670.30 ms /     1 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1465.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.12 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     656.53 ms /     1 runs   (  656.53 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.58 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     664.05 ms /     1 runs   (  664.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1495.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.58 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     666.66 ms /     1 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.69 ms /    15 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =     670.60 ms /     1 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1489.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.49 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     668.87 ms /     1 runs   (  668.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.23 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     659.05 ms /     1 runs   (  659.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.34 ms /    15 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     656.51 ms /     1 runs   (  656.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1458.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.20 ms /    14 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     696.83 ms /     1 runs   (  696.83 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1423.54 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.24 ms /    16 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     654.50 ms /     1 runs   (  654.50 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1493.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.39 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     656.36 ms /     1 runs   (  656.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.30 ms /    16 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     675.62 ms /     1 runs   (  675.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1523.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.48 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     659.36 ms /     1 runs   (  659.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.49 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     656.71 ms /     1 runs   (  656.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.20 ms /    16 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     652.67 ms /     1 runs   (  652.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1495.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.77 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     649.82 ms /     1 runs   (  649.82 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.60 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     659.96 ms /     1 runs   (  659.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.32 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     645.66 ms /     1 runs   (  645.66 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1481.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.62 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     671.21 ms /     1 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.94 ms /    15 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     666.63 ms /     1 runs   (  666.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1447.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.40 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     665.45 ms /     1 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.90 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     646.79 ms /     1 runs   (  646.79 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1478.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.80 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     664.98 ms /     1 runs   (  664.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.43 ms /    15 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     645.46 ms /     1 runs   (  645.46 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1437.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.95 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     673.06 ms /     1 runs   (  673.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.76 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     715.76 ms /     1 runs   (  715.76 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1545.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.23 ms /    14 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     654.96 ms /     1 runs   (  654.96 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1391.98 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.33 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     660.70 ms /     1 runs   (  660.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.76 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     641.87 ms /     1 runs   (  641.87 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     884.64 ms /    16 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =     644.67 ms /     1 runs   (  644.67 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1535.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.07 ms /    14 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     651.10 ms /     1 runs   (  651.10 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1386.57 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.53 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     673.35 ms /     1 runs   (  673.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.09 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     663.99 ms /     1 runs   (  663.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1495.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.90 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     663.83 ms /     1 runs   (  663.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.94 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     690.64 ms /     1 runs   (  690.64 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1504.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.31 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     663.64 ms /     1 runs   (  663.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.81 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     656.42 ms /     1 runs   (  656.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.97 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     686.21 ms /     1 runs   (  686.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1512.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.15 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     669.69 ms /     1 runs   (  669.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.26 ms /    16 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     645.68 ms /     1 runs   (  645.68 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1493.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.23 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     655.15 ms /     1 runs   (  655.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.84 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     665.03 ms /     1 runs   (  665.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.97 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.17 ms /     1 runs   (  659.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.19 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     656.04 ms /     1 runs   (  656.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.23 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     657.09 ms /     1 runs   (  657.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.63 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     690.67 ms /     1 runs   (  690.67 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1467.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.79 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     709.96 ms /     1 runs   (  709.96 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1531.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.97 ms /    15 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     729.82 ms /     1 runs   (  729.82 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1521.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     875.77 ms /    16 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =     697.02 ms /     1 runs   (  697.02 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1578.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     865.20 ms /    16 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =     674.60 ms /     1 runs   (  674.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1545.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     875.47 ms /    16 tokens (   54.72 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =     648.21 ms /     1 runs   (  648.21 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1529.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.93 ms /    14 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =     654.35 ms /     1 runs   (  654.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1406.68 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.50 ms /    15 tokens (   55.57 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =     677.93 ms /     1 runs   (  677.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1516.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.84 ms /    15 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     686.02 ms /     1 runs   (  686.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1465.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.35 ms /    16 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     671.57 ms /     1 runs   (  671.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1527.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.48 ms /    14 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     665.65 ms /     1 runs   (  665.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1395.73 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.72 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     667.85 ms /     1 runs   (  667.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.58 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     663.58 ms /     1 runs   (  663.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.71 ms /    16 tokens (   50.54 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     650.42 ms /     1 runs   (  650.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.41 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     648.60 ms /     1 runs   (  648.60 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.31 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     683.01 ms /     1 runs   (  683.01 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1510.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.02 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     669.00 ms /     1 runs   (  669.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.34 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     668.06 ms /     1 runs   (  668.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.83 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     678.53 ms /     1 runs   (  678.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1504.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2105.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.27 ms /    15 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     665.57 ms /     1 runs   (  665.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1444.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.61 ms /    16 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     655.36 ms /     1 runs   (  655.36 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1513.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.73 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     653.42 ms /     1 runs   (  653.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1426.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.64 ms /    14 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     641.15 ms /     1 runs   (  641.15 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1379.22 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.28 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     673.14 ms /     1 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1499.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.64 ms /    16 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     666.26 ms /     1 runs   (  666.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1509.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2166.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.22 ms /    15 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     712.08 ms /     1 runs   (  712.08 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1488.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2107.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.82 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     677.51 ms /     1 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1506.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.26 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     657.43 ms /     1 runs   (  657.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.26 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     660.73 ms /     1 runs   (  660.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.39 ms /    16 tokens (   50.77 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     654.38 ms /     1 runs   (  654.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.33 ms /    16 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     677.98 ms /     1 runs   (  677.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1517.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.96 ms /    16 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     680.23 ms /     1 runs   (  680.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1531.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     870.71 ms /    16 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =     641.29 ms /     1 runs   (  641.29 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1517.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2171.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.33 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     652.93 ms /     1 runs   (  652.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.82 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     650.57 ms /     1 runs   (  650.57 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.87 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     659.21 ms /     1 runs   (  659.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1497.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.01 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     648.28 ms /     1 runs   (  648.28 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.16 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     664.59 ms /     1 runs   (  664.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1499.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.60 ms /    16 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =     678.28 ms /     1 runs   (  678.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1548.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.06 ms /    16 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     664.29 ms /     1 runs   (  664.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1502.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.31 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     659.28 ms /     1 runs   (  659.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2103.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.09 ms /    15 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     700.20 ms /     1 runs   (  700.20 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1475.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.55 ms /    15 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     660.27 ms /     1 runs   (  660.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1441.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.44 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     646.71 ms /     1 runs   (  646.71 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1421.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     749.48 ms /    14 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =     648.00 ms /     1 runs   (  648.00 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1403.19 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.98 ms /    15 tokens (   51.67 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     661.57 ms /     1 runs   (  661.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1442.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.95 ms /    15 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     670.64 ms /     1 runs   (  670.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1443.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.32 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     658.88 ms /     1 runs   (  658.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1435.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.15 ms /    15 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     675.01 ms /     1 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1448.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.62 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     648.56 ms /     1 runs   (  648.56 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1420.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.68 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     650.35 ms /     1 runs   (  650.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.01 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     656.86 ms /     1 runs   (  656.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.08 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     680.10 ms /     1 runs   (  680.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1510.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.95 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =     706.89 ms /     1 runs   (  706.89 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1352.91 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.60 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     660.70 ms /     1 runs   (  660.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1499.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.48 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     639.49 ms /     1 runs   (  639.49 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1455.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.22 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     660.06 ms /     1 runs   (  660.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.35 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     646.62 ms /     1 runs   (  646.62 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.40 ms /    13 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =     663.39 ms /     1 runs   (  663.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1356.29 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.05 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     663.63 ms /     1 runs   (  663.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.08 ms /    14 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     650.02 ms /     1 runs   (  650.02 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1387.63 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.98 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     666.80 ms /     1 runs   (  666.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.05 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     674.09 ms /     1 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.15 ms /    15 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     668.56 ms /     1 runs   (  668.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1451.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.00 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     657.95 ms /     1 runs   (  657.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1496.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.11 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     653.47 ms /     1 runs   (  653.47 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.62 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     647.70 ms /     1 runs   (  647.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.98 ms /    15 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     668.51 ms /     1 runs   (  668.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1450.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.39 ms /    15 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     656.75 ms /     1 runs   (  656.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1423.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.17 ms /    16 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     653.59 ms /     1 runs   (  653.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1498.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     863.96 ms /    16 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =     660.97 ms /     1 runs   (  660.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1530.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.20 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     657.74 ms /     1 runs   (  657.74 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.95 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     665.73 ms /     1 runs   (  665.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.01 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     655.09 ms /     1 runs   (  655.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.86 ms /    16 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     647.84 ms /     1 runs   (  647.84 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.42 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     653.65 ms /     1 runs   (  653.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.58 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     648.26 ms /     1 runs   (  648.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.77 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     666.19 ms /     1 runs   (  666.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1504.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.71 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     690.74 ms /     1 runs   (  690.74 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1510.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.79 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     668.02 ms /     1 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.01 ms /    15 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     652.15 ms /     1 runs   (  652.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1429.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.19 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     657.73 ms /     1 runs   (  657.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2098.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.56 ms /    15 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     657.90 ms /     1 runs   (  657.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1443.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.01 ms /    15 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     673.52 ms /     1 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1453.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.25 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     670.31 ms /     1 runs   (  670.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.70 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     647.95 ms /     1 runs   (  647.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.71 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     653.38 ms /     1 runs   (  653.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.65 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     647.55 ms /     1 runs   (  647.55 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.15 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     669.02 ms /     1 runs   (  669.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1483.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.29 ms /    14 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     657.32 ms /     1 runs   (  657.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1388.78 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.56 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     656.95 ms /     1 runs   (  656.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.37 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     680.29 ms /     1 runs   (  680.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1503.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.46 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     646.02 ms /     1 runs   (  646.02 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1479.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.77 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     644.53 ms /     1 runs   (  644.53 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1458.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.69 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     660.41 ms /     1 runs   (  660.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.10 ms /    16 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     646.77 ms /     1 runs   (  646.77 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1471.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.06 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     664.38 ms /     1 runs   (  664.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1508.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.43 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     652.95 ms /     1 runs   (  652.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.97 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     656.62 ms /     1 runs   (  656.62 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.36 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     665.45 ms /     1 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.45 ms /    16 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =     690.37 ms /     1 runs   (  690.37 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1560.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.26 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     660.18 ms /     1 runs   (  660.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.18 ms /    15 tokens (   51.75 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     653.60 ms /     1 runs   (  653.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1435.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.36 ms /    14 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     667.99 ms /     1 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1401.84 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.98 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     652.88 ms /     1 runs   (  652.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.38 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     707.18 ms /     1 runs   (  707.18 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1542.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.13 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     653.41 ms /     1 runs   (  653.41 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.82 ms /    16 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     645.86 ms /     1 runs   (  645.86 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1482.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.28 ms /    16 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     664.40 ms /     1 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.60 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     668.28 ms /     1 runs   (  668.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.12 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     689.49 ms /     1 runs   (  689.49 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1505.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.11 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     677.04 ms /     1 runs   (  677.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1499.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.53 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     672.52 ms /     1 runs   (  672.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.44 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     645.48 ms /     1 runs   (  645.48 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.64 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     674.12 ms /     1 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.28 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     667.03 ms /     1 runs   (  667.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     873.57 ms /    16 tokens (   54.60 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =     671.51 ms /     1 runs   (  671.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1550.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.10 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     661.60 ms /     1 runs   (  661.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.90 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     660.16 ms /     1 runs   (  660.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.26 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     698.38 ms /     1 runs   (  698.38 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1516.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.95 ms /    15 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     681.36 ms /     1 runs   (  681.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1469.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     991.13 ms /    15 tokens (   66.08 ms per token,    15.13 tokens per second)\n",
      "llama_print_timings:        eval time =     727.11 ms /     1 runs   (  727.11 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1723.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.96 ms /    14 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     671.71 ms /     1 runs   (  671.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1411.88 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.48 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     654.07 ms /     1 runs   (  654.07 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.64 ms /    15 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =     757.21 ms /     1 runs   (  757.21 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =    1567.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /     2 runs   (    0.51 ms per token,  1970.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.91 ms /    16 tokens (   68.18 ms per token,    14.67 tokens per second)\n",
      "llama_print_timings:        eval time =     673.38 ms /     1 runs   (  673.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1769.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     928.26 ms /    16 tokens (   58.02 ms per token,    17.24 tokens per second)\n",
      "llama_print_timings:        eval time =     661.83 ms /     1 runs   (  661.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1595.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.14 ms /    14 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     676.41 ms /     1 runs   (  676.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1412.54 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.18 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     653.49 ms /     1 runs   (  653.49 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1497.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     2 runs   (    0.89 ms per token,  1117.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     900.23 ms /    16 tokens (   56.26 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =     657.51 ms /     1 runs   (  657.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1567.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.53 ms /    15 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     686.50 ms /     1 runs   (  686.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1471.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.21 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     653.38 ms /     1 runs   (  653.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.90 ms /    16 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     670.71 ms /     1 runs   (  670.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1501.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.17 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     655.68 ms /     1 runs   (  655.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.13 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     667.31 ms /     1 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1500.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.75 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     653.18 ms /     1 runs   (  653.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.66 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     648.82 ms /     1 runs   (  648.82 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.92 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     670.01 ms /     1 runs   (  670.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.89 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     664.05 ms /     1 runs   (  664.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.29 ms /    15 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     655.54 ms /     1 runs   (  655.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1460.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.30 ms /    16 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     659.87 ms /     1 runs   (  659.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1515.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.89 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     689.12 ms /     1 runs   (  689.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1504.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.48 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     652.75 ms /     1 runs   (  652.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.78 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     652.77 ms /     1 runs   (  652.77 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.83 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     665.84 ms /     1 runs   (  665.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.66 ms /    15 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     678.72 ms /     1 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1462.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.33 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     648.92 ms /     1 runs   (  648.92 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.27 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     685.25 ms /     1 runs   (  685.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1499.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.00 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     656.02 ms /     1 runs   (  656.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.43 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     646.23 ms /     1 runs   (  646.23 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1475.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.79 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.21 ms /     1 runs   (  659.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.60 ms /    16 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     659.07 ms /     1 runs   (  659.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.84 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     683.28 ms /     1 runs   (  683.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1500.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.83 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     657.32 ms /     1 runs   (  657.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.23 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     667.11 ms /     1 runs   (  667.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.27 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     675.12 ms /     1 runs   (  675.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.88 ms /    16 tokens (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     651.68 ms /     1 runs   (  651.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1464.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.97 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     654.06 ms /     1 runs   (  654.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.05 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     649.55 ms /     1 runs   (  649.55 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1480.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.80 ms /    15 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     663.37 ms /     1 runs   (  663.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1453.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.82 ms /    15 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     657.80 ms /     1 runs   (  657.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1446.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     891.71 ms /    16 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =     665.45 ms /     1 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1562.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.23 ms /    15 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     664.09 ms /     1 runs   (  664.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1442.74 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.12 ms /    16 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     669.40 ms /     1 runs   (  669.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1511.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.02 ms /    15 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     677.14 ms /     1 runs   (  677.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1456.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.83 ms /    15 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     739.15 ms /     1 runs   (  739.15 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =    1538.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.89 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     671.53 ms /     1 runs   (  671.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.00 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     699.20 ms /     1 runs   (  699.20 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1529.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.60 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     654.02 ms /     1 runs   (  654.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.41 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     659.11 ms /     1 runs   (  659.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.93 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     669.37 ms /     1 runs   (  669.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.60 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     685.41 ms /     1 runs   (  685.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.79 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     684.03 ms /     1 runs   (  684.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1464.31 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.98 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     655.82 ms /     1 runs   (  655.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2136.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.62 ms /    16 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =     669.52 ms /     1 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1481.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.99 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     707.57 ms /     1 runs   (  707.57 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1528.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.45 ms /    16 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     666.71 ms /     1 runs   (  666.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1511.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     743.92 ms /    14 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     666.57 ms /     1 runs   (  666.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1415.59 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.95 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     646.68 ms /     1 runs   (  646.68 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.94 ms /    15 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     650.30 ms /     1 runs   (  650.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1427.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.62 ms /    15 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     678.92 ms /     1 runs   (  678.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1449.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.79 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     678.74 ms /     1 runs   (  678.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1495.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.17 ms /    15 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =     667.93 ms /     1 runs   (  667.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1463.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.75 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     649.63 ms /     1 runs   (  649.63 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2166.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     920.81 ms /    16 tokens (   57.55 ms per token,    17.38 tokens per second)\n",
      "llama_print_timings:        eval time =     653.34 ms /     1 runs   (  653.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1580.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.59 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     654.03 ms /     1 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.79 ms /    14 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     641.10 ms /     1 runs   (  641.10 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1371.24 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.37 ms /    16 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     676.96 ms /     1 runs   (  676.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1520.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.34 ms /    14 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     649.09 ms /     1 runs   (  649.09 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1384.66 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.82 ms /    16 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     646.80 ms /     1 runs   (  646.80 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1480.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2162.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.37 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     705.05 ms /     1 runs   (  705.05 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1529.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.41 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     648.37 ms /     1 runs   (  648.37 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.91 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     653.53 ms /     1 runs   (  653.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.96 ms /    14 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     669.95 ms /     1 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1399.55 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.92 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     654.57 ms /     1 runs   (  654.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.85 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     644.25 ms /     1 runs   (  644.25 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.49 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     653.23 ms /     1 runs   (  653.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.08 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     652.30 ms /     1 runs   (  652.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.22 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     657.96 ms /     1 runs   (  657.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.49 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     665.95 ms /     1 runs   (  665.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.34 ms /    16 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     674.72 ms /     1 runs   (  674.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1486.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.74 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     699.67 ms /     1 runs   (  699.67 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1518.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.51 ms /    15 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     648.75 ms /     1 runs   (  648.75 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1425.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.34 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     646.53 ms /     1 runs   (  646.53 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.72 ms /    15 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =     653.16 ms /     1 runs   (  653.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.55 ms /    15 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     686.60 ms /     1 runs   (  686.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1480.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.15 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     689.88 ms /     1 runs   (  689.88 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1508.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.03 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     672.14 ms /     1 runs   (  672.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1517.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.11 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     682.95 ms /     1 runs   (  682.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1506.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.74 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     668.26 ms /     1 runs   (  668.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2143.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.03 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     721.42 ms /     1 runs   (  721.42 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1548.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.49 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     663.93 ms /     1 runs   (  663.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.53 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     723.54 ms /     1 runs   (  723.54 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1551.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.11 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     663.95 ms /     1 runs   (  663.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.74 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     688.36 ms /     1 runs   (  688.36 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1500.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.53 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     650.23 ms /     1 runs   (  650.23 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2114.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     862.59 ms /    16 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =     697.68 ms /     1 runs   (  697.68 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1566.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.41 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     629.52 ms /     1 runs   (  629.52 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1442.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.34 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     656.57 ms /     1 runs   (  656.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1468.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.82 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     640.03 ms /     1 runs   (  640.03 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1463.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.54 ms /    16 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     646.45 ms /     1 runs   (  646.45 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1495.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.32 ms /    14 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     644.63 ms /     1 runs   (  644.63 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1370.20 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.95 ms /    16 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     647.81 ms /     1 runs   (  647.81 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.41 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     647.92 ms /     1 runs   (  647.92 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.64 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     663.58 ms /     1 runs   (  663.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.33 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     683.60 ms /     1 runs   (  683.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1506.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.67 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     658.76 ms /     1 runs   (  658.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.23 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     644.23 ms /     1 runs   (  644.23 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1420.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.90 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     659.16 ms /     1 runs   (  659.16 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1431.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.22 ms /    15 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     649.71 ms /     1 runs   (  649.71 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1426.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.56 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     668.21 ms /     1 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.57 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     664.34 ms /     1 runs   (  664.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.10 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     652.04 ms /     1 runs   (  652.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.84 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     651.22 ms /     1 runs   (  651.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.52 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     658.41 ms /     1 runs   (  658.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.84 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     654.74 ms /     1 runs   (  654.74 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2076.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.20 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     677.60 ms /     1 runs   (  677.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.14 ms /    16 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     671.55 ms /     1 runs   (  671.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1483.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.04 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     664.30 ms /     1 runs   (  664.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.55 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     669.69 ms /     1 runs   (  669.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.28 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     645.34 ms /     1 runs   (  645.34 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.89 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     662.65 ms /     1 runs   (  662.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.67 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     651.73 ms /     1 runs   (  651.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.22 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     656.44 ms /     1 runs   (  656.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.63 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     653.50 ms /     1 runs   (  653.50 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.50 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     654.33 ms /     1 runs   (  654.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.52 ms /    15 tokens (   52.70 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     665.82 ms /     1 runs   (  665.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1461.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.74 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     647.14 ms /     1 runs   (  647.14 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.83 ms /    15 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =     670.73 ms /     1 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1506.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.45 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     668.01 ms /     1 runs   (  668.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.18 ms /    15 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     661.36 ms /     1 runs   (  661.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1439.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.36 ms /    15 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     677.10 ms /     1 runs   (  677.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1448.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2162.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.06 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     675.82 ms /     1 runs   (  675.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.89 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     646.09 ms /     1 runs   (  646.09 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.53 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     659.95 ms /     1 runs   (  659.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1493.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.03 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     679.51 ms /     1 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1516.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2150.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.63 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     673.72 ms /     1 runs   (  673.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1501.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.71 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     656.10 ms /     1 runs   (  656.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1427.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =      64.78 ms /   147 runs   (    0.44 ms per token,  2269.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.46 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =   98465.62 ms /   146 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   99721.46 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.47 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     730.75 ms /     1 runs   (  730.75 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1552.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.89 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     678.80 ms /     1 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1498.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.26 ms /    16 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     657.25 ms /     1 runs   (  657.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.90 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     653.62 ms /     1 runs   (  653.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.33 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     649.94 ms /     1 runs   (  649.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.59 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     660.57 ms /     1 runs   (  660.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1436.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2139.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.43 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     656.59 ms /     1 runs   (  656.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.74 ms /    15 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     647.94 ms /     1 runs   (  647.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1416.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.23 ms /    16 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =     684.67 ms /     1 runs   (  684.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1546.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.05 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     678.67 ms /     1 runs   (  678.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1511.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.09 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     701.30 ms /     1 runs   (  701.30 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1545.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.95 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     668.65 ms /     1 runs   (  668.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1506.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.35 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     676.09 ms /     1 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1504.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.87 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     669.01 ms /     1 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.42 ms /    16 tokens (   51.96 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     688.03 ms /     1 runs   (  688.03 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1525.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.01 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     644.53 ms /     1 runs   (  644.53 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1416.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.84 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     693.57 ms /     1 runs   (  693.57 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1525.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.45 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     664.83 ms /     1 runs   (  664.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.44 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     685.20 ms /     1 runs   (  685.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.38 ms /    16 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     656.92 ms /     1 runs   (  656.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1502.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.43 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     659.54 ms /     1 runs   (  659.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.25 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     710.73 ms /     1 runs   (  710.73 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1531.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.50 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     667.48 ms /     1 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.45 ms /    15 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     668.97 ms /     1 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1441.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.51 ms /    15 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     647.50 ms /     1 runs   (  647.50 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1426.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.76 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.24 ms /     1 runs   (  659.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.09 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     655.54 ms /     1 runs   (  655.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.78 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     655.18 ms /     1 runs   (  655.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.97 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     677.28 ms /     1 runs   (  677.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.09 ms /    16 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     653.58 ms /     1 runs   (  653.58 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.73 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     655.71 ms /     1 runs   (  655.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1434.18 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.82 ms /    15 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     676.36 ms /     1 runs   (  676.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1446.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.29 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     655.83 ms /     1 runs   (  655.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.49 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     645.67 ms /     1 runs   (  645.67 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2190.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.94 ms /    15 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     684.45 ms /     1 runs   (  684.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1477.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.41 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     649.72 ms /     1 runs   (  649.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.89 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     655.16 ms /     1 runs   (  655.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.68 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     685.85 ms /     1 runs   (  685.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1523.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.30 ms /    13 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     643.94 ms /     1 runs   (  643.94 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1328.23 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.56 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     645.29 ms /     1 runs   (  645.29 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.86 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     672.54 ms /     1 runs   (  672.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.21 ms /    14 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     688.58 ms /     1 runs   (  688.58 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1420.45 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.47 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     697.08 ms /     1 runs   (  697.08 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1524.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.89 ms /    14 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     659.93 ms /     1 runs   (  659.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1386.56 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.60 ms /    16 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =     657.37 ms /     1 runs   (  657.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1521.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.46 ms /    15 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     646.46 ms /     1 runs   (  646.46 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1429.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.32 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     645.11 ms /     1 runs   (  645.11 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.89 ms /    15 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     641.78 ms /     1 runs   (  641.78 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1423.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.02 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     669.17 ms /     1 runs   (  669.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1483.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.15 ms /    15 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     678.11 ms /     1 runs   (  678.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1447.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.15 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     694.56 ms /     1 runs   (  694.56 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1511.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.71 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     643.99 ms /     1 runs   (  643.99 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1415.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.60 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     645.09 ms /     1 runs   (  645.09 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.12 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     662.43 ms /     1 runs   (  662.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.59 ms /    16 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     655.16 ms /     1 runs   (  655.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1495.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.16 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     651.65 ms /     1 runs   (  651.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1424.64 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.44 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     670.21 ms /     1 runs   (  670.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.19 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     673.92 ms /     1 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.51 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     659.61 ms /     1 runs   (  659.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.41 ms /    16 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     650.26 ms /     1 runs   (  650.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.88 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     711.62 ms /     1 runs   (  711.62 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1533.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2185.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.69 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     660.82 ms /     1 runs   (  660.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.59 ms /    16 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     670.30 ms /     1 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1517.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.98 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     636.41 ms /     1 runs   (  636.41 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1454.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.60 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     657.69 ms /     1 runs   (  657.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2049.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.02 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     661.97 ms /     1 runs   (  661.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.53 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     678.72 ms /     1 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1498.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.86 ms /    15 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =     660.69 ms /     1 runs   (  660.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.89 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     659.73 ms /     1 runs   (  659.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.79 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     647.89 ms /     1 runs   (  647.89 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.75 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     659.08 ms /     1 runs   (  659.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.67 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     645.67 ms /     1 runs   (  645.67 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.33 ms /    16 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     665.73 ms /     1 runs   (  665.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1504.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.42 ms /    15 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     719.93 ms /     1 runs   (  719.93 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1493.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.64 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     684.88 ms /     1 runs   (  684.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1498.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.83 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     646.69 ms /     1 runs   (  646.69 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.41 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     645.99 ms /     1 runs   (  645.99 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.18 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     646.88 ms /     1 runs   (  646.88 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.45 ms /    16 tokens (   51.22 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     645.00 ms /     1 runs   (  645.00 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.17 ms /    16 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     676.89 ms /     1 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1506.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.14 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     683.07 ms /     1 runs   (  683.07 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1501.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.18 ms /    15 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     654.72 ms /     1 runs   (  654.72 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1442.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.53 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     656.55 ms /     1 runs   (  656.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     867.48 ms /    16 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =     651.08 ms /     1 runs   (  651.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1523.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.21 ms /    15 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     675.96 ms /     1 runs   (  675.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1472.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.62 ms /    14 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     721.37 ms /     1 runs   (  721.37 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1450.43 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.96 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     648.36 ms /     1 runs   (  648.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.44 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     683.73 ms /     1 runs   (  683.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.91 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     653.69 ms /     1 runs   (  653.69 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.21 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     670.33 ms /     1 runs   (  670.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.42 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     664.02 ms /     1 runs   (  664.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.37 ms /    16 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =     659.23 ms /     1 runs   (  659.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1518.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.33 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     674.46 ms /     1 runs   (  674.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.19 ms /    15 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     646.42 ms /     1 runs   (  646.42 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1443.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.36 ms /    16 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     649.98 ms /     1 runs   (  649.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1496.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.63 ms /    15 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     649.76 ms /     1 runs   (  649.76 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1431.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.79 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     663.26 ms /     1 runs   (  663.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.69 ms /    16 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     671.70 ms /     1 runs   (  671.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1516.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.36 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     647.95 ms /     1 runs   (  647.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.02 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     673.46 ms /     1 runs   (  673.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.91 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     658.84 ms /     1 runs   (  658.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.20 ms /    16 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     663.70 ms /     1 runs   (  663.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1499.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.10 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     667.24 ms /     1 runs   (  667.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.33 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     665.55 ms /     1 runs   (  665.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.23 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     667.88 ms /     1 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.02 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     688.16 ms /     1 runs   (  688.16 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1513.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.58 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     672.08 ms /     1 runs   (  672.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.60 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     658.29 ms /     1 runs   (  658.29 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.55 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     663.31 ms /     1 runs   (  663.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.01 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     681.72 ms /     1 runs   (  681.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1519.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.66 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     660.42 ms /     1 runs   (  660.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1499.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.15 ms /    16 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     656.65 ms /     1 runs   (  656.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1468.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.87 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     689.85 ms /     1 runs   (  689.85 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1466.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.75 ms /    14 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     663.79 ms /     1 runs   (  663.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1393.23 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.49 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.78 ms /     1 runs   (  652.78 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.47 ms /    14 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     670.58 ms /     1 runs   (  670.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1408.87 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.33 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     668.31 ms /     1 runs   (  668.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1497.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.39 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     653.12 ms /     1 runs   (  653.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.35 ms /    15 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     657.81 ms /     1 runs   (  657.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1427.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.38 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     640.29 ms /     1 runs   (  640.29 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.73 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     643.35 ms /     1 runs   (  643.35 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.26 ms /    15 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     673.70 ms /     1 runs   (  673.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1462.23 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.12 ms /    16 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     642.14 ms /     1 runs   (  642.14 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1482.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.06 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     645.47 ms /     1 runs   (  645.47 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1415.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.89 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     662.33 ms /     1 runs   (  662.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.32 ms /    16 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     662.12 ms /     1 runs   (  662.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.31 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     647.60 ms /     1 runs   (  647.60 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.64 ms /    16 tokens (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =     705.50 ms /     1 runs   (  705.50 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1515.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.65 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     653.34 ms /     1 runs   (  653.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.54 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     646.86 ms /     1 runs   (  646.86 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.16 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     684.42 ms /     1 runs   (  684.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.96 ms /    14 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     646.99 ms /     1 runs   (  646.99 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1379.50 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.84 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     659.32 ms /     1 runs   (  659.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1484.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.67 ms /    15 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     670.89 ms /     1 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1439.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.55 ms /    14 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     649.47 ms /     1 runs   (  649.47 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1376.99 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.14 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     673.68 ms /     1 runs   (  673.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.88 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     672.61 ms /     1 runs   (  672.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.87 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     658.30 ms /     1 runs   (  658.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.77 ms /    15 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     636.85 ms /     1 runs   (  636.85 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1419.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.15 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     648.53 ms /     1 runs   (  648.53 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.86 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     642.09 ms /     1 runs   (  642.09 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1480.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.44 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     640.31 ms /     1 runs   (  640.31 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1470.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.32 ms /    15 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     664.40 ms /     1 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1461.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.57 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     641.61 ms /     1 runs   (  641.61 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.58 ms /    15 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     660.04 ms /     1 runs   (  660.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1429.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.63 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     645.50 ms /     1 runs   (  645.50 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1482.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.89 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     646.05 ms /     1 runs   (  646.05 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.93 ms /    15 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =     675.52 ms /     1 runs   (  675.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1480.67 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.96 ms /    14 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =     629.13 ms /     1 runs   (  629.13 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1400.51 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.31 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     653.65 ms /     1 runs   (  653.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.75 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     660.98 ms /     1 runs   (  660.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.29 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     649.91 ms /     1 runs   (  649.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.87 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     661.06 ms /     1 runs   (  661.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.00 ms /    15 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     656.80 ms /     1 runs   (  656.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1448.79 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.75 ms /    16 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     658.44 ms /     1 runs   (  658.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.38 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     655.67 ms /     1 runs   (  655.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.77 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     650.77 ms /     1 runs   (  650.77 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.21 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     652.89 ms /     1 runs   (  652.89 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.83 ms /    15 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     650.44 ms /     1 runs   (  650.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1425.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.27 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     729.68 ms /     1 runs   (  729.68 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1546.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.63 ms /    16 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     657.37 ms /     1 runs   (  657.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1493.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.52 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     685.79 ms /     1 runs   (  685.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1507.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.00 ms /    16 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     658.21 ms /     1 runs   (  658.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.26 ms /    15 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     658.27 ms /     1 runs   (  658.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1444.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.28 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     708.34 ms /     1 runs   (  708.34 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1546.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.46 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     688.50 ms /     1 runs   (  688.50 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1507.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.46 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     664.20 ms /     1 runs   (  664.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2134.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.86 ms /    15 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     687.26 ms /     1 runs   (  687.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1460.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.42 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     658.46 ms /     1 runs   (  658.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.06 ms /    14 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     660.89 ms /     1 runs   (  660.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1395.78 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.52 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     650.94 ms /     1 runs   (  650.94 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.90 ms /    16 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     666.53 ms /     1 runs   (  666.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1512.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.84 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     663.35 ms /     1 runs   (  663.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1435.67 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.25 ms /    16 tokens (   52.70 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     656.67 ms /     1 runs   (  656.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1505.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.35 ms /    16 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     649.52 ms /     1 runs   (  649.52 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1494.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2183.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.09 ms /    16 tokens (   51.51 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     664.37 ms /     1 runs   (  664.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.11 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     661.20 ms /     1 runs   (  661.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.63 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     634.70 ms /     1 runs   (  634.70 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1449.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.56 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     650.99 ms /     1 runs   (  650.99 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.49 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     667.32 ms /     1 runs   (  667.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.63 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     672.91 ms /     1 runs   (  672.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.46 ms /    16 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     675.80 ms /     1 runs   (  675.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1528.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.38 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     672.15 ms /     1 runs   (  672.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.35 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     675.39 ms /     1 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.56 ms /    16 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     640.50 ms /     1 runs   (  640.50 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1478.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.53 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     665.34 ms /     1 runs   (  665.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.51 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     653.85 ms /     1 runs   (  653.85 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1428.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.33 ms /    15 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     662.91 ms /     1 runs   (  662.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1434.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.22 ms /    16 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     653.19 ms /     1 runs   (  653.19 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1497.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.26 ms /    15 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     662.35 ms /     1 runs   (  662.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1448.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.11 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     642.13 ms /     1 runs   (  642.13 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1460.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.28 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     660.27 ms /     1 runs   (  660.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.17 ms /    15 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     685.48 ms /     1 runs   (  685.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1467.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.17 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     659.68 ms /     1 runs   (  659.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     868.57 ms /    16 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =     658.34 ms /     1 runs   (  658.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1532.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.11 ms /    16 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     670.61 ms /     1 runs   (  670.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.29 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     661.15 ms /     1 runs   (  661.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.61 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     661.05 ms /     1 runs   (  661.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.44 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     667.74 ms /     1 runs   (  667.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.51 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     642.32 ms /     1 runs   (  642.32 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1456.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.70 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     661.05 ms /     1 runs   (  661.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.48 ms per token,  2068.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.00 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     666.26 ms /     1 runs   (  666.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2148.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.05 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     650.57 ms /     1 runs   (  650.57 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.51 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     660.79 ms /     1 runs   (  660.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.30 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     655.44 ms /     1 runs   (  655.44 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.41 ms /    15 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     648.36 ms /     1 runs   (  648.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.05 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     652.54 ms /     1 runs   (  652.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1423.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.04 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     647.66 ms /     1 runs   (  647.66 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.58 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     648.82 ms /     1 runs   (  648.82 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1419.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.39 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     640.98 ms /     1 runs   (  640.98 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1460.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.37 ms /    16 tokens (   51.77 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     669.41 ms /     1 runs   (  669.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.84 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     643.95 ms /     1 runs   (  643.95 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.68 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     648.71 ms /     1 runs   (  648.71 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1428.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.77 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     676.35 ms /     1 runs   (  676.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1454.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.49 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     649.81 ms /     1 runs   (  649.81 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.59 ms /    16 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     673.40 ms /     1 runs   (  673.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1523.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.49 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     658.34 ms /     1 runs   (  658.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.74 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     658.21 ms /     1 runs   (  658.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.55 ms /    15 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     648.98 ms /     1 runs   (  648.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1426.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.97 ms /    15 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     660.38 ms /     1 runs   (  660.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1436.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.99 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     675.71 ms /     1 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.48 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     682.07 ms /     1 runs   (  682.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1496.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.95 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     651.08 ms /     1 runs   (  651.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.27 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     660.25 ms /     1 runs   (  660.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.43 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     646.64 ms /     1 runs   (  646.64 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.25 ms /    16 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =     687.33 ms /     1 runs   (  687.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1548.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.16 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     679.82 ms /     1 runs   (  679.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1495.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.95 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     668.46 ms /     1 runs   (  668.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.46 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     659.73 ms /     1 runs   (  659.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.44 ms /    15 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     693.66 ms /     1 runs   (  693.66 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1470.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.03 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     653.45 ms /     1 runs   (  653.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.32 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     649.22 ms /     1 runs   (  649.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.08 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     664.87 ms /     1 runs   (  664.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.77 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     675.05 ms /     1 runs   (  675.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.58 ms /    14 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     655.21 ms /     1 runs   (  655.21 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1389.16 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.72 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     656.16 ms /     1 runs   (  656.16 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.27 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     672.21 ms /     1 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2139.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.21 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     655.83 ms /     1 runs   (  655.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1484.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.47 ms /    15 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     691.01 ms /     1 runs   (  691.01 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1473.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.41 ms /    15 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     655.84 ms /     1 runs   (  655.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1430.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.41 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     656.16 ms /     1 runs   (  656.16 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.78 ms /    15 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     656.69 ms /     1 runs   (  656.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1430.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.24 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     646.11 ms /     1 runs   (  646.11 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.66 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     683.55 ms /     1 runs   (  683.55 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1500.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.45 ms /    16 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     667.29 ms /     1 runs   (  667.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1505.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.50 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     697.32 ms /     1 runs   (  697.32 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1518.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.39 ms /    15 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     663.16 ms /     1 runs   (  663.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1449.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.67 ms /    16 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     658.70 ms /     1 runs   (  658.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.56 ms /    16 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     651.52 ms /     1 runs   (  651.52 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1492.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.19 ms /    16 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     649.23 ms /     1 runs   (  649.23 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.32 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     647.86 ms /     1 runs   (  647.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.75 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     643.72 ms /     1 runs   (  643.72 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.30 ms /    15 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     671.10 ms /     1 runs   (  671.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1465.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.45 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     649.14 ms /     1 runs   (  649.14 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.95 ms /    15 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     646.08 ms /     1 runs   (  646.08 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1422.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.03 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     670.89 ms /     1 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.09 ms /    16 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     705.70 ms /     1 runs   (  705.70 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1542.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.00 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     667.53 ms /     1 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.41 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     668.66 ms /     1 runs   (  668.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.40 ms /    15 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     648.72 ms /     1 runs   (  648.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1422.74 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.05 ms /    15 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     653.01 ms /     1 runs   (  653.01 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1422.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.39 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     650.74 ms /     1 runs   (  650.74 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.64 ms /    15 tokens (   57.18 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =     657.33 ms /     1 runs   (  657.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1520.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.89 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     652.79 ms /     1 runs   (  652.79 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.26 ms /    16 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     647.23 ms /     1 runs   (  647.23 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.61 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     646.45 ms /     1 runs   (  646.45 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.22 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     663.94 ms /     1 runs   (  663.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.73 ms /    15 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     648.69 ms /     1 runs   (  648.69 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1438.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.75 ms /    16 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     650.47 ms /     1 runs   (  650.47 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1503.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.56 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     652.01 ms /     1 runs   (  652.01 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1464.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.00 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     690.70 ms /     1 runs   (  690.70 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1518.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.98 ms /    15 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     648.77 ms /     1 runs   (  648.77 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1443.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.78 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     672.00 ms /     1 runs   (  672.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.69 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     659.77 ms /     1 runs   (  659.77 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.71 ms /    16 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     660.49 ms /     1 runs   (  660.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2087.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.81 ms /    16 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     700.82 ms /     1 runs   (  700.82 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1549.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.31 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     671.47 ms /     1 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1500.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.62 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     647.01 ms /     1 runs   (  647.01 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1474.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     751.15 ms /    14 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =     640.84 ms /     1 runs   (  640.84 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1397.09 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.65 ms /    16 tokens (   51.67 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     644.91 ms /     1 runs   (  644.91 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1477.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.74 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     656.83 ms /     1 runs   (  656.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.33 ms /    16 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     712.07 ms /     1 runs   (  712.07 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1552.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.54 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     659.54 ms /     1 runs   (  659.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.75 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     647.17 ms /     1 runs   (  647.17 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.08 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     714.78 ms /     1 runs   (  714.78 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1542.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.53 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     660.62 ms /     1 runs   (  660.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     751.74 ms /    14 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =     648.42 ms /     1 runs   (  648.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1405.76 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.97 ms /    16 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     735.10 ms /     1 runs   (  735.10 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1581.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.63 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     650.25 ms /     1 runs   (  650.25 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.09 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     650.12 ms /     1 runs   (  650.12 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.46 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     648.93 ms /     1 runs   (  648.93 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1484.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.81 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     653.07 ms /     1 runs   (  653.07 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.74 ms /    16 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     651.91 ms /     1 runs   (  651.91 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1495.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.81 ms /    16 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     652.73 ms /     1 runs   (  652.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1505.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.63 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     660.95 ms /     1 runs   (  660.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2143.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.99 ms /    14 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     674.25 ms /     1 runs   (  674.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1403.03 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.15 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     657.94 ms /     1 runs   (  657.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.88 ms /    16 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     660.83 ms /     1 runs   (  660.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1500.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.69 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     644.56 ms /     1 runs   (  644.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.86 ms /    15 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     647.91 ms /     1 runs   (  647.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.22 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     670.92 ms /     1 runs   (  670.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.50 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     646.35 ms /     1 runs   (  646.35 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.64 ms /    15 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     662.63 ms /     1 runs   (  662.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1443.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2183.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.18 ms /    15 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     662.80 ms /     1 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1463.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.06 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     658.95 ms /     1 runs   (  658.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.13 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     695.46 ms /     1 runs   (  695.46 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1521.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.44 ms /    16 tokens (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =     656.58 ms /     1 runs   (  656.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1466.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.86 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     648.22 ms /     1 runs   (  648.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.08 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     651.06 ms /     1 runs   (  651.06 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.33 ms /    15 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     660.54 ms /     1 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1429.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.16 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     680.15 ms /     1 runs   (  680.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1506.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.32 ms /    15 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     649.19 ms /     1 runs   (  649.19 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1419.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.24 ms /    16 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     676.05 ms /     1 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1531.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.33 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     665.12 ms /     1 runs   (  665.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2190.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.79 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     667.05 ms /     1 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.83 ms /    16 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     667.91 ms /     1 runs   (  667.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.84 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     664.57 ms /     1 runs   (  664.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.57 ms /    14 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =     672.17 ms /     1 runs   (  672.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1422.08 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     743.11 ms /    14 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     653.18 ms /     1 runs   (  653.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1402.34 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.64 ms /    16 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     661.48 ms /     1 runs   (  661.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1505.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.12 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     651.63 ms /     1 runs   (  651.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.23 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     670.82 ms /     1 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.95 ms /    15 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     658.21 ms /     1 runs   (  658.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1439.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.97 ms /    15 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     674.84 ms /     1 runs   (  674.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1444.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.96 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     660.95 ms /     1 runs   (  660.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.87 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     664.48 ms /     1 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1497.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.74 ms /    15 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     658.36 ms /     1 runs   (  658.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1427.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.02 ms /    16 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     657.11 ms /     1 runs   (  657.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1499.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.41 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     655.91 ms /     1 runs   (  655.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.47 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     669.73 ms /     1 runs   (  669.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.34 ms /    15 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     655.96 ms /     1 runs   (  655.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1424.80 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.74 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     656.13 ms /     1 runs   (  656.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.12 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     684.35 ms /     1 runs   (  684.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1506.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.88 ms /    15 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     657.20 ms /     1 runs   (  657.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1431.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.53 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     660.30 ms /     1 runs   (  660.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1497.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.32 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     655.05 ms /     1 runs   (  655.05 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.87 ms /    16 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     656.20 ms /     1 runs   (  656.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1468.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.00 ms /    15 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     660.37 ms /     1 runs   (  660.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1437.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.58 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     655.13 ms /     1 runs   (  655.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.79 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     644.92 ms /     1 runs   (  644.92 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.25 ms /    15 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     662.99 ms /     1 runs   (  662.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1441.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.15 ms /    14 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     657.94 ms /     1 runs   (  657.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1388.25 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.71 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     688.22 ms /     1 runs   (  688.22 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1463.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.95 ms /    15 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     645.85 ms /     1 runs   (  645.85 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1431.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.30 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     747.58 ms /     1 runs   (  747.58 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =    1574.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.73 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     696.75 ms /     1 runs   (  696.75 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1520.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.91 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     666.16 ms /     1 runs   (  666.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.80 ms /    15 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     657.74 ms /     1 runs   (  657.74 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1438.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.06 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     656.36 ms /     1 runs   (  656.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.62 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     658.81 ms /     1 runs   (  658.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.59 ms /    15 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     653.41 ms /     1 runs   (  653.41 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1423.49 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.14 ms /    16 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     648.38 ms /     1 runs   (  648.38 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.06 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     649.06 ms /     1 runs   (  649.06 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.82 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     664.40 ms /     1 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     872.25 ms /    16 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =     653.06 ms /     1 runs   (  653.06 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1530.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.34 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     678.82 ms /     1 runs   (  678.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1500.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.63 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     672.00 ms /     1 runs   (  672.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.95 ms /    16 tokens (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:        eval time =     671.34 ms /     1 runs   (  671.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1481.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.85 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     650.36 ms /     1 runs   (  650.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1422.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.63 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     655.05 ms /     1 runs   (  655.05 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.15 ms /    15 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     668.52 ms /     1 runs   (  668.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1444.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.08 ms /    15 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     685.62 ms /     1 runs   (  685.62 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1462.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.74 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     699.45 ms /     1 runs   (  699.45 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1539.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.37 ms /    15 tokens (   54.69 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =     666.15 ms /     1 runs   (  666.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.51 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     668.96 ms /     1 runs   (  668.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.54 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     677.04 ms /     1 runs   (  677.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1505.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.60 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     685.30 ms /     1 runs   (  685.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1520.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.43 ms /    15 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     671.41 ms /     1 runs   (  671.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1468.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.77 ms /    16 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     655.10 ms /     1 runs   (  655.10 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1496.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.56 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     654.28 ms /     1 runs   (  654.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.84 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     670.95 ms /     1 runs   (  670.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1445.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.52 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     656.14 ms /     1 runs   (  656.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.62 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     649.98 ms /     1 runs   (  649.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.15 ms /    15 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     636.05 ms /     1 runs   (  636.05 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1411.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.58 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     655.25 ms /     1 runs   (  655.25 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.70 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     647.13 ms /     1 runs   (  647.13 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.87 ms /    15 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =     703.71 ms /     1 runs   (  703.71 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1515.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.89 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     652.51 ms /     1 runs   (  652.51 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.58 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     657.12 ms /     1 runs   (  657.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.74 ms /    15 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     649.03 ms /     1 runs   (  649.03 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1434.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.91 ms /    16 tokens (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     696.54 ms /     1 runs   (  696.54 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1510.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.80 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     663.22 ms /     1 runs   (  663.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.10 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     663.23 ms /     1 runs   (  663.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.05 ms /    16 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     686.16 ms /     1 runs   (  686.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1538.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.16 ms /    15 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     650.42 ms /     1 runs   (  650.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1420.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.16 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     660.75 ms /     1 runs   (  660.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.37 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     662.82 ms /     1 runs   (  662.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.53 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     677.38 ms /     1 runs   (  677.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.02 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     656.16 ms /     1 runs   (  656.16 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.20 ms /    14 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     652.93 ms /     1 runs   (  652.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1384.98 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.99 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     663.47 ms /     1 runs   (  663.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.12 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     664.88 ms /     1 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.19 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     687.89 ms /     1 runs   (  687.89 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1513.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.44 ms /    16 tokens (   50.47 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     671.37 ms /     1 runs   (  671.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1484.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.51 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.60 ms /     1 runs   (  652.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.32 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     666.29 ms /     1 runs   (  666.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.55 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     673.03 ms /     1 runs   (  673.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.72 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     668.62 ms /     1 runs   (  668.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1441.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2125.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.40 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     721.61 ms /     1 runs   (  721.61 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1546.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     761.25 ms /    15 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     651.60 ms /     1 runs   (  651.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1418.23 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.21 ms /    14 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     644.41 ms /     1 runs   (  644.41 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1385.50 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.65 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     656.49 ms /     1 runs   (  656.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.75 ms /    15 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     661.36 ms /     1 runs   (  661.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1436.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.93 ms /    15 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     657.21 ms /     1 runs   (  657.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1441.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.71 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     663.48 ms /     1 runs   (  663.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1434.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.27 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     704.03 ms /     1 runs   (  704.03 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1529.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.41 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     652.92 ms /     1 runs   (  652.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.70 ms /    15 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     653.61 ms /     1 runs   (  653.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1430.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.10 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     680.70 ms /     1 runs   (  680.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1499.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.52 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     654.03 ms /     1 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.86 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     653.91 ms /     1 runs   (  653.91 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.93 ms /    16 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     667.99 ms /     1 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.08 ms /    15 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     698.39 ms /     1 runs   (  698.39 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1482.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.71 ms /    15 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     675.02 ms /     1 runs   (  675.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1445.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.35 ms /    15 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     656.12 ms /     1 runs   (  656.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1424.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.03 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     648.90 ms /     1 runs   (  648.90 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.99 ms /    16 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     664.08 ms /     1 runs   (  664.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1514.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.97 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     660.55 ms /     1 runs   (  660.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.16 ms /    15 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     675.17 ms /     1 runs   (  675.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1447.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.85 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     663.91 ms /     1 runs   (  663.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    13 runs   (    0.41 ms per token,  2463.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.07 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =    8038.56 ms /    12 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    8892.63 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.08 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     675.30 ms /     1 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1507.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.07 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     663.72 ms /     1 runs   (  663.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1498.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.18 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     674.28 ms /     1 runs   (  674.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.69 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     656.63 ms /     1 runs   (  656.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.09 ms /    16 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     644.53 ms /     1 runs   (  644.53 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1491.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.90 ms /    15 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     646.70 ms /     1 runs   (  646.70 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1420.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.18 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     661.54 ms /     1 runs   (  661.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.58 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     656.57 ms /     1 runs   (  656.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.96 ms /    16 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     644.58 ms /     1 runs   (  644.58 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1484.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.83 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     651.63 ms /     1 runs   (  651.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.99 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     661.86 ms /     1 runs   (  661.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.80 ms /    16 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     647.77 ms /     1 runs   (  647.77 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.98 ms /    16 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     657.22 ms /     1 runs   (  657.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1506.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.84 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     646.79 ms /     1 runs   (  646.79 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.44 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     685.16 ms /     1 runs   (  685.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1499.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.32 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     661.57 ms /     1 runs   (  661.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.39 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     647.50 ms /     1 runs   (  647.50 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.64 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     670.90 ms /     1 runs   (  670.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1484.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.46 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     662.30 ms /     1 runs   (  662.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.19 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     661.99 ms /     1 runs   (  661.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.24 ms /    16 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     679.17 ms /     1 runs   (  679.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1526.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.10 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     660.55 ms /     1 runs   (  660.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1497.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.12 ms /    15 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     648.17 ms /     1 runs   (  648.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1424.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.64 ms /    15 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     650.61 ms /     1 runs   (  650.61 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1440.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.97 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     661.40 ms /     1 runs   (  661.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.38 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     654.12 ms /     1 runs   (  654.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.65 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     648.29 ms /     1 runs   (  648.29 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1419.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.76 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     683.25 ms /     1 runs   (  683.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1510.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.51 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     644.77 ms /     1 runs   (  644.77 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.74 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     659.23 ms /     1 runs   (  659.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.79 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     654.13 ms /     1 runs   (  654.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.33 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     655.48 ms /     1 runs   (  655.48 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.66 ms /    16 tokens (   51.85 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     701.42 ms /     1 runs   (  701.42 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1536.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.80 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     655.71 ms /     1 runs   (  655.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.63 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     648.33 ms /     1 runs   (  648.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.30 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     639.78 ms /     1 runs   (  639.78 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1463.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.37 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     663.00 ms /     1 runs   (  663.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1440.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.21 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     715.31 ms /     1 runs   (  715.31 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1528.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.71 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     661.85 ms /     1 runs   (  661.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     922.88 ms /    16 tokens (   57.68 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =     719.21 ms /     1 runs   (  719.21 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1647.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.24 ms /    14 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     688.67 ms /     1 runs   (  688.67 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1418.73 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.93 ms /    16 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =     686.21 ms /     1 runs   (  686.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1495.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.23 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     708.93 ms /     1 runs   (  708.93 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1524.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.38 ms /    14 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     661.14 ms /     1 runs   (  661.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1395.39 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.62 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     679.14 ms /     1 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1496.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.61 ms /    15 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     692.22 ms /     1 runs   (  692.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1483.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.00 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     703.54 ms /     1 runs   (  703.54 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1520.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.46 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     654.57 ms /     1 runs   (  654.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.56 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     665.92 ms /     1 runs   (  665.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.53 ms /    15 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     642.68 ms /     1 runs   (  642.68 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1415.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.62 ms /    16 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     676.10 ms /     1 runs   (  676.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1525.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.12 ms /    15 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     658.83 ms /     1 runs   (  658.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1450.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.25 ms /    14 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     673.77 ms /     1 runs   (  673.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1405.21 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.76 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     651.31 ms /     1 runs   (  651.31 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     855.96 ms /    16 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =     682.84 ms /     1 runs   (  682.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1544.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.76 ms /    15 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     648.40 ms /     1 runs   (  648.40 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1429.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.31 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     684.40 ms /     1 runs   (  684.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1501.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.81 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     675.32 ms /     1 runs   (  675.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1500.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.87 ms /    16 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     698.35 ms /     1 runs   (  698.35 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1532.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.25 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     652.17 ms /     1 runs   (  652.17 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.62 ms /    14 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     662.90 ms /     1 runs   (  662.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1397.93 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.97 ms /    16 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     740.51 ms /     1 runs   (  740.51 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =    1586.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.09 ms /    16 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =     673.39 ms /     1 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1525.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.25 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     693.28 ms /     1 runs   (  693.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1537.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.87 ms /    16 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =     650.30 ms /     1 runs   (  650.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1508.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.85 ms /    15 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     664.53 ms /     1 runs   (  664.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1435.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.98 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     688.75 ms /     1 runs   (  688.75 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1511.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.99 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     660.81 ms /     1 runs   (  660.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.17 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     670.80 ms /     1 runs   (  670.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1484.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2181.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.64 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     660.06 ms /     1 runs   (  660.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.85 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     656.46 ms /     1 runs   (  656.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.77 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     649.33 ms /     1 runs   (  649.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.84 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     683.36 ms /     1 runs   (  683.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1498.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.15 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     685.71 ms /     1 runs   (  685.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1507.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.15 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     689.61 ms /     1 runs   (  689.61 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1508.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.33 ms /    16 tokens (   58.21 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =     674.99 ms /     1 runs   (  674.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1611.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.69 ms /    16 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     672.81 ms /     1 runs   (  672.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1521.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.52 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     654.24 ms /     1 runs   (  654.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.11 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     683.95 ms /     1 runs   (  683.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1496.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.34 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     665.30 ms /     1 runs   (  665.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.89 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     683.23 ms /     1 runs   (  683.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1509.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.66 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     656.55 ms /     1 runs   (  656.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1427.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.58 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     666.45 ms /     1 runs   (  666.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.63 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     654.15 ms /     1 runs   (  654.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.44 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     659.35 ms /     1 runs   (  659.35 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.14 ms /    16 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     651.17 ms /     1 runs   (  651.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.29 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     649.85 ms /     1 runs   (  649.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.95 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     699.19 ms /     1 runs   (  699.19 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1518.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.22 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     687.99 ms /     1 runs   (  687.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1507.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.41 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     659.07 ms /     1 runs   (  659.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.98 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     654.02 ms /     1 runs   (  654.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.29 ms /    16 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     662.07 ms /     1 runs   (  662.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1473.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.15 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     686.55 ms /     1 runs   (  686.55 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.66 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     646.97 ms /     1 runs   (  646.97 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1474.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.50 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     678.17 ms /     1 runs   (  678.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1491.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.95 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     660.21 ms /     1 runs   (  660.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.25 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     642.60 ms /     1 runs   (  642.60 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1474.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.45 ms /    15 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     751.15 ms /     1 runs   (  751.15 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =    1522.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.46 ms /    16 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     659.70 ms /     1 runs   (  659.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1516.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.97 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     686.19 ms /     1 runs   (  686.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1507.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.62 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     697.36 ms /     1 runs   (  697.36 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1526.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.92 ms /    16 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =     639.27 ms /     1 runs   (  639.27 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1497.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.79 ms /    15 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     666.99 ms /     1 runs   (  666.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1440.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.16 ms /    16 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =     634.25 ms /     1 runs   (  634.25 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1496.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.92 ms /    15 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     646.37 ms /     1 runs   (  646.37 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1441.49 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.16 ms /    16 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     662.55 ms /     1 runs   (  662.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1498.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.13 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     662.40 ms /     1 runs   (  662.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.13 ms /    16 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     660.32 ms /     1 runs   (  660.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1497.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.67 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.10 ms /     1 runs   (  659.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.21 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     655.56 ms /     1 runs   (  655.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.35 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     653.08 ms /     1 runs   (  653.08 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.98 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     672.15 ms /     1 runs   (  672.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2134.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.95 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     649.72 ms /     1 runs   (  649.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1481.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.99 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     661.77 ms /     1 runs   (  661.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.07 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     676.83 ms /     1 runs   (  676.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.68 ms /    15 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     660.56 ms /     1 runs   (  660.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1439.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.43 ms /    16 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     642.75 ms /     1 runs   (  642.75 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1491.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.98 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     659.31 ms /     1 runs   (  659.31 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.25 ms /    16 tokens (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     648.51 ms /     1 runs   (  648.51 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.87 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     684.58 ms /     1 runs   (  684.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1457.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.93 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     659.28 ms /     1 runs   (  659.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.47 ms /    16 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     685.43 ms /     1 runs   (  685.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1535.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.68 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     648.46 ms /     1 runs   (  648.46 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1424.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.50 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     657.05 ms /     1 runs   (  657.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.91 ms /    15 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     668.85 ms /     1 runs   (  668.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1450.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.24 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     669.45 ms /     1 runs   (  669.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.88 ms /    15 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     658.03 ms /     1 runs   (  658.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1436.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.59 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     646.90 ms /     1 runs   (  646.90 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.03 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     655.89 ms /     1 runs   (  655.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.68 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     654.68 ms /     1 runs   (  654.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.11 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     649.50 ms /     1 runs   (  649.50 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.18 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     653.65 ms /     1 runs   (  653.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.84 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     650.19 ms /     1 runs   (  650.19 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1428.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.36 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     681.00 ms /     1 runs   (  681.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1515.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.80 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     667.06 ms /     1 runs   (  667.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.06 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     669.91 ms /     1 runs   (  669.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1502.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.04 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     653.85 ms /     1 runs   (  653.85 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.60 ms /    16 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     654.35 ms /     1 runs   (  654.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1500.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.53 ms /    15 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     670.39 ms /     1 runs   (  670.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1443.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.72 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     675.27 ms /     1 runs   (  675.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.22 ms /    16 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     654.40 ms /     1 runs   (  654.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.34 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     658.42 ms /     1 runs   (  658.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.76 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     655.59 ms /     1 runs   (  655.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.35 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     691.76 ms /     1 runs   (  691.76 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1511.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.38 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     655.59 ms /     1 runs   (  655.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1492.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.25 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     704.72 ms /     1 runs   (  704.72 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1481.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.46 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     643.16 ms /     1 runs   (  643.16 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1476.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.46 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     659.57 ms /     1 runs   (  659.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.10 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     647.29 ms /     1 runs   (  647.29 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.56 ms /    15 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     661.63 ms /     1 runs   (  661.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1435.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.23 ms /    15 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =     650.72 ms /     1 runs   (  650.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.41 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     676.08 ms /     1 runs   (  676.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.45 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     649.79 ms /     1 runs   (  649.79 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.70 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     668.80 ms /     1 runs   (  668.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.26 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     655.72 ms /     1 runs   (  655.72 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.07 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     668.78 ms /     1 runs   (  668.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.37 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     656.46 ms /     1 runs   (  656.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.60 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     647.12 ms /     1 runs   (  647.12 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.54 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     678.45 ms /     1 runs   (  678.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1509.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.51 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     660.47 ms /     1 runs   (  660.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.02 ms /    16 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =     650.01 ms /     1 runs   (  650.01 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1508.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.39 ms /    15 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     666.82 ms /     1 runs   (  666.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1443.31 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.43 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     652.50 ms /     1 runs   (  652.50 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.22 ms /    15 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     686.88 ms /     1 runs   (  686.88 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1462.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.89 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     668.85 ms /     1 runs   (  668.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.60 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     686.98 ms /     1 runs   (  686.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1521.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.14 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     645.71 ms /     1 runs   (  645.71 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.92 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     663.86 ms /     1 runs   (  663.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.35 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     666.30 ms /     1 runs   (  666.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1443.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.62 ms /    14 tokens (   52.04 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     659.33 ms /     1 runs   (  659.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1393.13 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.39 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     684.30 ms /     1 runs   (  684.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1501.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.87 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     660.02 ms /     1 runs   (  660.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.60 ms /    15 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     658.77 ms /     1 runs   (  658.77 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1453.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.88 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     692.26 ms /     1 runs   (  692.26 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1512.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.96 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     682.53 ms /     1 runs   (  682.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1523.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.26 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     648.18 ms /     1 runs   (  648.18 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.11 ms /    14 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     700.54 ms /     1 runs   (  700.54 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1428.00 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.57 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     671.25 ms /     1 runs   (  671.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     2 runs   (    0.57 ms per token,  1749.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.13 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     678.55 ms /     1 runs   (  678.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1507.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.07 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     645.92 ms /     1 runs   (  645.92 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.26 ms /    15 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     665.34 ms /     1 runs   (  665.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1440.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.31 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     659.80 ms /     1 runs   (  659.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.40 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     664.64 ms /     1 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.30 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     683.84 ms /     1 runs   (  683.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1503.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.18 ms /    16 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     662.14 ms /     1 runs   (  662.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.35 ms /    15 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     652.19 ms /     1 runs   (  652.19 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1428.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.27 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     640.31 ms /     1 runs   (  640.31 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1467.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.92 ms /    15 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     662.97 ms /     1 runs   (  662.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1453.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.93 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     657.09 ms /     1 runs   (  657.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.42 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     648.82 ms /     1 runs   (  648.82 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.16 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     684.57 ms /     1 runs   (  684.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1508.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.26 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     663.77 ms /     1 runs   (  663.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.61 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     643.88 ms /     1 runs   (  643.88 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.34 ms /    15 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =     688.80 ms /     1 runs   (  688.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1485.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.67 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     660.56 ms /     1 runs   (  660.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.81 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     660.11 ms /     1 runs   (  660.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2176.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.83 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     645.03 ms /     1 runs   (  645.03 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1477.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.64 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     650.32 ms /     1 runs   (  650.32 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.14 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     650.27 ms /     1 runs   (  650.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.05 ms /    16 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     658.08 ms /     1 runs   (  658.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1505.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.30 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     715.41 ms /     1 runs   (  715.41 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1539.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.91 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     693.32 ms /     1 runs   (  693.32 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1527.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.34 ms /    15 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     659.48 ms /     1 runs   (  659.48 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1433.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.19 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     663.21 ms /     1 runs   (  663.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.52 ms /    15 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     660.39 ms /     1 runs   (  660.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1428.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.96 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     649.86 ms /     1 runs   (  649.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.21 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     674.44 ms /     1 runs   (  674.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.78 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     658.19 ms /     1 runs   (  658.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.98 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     653.71 ms /     1 runs   (  653.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.24 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     664.06 ms /     1 runs   (  664.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.34 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     663.35 ms /     1 runs   (  663.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.79 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     651.47 ms /     1 runs   (  651.47 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.56 ms /    16 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     694.86 ms /     1 runs   (  694.86 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1545.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.06 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     652.52 ms /     1 runs   (  652.52 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.71 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     663.20 ms /     1 runs   (  663.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.87 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     666.10 ms /     1 runs   (  666.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.96 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     659.42 ms /     1 runs   (  659.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.79 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     648.35 ms /     1 runs   (  648.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1419.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.50 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     657.09 ms /     1 runs   (  657.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.62 ms /    14 tokens (   52.04 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     688.66 ms /     1 runs   (  688.66 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1422.73 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.48 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     671.73 ms /     1 runs   (  671.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.85 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     652.02 ms /     1 runs   (  652.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1465.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.14 ms /    15 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     694.12 ms /     1 runs   (  694.12 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1479.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.23 ms /    15 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     655.64 ms /     1 runs   (  655.64 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1427.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.61 ms /    16 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     688.27 ms /     1 runs   (  688.27 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1535.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.93 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     660.36 ms /     1 runs   (  660.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.38 ms /    14 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     678.32 ms /     1 runs   (  678.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1405.04 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.60 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     668.72 ms /     1 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.79 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     661.06 ms /     1 runs   (  661.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.90 ms /    16 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     721.41 ms /     1 runs   (  721.41 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1551.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.14 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     670.61 ms /     1 runs   (  670.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1443.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.13 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     655.67 ms /     1 runs   (  655.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.73 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     645.63 ms /     1 runs   (  645.63 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.13 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     658.81 ms /     1 runs   (  658.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.72 ms /    14 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     679.62 ms /     1 runs   (  679.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1407.72 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.45 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     652.35 ms /     1 runs   (  652.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1486.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.57 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     650.56 ms /     1 runs   (  650.56 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.48 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     663.67 ms /     1 runs   (  663.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.38 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     660.87 ms /     1 runs   (  660.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.33 ms /    15 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     676.36 ms /     1 runs   (  676.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1462.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.74 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     653.71 ms /     1 runs   (  653.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     910.13 ms /    16 tokens (   56.88 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =     653.83 ms /     1 runs   (  653.83 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1570.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.10 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     651.04 ms /     1 runs   (  651.04 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /     2 runs   (    0.49 ms per token,  2022.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.57 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     660.39 ms /     1 runs   (  660.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.89 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     647.85 ms /     1 runs   (  647.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1424.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.84 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     659.22 ms /     1 runs   (  659.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.93 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     646.00 ms /     1 runs   (  646.00 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1420.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.72 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     651.63 ms /     1 runs   (  651.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1428.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.38 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     662.74 ms /     1 runs   (  662.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.37 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     648.92 ms /     1 runs   (  648.92 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.05 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     648.32 ms /     1 runs   (  648.32 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.36 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     658.40 ms /     1 runs   (  658.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.02 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     692.75 ms /     1 runs   (  692.75 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1516.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.59 ms /    15 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     663.49 ms /     1 runs   (  663.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1439.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     736.65 ms /    14 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     662.72 ms /     1 runs   (  662.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1404.79 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.90 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     657.43 ms /     1 runs   (  657.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.86 ms /    14 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =     656.05 ms /     1 runs   (  656.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1405.83 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.58 ms /    16 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     686.39 ms /     1 runs   (  686.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1544.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.87 ms /    15 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     694.66 ms /     1 runs   (  694.66 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1466.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.73 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     677.22 ms /     1 runs   (  677.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.19 ms /    15 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     677.29 ms /     1 runs   (  677.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1449.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.07 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     675.80 ms /     1 runs   (  675.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.86 ms /    14 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     658.21 ms /     1 runs   (  658.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1392.46 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.10 ms /    16 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =     663.94 ms /     1 runs   (  663.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.62 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     735.20 ms /     1 runs   (  735.20 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1567.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     872.71 ms /    16 tokens (   54.54 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =     662.53 ms /     1 runs   (  662.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1541.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.95 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     665.57 ms /     1 runs   (  665.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     855.19 ms /    16 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =     663.94 ms /     1 runs   (  663.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1524.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.18 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     675.38 ms /     1 runs   (  675.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.28 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     656.75 ms /     1 runs   (  656.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.62 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     682.26 ms /     1 runs   (  682.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1500.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.29 ms /    14 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     656.13 ms /     1 runs   (  656.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1383.16 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.20 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     656.27 ms /     1 runs   (  656.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.08 ms /    15 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     650.72 ms /     1 runs   (  650.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.91 ms /    15 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     680.49 ms /     1 runs   (  680.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1452.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.59 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     660.91 ms /     1 runs   (  660.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.48 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     661.17 ms /     1 runs   (  661.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.50 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     649.85 ms /     1 runs   (  649.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.54 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     682.51 ms /     1 runs   (  682.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1507.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.93 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     690.70 ms /     1 runs   (  690.70 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1506.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.10 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     642.68 ms /     1 runs   (  642.68 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1459.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.10 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     696.42 ms /     1 runs   (  696.42 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1530.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2192.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     878.96 ms /    16 tokens (   54.94 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =     683.17 ms /     1 runs   (  683.17 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1567.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.32 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     656.98 ms /     1 runs   (  656.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.59 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     664.44 ms /     1 runs   (  664.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.43 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     683.80 ms /     1 runs   (  683.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1500.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.02 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     658.95 ms /     1 runs   (  658.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.66 ms /    16 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     698.86 ms /     1 runs   (  698.86 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1550.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.64 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     655.02 ms /     1 runs   (  655.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.77 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     673.57 ms /     1 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.91 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     663.83 ms /     1 runs   (  663.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.10 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     651.00 ms /     1 runs   (  651.00 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.25 ms /    15 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     687.64 ms /     1 runs   (  687.64 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1479.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.84 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     657.13 ms /     1 runs   (  657.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.39 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     658.08 ms /     1 runs   (  658.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.65 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     685.91 ms /     1 runs   (  685.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1506.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.76 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     657.15 ms /     1 runs   (  657.15 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1494.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.95 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     664.55 ms /     1 runs   (  664.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.72 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     651.94 ms /     1 runs   (  651.94 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.43 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     638.71 ms /     1 runs   (  638.71 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1460.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.97 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     664.40 ms /     1 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.14 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     662.39 ms /     1 runs   (  662.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.91 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     667.16 ms /     1 runs   (  667.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.74 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     655.45 ms /     1 runs   (  655.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.31 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     665.01 ms /     1 runs   (  665.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.00 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     688.32 ms /     1 runs   (  688.32 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1524.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.74 ms /    16 tokens (   52.23 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     679.66 ms /     1 runs   (  679.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1520.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.35 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     659.55 ms /     1 runs   (  659.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.89 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     662.12 ms /     1 runs   (  662.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.08 ms /    16 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =     657.93 ms /     1 runs   (  657.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1521.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.92 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     692.71 ms /     1 runs   (  692.71 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1510.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.70 ms /    16 tokens (   50.54 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     637.03 ms /     1 runs   (  637.03 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1451.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.18 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     678.35 ms /     1 runs   (  678.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1504.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2139.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.88 ms /    16 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     682.95 ms /     1 runs   (  682.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1523.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.29 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     652.75 ms /     1 runs   (  652.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.68 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     694.05 ms /     1 runs   (  694.05 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1508.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.80 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     646.76 ms /     1 runs   (  646.76 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.21 ms /    15 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     656.11 ms /     1 runs   (  656.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1434.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.02 ms /    13 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     664.54 ms /     1 runs   (  664.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1352.22 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.03 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     693.07 ms /     1 runs   (  693.07 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1520.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.02 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     658.72 ms /     1 runs   (  658.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.71 ms /    16 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     710.57 ms /     1 runs   (  710.57 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1544.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.06 ms /    16 tokens (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     661.40 ms /     1 runs   (  661.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.56 ms /    15 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     712.67 ms /     1 runs   (  712.67 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1495.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.66 ms /    15 tokens (   52.04 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     667.70 ms /     1 runs   (  667.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1453.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.71 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     678.60 ms /     1 runs   (  678.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1494.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.33 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     663.30 ms /     1 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.18 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     662.92 ms /     1 runs   (  662.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.53 ms per token,  1874.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.99 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     705.40 ms /     1 runs   (  705.40 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1529.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.78 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     656.82 ms /     1 runs   (  656.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.02 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     648.92 ms /     1 runs   (  648.92 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.39 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     694.89 ms /     1 runs   (  694.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1516.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.60 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     664.26 ms /     1 runs   (  664.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.73 ms /    15 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     669.03 ms /     1 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1448.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.78 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     660.74 ms /     1 runs   (  660.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1433.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.84 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     661.02 ms /     1 runs   (  661.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.63 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     655.21 ms /     1 runs   (  655.21 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.57 ms /    13 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     664.26 ms /     1 runs   (  664.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1344.86 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.69 ms /    15 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     651.67 ms /     1 runs   (  651.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1430.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.85 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     688.72 ms /     1 runs   (  688.72 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1502.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.22 ms /    16 tokens (   52.70 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     638.20 ms /     1 runs   (  638.20 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1486.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.18 ms /    16 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     657.49 ms /     1 runs   (  657.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1495.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.22 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     682.18 ms /     1 runs   (  682.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1500.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.17 ms /    15 tokens (   54.54 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =     656.99 ms /     1 runs   (  656.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.07 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     695.20 ms /     1 runs   (  695.20 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1467.64 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.75 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     656.87 ms /     1 runs   (  656.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1435.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.11 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     650.26 ms /     1 runs   (  650.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.31 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     669.16 ms /     1 runs   (  669.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.64 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     664.23 ms /     1 runs   (  664.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.26 ms /    16 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =     673.04 ms /     1 runs   (  673.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1532.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.72 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     655.32 ms /     1 runs   (  655.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.01 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     649.91 ms /     1 runs   (  649.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.26 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     670.99 ms /     1 runs   (  670.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.51 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     660.81 ms /     1 runs   (  660.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.75 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     650.71 ms /     1 runs   (  650.71 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.72 ms /    16 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     662.39 ms /     1 runs   (  662.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.57 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     660.37 ms /     1 runs   (  660.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.28 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     659.47 ms /     1 runs   (  659.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.13 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     694.78 ms /     1 runs   (  694.78 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1516.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.91 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     665.72 ms /     1 runs   (  665.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.07 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     659.41 ms /     1 runs   (  659.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.94 ms /    15 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     648.97 ms /     1 runs   (  648.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1424.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.29 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     651.63 ms /     1 runs   (  651.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.76 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     651.49 ms /     1 runs   (  651.49 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.70 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     667.80 ms /     1 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1508.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.25 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     666.45 ms /     1 runs   (  666.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1501.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.82 ms /    15 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     648.75 ms /     1 runs   (  648.75 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1417.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.06 ms /    16 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     646.91 ms /     1 runs   (  646.91 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1485.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.86 ms /    16 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     667.53 ms /     1 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1508.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.21 ms /    16 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     685.22 ms /     1 runs   (  685.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1526.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.13 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     684.84 ms /     1 runs   (  684.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1502.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.43 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     656.73 ms /     1 runs   (  656.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.01 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     672.75 ms /     1 runs   (  672.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.38 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     652.76 ms /     1 runs   (  652.76 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     860.64 ms /    16 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =     647.27 ms /     1 runs   (  647.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1513.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.53 ms /    16 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     653.22 ms /     1 runs   (  653.22 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1499.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.59 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     678.70 ms /     1 runs   (  678.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1495.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.91 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     647.46 ms /     1 runs   (  647.46 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2143.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.68 ms /    15 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     671.27 ms /     1 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1463.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.35 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     650.65 ms /     1 runs   (  650.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.28 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     644.20 ms /     1 runs   (  644.20 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.39 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     652.56 ms /     1 runs   (  652.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.38 ms /    15 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     647.10 ms /     1 runs   (  647.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1436.67 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.17 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     647.89 ms /     1 runs   (  647.89 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.72 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     665.81 ms /     1 runs   (  665.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1441.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.15 ms /    16 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     669.18 ms /     1 runs   (  669.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1505.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.48 ms /    15 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     647.44 ms /     1 runs   (  647.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1422.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.04 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     645.20 ms /     1 runs   (  645.20 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1479.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.38 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     648.59 ms /     1 runs   (  648.59 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1425.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.38 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     663.09 ms /     1 runs   (  663.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.02 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     668.31 ms /     1 runs   (  668.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.28 ms /    15 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     673.81 ms /     1 runs   (  673.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1448.49 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.07 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     697.37 ms /     1 runs   (  697.37 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1515.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.30 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     682.66 ms /     1 runs   (  682.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1506.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.52 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.89 ms /     1 runs   (  652.89 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.68 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     660.94 ms /     1 runs   (  660.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1495.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.30 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     659.75 ms /     1 runs   (  659.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.54 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     671.08 ms /     1 runs   (  671.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1502.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.21 ms /    15 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     657.89 ms /     1 runs   (  657.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1439.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.13 ms /    15 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =     646.39 ms /     1 runs   (  646.39 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1445.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.39 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     657.77 ms /     1 runs   (  657.77 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.54 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     674.26 ms /     1 runs   (  674.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1449.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.05 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     672.63 ms /     1 runs   (  672.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.62 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     645.47 ms /     1 runs   (  645.47 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.98 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     660.35 ms /     1 runs   (  660.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1430.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.36 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     674.27 ms /     1 runs   (  674.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1507.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.63 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     682.65 ms /     1 runs   (  682.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1453.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.62 ms /    15 tokens (   51.37 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     663.24 ms /     1 runs   (  663.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1439.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.07 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     659.86 ms /     1 runs   (  659.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.85 ms /    15 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     718.25 ms /     1 runs   (  718.25 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1496.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.93 ms /    15 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     666.02 ms /     1 runs   (  666.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1435.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.16 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     648.34 ms /     1 runs   (  648.34 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.77 ms /    15 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     672.41 ms /     1 runs   (  672.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1457.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.02 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     679.70 ms /     1 runs   (  679.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1509.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.92 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     661.36 ms /     1 runs   (  661.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.53 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     675.28 ms /     1 runs   (  675.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.72 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     693.99 ms /     1 runs   (  693.99 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1470.64 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.34 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     658.81 ms /     1 runs   (  658.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.47 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     665.20 ms /     1 runs   (  665.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1478.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.83 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     647.36 ms /     1 runs   (  647.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.53 ms /    16 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =     672.81 ms /     1 runs   (  672.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1536.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.15 ms /    16 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     643.32 ms /     1 runs   (  643.32 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1478.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.42 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     667.48 ms /     1 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.01 ms /    15 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     697.23 ms /     1 runs   (  697.23 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1473.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.04 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     652.97 ms /     1 runs   (  652.97 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1489.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.20 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     665.04 ms /     1 runs   (  665.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.84 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     664.05 ms /     1 runs   (  664.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.53 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     663.01 ms /     1 runs   (  663.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.57 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     670.30 ms /     1 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1500.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.12 ms /    16 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     660.74 ms /     1 runs   (  660.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1498.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.01 ms /    16 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     648.18 ms /     1 runs   (  648.18 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1459.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.75 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     661.89 ms /     1 runs   (  661.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1504.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.63 ms /    15 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     660.79 ms /     1 runs   (  660.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1435.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.47 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     684.58 ms /     1 runs   (  684.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1501.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.19 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     655.46 ms /     1 runs   (  655.46 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.88 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     656.01 ms /     1 runs   (  656.01 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.70 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     651.81 ms /     1 runs   (  651.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.36 ms /    16 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     688.80 ms /     1 runs   (  688.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1536.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     2 runs   (    0.96 ms per token,  1042.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.37 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     690.57 ms /     1 runs   (  690.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1513.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     2 runs   (    0.74 ms per token,  1351.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.27 ms /    16 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     680.87 ms /     1 runs   (  680.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1524.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.66 ms /    16 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     666.93 ms /     1 runs   (  666.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1502.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.38 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     662.16 ms /     1 runs   (  662.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.45 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     645.95 ms /     1 runs   (  645.95 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2094.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     897.32 ms /    16 tokens (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =     707.70 ms /     1 runs   (  707.70 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1610.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.90 ms /    16 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     674.19 ms /     1 runs   (  674.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1511.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.12 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     661.66 ms /     1 runs   (  661.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.98 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     645.65 ms /     1 runs   (  645.65 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.49 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     686.27 ms /     1 runs   (  686.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1513.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.32 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     664.29 ms /     1 runs   (  664.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1501.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.55 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     677.92 ms /     1 runs   (  677.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2181.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.36 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     661.00 ms /     1 runs   (  661.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     870.99 ms /    16 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =     664.28 ms /     1 runs   (  664.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1540.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     869.72 ms /    15 tokens (   57.98 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =     649.11 ms /     1 runs   (  649.11 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1524.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.87 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     638.35 ms /     1 runs   (  638.35 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1452.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.95 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     679.00 ms /     1 runs   (  679.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1510.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.86 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     672.77 ms /     1 runs   (  672.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.35 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     678.46 ms /     1 runs   (  678.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1493.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.38 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     651.57 ms /     1 runs   (  651.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.69 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     677.46 ms /     1 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1508.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.02 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     663.34 ms /     1 runs   (  663.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.61 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     666.89 ms /     1 runs   (  666.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.81 ms /    16 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     641.04 ms /     1 runs   (  641.04 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1488.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.74 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     664.91 ms /     1 runs   (  664.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     2 runs   (    0.93 ms per token,  1075.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     927.60 ms /    16 tokens (   57.97 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =     747.80 ms /     1 runs   (  747.80 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =    1686.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.57 ms /    15 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     672.55 ms /     1 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1455.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.22 ms /    15 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     680.51 ms /     1 runs   (  680.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1457.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     873.96 ms /    16 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =     678.56 ms /     1 runs   (  678.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1557.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.27 ms /    16 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     682.41 ms /     1 runs   (  682.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1537.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.27 ms /    15 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =     658.08 ms /     1 runs   (  658.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.50 ms /    16 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     665.36 ms /     1 runs   (  665.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1513.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.38 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     702.45 ms /     1 runs   (  702.45 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1522.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.01 ms /    15 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     658.41 ms /     1 runs   (  658.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1454.49 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.43 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     658.80 ms /     1 runs   (  658.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2089.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.68 ms /    15 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     704.43 ms /     1 runs   (  704.43 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1489.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.05 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     667.36 ms /     1 runs   (  667.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.81 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     652.84 ms /     1 runs   (  652.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.47 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     656.09 ms /     1 runs   (  656.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.11 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     666.84 ms /     1 runs   (  666.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.16 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     650.28 ms /     1 runs   (  650.28 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.54 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     645.00 ms /     1 runs   (  645.00 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1419.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.15 ms /    16 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     665.65 ms /     1 runs   (  665.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2157.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.47 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     656.73 ms /     1 runs   (  656.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.63 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     666.54 ms /     1 runs   (  666.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2155.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     943.50 ms /    16 tokens (   58.97 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =     721.12 ms /     1 runs   (  721.12 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1670.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.57 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     676.31 ms /     1 runs   (  676.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.61 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     674.17 ms /     1 runs   (  674.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1489.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.27 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     660.06 ms /     1 runs   (  660.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.07 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     660.56 ms /     1 runs   (  660.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.23 ms /    15 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     670.19 ms /     1 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1460.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.13 ms /    15 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     692.45 ms /     1 runs   (  692.45 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1461.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.95 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     652.80 ms /     1 runs   (  652.80 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1465.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.18 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     658.13 ms /     1 runs   (  658.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.25 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     660.98 ms /     1 runs   (  660.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.72 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     637.83 ms /     1 runs   (  637.83 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1477.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.19 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     659.02 ms /     1 runs   (  659.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.23 ms /    15 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     665.36 ms /     1 runs   (  665.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1455.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.28 ms /    16 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     648.95 ms /     1 runs   (  648.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.21 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     648.18 ms /     1 runs   (  648.18 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.61 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     670.84 ms /     1 runs   (  670.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1506.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.49 ms /    16 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     651.10 ms /     1 runs   (  651.10 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1503.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.29 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     662.84 ms /     1 runs   (  662.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.73 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     660.91 ms /     1 runs   (  660.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.68 ms /    15 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     661.33 ms /     1 runs   (  661.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1447.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.12 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     672.18 ms /     1 runs   (  672.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.16 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     695.58 ms /     1 runs   (  695.58 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1515.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.56 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     646.23 ms /     1 runs   (  646.23 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2109.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.26 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     655.51 ms /     1 runs   (  655.51 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.73 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     654.25 ms /     1 runs   (  654.25 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.20 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     688.80 ms /     1 runs   (  688.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1510.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.80 ms /    15 tokens (   55.19 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =     653.08 ms /     1 runs   (  653.08 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1486.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.52 ms /    16 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     650.56 ms /     1 runs   (  650.56 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1487.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.84 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     655.43 ms /     1 runs   (  655.43 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.43 ms /    14 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     656.17 ms /     1 runs   (  656.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1389.01 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.74 ms /    14 tokens (   57.98 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =     670.14 ms /     1 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.52 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.09 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     640.99 ms /     1 runs   (  640.99 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1469.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.01 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     667.67 ms /     1 runs   (  667.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1502.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.47 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     643.55 ms /     1 runs   (  643.55 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.19 ms /    16 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =     668.23 ms /     1 runs   (  668.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1526.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.76 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     656.43 ms /     1 runs   (  656.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.61 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     693.88 ms /     1 runs   (  693.88 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1514.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.09 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     651.22 ms /     1 runs   (  651.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.33 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     649.43 ms /     1 runs   (  649.43 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.53 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     648.60 ms /     1 runs   (  648.60 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1480.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.87 ms /    15 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     711.39 ms /     1 runs   (  711.39 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1493.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.31 ms /    16 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     663.74 ms /     1 runs   (  663.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1505.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.07 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     661.09 ms /     1 runs   (  661.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.78 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     649.01 ms /     1 runs   (  649.01 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2157.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.64 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     659.26 ms /     1 runs   (  659.26 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.75 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     652.85 ms /     1 runs   (  652.85 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.39 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     660.85 ms /     1 runs   (  660.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.60 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     649.26 ms /     1 runs   (  649.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.26 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     676.40 ms /     1 runs   (  676.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1501.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.22 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     655.34 ms /     1 runs   (  655.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.97 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     653.58 ms /     1 runs   (  653.58 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.60 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     628.08 ms /     1 runs   (  628.08 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1449.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     868.15 ms /    16 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =     644.71 ms /     1 runs   (  644.71 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1519.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.77 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     671.54 ms /     1 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.67 ms /    15 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     655.96 ms /     1 runs   (  655.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1430.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.79 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.23 ms /     1 runs   (  652.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.79 ms /    15 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     661.15 ms /     1 runs   (  661.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1435.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.01 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     668.71 ms /     1 runs   (  668.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.51 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     644.05 ms /     1 runs   (  644.05 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1475.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.13 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     714.84 ms /     1 runs   (  714.84 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1537.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.05 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     700.01 ms /     1 runs   (  700.01 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1527.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.49 ms /    16 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     635.75 ms /     1 runs   (  635.75 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1468.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.58 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     685.65 ms /     1 runs   (  685.65 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1508.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.24 ms /    15 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     686.26 ms /     1 runs   (  686.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1461.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.41 ms /    15 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =     652.61 ms /     1 runs   (  652.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1450.67 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2143.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.37 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     650.26 ms /     1 runs   (  650.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.70 ms /    16 tokens (   50.54 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     655.78 ms /     1 runs   (  655.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1469.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.96 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     660.05 ms /     1 runs   (  660.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.41 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     658.36 ms /     1 runs   (  658.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.57 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     656.54 ms /     1 runs   (  656.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.11 ms /    15 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =     640.27 ms /     1 runs   (  640.27 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1454.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.74 ms /    16 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =     697.90 ms /     1 runs   (  697.90 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1557.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.15 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     707.96 ms /     1 runs   (  707.96 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1526.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.81 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     646.44 ms /     1 runs   (  646.44 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.08 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     657.60 ms /     1 runs   (  657.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.94 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     644.10 ms /     1 runs   (  644.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1472.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.29 ms /    15 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     662.03 ms /     1 runs   (  662.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1441.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.37 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     697.30 ms /     1 runs   (  697.30 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1515.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.50 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     638.98 ms /     1 runs   (  638.98 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1463.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.98 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     652.95 ms /     1 runs   (  652.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1493.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.75 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     706.79 ms /     1 runs   (  706.79 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1518.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     943.01 ms /    16 tokens (   58.94 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:        eval time =     654.04 ms /     1 runs   (  654.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1602.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.87 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     642.14 ms /     1 runs   (  642.14 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1469.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.07 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     660.50 ms /     1 runs   (  660.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.26 ms /    16 tokens (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =     675.68 ms /     1 runs   (  675.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1485.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.42 ms /    15 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     643.66 ms /     1 runs   (  643.66 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1419.80 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.31 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     648.55 ms /     1 runs   (  648.55 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.47 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     666.51 ms /     1 runs   (  666.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     760.18 ms /    15 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     657.63 ms /     1 runs   (  657.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1422.87 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.24 ms /    16 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     656.81 ms /     1 runs   (  656.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1493.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.64 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     644.37 ms /     1 runs   (  644.37 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.42 ms /    15 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     642.59 ms /     1 runs   (  642.59 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1415.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.35 ms /    14 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     665.13 ms /     1 runs   (  665.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1415.06 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.08 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     669.91 ms /     1 runs   (  669.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1482.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.40 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     662.27 ms /     1 runs   (  662.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.56 ms /    16 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     642.96 ms /     1 runs   (  642.96 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1478.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.65 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     653.32 ms /     1 runs   (  653.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.38 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     640.57 ms /     1 runs   (  640.57 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1462.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.07 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     631.03 ms /     1 runs   (  631.03 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1443.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.07 ms /    15 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     640.72 ms /     1 runs   (  640.72 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1429.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2173.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.86 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     664.46 ms /     1 runs   (  664.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.78 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     655.35 ms /     1 runs   (  655.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.09 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     660.16 ms /     1 runs   (  660.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.14 ms /    15 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     668.66 ms /     1 runs   (  668.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1440.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.33 ms /    16 tokens (   52.40 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     664.65 ms /     1 runs   (  664.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1508.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.23 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     686.60 ms /     1 runs   (  686.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1518.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.26 ms /    16 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     643.66 ms /     1 runs   (  643.66 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1484.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.49 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     647.97 ms /     1 runs   (  647.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.21 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     658.18 ms /     1 runs   (  658.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.96 ms /    15 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     647.95 ms /     1 runs   (  647.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1416.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.34 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     670.38 ms /     1 runs   (  670.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.91 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     652.44 ms /     1 runs   (  652.44 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.80 ms /    16 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     675.24 ms /     1 runs   (  675.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1503.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.38 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     669.89 ms /     1 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.45 ms /    16 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     645.68 ms /     1 runs   (  645.68 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1457.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.95 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     691.41 ms /     1 runs   (  691.41 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1513.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.06 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     650.30 ms /     1 runs   (  650.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.38 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     704.62 ms /     1 runs   (  704.62 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1529.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.44 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     665.85 ms /     1 runs   (  665.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.63 ms /    16 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     659.16 ms /     1 runs   (  659.16 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1509.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.89 ms /    16 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     647.30 ms /     1 runs   (  647.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1488.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.34 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     683.83 ms /     1 runs   (  683.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1505.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.50 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     655.59 ms /     1 runs   (  655.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.14 ms /    15 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     653.23 ms /     1 runs   (  653.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1438.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.89 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     666.83 ms /     1 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.97 ms /    15 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     644.33 ms /     1 runs   (  644.33 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1426.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.13 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     645.02 ms /     1 runs   (  645.02 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.00 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     645.30 ms /     1 runs   (  645.30 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1417.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.98 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     671.66 ms /     1 runs   (  671.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1499.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.34 ms /    15 tokens (   52.76 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     664.04 ms /     1 runs   (  664.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1460.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.15 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     660.68 ms /     1 runs   (  660.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.26 ms /    15 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =     656.03 ms /     1 runs   (  656.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1454.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.76 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     644.11 ms /     1 runs   (  644.11 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1417.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.81 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     641.09 ms /     1 runs   (  641.09 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1456.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.36 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     632.43 ms /     1 runs   (  632.43 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1448.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.47 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     693.46 ms /     1 runs   (  693.46 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1511.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.01 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     653.10 ms /     1 runs   (  653.10 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.09 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     664.88 ms /     1 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.55 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     655.26 ms /     1 runs   (  655.26 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.31 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     649.22 ms /     1 runs   (  649.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1483.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.32 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     650.35 ms /     1 runs   (  650.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.05 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     653.99 ms /     1 runs   (  653.99 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.44 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     654.00 ms /     1 runs   (  654.00 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.53 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     676.98 ms /     1 runs   (  676.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.64 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     640.18 ms /     1 runs   (  640.18 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1473.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.23 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     670.49 ms /     1 runs   (  670.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.48 ms /    16 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     647.60 ms /     1 runs   (  647.60 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1497.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.02 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     681.44 ms /     1 runs   (  681.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1518.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.08 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     649.14 ms /     1 runs   (  649.14 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.00 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     650.93 ms /     1 runs   (  650.93 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.82 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     656.73 ms /     1 runs   (  656.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.28 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     671.82 ms /     1 runs   (  671.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.29 ms /    16 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     660.89 ms /     1 runs   (  660.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1503.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.82 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     648.38 ms /     1 runs   (  648.38 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.87 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     683.63 ms /     1 runs   (  683.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1510.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.56 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     671.11 ms /     1 runs   (  671.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1446.44 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.55 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     646.85 ms /     1 runs   (  646.85 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.86 ms /    13 tokens (   51.99 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     684.25 ms /     1 runs   (  684.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1365.26 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.08 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     674.42 ms /     1 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.37 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     660.78 ms /     1 runs   (  660.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.70 ms /    16 tokens (   50.54 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     684.99 ms /     1 runs   (  684.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1499.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.60 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     658.75 ms /     1 runs   (  658.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.37 ms /    16 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     659.54 ms /     1 runs   (  659.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1499.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.88 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     663.05 ms /     1 runs   (  663.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.40 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     661.36 ms /     1 runs   (  661.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.91 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     657.28 ms /     1 runs   (  657.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.72 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     650.61 ms /     1 runs   (  650.61 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.80 ms /    15 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     672.85 ms /     1 runs   (  672.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1441.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.50 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     661.98 ms /     1 runs   (  661.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.71 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     664.65 ms /     1 runs   (  664.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1479.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.41 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     674.98 ms /     1 runs   (  674.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.28 ms /    15 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     685.16 ms /     1 runs   (  685.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1473.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.70 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     643.57 ms /     1 runs   (  643.57 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1483.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.95 ms /    16 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     655.56 ms /     1 runs   (  655.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.87 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     686.26 ms /     1 runs   (  686.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1510.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.28 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     668.88 ms /     1 runs   (  668.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.27 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     671.88 ms /     1 runs   (  671.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.81 ms /    15 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     644.83 ms /     1 runs   (  644.83 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1438.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.61 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     673.89 ms /     1 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.21 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     668.48 ms /     1 runs   (  668.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1502.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.03 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     646.18 ms /     1 runs   (  646.18 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.73 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     668.60 ms /     1 runs   (  668.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1444.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.62 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     675.49 ms /     1 runs   (  675.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.68 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     661.79 ms /     1 runs   (  661.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.25 ms /    15 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     647.29 ms /     1 runs   (  647.29 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1449.44 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.22 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     691.02 ms /     1 runs   (  691.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1515.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     877.09 ms /    15 tokens (   58.47 ms per token,    17.10 tokens per second)\n",
      "llama_print_timings:        eval time =     672.17 ms /     1 runs   (  672.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1554.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.98 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     706.09 ms /     1 runs   (  706.09 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1535.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.19 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     683.26 ms /     1 runs   (  683.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.48 ms per token,  2061.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.50 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     683.61 ms /     1 runs   (  683.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1513.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.87 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     678.66 ms /     1 runs   (  678.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1507.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.36 ms /    14 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     662.69 ms /     1 runs   (  662.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1392.63 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.63 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     708.92 ms /     1 runs   (  708.92 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1534.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.51 ms /    15 tokens (   51.03 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     669.66 ms /     1 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1440.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.44 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     650.23 ms /     1 runs   (  650.23 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.67 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     671.09 ms /     1 runs   (  671.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.46 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     667.88 ms /     1 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.74 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     663.17 ms /     1 runs   (  663.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.73 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     698.07 ms /     1 runs   (  698.07 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1522.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.33 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     660.97 ms /     1 runs   (  660.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.41 ms /    16 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     654.16 ms /     1 runs   (  654.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1493.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.98 ms /    14 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     659.37 ms /     1 runs   (  659.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1398.66 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.00 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     664.69 ms /     1 runs   (  664.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1508.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.88 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     710.47 ms /     1 runs   (  710.47 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1531.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.65 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     656.76 ms /     1 runs   (  656.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.11 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     645.67 ms /     1 runs   (  645.67 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.95 ms /    16 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     657.96 ms /     1 runs   (  657.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1501.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.56 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     641.12 ms /     1 runs   (  641.12 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1467.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.79 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     672.76 ms /     1 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1515.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.08 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     669.82 ms /     1 runs   (  669.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.27 ms /    15 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     691.12 ms /     1 runs   (  691.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1476.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.20 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     661.28 ms /     1 runs   (  661.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.99 ms /    16 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     658.30 ms /     1 runs   (  658.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.02 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     657.84 ms /     1 runs   (  657.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.47 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     657.21 ms /     1 runs   (  657.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.87 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     697.88 ms /     1 runs   (  697.88 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1515.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.85 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     655.32 ms /     1 runs   (  655.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.12 ms /    15 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     678.54 ms /     1 runs   (  678.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1472.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.02 ms /    15 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =     695.93 ms /     1 runs   (  695.93 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1494.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.83 ms /    15 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     667.31 ms /     1 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1463.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.40 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     646.71 ms /     1 runs   (  646.71 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.75 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     645.41 ms /     1 runs   (  645.41 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1418.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.39 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     657.29 ms /     1 runs   (  657.29 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.53 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     652.81 ms /     1 runs   (  652.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /     2 runs   (    0.52 ms per token,  1937.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.54 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     675.58 ms /     1 runs   (  675.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1499.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.77 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     678.47 ms /     1 runs   (  678.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1507.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.54 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     667.81 ms /     1 runs   (  667.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.19 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     651.66 ms /     1 runs   (  651.66 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.87 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     681.65 ms /     1 runs   (  681.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1497.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.46 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     663.73 ms /     1 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.63 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     657.91 ms /     1 runs   (  657.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1495.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.16 ms /    15 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     673.47 ms /     1 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1450.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.09 ms /    15 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     676.12 ms /     1 runs   (  676.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1461.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.12 ms /    15 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     740.13 ms /     1 runs   (  740.13 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =    1533.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.48 ms /    15 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     655.75 ms /     1 runs   (  655.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1431.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.72 ms /    15 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =     648.80 ms /     1 runs   (  648.80 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.26 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     674.18 ms /     1 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     798.67 ms /    15 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =     704.15 ms /     1 runs   (  704.15 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1508.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.31 ms /    14 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     657.37 ms /     1 runs   (  657.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1384.64 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.61 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     677.56 ms /     1 runs   (  677.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1495.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.65 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     665.75 ms /     1 runs   (  665.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.67 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     674.59 ms /     1 runs   (  674.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2171.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.51 ms /    16 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =     631.86 ms /     1 runs   (  631.86 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1495.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     884.61 ms /    15 tokens (   58.97 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =     681.64 ms /     1 runs   (  681.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1572.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.08 ms /    15 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     654.18 ms /     1 runs   (  654.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1430.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.29 ms /    16 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     685.37 ms /     1 runs   (  685.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1527.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.26 ms /    15 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     645.37 ms /     1 runs   (  645.37 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1419.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.99 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     666.83 ms /     1 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1439.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.25 ms /    16 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     650.28 ms /     1 runs   (  650.28 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.88 ms /    16 tokens (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     681.01 ms /     1 runs   (  681.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1494.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.32 ms /    15 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     659.46 ms /     1 runs   (  659.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1449.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.45 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     668.99 ms /     1 runs   (  668.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1489.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.00 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     660.74 ms /     1 runs   (  660.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.30 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     667.20 ms /     1 runs   (  667.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.61 ms /    16 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     647.42 ms /     1 runs   (  647.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1483.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.96 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     671.36 ms /     1 runs   (  671.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.39 ms /    15 tokens (   53.09 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =     664.02 ms /     1 runs   (  664.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1465.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.48 ms /    15 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     649.70 ms /     1 runs   (  649.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1420.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.98 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     677.74 ms /     1 runs   (  677.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1507.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.88 ms /    15 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     653.44 ms /     1 runs   (  653.44 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1431.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.49 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     665.75 ms /     1 runs   (  665.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.57 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     647.05 ms /     1 runs   (  647.05 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.37 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     678.57 ms /     1 runs   (  678.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1491.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.19 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     651.37 ms /     1 runs   (  651.37 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.77 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     691.73 ms /     1 runs   (  691.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1531.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.31 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     703.68 ms /     1 runs   (  703.68 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1532.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.97 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     648.16 ms /     1 runs   (  648.16 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.92 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     656.13 ms /     1 runs   (  656.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1484.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.59 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     661.67 ms /     1 runs   (  661.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.38 ms /    15 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     644.90 ms /     1 runs   (  644.90 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1440.30 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.78 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     647.44 ms /     1 runs   (  647.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.85 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     653.15 ms /     1 runs   (  653.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.19 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     675.73 ms /     1 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2185.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.37 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     705.62 ms /     1 runs   (  705.62 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1482.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.17 ms /    15 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     648.10 ms /     1 runs   (  648.10 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1426.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.85 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     648.27 ms /     1 runs   (  648.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.85 ms /    16 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     645.70 ms /     1 runs   (  645.70 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1489.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.82 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     669.04 ms /     1 runs   (  669.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1506.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.96 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     657.81 ms /     1 runs   (  657.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.06 ms /    16 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     701.78 ms /     1 runs   (  701.78 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1544.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.13 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     682.72 ms /     1 runs   (  682.72 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1515.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.31 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     651.07 ms /     1 runs   (  651.07 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.28 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     661.13 ms /     1 runs   (  661.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.46 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     661.57 ms /     1 runs   (  661.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.40 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     660.69 ms /     1 runs   (  660.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1439.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.73 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     655.98 ms /     1 runs   (  655.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.85 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     658.54 ms /     1 runs   (  658.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.22 ms /    15 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     668.56 ms /     1 runs   (  668.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1438.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.91 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     655.62 ms /     1 runs   (  655.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.60 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     670.44 ms /     1 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.54 ms /    16 tokens (   51.03 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     653.77 ms /     1 runs   (  653.77 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.93 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     664.21 ms /     1 runs   (  664.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.96 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     657.32 ms /     1 runs   (  657.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.70 ms /    14 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     658.27 ms /     1 runs   (  658.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1383.66 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.45 ms /    15 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     672.61 ms /     1 runs   (  672.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1450.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.26 ms /    15 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     649.41 ms /     1 runs   (  649.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1440.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.42 ms /    16 tokens (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:        eval time =     671.28 ms /     1 runs   (  671.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1481.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.26 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     660.27 ms /     1 runs   (  660.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.48 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     642.91 ms /     1 runs   (  642.91 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1468.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.94 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     665.96 ms /     1 runs   (  665.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.62 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     658.62 ms /     1 runs   (  658.62 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.28 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     670.45 ms /     1 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.72 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     661.27 ms /     1 runs   (  661.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1473.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.82 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     669.18 ms /     1 runs   (  669.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1508.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.67 ms /    15 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     655.48 ms /     1 runs   (  655.48 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1450.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.20 ms /    16 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     646.10 ms /     1 runs   (  646.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1476.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.84 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     662.91 ms /     1 runs   (  662.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.64 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     642.65 ms /     1 runs   (  642.65 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1481.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.24 ms /    14 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     653.69 ms /     1 runs   (  653.69 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1384.63 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.47 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     660.30 ms /     1 runs   (  660.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.28 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     647.21 ms /     1 runs   (  647.21 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1419.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.15 ms /    16 tokens (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     665.89 ms /     1 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1477.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.28 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     647.99 ms /     1 runs   (  647.99 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.14 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     650.86 ms /     1 runs   (  650.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1423.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.74 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     658.13 ms /     1 runs   (  658.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.52 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     641.89 ms /     1 runs   (  641.89 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1465.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2118.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.17 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     689.82 ms /     1 runs   (  689.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1509.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.52 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     657.72 ms /     1 runs   (  657.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.90 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     640.74 ms /     1 runs   (  640.74 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1459.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.60 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     652.75 ms /     1 runs   (  652.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2120.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.83 ms /    16 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =     653.18 ms /     1 runs   (  653.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1507.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.65 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     644.45 ms /     1 runs   (  644.45 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1457.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.81 ms /    16 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     638.29 ms /     1 runs   (  638.29 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1450.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.07 ms /    16 tokens (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     704.32 ms /     1 runs   (  704.32 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1519.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.85 ms /    14 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =     658.04 ms /     1 runs   (  658.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1412.08 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.06 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     671.07 ms /     1 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.22 ms /    16 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     646.49 ms /     1 runs   (  646.49 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1482.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.35 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     658.78 ms /     1 runs   (  658.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.64 ms /    15 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     662.73 ms /     1 runs   (  662.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1441.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.48 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     663.13 ms /     1 runs   (  663.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.79 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     690.64 ms /     1 runs   (  690.64 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1514.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.05 ms /    16 tokens (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     668.08 ms /     1 runs   (  668.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.05 ms /    14 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     668.60 ms /     1 runs   (  668.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1397.52 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.48 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     658.61 ms /     1 runs   (  658.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.14 ms /    15 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     696.81 ms /     1 runs   (  696.81 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1468.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.16 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     660.64 ms /     1 runs   (  660.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.25 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     645.30 ms /     1 runs   (  645.30 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1474.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.35 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     645.50 ms /     1 runs   (  645.50 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.48 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     645.98 ms /     1 runs   (  645.98 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.81 ms /    15 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     645.80 ms /     1 runs   (  645.80 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1418.31 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.24 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     643.73 ms /     1 runs   (  643.73 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.08 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     647.65 ms /     1 runs   (  647.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.31 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     651.69 ms /     1 runs   (  651.69 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.57 ms /    16 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     656.00 ms /     1 runs   (  656.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.84 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     644.88 ms /     1 runs   (  644.88 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.67 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     643.12 ms /     1 runs   (  643.12 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1474.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.22 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     652.19 ms /     1 runs   (  652.19 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.05 ms /    16 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     657.23 ms /     1 runs   (  657.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1500.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.23 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     651.04 ms /     1 runs   (  651.04 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.68 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     657.23 ms /     1 runs   (  657.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.96 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     666.72 ms /     1 runs   (  666.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1507.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.79 ms /    15 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     657.62 ms /     1 runs   (  657.62 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1445.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.92 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     661.49 ms /     1 runs   (  661.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.96 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     689.55 ms /     1 runs   (  689.55 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1513.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.09 ms /    16 tokens (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     668.30 ms /     1 runs   (  668.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.87 ms /    15 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     646.45 ms /     1 runs   (  646.45 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1425.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.31 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     654.67 ms /     1 runs   (  654.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1482.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.22 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     648.10 ms /     1 runs   (  648.10 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.52 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     658.78 ms /     1 runs   (  658.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1484.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.70 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     663.66 ms /     1 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.54 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     659.65 ms /     1 runs   (  659.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.75 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     673.49 ms /     1 runs   (  673.49 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.38 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     660.85 ms /     1 runs   (  660.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.80 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     663.07 ms /     1 runs   (  663.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.51 ms /    16 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     657.76 ms /     1 runs   (  657.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1469.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.63 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     676.62 ms /     1 runs   (  676.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.89 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     662.24 ms /     1 runs   (  662.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.64 ms /    15 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =     664.82 ms /     1 runs   (  664.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1466.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.84 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     654.82 ms /     1 runs   (  654.82 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     742.20 ms /    14 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     658.22 ms /     1 runs   (  658.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1405.94 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.64 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     647.00 ms /     1 runs   (  647.00 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1469.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.93 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     652.83 ms /     1 runs   (  652.83 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.76 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     643.56 ms /     1 runs   (  643.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.97 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     660.60 ms /     1 runs   (  660.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.30 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     667.84 ms /     1 runs   (  667.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1511.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.65 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     653.38 ms /     1 runs   (  653.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.13 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     649.26 ms /     1 runs   (  649.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.38 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     643.23 ms /     1 runs   (  643.23 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.69 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     645.64 ms /     1 runs   (  645.64 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.73 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     663.60 ms /     1 runs   (  663.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.18 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     673.30 ms /     1 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.43 ms /    16 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     658.99 ms /     1 runs   (  658.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.30 ms /    15 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     657.63 ms /     1 runs   (  657.63 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1430.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.79 ms /    15 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     663.12 ms /     1 runs   (  663.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1438.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.45 ms /    15 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     647.74 ms /     1 runs   (  647.74 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1436.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.09 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     651.43 ms /     1 runs   (  651.43 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.24 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     646.76 ms /     1 runs   (  646.76 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.58 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     658.82 ms /     1 runs   (  658.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.01 ms /    16 tokens (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     676.54 ms /     1 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     896.05 ms /    16 tokens (   56.00 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =     670.82 ms /     1 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1572.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.34 ms /    16 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     665.48 ms /     1 runs   (  665.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1510.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.60 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     658.42 ms /     1 runs   (  658.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.67 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     663.33 ms /     1 runs   (  663.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1503.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.35 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     646.56 ms /     1 runs   (  646.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1476.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.31 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     650.49 ms /     1 runs   (  650.49 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.09 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     669.85 ms /     1 runs   (  669.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.43 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     673.13 ms /     1 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.47 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     647.96 ms /     1 runs   (  647.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.80 ms /    15 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     665.08 ms /     1 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1449.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.74 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     658.58 ms /     1 runs   (  658.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.19 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     659.01 ms /     1 runs   (  659.01 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.43 ms /    16 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     674.11 ms /     1 runs   (  674.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1532.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.55 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     672.10 ms /     1 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.21 ms /    16 tokens (   50.83 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     649.77 ms /     1 runs   (  649.77 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.25 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     649.21 ms /     1 runs   (  649.21 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.96 ms /    16 tokens (   58.19 ms per token,    17.19 tokens per second)\n",
      "llama_print_timings:        eval time =     649.91 ms /     1 runs   (  649.91 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1585.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.62 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     688.98 ms /     1 runs   (  688.98 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1528.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.36 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     645.12 ms /     1 runs   (  645.12 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1478.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.46 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     661.55 ms /     1 runs   (  661.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.98 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     651.41 ms /     1 runs   (  651.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.30 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     686.38 ms /     1 runs   (  686.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.01 ms /    15 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     685.39 ms /     1 runs   (  685.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1478.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.64 ms /    15 tokens (   54.51 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =     658.65 ms /     1 runs   (  658.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.03 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     644.11 ms /     1 runs   (  644.11 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1475.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2109.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.75 ms /    14 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     646.75 ms /     1 runs   (  646.75 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1373.81 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.00 ms /    16 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =     668.67 ms /     1 runs   (  668.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1535.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2107.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.98 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     651.93 ms /     1 runs   (  651.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.10 ms /    15 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     668.77 ms /     1 runs   (  668.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1443.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.05 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     661.90 ms /     1 runs   (  661.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.82 ms /    15 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     660.51 ms /     1 runs   (  660.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1428.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.00 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     668.59 ms /     1 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.46 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     648.59 ms /     1 runs   (  648.59 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.15 ms /    16 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     650.45 ms /     1 runs   (  650.45 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.86 ms /    14 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     655.09 ms /     1 runs   (  655.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1385.30 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.71 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     659.12 ms /     1 runs   (  659.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1434.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.58 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     700.17 ms /     1 runs   (  700.17 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1520.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.28 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     657.28 ms /     1 runs   (  657.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.31 ms /    15 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     672.67 ms /     1 runs   (  672.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1447.31 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.94 ms /    15 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     676.15 ms /     1 runs   (  676.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1453.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     2 runs   (    0.96 ms per token,  1042.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.29 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     687.38 ms /     1 runs   (  687.38 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1515.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.92 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     667.72 ms /     1 runs   (  667.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1506.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.11 ms /    15 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     649.62 ms /     1 runs   (  649.62 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1424.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.37 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     654.87 ms /     1 runs   (  654.87 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2183.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.23 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     670.83 ms /     1 runs   (  670.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.13 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     657.14 ms /     1 runs   (  657.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.70 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     678.66 ms /     1 runs   (  678.66 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1498.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.03 ms /    15 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     679.99 ms /     1 runs   (  679.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1462.18 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.22 ms /    15 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     656.49 ms /     1 runs   (  656.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1425.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.20 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     654.88 ms /     1 runs   (  654.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.34 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     663.13 ms /     1 runs   (  663.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.66 ms /    15 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     655.01 ms /     1 runs   (  655.01 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1440.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.68 ms /    15 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     652.62 ms /     1 runs   (  652.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1430.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.15 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     656.59 ms /     1 runs   (  656.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.82 ms /    16 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     644.56 ms /     1 runs   (  644.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1472.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.71 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     720.23 ms /     1 runs   (  720.23 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1538.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.06 ms /    15 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     645.41 ms /     1 runs   (  645.41 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1417.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.44 ms /    16 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     654.72 ms /     1 runs   (  654.72 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1487.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.79 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     683.73 ms /     1 runs   (  683.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1504.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.97 ms /    15 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     674.93 ms /     1 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1462.31 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.39 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     651.06 ms /     1 runs   (  651.06 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.01 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     655.15 ms /     1 runs   (  655.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1489.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.16 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     673.63 ms /     1 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1500.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.45 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     659.28 ms /     1 runs   (  659.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.64 ms /    16 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     662.80 ms /     1 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1509.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.07 ms /    15 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     665.49 ms /     1 runs   (  665.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1458.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.04 ms /    16 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     673.95 ms /     1 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1486.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.41 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     671.94 ms /     1 runs   (  671.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1489.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.22 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     667.57 ms /     1 runs   (  667.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.16 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     651.35 ms /     1 runs   (  651.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1485.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.26 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     646.60 ms /     1 runs   (  646.60 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1418.86 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.37 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     658.69 ms /     1 runs   (  658.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.06 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     652.42 ms /     1 runs   (  652.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.94 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     648.05 ms /     1 runs   (  648.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1417.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.70 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.06 ms /     1 runs   (  659.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.46 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     646.07 ms /     1 runs   (  646.07 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1469.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.38 ms /    15 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =     668.04 ms /     1 runs   (  668.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1466.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.74 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     687.36 ms /     1 runs   (  687.36 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1507.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.39 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     662.88 ms /     1 runs   (  662.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.33 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     669.26 ms /     1 runs   (  669.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1501.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.35 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     667.31 ms /     1 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1444.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.91 ms /    15 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     659.64 ms /     1 runs   (  659.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1442.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.62 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     674.30 ms /     1 runs   (  674.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1445.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.05 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     702.48 ms /     1 runs   (  702.48 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1534.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.99 ms /    16 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     707.66 ms /     1 runs   (  707.66 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1520.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.75 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     672.49 ms /     1 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1511.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.07 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     662.90 ms /     1 runs   (  662.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.21 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     654.30 ms /     1 runs   (  654.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.54 ms /    16 tokens (   51.72 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     670.23 ms /     1 runs   (  670.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.60 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     680.50 ms /     1 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1497.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.01 ms /    15 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     667.99 ms /     1 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1437.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.88 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     659.70 ms /     1 runs   (  659.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.32 ms /    16 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     677.19 ms /     1 runs   (  677.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1488.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.71 ms /    16 tokens (   50.54 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     661.60 ms /     1 runs   (  661.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.12 ms /    16 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     662.79 ms /     1 runs   (  662.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.10 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     659.31 ms /     1 runs   (  659.31 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     855.76 ms /    16 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =     691.47 ms /     1 runs   (  691.47 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1552.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.64 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     663.32 ms /     1 runs   (  663.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1500.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.13 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     656.79 ms /     1 runs   (  656.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.31 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     651.79 ms /     1 runs   (  651.79 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.65 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     689.03 ms /     1 runs   (  689.03 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1524.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.12 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     658.32 ms /     1 runs   (  658.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.83 ms /    16 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     659.47 ms /     1 runs   (  659.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1510.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.05 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     667.36 ms /     1 runs   (  667.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.00 ms /    15 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     681.93 ms /     1 runs   (  681.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1460.80 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.63 ms /    15 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     657.03 ms /     1 runs   (  657.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1441.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.29 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     643.40 ms /     1 runs   (  643.40 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1420.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.14 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     672.72 ms /     1 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1501.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.17 ms /    16 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     647.88 ms /     1 runs   (  647.88 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.99 ms /    16 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     653.92 ms /     1 runs   (  653.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.82 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     667.70 ms /     1 runs   (  667.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.44 ms /    15 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     653.78 ms /     1 runs   (  653.78 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1435.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.66 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     685.46 ms /     1 runs   (  685.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1500.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.05 ms /    16 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     701.64 ms /     1 runs   (  701.64 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1514.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.80 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     694.33 ms /     1 runs   (  694.33 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1520.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.37 ms /    16 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     674.82 ms /     1 runs   (  674.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1515.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.23 ms /    15 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     664.64 ms /     1 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1447.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.22 ms /    16 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =     664.61 ms /     1 runs   (  664.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1521.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.75 ms /    15 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     644.12 ms /     1 runs   (  644.12 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1418.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.91 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     644.71 ms /     1 runs   (  644.71 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.10 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     666.90 ms /     1 runs   (  666.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.96 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     651.19 ms /     1 runs   (  651.19 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.68 ms /    14 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     652.09 ms /     1 runs   (  652.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1383.44 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.02 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     673.44 ms /     1 runs   (  673.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.59 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     642.19 ms /     1 runs   (  642.19 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1465.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.34 ms /    15 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     664.78 ms /     1 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1451.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.36 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     658.91 ms /     1 runs   (  658.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.10 ms /    16 tokens (   51.51 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     654.56 ms /     1 runs   (  654.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.20 ms /    16 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     671.54 ms /     1 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1525.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.75 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     658.54 ms /     1 runs   (  658.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.46 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     672.10 ms /     1 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.12 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     655.63 ms /     1 runs   (  655.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.17 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     657.25 ms /     1 runs   (  657.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.99 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     640.05 ms /     1 runs   (  640.05 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1478.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.11 ms /    16 tokens (   51.69 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     653.83 ms /     1 runs   (  653.83 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1486.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.88 ms /    15 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     650.73 ms /     1 runs   (  650.73 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1429.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.08 ms /    15 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     664.42 ms /     1 runs   (  664.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1446.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.75 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     636.62 ms /     1 runs   (  636.62 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1467.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.93 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     640.95 ms /     1 runs   (  640.95 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1456.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.47 ms per token,  2111.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.55 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     654.94 ms /     1 runs   (  654.94 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.54 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     651.83 ms /     1 runs   (  651.83 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1465.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.23 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     641.99 ms /     1 runs   (  641.99 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.17 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     673.80 ms /     1 runs   (  673.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1507.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.69 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     653.88 ms /     1 runs   (  653.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1475.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.64 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     658.71 ms /     1 runs   (  658.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.06 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     645.20 ms /     1 runs   (  645.20 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.11 ms /    15 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     653.63 ms /     1 runs   (  653.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1444.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.42 ms /    15 tokens (   51.69 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     665.71 ms /     1 runs   (  665.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1446.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.00 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     668.16 ms /     1 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1502.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.70 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     651.53 ms /     1 runs   (  651.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.39 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     661.96 ms /     1 runs   (  661.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.08 ms /    16 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     649.77 ms /     1 runs   (  649.77 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.89 ms /    15 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     648.28 ms /     1 runs   (  648.28 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1435.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.37 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     668.03 ms /     1 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.68 ms /    16 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =     666.24 ms /     1 runs   (  666.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1525.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2169.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.32 ms /    16 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     660.14 ms /     1 runs   (  660.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1472.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.41 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     682.29 ms /     1 runs   (  682.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1496.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.75 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     643.15 ms /     1 runs   (  643.15 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1456.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.26 ms /    15 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     642.80 ms /     1 runs   (  642.80 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1423.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.70 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     718.82 ms /     1 runs   (  718.82 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1492.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2157.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.80 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     682.04 ms /     1 runs   (  682.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1509.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.46 ms /    16 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     648.64 ms /     1 runs   (  648.64 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1489.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.96 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     644.45 ms /     1 runs   (  644.45 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.65 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     651.35 ms /     1 runs   (  651.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.20 ms /    15 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     665.40 ms /     1 runs   (  665.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1462.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.72 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     663.42 ms /     1 runs   (  663.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.46 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     697.48 ms /     1 runs   (  697.48 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1511.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.38 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     665.76 ms /     1 runs   (  665.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.43 ms /    15 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     655.84 ms /     1 runs   (  655.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1434.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.55 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     665.43 ms /     1 runs   (  665.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.05 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     718.98 ms /     1 runs   (  718.98 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1545.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.18 ms /    14 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     648.59 ms /     1 runs   (  648.59 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1378.93 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.89 ms /    16 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     637.87 ms /     1 runs   (  637.87 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1449.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.40 ms /    14 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     655.41 ms /     1 runs   (  655.41 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1387.40 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.10 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     668.94 ms /     1 runs   (  668.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1483.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.97 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     667.07 ms /     1 runs   (  667.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1484.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.58 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     664.56 ms /     1 runs   (  664.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.95 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     654.30 ms /     1 runs   (  654.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     874.38 ms /    16 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =     776.25 ms /     1 runs   (  776.25 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =    1656.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.91 ms /    15 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     704.63 ms /     1 runs   (  704.63 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1477.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.18 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     678.25 ms /     1 runs   (  678.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1494.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.19 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     679.84 ms /     1 runs   (  679.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1498.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.34 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     713.85 ms /     1 runs   (  713.85 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1531.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.35 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     660.14 ms /     1 runs   (  660.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1438.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.53 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     680.38 ms /     1 runs   (  680.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1497.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.65 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     658.11 ms /     1 runs   (  658.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.05 ms /    16 tokens (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     670.60 ms /     1 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.23 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     668.04 ms /     1 runs   (  668.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1444.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.02 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     686.49 ms /     1 runs   (  686.49 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1510.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.91 ms /    16 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     672.48 ms /     1 runs   (  672.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1515.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.17 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     657.54 ms /     1 runs   (  657.54 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.60 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     649.09 ms /     1 runs   (  649.09 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1486.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.04 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     661.24 ms /     1 runs   (  661.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.55 ms /    15 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     650.59 ms /     1 runs   (  650.59 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1421.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.16 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     700.22 ms /     1 runs   (  700.22 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1526.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.55 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     676.93 ms /     1 runs   (  676.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.25 ms /    15 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     654.12 ms /     1 runs   (  654.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1429.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.88 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     659.67 ms /     1 runs   (  659.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.52 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     652.19 ms /     1 runs   (  652.19 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.72 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     660.80 ms /     1 runs   (  660.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.83 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     677.88 ms /     1 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.43 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     653.80 ms /     1 runs   (  653.80 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2134.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.70 ms /    15 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =     683.92 ms /     1 runs   (  683.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1498.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     868.57 ms /    16 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =     722.59 ms /     1 runs   (  722.59 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1596.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.01 ms /    15 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     671.19 ms /     1 runs   (  671.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1444.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.94 ms /    16 tokens (   51.75 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     660.92 ms /     1 runs   (  660.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.22 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     647.81 ms /     1 runs   (  647.81 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.97 ms /    15 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     647.39 ms /     1 runs   (  647.39 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1419.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.47 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     729.58 ms /     1 runs   (  729.58 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1566.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.16 ms /    16 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     657.93 ms /     1 runs   (  657.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1513.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.10 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     659.23 ms /     1 runs   (  659.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.52 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     665.19 ms /     1 runs   (  665.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.76 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     688.64 ms /     1 runs   (  688.64 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1520.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.94 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     683.84 ms /     1 runs   (  683.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1500.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     871.11 ms /    16 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =     670.87 ms /     1 runs   (  670.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1547.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.86 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     648.02 ms /     1 runs   (  648.02 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.92 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     641.69 ms /     1 runs   (  641.69 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1474.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.57 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     671.01 ms /     1 runs   (  671.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.15 ms /    15 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     652.46 ms /     1 runs   (  652.46 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1430.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.12 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     657.00 ms /     1 runs   (  657.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.49 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     667.92 ms /     1 runs   (  667.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.79 ms /    15 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     667.81 ms /     1 runs   (  667.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1452.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.39 ms /    15 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     669.20 ms /     1 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1441.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.83 ms /    16 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     645.10 ms /     1 runs   (  645.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1491.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.46 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     649.46 ms /     1 runs   (  649.46 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.40 ms /    15 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     646.00 ms /     1 runs   (  646.00 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1416.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.40 ms /    16 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     686.86 ms /     1 runs   (  686.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1507.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.17 ms /    16 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     675.43 ms /     1 runs   (  675.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1499.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.32 ms /    16 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     659.94 ms /     1 runs   (  659.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.37 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     643.93 ms /     1 runs   (  643.93 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.16 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     650.74 ms /     1 runs   (  650.74 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.74 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     646.35 ms /     1 runs   (  646.35 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.11 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     660.68 ms /     1 runs   (  660.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.87 ms /    14 tokens (   53.78 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =     639.40 ms /     1 runs   (  639.40 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1398.19 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.12 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     650.86 ms /     1 runs   (  650.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.66 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     640.72 ms /     1 runs   (  640.72 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1468.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.09 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     652.27 ms /     1 runs   (  652.27 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.48 ms per token,  2066.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.54 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     653.42 ms /     1 runs   (  653.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     869.40 ms /    16 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =     681.42 ms /     1 runs   (  681.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1556.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.62 ms /    16 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     651.99 ms /     1 runs   (  651.99 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1464.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.05 ms /    15 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     673.65 ms /     1 runs   (  673.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1442.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.50 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     667.43 ms /     1 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.62 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     675.50 ms /     1 runs   (  675.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.01 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     669.75 ms /     1 runs   (  669.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.74 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     716.01 ms /     1 runs   (  716.01 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1529.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.70 ms /    14 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     671.61 ms /     1 runs   (  671.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1409.74 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.95 ms /    15 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     707.25 ms /     1 runs   (  707.25 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1482.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.38 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     750.56 ms /     1 runs   (  750.56 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =    1572.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.19 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     647.08 ms /     1 runs   (  647.08 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.72 ms /    16 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     671.05 ms /     1 runs   (  671.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1518.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.40 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     646.33 ms /     1 runs   (  646.33 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1469.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.02 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     672.72 ms /     1 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.94 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     674.35 ms /     1 runs   (  674.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.06 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     658.26 ms /     1 runs   (  658.26 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.14 ms /    14 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     669.79 ms /     1 runs   (  669.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1402.38 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.92 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     667.79 ms /     1 runs   (  667.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.86 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     647.36 ms /     1 runs   (  647.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.33 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     651.95 ms /     1 runs   (  651.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1465.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.90 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     654.45 ms /     1 runs   (  654.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.68 ms /    14 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =     680.97 ms /     1 runs   (  680.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1426.03 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.30 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     661.70 ms /     1 runs   (  661.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.13 ms /    16 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     658.03 ms /     1 runs   (  658.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.30 ms /    15 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     674.09 ms /     1 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1451.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.06 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     644.32 ms /     1 runs   (  644.32 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.14 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     658.20 ms /     1 runs   (  658.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.88 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     643.27 ms /     1 runs   (  643.27 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.01 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     665.51 ms /     1 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.64 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     665.57 ms /     1 runs   (  665.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1483.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.66 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     693.89 ms /     1 runs   (  693.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1511.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.92 ms /    16 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     666.27 ms /     1 runs   (  666.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1477.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.45 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     645.99 ms /     1 runs   (  645.99 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.53 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     666.71 ms /     1 runs   (  666.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.90 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     650.95 ms /     1 runs   (  650.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.08 ms /    15 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     657.52 ms /     1 runs   (  657.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1430.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.64 ms /    16 tokens (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     661.80 ms /     1 runs   (  661.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.30 ms /    15 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     679.25 ms /     1 runs   (  679.25 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1471.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.91 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     675.07 ms /     1 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.03 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     677.47 ms /     1 runs   (  677.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1492.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.09 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     672.42 ms /     1 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.48 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     659.68 ms /     1 runs   (  659.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.21 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     664.10 ms /     1 runs   (  664.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1436.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.93 ms /    16 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     673.94 ms /     1 runs   (  673.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1510.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.00 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     666.15 ms /     1 runs   (  666.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1436.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.72 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     671.05 ms /     1 runs   (  671.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.44 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     701.35 ms /     1 runs   (  701.35 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1516.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.67 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     704.05 ms /     1 runs   (  704.05 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1520.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.70 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     673.92 ms /     1 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1489.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.06 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     709.40 ms /     1 runs   (  709.40 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1529.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.27 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     675.07 ms /     1 runs   (  675.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1490.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.99 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     662.71 ms /     1 runs   (  662.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.51 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     664.15 ms /     1 runs   (  664.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.72 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     656.55 ms /     1 runs   (  656.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.46 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     655.42 ms /     1 runs   (  655.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.96 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     697.59 ms /     1 runs   (  697.59 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1530.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.28 ms /    16 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     657.27 ms /     1 runs   (  657.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1471.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     794.74 ms /    15 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =     658.44 ms /     1 runs   (  658.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1458.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.62 ms /    15 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     668.85 ms /     1 runs   (  668.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1443.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.03 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     646.63 ms /     1 runs   (  646.63 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.74 ms /    16 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     643.81 ms /     1 runs   (  643.81 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.22 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     673.69 ms /     1 runs   (  673.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.73 ms /    16 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     657.71 ms /     1 runs   (  657.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.95 ms /    16 tokens (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     658.39 ms /     1 runs   (  658.39 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.71 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.23 ms /     1 runs   (  652.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.14 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     664.10 ms /     1 runs   (  664.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.55 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     648.74 ms /     1 runs   (  648.74 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.25 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     627.17 ms /     1 runs   (  627.17 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1444.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.77 ms /    16 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     671.31 ms /     1 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1515.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.98 ms /    16 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     657.72 ms /     1 runs   (  657.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1470.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.27 ms /    15 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =     679.60 ms /     1 runs   (  679.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1491.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.27 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     681.67 ms /     1 runs   (  681.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1507.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.86 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     644.46 ms /     1 runs   (  644.46 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.54 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     660.96 ms /     1 runs   (  660.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2132.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.94 ms /    16 tokens (   51.75 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     661.39 ms /     1 runs   (  661.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.53 ms /    16 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     652.37 ms /     1 runs   (  652.37 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1464.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.57 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     644.94 ms /     1 runs   (  644.94 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.97 ms /    16 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     684.20 ms /     1 runs   (  684.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1526.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.62 ms /    16 tokens (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     651.89 ms /     1 runs   (  651.89 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1464.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.08 ms /    15 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     663.52 ms /     1 runs   (  663.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1435.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.74 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     656.50 ms /     1 runs   (  656.50 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.48 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     638.04 ms /     1 runs   (  638.04 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1459.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.82 ms /    15 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     653.84 ms /     1 runs   (  653.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1444.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.95 ms /    14 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     655.22 ms /     1 runs   (  655.22 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1381.23 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.38 ms /    16 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     648.24 ms /     1 runs   (  648.24 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1490.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.27 ms /    16 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     669.98 ms /     1 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1507.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.85 ms /    12 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     676.05 ms /     1 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1316.08 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.84 ms /    14 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     665.76 ms /     1 runs   (  665.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1403.44 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2087.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.12 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     672.10 ms /     1 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1501.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.00 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     670.45 ms /     1 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2162.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.84 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     654.65 ms /     1 runs   (  654.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1429.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.73 ms /    15 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     648.44 ms /     1 runs   (  648.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1440.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     737.22 ms /    14 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     660.64 ms /     1 runs   (  660.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1403.18 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.03 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     643.62 ms /     1 runs   (  643.62 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1471.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.49 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     686.54 ms /     1 runs   (  686.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1510.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2139.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.13 ms /    16 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     664.02 ms /     1 runs   (  664.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.37 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     660.99 ms /     1 runs   (  660.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     879.55 ms /    16 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =     678.80 ms /     1 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1563.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.71 ms /    16 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     657.22 ms /     1 runs   (  657.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1504.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.41 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     649.27 ms /     1 runs   (  649.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.19 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     672.74 ms /     1 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1489.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.60 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     669.65 ms /     1 runs   (  669.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     956.03 ms /    16 tokens (   59.75 ms per token,    16.74 tokens per second)\n",
      "llama_print_timings:        eval time =     653.59 ms /     1 runs   (  653.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1615.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.83 ms /    16 tokens (   51.11 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     654.47 ms /     1 runs   (  654.47 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.60 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     646.07 ms /     1 runs   (  646.07 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.75 ms /    16 tokens (   50.67 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     630.09 ms /     1 runs   (  630.09 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1446.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.91 ms /    15 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     652.32 ms /     1 runs   (  652.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1422.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.08 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     650.15 ms /     1 runs   (  650.15 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.96 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     689.92 ms /     1 runs   (  689.92 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1505.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.26 ms /    16 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =     648.34 ms /     1 runs   (  648.34 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1459.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.27 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     646.08 ms /     1 runs   (  646.08 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1469.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.25 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     652.72 ms /     1 runs   (  652.72 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.61 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     678.45 ms /     1 runs   (  678.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1505.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.83 ms /    16 tokens (   51.61 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     651.09 ms /     1 runs   (  651.09 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.28 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     646.91 ms /     1 runs   (  646.91 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1419.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.44 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     679.14 ms /     1 runs   (  679.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1453.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.46 ms /    16 tokens (   51.22 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     650.61 ms /     1 runs   (  650.61 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.86 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     644.01 ms /     1 runs   (  644.01 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1482.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.95 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     653.42 ms /     1 runs   (  653.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.95 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     668.81 ms /     1 runs   (  668.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.70 ms /    14 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     666.94 ms /     1 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1403.89 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.30 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     665.69 ms /     1 runs   (  665.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.21 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     657.61 ms /     1 runs   (  657.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.51 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     648.08 ms /     1 runs   (  648.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1462.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.65 ms /    15 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     663.52 ms /     1 runs   (  663.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1437.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.82 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     650.73 ms /     1 runs   (  650.73 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1486.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2076.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.34 ms /    16 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     670.13 ms /     1 runs   (  670.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1513.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.73 ms /    15 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     650.89 ms /     1 runs   (  650.89 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1423.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.55 ms /    15 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     646.85 ms /     1 runs   (  646.85 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1415.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.30 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     674.04 ms /     1 runs   (  674.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.99 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     657.09 ms /     1 runs   (  657.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1494.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.00 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     677.28 ms /     1 runs   (  677.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1500.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.21 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     657.38 ms /     1 runs   (  657.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.74 ms /    16 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     647.13 ms /     1 runs   (  647.13 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1489.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.34 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     652.40 ms /     1 runs   (  652.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.47 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     662.19 ms /     1 runs   (  662.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.54 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     652.97 ms /     1 runs   (  652.97 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.09 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     659.38 ms /     1 runs   (  659.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.02 ms /    15 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     672.82 ms /     1 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1464.23 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.82 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     646.33 ms /     1 runs   (  646.33 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1476.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.90 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     649.70 ms /     1 runs   (  649.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.15 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     677.08 ms /     1 runs   (  677.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.52 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     660.76 ms /     1 runs   (  660.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     928.66 ms /    16 tokens (   58.04 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =     655.02 ms /     1 runs   (  655.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1589.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.32 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     663.74 ms /     1 runs   (  663.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1498.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.42 ms /    15 tokens (   53.09 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =     682.91 ms /     1 runs   (  682.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1484.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.12 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     656.60 ms /     1 runs   (  656.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.48 ms /    15 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     658.93 ms /     1 runs   (  658.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1431.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.28 ms /    15 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     647.86 ms /     1 runs   (  647.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1422.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.78 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     652.02 ms /     1 runs   (  652.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2155.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.31 ms /    15 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     681.49 ms /     1 runs   (  681.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1451.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     2 runs   (    0.52 ms per token,  1926.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.13 ms /    16 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_print_timings:        eval time =     719.83 ms /     1 runs   (  719.83 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1530.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.63 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     658.39 ms /     1 runs   (  658.39 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.78 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     675.83 ms /     1 runs   (  675.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1488.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.58 ms /    16 tokens (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     668.85 ms /     1 runs   (  668.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.27 ms /    16 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     654.76 ms /     1 runs   (  654.76 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1496.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.23 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     660.58 ms /     1 runs   (  660.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.22 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     650.41 ms /     1 runs   (  650.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1481.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.57 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     676.64 ms /     1 runs   (  676.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.31 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     642.95 ms /     1 runs   (  642.95 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1458.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.28 ms /    16 tokens (   50.52 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     701.48 ms /     1 runs   (  701.48 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1515.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.87 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     630.33 ms /     1 runs   (  630.33 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1447.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.92 ms /    15 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     660.81 ms /     1 runs   (  660.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1430.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.47 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     658.30 ms /     1 runs   (  658.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.52 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.56 ms /     1 runs   (  652.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.87 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     662.10 ms /     1 runs   (  662.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.33 ms /    14 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     684.25 ms /     1 runs   (  684.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1409.19 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.67 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     727.54 ms /     1 runs   (  727.54 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1547.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.20 ms /    16 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     738.66 ms /     1 runs   (  738.66 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =    1577.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     860.75 ms /    16 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =     676.09 ms /     1 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1542.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.21 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     647.67 ms /     1 runs   (  647.67 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.24 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     672.90 ms /     1 runs   (  672.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.84 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     657.36 ms /     1 runs   (  657.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1496.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.78 ms /    14 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     663.91 ms /     1 runs   (  663.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1399.27 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.84 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     681.71 ms /     1 runs   (  681.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1500.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.94 ms /    16 tokens (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     676.19 ms /     1 runs   (  676.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1489.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.45 ms /    16 tokens (   50.47 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     648.57 ms /     1 runs   (  648.57 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.26 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     647.60 ms /     1 runs   (  647.60 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.43 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     671.14 ms /     1 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.00 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     669.19 ms /     1 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.57 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     675.99 ms /     1 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1363.15 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.99 ms /    15 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     664.50 ms /     1 runs   (  664.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1457.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.17 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     674.50 ms /     1 runs   (  674.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1487.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.24 ms /    16 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     669.82 ms /     1 runs   (  669.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1510.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.17 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     691.00 ms /     1 runs   (  691.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1504.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.34 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     659.49 ms /     1 runs   (  659.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.20 ms /    16 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     646.04 ms /     1 runs   (  646.04 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1469.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     870.72 ms /    16 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =     663.87 ms /     1 runs   (  663.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1540.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.79 ms /    16 tokens (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     656.04 ms /     1 runs   (  656.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.97 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     661.70 ms /     1 runs   (  661.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.19 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     652.90 ms /     1 runs   (  652.90 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1468.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.18 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     671.99 ms /     1 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.92 ms /    16 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     649.01 ms /     1 runs   (  649.01 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1495.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.21 ms /    16 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     680.95 ms /     1 runs   (  680.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1518.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.60 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     639.28 ms /     1 runs   (  639.28 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1471.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.21 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     685.20 ms /     1 runs   (  685.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1500.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.72 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     661.29 ms /     1 runs   (  661.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.43 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     736.66 ms /     1 runs   (  736.66 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1556.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.06 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     648.82 ms /     1 runs   (  648.82 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.31 ms /    15 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     654.85 ms /     1 runs   (  654.85 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1432.60 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.17 ms /    15 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     648.98 ms /     1 runs   (  648.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1435.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.08 ms /    14 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     657.68 ms /     1 runs   (  657.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1390.92 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.01 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     690.55 ms /     1 runs   (  690.55 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1506.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.88 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     660.29 ms /     1 runs   (  660.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.11 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     660.00 ms /     1 runs   (  660.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.92 ms /    16 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     658.12 ms /     1 runs   (  658.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.83 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     658.71 ms /     1 runs   (  658.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1345.83 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.34 ms /    15 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     652.75 ms /     1 runs   (  652.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1433.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.18 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     648.41 ms /     1 runs   (  648.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.54 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     658.12 ms /     1 runs   (  658.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.79 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     660.36 ms /     1 runs   (  660.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.32 ms /    16 tokens (   51.52 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     659.40 ms /     1 runs   (  659.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.61 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     645.32 ms /     1 runs   (  645.32 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1484.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.03 ms /    16 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     666.53 ms /     1 runs   (  666.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1501.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.05 ms /    16 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     661.27 ms /     1 runs   (  661.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.28 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     649.87 ms /     1 runs   (  649.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.94 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     667.17 ms /     1 runs   (  667.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.29 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     667.55 ms /     1 runs   (  667.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.09 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     647.42 ms /     1 runs   (  647.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.61 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     695.02 ms /     1 runs   (  695.02 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1522.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.97 ms /    15 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     660.11 ms /     1 runs   (  660.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1438.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.04 ms /    16 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     662.33 ms /     1 runs   (  662.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.68 ms /    15 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     669.32 ms /     1 runs   (  669.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1448.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.99 ms /    16 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     696.86 ms /     1 runs   (  696.86 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1533.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.23 ms /    15 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     664.06 ms /     1 runs   (  664.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1446.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.42 ms /    16 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     676.73 ms /     1 runs   (  676.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1516.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2143.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.05 ms /    15 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     661.21 ms /     1 runs   (  661.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1456.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.53 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     646.39 ms /     1 runs   (  646.39 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.51 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.88 ms /     1 runs   (  652.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.96 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     648.32 ms /     1 runs   (  648.32 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.03 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     653.10 ms /     1 runs   (  653.10 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.46 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     649.31 ms /     1 runs   (  649.31 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.79 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     652.28 ms /     1 runs   (  652.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1464.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.04 ms /    16 tokens (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     645.99 ms /     1 runs   (  645.99 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1458.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.07 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     708.98 ms /     1 runs   (  708.98 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1480.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.94 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     660.92 ms /     1 runs   (  660.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.21 ms /    15 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =     655.11 ms /     1 runs   (  655.11 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.19 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     693.04 ms /     1 runs   (  693.04 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1510.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.08 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     662.15 ms /     1 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.01 ms /    15 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     684.99 ms /     1 runs   (  684.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1453.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.28 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     660.29 ms /     1 runs   (  660.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1473.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.96 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     668.14 ms /     1 runs   (  668.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1497.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.47 ms /    15 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     630.46 ms /     1 runs   (  630.46 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =    1405.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.98 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     659.69 ms /     1 runs   (  659.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.76 ms /    16 tokens (   50.98 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     693.50 ms /     1 runs   (  693.50 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1515.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.07 ms /    16 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =     665.73 ms /     1 runs   (  665.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1532.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.97 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     641.50 ms /     1 runs   (  641.50 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1470.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.10 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     649.10 ms /     1 runs   (  649.10 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.16 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     655.13 ms /     1 runs   (  655.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.84 ms /    16 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     641.00 ms /     1 runs   (  641.00 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1470.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.89 ms /    15 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     659.10 ms /     1 runs   (  659.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1438.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.50 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     657.20 ms /     1 runs   (  657.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1469.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.56 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     663.61 ms /     1 runs   (  663.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.51 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     657.04 ms /     1 runs   (  657.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.12 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     676.16 ms /     1 runs   (  676.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.53 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     656.95 ms /     1 runs   (  656.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.38 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     675.30 ms /     1 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.80 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     646.89 ms /     1 runs   (  646.89 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.70 ms /    15 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     657.86 ms /     1 runs   (  657.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1434.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.66 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     696.22 ms /     1 runs   (  696.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1515.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.35 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     645.18 ms /     1 runs   (  645.18 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.47 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     685.40 ms /     1 runs   (  685.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1508.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.14 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     657.96 ms /     1 runs   (  657.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.84 ms /    14 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     676.35 ms /     1 runs   (  676.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1407.14 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.31 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     641.69 ms /     1 runs   (  641.69 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1472.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.04 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     678.69 ms /     1 runs   (  678.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1496.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.53 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     652.35 ms /     1 runs   (  652.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1470.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.67 ms /    14 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     650.24 ms /     1 runs   (  650.24 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1379.24 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.55 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     697.02 ms /     1 runs   (  697.02 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1521.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.93 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     652.62 ms /     1 runs   (  652.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.57 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.86 ms /     1 runs   (  659.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.57 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     670.22 ms /     1 runs   (  670.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.34 ms /    16 tokens (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     697.70 ms /     1 runs   (  697.70 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1511.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.49 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     675.62 ms /     1 runs   (  675.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1489.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.69 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.52 ms /     1 runs   (  659.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.76 ms /    15 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     669.20 ms /     1 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1443.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.23 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     660.86 ms /     1 runs   (  660.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     734.97 ms /    14 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     684.37 ms /     1 runs   (  684.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1425.29 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.80 ms /    15 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     658.23 ms /     1 runs   (  658.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1442.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.33 ms /    15 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     648.86 ms /     1 runs   (  648.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1434.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.39 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     661.41 ms /     1 runs   (  661.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.54 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     648.48 ms /     1 runs   (  648.48 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2150.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.78 ms /    15 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     667.47 ms /     1 runs   (  667.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1438.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.29 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     694.19 ms /     1 runs   (  694.19 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1511.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.83 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     650.87 ms /     1 runs   (  650.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.49 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     668.56 ms /     1 runs   (  668.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1499.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.67 ms /    16 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     655.03 ms /     1 runs   (  655.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.86 ms /    16 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     647.98 ms /     1 runs   (  647.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1490.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.32 ms /    16 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     652.10 ms /     1 runs   (  652.10 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1491.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.45 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     632.45 ms /     1 runs   (  632.45 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1450.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.75 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     650.43 ms /     1 runs   (  650.43 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1475.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.17 ms /    16 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     653.04 ms /     1 runs   (  653.04 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.07 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     659.90 ms /     1 runs   (  659.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1480.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.32 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     653.64 ms /     1 runs   (  653.64 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.17 ms /    16 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     656.05 ms /     1 runs   (  656.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1500.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.55 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     650.21 ms /     1 runs   (  650.21 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1470.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.45 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     646.29 ms /     1 runs   (  646.29 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.95 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     668.15 ms /     1 runs   (  668.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.35 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     660.26 ms /     1 runs   (  660.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.40 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     658.22 ms /     1 runs   (  658.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.60 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     662.74 ms /     1 runs   (  662.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1499.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.79 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     649.19 ms /     1 runs   (  649.19 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.73 ms /    15 tokens (   51.72 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     651.48 ms /     1 runs   (  651.48 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1432.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.14 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     654.77 ms /     1 runs   (  654.77 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.30 ms /    16 tokens (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     647.05 ms /     1 runs   (  647.05 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     923.04 ms /    16 tokens (   57.69 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =     651.21 ms /     1 runs   (  651.21 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1579.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.80 ms /    15 tokens (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     653.51 ms /     1 runs   (  653.51 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1422.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.51 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     655.19 ms /     1 runs   (  655.19 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.24 ms /    16 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     646.03 ms /     1 runs   (  646.03 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1458.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.87 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     659.82 ms /     1 runs   (  659.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.94 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     650.96 ms /     1 runs   (  650.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.83 ms /    16 tokens (   53.18 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     639.65 ms /     1 runs   (  639.65 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1495.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.96 ms /    16 tokens (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     642.85 ms /     1 runs   (  642.85 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1457.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.67 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     720.68 ms /     1 runs   (  720.68 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1538.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.13 ms /    14 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     668.58 ms /     1 runs   (  668.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1396.02 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.68 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     644.02 ms /     1 runs   (  644.02 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.20 ms /    15 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     646.77 ms /     1 runs   (  646.77 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1415.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.75 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     665.41 ms /     1 runs   (  665.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.90 ms /    16 tokens (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     645.65 ms /     1 runs   (  645.65 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.60 ms /    16 tokens (   50.72 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     652.97 ms /     1 runs   (  652.97 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.54 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     651.50 ms /     1 runs   (  651.50 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1464.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.59 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     683.22 ms /     1 runs   (  683.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1515.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.84 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     661.49 ms /     1 runs   (  661.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.36 ms /    16 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     647.62 ms /     1 runs   (  647.62 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.92 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     675.34 ms /     1 runs   (  675.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1500.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.62 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     654.39 ms /     1 runs   (  654.39 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1488.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.94 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     676.74 ms /     1 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2173.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.01 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     676.99 ms /     1 runs   (  676.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.64 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     651.25 ms /     1 runs   (  651.25 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.56 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     658.07 ms /     1 runs   (  658.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2176.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.25 ms /    16 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     674.99 ms /     1 runs   (  674.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1531.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.02 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     656.69 ms /     1 runs   (  656.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1493.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.65 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     671.66 ms /     1 runs   (  671.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.98 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     641.40 ms /     1 runs   (  641.40 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1461.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.20 ms /    16 tokens (   51.14 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     659.87 ms /     1 runs   (  659.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.43 ms /    16 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     717.58 ms /     1 runs   (  717.58 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1555.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.28 ms /    15 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     676.34 ms /     1 runs   (  676.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1451.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.26 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     663.92 ms /     1 runs   (  663.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1482.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.13 ms /    14 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     666.85 ms /     1 runs   (  666.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1399.73 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.13 ms /    15 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     666.67 ms /     1 runs   (  666.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1460.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.84 ms /    16 tokens (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     730.97 ms /     1 runs   (  730.97 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1544.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.09 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     673.34 ms /     1 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.70 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     650.66 ms /     1 runs   (  650.66 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1483.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.52 ms /    15 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     650.24 ms /     1 runs   (  650.24 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1419.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.34 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     677.39 ms /     1 runs   (  677.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1512.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.84 ms /    16 tokens (   58.12 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =     668.71 ms /     1 runs   (  668.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1604.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.24 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     660.36 ms /     1 runs   (  660.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.69 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     655.21 ms /     1 runs   (  655.21 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.54 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     644.92 ms /     1 runs   (  644.92 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1471.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2094.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.41 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     664.37 ms /     1 runs   (  664.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.52 ms /    16 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     666.99 ms /     1 runs   (  666.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1481.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.64 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     658.79 ms /     1 runs   (  658.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.56 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     664.79 ms /     1 runs   (  664.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1479.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.83 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     646.85 ms /     1 runs   (  646.85 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.41 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     649.35 ms /     1 runs   (  649.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.65 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     652.24 ms /     1 runs   (  652.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.86 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.33 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     652.57 ms /     1 runs   (  652.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1486.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.88 ms /    15 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     645.61 ms /     1 runs   (  645.61 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1439.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.02 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     651.97 ms /     1 runs   (  651.97 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1473.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.68 ms /    16 tokens (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     650.28 ms /     1 runs   (  650.28 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.97 ms /    15 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     680.72 ms /     1 runs   (  680.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1460.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.92 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     690.92 ms /     1 runs   (  690.92 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1515.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.87 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     679.27 ms /     1 runs   (  679.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1454.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.97 ms /    16 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     645.98 ms /     1 runs   (  645.98 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.24 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     691.33 ms /     1 runs   (  691.33 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1514.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.40 ms /    13 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =     660.92 ms /     1 runs   (  660.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1360.47 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2209.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.70 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     673.80 ms /     1 runs   (  673.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.99 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     650.54 ms /     1 runs   (  650.54 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1480.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.11 ms /    15 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     649.53 ms /     1 runs   (  649.53 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1443.80 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.67 ms /    14 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     662.99 ms /     1 runs   (  662.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1399.26 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.97 ms /    16 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     667.97 ms /     1 runs   (  667.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1503.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.84 ms /    16 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =     664.43 ms /     1 runs   (  664.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1530.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.20 ms /    15 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =     664.82 ms /     1 runs   (  664.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.39 ms /    15 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     656.82 ms /     1 runs   (  656.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1429.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.45 ms /    16 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     650.74 ms /     1 runs   (  650.74 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1501.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.20 ms /    15 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     679.22 ms /     1 runs   (  679.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1459.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.69 ms /    16 tokens (   51.61 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     702.34 ms /     1 runs   (  702.34 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1534.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.00 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     636.58 ms /     1 runs   (  636.58 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1455.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.29 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     707.87 ms /     1 runs   (  707.87 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1536.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.61 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     646.49 ms /     1 runs   (  646.49 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1461.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.64 ms /    16 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =     663.47 ms /     1 runs   (  663.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1475.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.42 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     673.60 ms /     1 runs   (  673.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1501.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.61 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     681.80 ms /     1 runs   (  681.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1502.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.38 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     688.72 ms /     1 runs   (  688.72 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1503.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.07 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     646.65 ms /     1 runs   (  646.65 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1464.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.67 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     747.29 ms /     1 runs   (  747.29 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =    1570.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     860.22 ms /    16 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =     658.00 ms /     1 runs   (  658.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1524.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.70 ms /    16 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     648.41 ms /     1 runs   (  648.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1497.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.66 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     650.08 ms /     1 runs   (  650.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1422.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.51 ms /    15 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     647.88 ms /     1 runs   (  647.88 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1416.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.24 ms /    16 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     670.98 ms /     1 runs   (  670.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1505.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.03 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     700.42 ms /     1 runs   (  700.42 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1519.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.87 ms /    16 tokens (   50.62 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     675.68 ms /     1 runs   (  675.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.43 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     644.94 ms /     1 runs   (  644.94 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1457.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.58 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     665.47 ms /     1 runs   (  665.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.72 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     667.69 ms /     1 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     869.42 ms /    16 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =     668.70 ms /     1 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1544.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.46 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     658.33 ms /     1 runs   (  658.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.17 ms /    16 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     663.84 ms /     1 runs   (  663.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.27 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     662.20 ms /     1 runs   (  662.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.89 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     666.42 ms /     1 runs   (  666.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.66 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     671.08 ms /     1 runs   (  671.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1444.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.44 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     643.85 ms /     1 runs   (  643.85 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.39 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     661.66 ms /     1 runs   (  661.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.50 ms /    16 tokens (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     648.70 ms /     1 runs   (  648.70 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.27 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     642.20 ms /     1 runs   (  642.20 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1467.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.21 ms /    16 tokens (   50.83 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     654.91 ms /     1 runs   (  654.91 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.65 ms /    14 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     678.20 ms /     1 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1405.52 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.82 ms /    16 tokens (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     654.10 ms /     1 runs   (  654.10 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.85 ms /    16 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     723.85 ms /     1 runs   (  723.85 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1562.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.21 ms /    15 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =     659.83 ms /     1 runs   (  659.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.17 ms /    16 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     653.10 ms /     1 runs   (  653.10 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1506.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.25 ms /    16 tokens (   50.83 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     654.12 ms /     1 runs   (  654.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.83 ms /    16 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     658.13 ms /     1 runs   (  658.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1510.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.15 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     706.46 ms /     1 runs   (  706.46 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1528.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.89 ms /    16 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     681.30 ms /     1 runs   (  681.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1501.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.25 ms /    16 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     661.88 ms /     1 runs   (  661.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1515.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.97 ms /    15 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     647.95 ms /     1 runs   (  647.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1427.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.21 ms /    16 tokens (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =     666.32 ms /     1 runs   (  666.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1477.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.61 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     638.72 ms /     1 runs   (  638.72 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1452.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.31 ms /    15 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     647.17 ms /     1 runs   (  647.17 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1421.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.51 ms /    15 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     654.24 ms /     1 runs   (  654.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1423.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.98 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     648.86 ms /     1 runs   (  648.86 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.50 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     641.78 ms /     1 runs   (  641.78 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1466.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.26 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     686.36 ms /     1 runs   (  686.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1508.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.47 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     643.06 ms /     1 runs   (  643.06 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1459.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.63 ms /    15 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     659.90 ms /     1 runs   (  659.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1447.10 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.20 ms /    16 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     668.35 ms /     1 runs   (  668.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1506.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.77 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     652.95 ms /     1 runs   (  652.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.45 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     669.96 ms /     1 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.78 ms /    15 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     651.84 ms /     1 runs   (  651.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1427.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.95 ms /    16 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     656.12 ms /     1 runs   (  656.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     801.67 ms /    15 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =     659.14 ms /     1 runs   (  659.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1466.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.94 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     668.34 ms /     1 runs   (  668.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1489.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.60 ms /    16 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     645.57 ms /     1 runs   (  645.57 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1468.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     794.44 ms /    15 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     669.10 ms /     1 runs   (  669.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1469.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.97 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     670.41 ms /     1 runs   (  670.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1445.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.03 ms /    15 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     689.79 ms /     1 runs   (  689.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1466.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.05 ms /    15 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     658.72 ms /     1 runs   (  658.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1430.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.76 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     651.07 ms /     1 runs   (  651.07 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.53 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     650.44 ms /     1 runs   (  650.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.03 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     671.93 ms /     1 runs   (  671.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.51 ms /    14 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     655.01 ms /     1 runs   (  655.01 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1398.77 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.09 ms /    16 tokens (   51.01 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     689.20 ms /     1 runs   (  689.20 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1511.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.84 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     645.55 ms /     1 runs   (  645.55 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1472.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.80 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     652.57 ms /     1 runs   (  652.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.61 ms /    15 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     671.51 ms /     1 runs   (  671.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1450.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.93 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     686.78 ms /     1 runs   (  686.78 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1519.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.49 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     662.27 ms /     1 runs   (  662.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.33 ms /    16 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =     648.35 ms /     1 runs   (  648.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1502.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.60 ms /    13 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =     671.47 ms /     1 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1369.50 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.63 ms /    15 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     685.79 ms /     1 runs   (  685.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1475.92 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.95 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     651.64 ms /     1 runs   (  651.64 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.59 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     663.43 ms /     1 runs   (  663.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1481.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.31 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     672.99 ms /     1 runs   (  672.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1504.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.36 ms /    15 tokens (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     665.58 ms /     1 runs   (  665.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1444.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.80 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     676.55 ms /     1 runs   (  676.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1494.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.01 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     652.83 ms /     1 runs   (  652.83 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.46 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     640.93 ms /     1 runs   (  640.93 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1476.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.57 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     659.74 ms /     1 runs   (  659.74 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.75 ms /    16 tokens (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     645.81 ms /     1 runs   (  645.81 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.15 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     658.42 ms /     1 runs   (  658.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     802.87 ms /    15 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =     670.96 ms /     1 runs   (  670.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1479.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.72 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     652.73 ms /     1 runs   (  652.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.31 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     644.51 ms /     1 runs   (  644.51 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1469.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.83 ms /    14 tokens (   51.77 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     662.72 ms /     1 runs   (  662.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1393.28 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.44 ms /    16 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     649.16 ms /     1 runs   (  649.16 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.29 ms /    15 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =     660.61 ms /     1 runs   (  660.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1470.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.56 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     674.48 ms /     1 runs   (  674.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.34 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     665.97 ms /     1 runs   (  665.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2183.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.93 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     681.05 ms /     1 runs   (  681.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1512.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.05 ms /    15 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     643.68 ms /     1 runs   (  643.68 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1413.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.41 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     644.93 ms /     1 runs   (  644.93 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.62 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     663.16 ms /     1 runs   (  663.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.99 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     663.88 ms /     1 runs   (  663.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.69 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     670.71 ms /     1 runs   (  670.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1504.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.68 ms /    15 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     686.51 ms /     1 runs   (  686.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1457.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.07 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     667.85 ms /     1 runs   (  667.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1480.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.44 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     679.80 ms /     1 runs   (  679.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1510.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.00 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     678.17 ms /     1 runs   (  678.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1503.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.05 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     649.24 ms /     1 runs   (  649.24 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.61 ms /    15 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     660.05 ms /     1 runs   (  660.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1435.18 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.25 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     650.72 ms /     1 runs   (  650.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2125.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.12 ms /    16 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     653.35 ms /     1 runs   (  653.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1505.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.35 ms /    15 tokens (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     651.60 ms /     1 runs   (  651.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1421.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.64 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     651.42 ms /     1 runs   (  651.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1488.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.69 ms /    16 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =     650.61 ms /     1 runs   (  650.61 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.44 ms /    15 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     646.08 ms /     1 runs   (  646.08 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1417.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.07 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     664.66 ms /     1 runs   (  664.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.15 ms /    16 tokens (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     648.35 ms /     1 runs   (  648.35 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.69 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     661.19 ms /     1 runs   (  661.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.94 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     648.56 ms /     1 runs   (  648.56 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.48 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     669.00 ms /     1 runs   (  669.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1481.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.90 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     673.52 ms /     1 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1491.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.59 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     680.11 ms /     1 runs   (  680.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1519.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.64 ms /    16 tokens (   51.16 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     675.25 ms /     1 runs   (  675.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1499.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.09 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     643.78 ms /     1 runs   (  643.78 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1460.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.13 ms /    16 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =     731.80 ms /     1 runs   (  731.80 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =    1542.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.06 ms /    15 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     687.54 ms /     1 runs   (  687.54 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1463.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.57 ms /    16 tokens (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     635.47 ms /     1 runs   (  635.47 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1451.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.50 ms /    16 tokens (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     661.87 ms /     1 runs   (  661.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.14 ms /    16 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     666.26 ms /     1 runs   (  666.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1482.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.02 ms /    15 tokens (   50.93 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     670.57 ms /     1 runs   (  670.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1440.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.95 ms /    16 tokens (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:        eval time =     652.07 ms /     1 runs   (  652.07 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1463.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.74 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     653.02 ms /     1 runs   (  653.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.25 ms /    15 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =     669.67 ms /     1 runs   (  669.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1468.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.70 ms /    15 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     647.89 ms /     1 runs   (  647.89 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1430.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.46 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     638.39 ms /     1 runs   (  638.39 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1472.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.04 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     634.43 ms /     1 runs   (  634.43 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1452.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2127.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.87 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     688.85 ms /     1 runs   (  688.85 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1513.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.80 ms /    16 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     663.66 ms /     1 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1505.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.02 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     655.61 ms /     1 runs   (  655.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.46 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     653.99 ms /     1 runs   (  653.99 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1477.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.83 ms /    15 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     644.01 ms /     1 runs   (  644.01 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1432.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.92 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     645.71 ms /     1 runs   (  645.71 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.25 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     670.49 ms /     1 runs   (  670.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1485.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.50 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     659.19 ms /     1 runs   (  659.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.73 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     643.66 ms /     1 runs   (  643.66 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1459.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.84 ms /    15 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     654.02 ms /     1 runs   (  654.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1449.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.34 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     697.60 ms /     1 runs   (  697.60 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1513.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.67 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     674.51 ms /     1 runs   (  674.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1489.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.66 ms /    16 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     698.56 ms /     1 runs   (  698.56 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1543.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.60 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     670.98 ms /     1 runs   (  670.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.01 ms /    15 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =     678.80 ms /     1 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1490.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2166.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.35 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     673.65 ms /     1 runs   (  673.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1505.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.05 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     661.44 ms /     1 runs   (  661.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.30 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     669.16 ms /     1 runs   (  669.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.46 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     649.82 ms /     1 runs   (  649.82 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1481.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.11 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     669.70 ms /     1 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1510.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.74 ms /    15 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     690.92 ms /     1 runs   (  690.92 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1470.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.76 ms /    16 tokens (   50.80 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     660.01 ms /     1 runs   (  660.01 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.10 ms /    16 tokens (   51.57 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     675.82 ms /     1 runs   (  675.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1506.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.16 ms /    16 tokens (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =     700.26 ms /     1 runs   (  700.26 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1511.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.53 ms /    16 tokens (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     767.32 ms /     1 runs   (  767.32 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =    1582.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.49 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     657.91 ms /     1 runs   (  657.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.88 ms /    15 tokens (   51.19 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     644.79 ms /     1 runs   (  644.79 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1418.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.70 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     685.46 ms /     1 runs   (  685.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1512.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.62 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     677.60 ms /     1 runs   (  677.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1502.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.33 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     656.98 ms /     1 runs   (  656.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.36 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     653.08 ms /     1 runs   (  653.08 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1483.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.94 ms /    15 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     666.42 ms /     1 runs   (  666.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1437.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.16 ms /    15 tokens (   50.94 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     648.51 ms /     1 runs   (  648.51 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1418.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.71 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     662.53 ms /     1 runs   (  662.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.83 ms /    15 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     693.94 ms /     1 runs   (  693.94 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1467.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.39 ms /    16 tokens (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     652.25 ms /     1 runs   (  652.25 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1471.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.96 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     666.75 ms /     1 runs   (  666.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.09 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     679.69 ms /     1 runs   (  679.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1496.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.69 ms /    14 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     650.21 ms /     1 runs   (  650.21 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1388.21 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.94 ms /    16 tokens (   63.31 ms per token,    15.80 tokens per second)\n",
      "llama_print_timings:        eval time =     645.44 ms /     1 runs   (  645.44 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1664.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.10 ms /    16 tokens (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     665.14 ms /     1 runs   (  665.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1487.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.80 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     663.09 ms /     1 runs   (  663.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.40 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     645.92 ms /     1 runs   (  645.92 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1462.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.47 ms /    16 tokens (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     657.85 ms /     1 runs   (  657.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.61 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     659.88 ms /     1 runs   (  659.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.58 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     675.23 ms /     1 runs   (  675.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.84 ms /    16 tokens (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     656.23 ms /     1 runs   (  656.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.07 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     711.67 ms /     1 runs   (  711.67 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1538.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.92 ms /    15 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     672.62 ms /     1 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1451.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.91 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     656.30 ms /     1 runs   (  656.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1473.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     794.34 ms /    15 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     655.61 ms /     1 runs   (  655.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1456.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.91 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     659.90 ms /     1 runs   (  659.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.98 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.97 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     647.81 ms /     1 runs   (  647.81 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.33 ms /    15 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     662.21 ms /     1 runs   (  662.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1435.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.01 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     645.12 ms /     1 runs   (  645.12 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1463.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.81 ms /    16 tokens (   51.99 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     651.02 ms /     1 runs   (  651.02 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1488.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.02 ms /    15 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     657.38 ms /     1 runs   (  657.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1430.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.61 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     654.03 ms /     1 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.12 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     656.61 ms /     1 runs   (  656.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.65 ms /    16 tokens (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:        eval time =     652.52 ms /     1 runs   (  652.52 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.74 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     660.57 ms /     1 runs   (  660.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1478.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.03 ms /    15 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     660.58 ms /     1 runs   (  660.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1452.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2200.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.14 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     671.91 ms /     1 runs   (  671.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1504.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.58 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     703.41 ms /     1 runs   (  703.41 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1526.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     736.17 ms /    14 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     711.11 ms /     1 runs   (  711.11 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1452.64 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.38 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     678.45 ms /     1 runs   (  678.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1496.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.37 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     695.87 ms /     1 runs   (  695.87 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1524.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.69 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     672.97 ms /     1 runs   (  672.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.05 ms /     2 runs   (    0.53 ms per token,  1904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.43 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     655.27 ms /     1 runs   (  655.27 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.01 ms /    15 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     688.00 ms /     1 runs   (  688.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1462.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.13 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     659.68 ms /     1 runs   (  659.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.00 ms /    16 tokens (   50.62 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     654.67 ms /     1 runs   (  654.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1469.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.00 ms /    16 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     647.30 ms /     1 runs   (  647.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1467.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.63 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     667.43 ms /     1 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1486.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.22 ms /    16 tokens (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     659.31 ms /     1 runs   (  659.31 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1475.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.74 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     650.55 ms /     1 runs   (  650.55 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1465.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.73 ms /    16 tokens (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     659.25 ms /     1 runs   (  659.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1472.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.55 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     668.14 ms /     1 runs   (  668.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.48 ms /    16 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_print_timings:        eval time =     649.32 ms /     1 runs   (  649.32 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1461.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.38 ms /    16 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     662.79 ms /     1 runs   (  662.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.16 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     666.07 ms /     1 runs   (  666.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1501.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.67 ms /    15 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     678.20 ms /     1 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1456.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.37 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     651.15 ms /     1 runs   (  651.15 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1469.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.59 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     649.69 ms /     1 runs   (  649.69 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.64 ms /    16 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     636.95 ms /     1 runs   (  636.95 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1472.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.83 ms /    16 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =     671.41 ms /     1 runs   (  671.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.50 ms /    16 tokens (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:        eval time =     651.16 ms /     1 runs   (  651.16 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.43 ms /    16 tokens (   50.34 ms per token,    19.87 tokens per second)\n",
      "llama_print_timings:        eval time =     651.84 ms /     1 runs   (  651.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1462.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.12 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     649.40 ms /     1 runs   (  649.40 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.99 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.47 ms /    16 tokens (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     663.30 ms /     1 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1483.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.71 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     640.38 ms /     1 runs   (  640.38 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1468.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.38 ms /    16 tokens (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     671.68 ms /     1 runs   (  671.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1491.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.10 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     674.34 ms /     1 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1487.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.58 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     660.88 ms /     1 runs   (  660.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1480.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.77 ms /    16 tokens (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =     648.66 ms /     1 runs   (  648.66 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.45 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     669.90 ms /     1 runs   (  669.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1493.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.18 ms /    16 tokens (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     649.64 ms /     1 runs   (  649.64 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1468.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.90 ms /    16 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     671.12 ms /     1 runs   (  671.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1511.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2610.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.07 ms /    16 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     673.14 ms /     1 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.91 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     692.52 ms /     1 runs   (  692.52 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1466.79 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.84 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     707.84 ms /     1 runs   (  707.84 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1537.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.50 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     690.79 ms /     1 runs   (  690.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1510.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.73 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     656.75 ms /     1 runs   (  656.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.68 ms /    16 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     725.77 ms /     1 runs   (  725.77 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1562.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.44 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     673.17 ms /     1 runs   (  673.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.24 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     679.51 ms /     1 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1456.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.50 ms /    14 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     662.60 ms /     1 runs   (  662.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1388.84 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.37 ms /    16 tokens (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:        eval time =     670.43 ms /     1 runs   (  670.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1486.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.09 ms /    16 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     642.04 ms /     1 runs   (  642.04 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1461.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.33 ms /    16 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     648.27 ms /     1 runs   (  648.27 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.68 ms /    16 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =     650.33 ms /     1 runs   (  650.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1514.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.58 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     654.53 ms /     1 runs   (  654.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.84 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     644.83 ms /     1 runs   (  644.83 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1470.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.13 ms /    15 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     666.93 ms /     1 runs   (  666.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1440.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.25 ms /    15 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     647.10 ms /     1 runs   (  647.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1429.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.81 ms /    16 tokens (   50.99 ms per token,    19.61 tokens per second)\n",
      "llama_print_timings:        eval time =     645.73 ms /     1 runs   (  645.73 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1467.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.58 ms /    16 tokens (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     668.91 ms /     1 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1490.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.83 ms /    16 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     705.47 ms /     1 runs   (  705.47 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1533.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.62 ms /    15 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     650.85 ms /     1 runs   (  650.85 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1448.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.98 ms /    16 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     676.57 ms /     1 runs   (  676.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1493.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.33 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     691.29 ms /     1 runs   (  691.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1513.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.34 ms /    15 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     643.99 ms /     1 runs   (  643.99 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1428.74 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.69 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     651.32 ms /     1 runs   (  651.32 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1480.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.96 ms /    16 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =     639.37 ms /     1 runs   (  639.37 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1451.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.08 ms /    16 tokens (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     667.99 ms /     1 runs   (  667.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1485.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.63 ms /    16 tokens (   50.91 ms per token,    19.64 tokens per second)\n",
      "llama_print_timings:        eval time =     646.56 ms /     1 runs   (  646.56 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2171.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.38 ms /    16 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     664.35 ms /     1 runs   (  664.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1500.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.19 ms /    16 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =     653.67 ms /     1 runs   (  653.67 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.85 ms /    15 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     646.58 ms /     1 runs   (  646.58 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1422.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.66 ms /    15 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     661.72 ms /     1 runs   (  661.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1434.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.83 ms /    16 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     655.64 ms /     1 runs   (  655.64 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1494.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.85 ms /    15 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =     714.48 ms /     1 runs   (  714.48 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1550.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.30 ms /    16 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     654.82 ms /     1 runs   (  654.82 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1467.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.04 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     649.33 ms /     1 runs   (  649.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1473.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.02 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     700.50 ms /     1 runs   (  700.50 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1526.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     784.38 ms /    15 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     662.32 ms /     1 runs   (  662.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1452.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.06 ms /    16 tokens (   50.44 ms per token,    19.82 tokens per second)\n",
      "llama_print_timings:        eval time =     647.78 ms /     1 runs   (  647.78 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.54 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     637.18 ms /     1 runs   (  637.18 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1457.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.93 ms /    16 tokens (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     638.00 ms /     1 runs   (  638.00 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1455.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.98 ms /    16 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     656.55 ms /     1 runs   (  656.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.61 ms /    16 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     649.05 ms /     1 runs   (  649.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.81 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     651.36 ms /     1 runs   (  651.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1483.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.86 ms /    16 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     643.53 ms /     1 runs   (  643.53 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1478.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.03 ms /    15 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     651.56 ms /     1 runs   (  651.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1432.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.30 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     632.82 ms /     1 runs   (  632.82 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1454.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.63 ms /    16 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     644.10 ms /     1 runs   (  644.10 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1481.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.28 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     662.41 ms /     1 runs   (  662.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.93 ms /    16 tokens (   50.81 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:        eval time =     658.30 ms /     1 runs   (  658.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.58 ms /    15 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     658.64 ms /     1 runs   (  658.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1436.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.80 ms /    16 tokens (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:        eval time =     662.32 ms /     1 runs   (  662.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1476.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.28 ms /    15 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     660.76 ms /     1 runs   (  660.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1432.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.38 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     688.44 ms /     1 runs   (  688.44 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1510.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.13 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     661.87 ms /     1 runs   (  661.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.58 ms /    16 tokens (   50.35 ms per token,    19.86 tokens per second)\n",
      "llama_print_timings:        eval time =     638.89 ms /     1 runs   (  638.89 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1449.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.18 ms /    15 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     698.55 ms /     1 runs   (  698.55 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1471.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.07 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     647.58 ms /     1 runs   (  647.58 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1463.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.43 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     644.48 ms /     1 runs   (  644.48 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1473.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.39 ms /    15 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     644.54 ms /     1 runs   (  644.54 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1418.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.24 ms /    16 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     667.71 ms /     1 runs   (  667.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1506.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.33 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     666.17 ms /     1 runs   (  666.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1503.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.14 ms /    15 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =     651.22 ms /     1 runs   (  651.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1460.25 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.11 ms /    16 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     652.03 ms /     1 runs   (  652.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1489.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.22 ms /    13 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =     665.50 ms /     1 runs   (  665.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1368.55 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.54 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     666.45 ms /     1 runs   (  666.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1499.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.92 ms /    16 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =     669.03 ms /     1 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1531.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.23 ms /    16 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     686.77 ms /     1 runs   (  686.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1518.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.45 ms /    16 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =     688.30 ms /     1 runs   (  688.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1538.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.30 ms /    16 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     658.71 ms /     1 runs   (  658.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1502.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.20 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     700.13 ms /     1 runs   (  700.13 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1528.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.86 ms /    16 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     724.07 ms /     1 runs   (  724.07 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1565.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.08 ms /    15 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     654.73 ms /     1 runs   (  654.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1441.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.46 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     675.65 ms /     1 runs   (  675.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1502.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.26 ms /    16 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     650.72 ms /     1 runs   (  650.72 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1482.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.09 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     740.84 ms /     1 runs   (  740.84 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =    1581.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.04 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     712.56 ms /     1 runs   (  712.56 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1536.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.78 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     656.67 ms /     1 runs   (  656.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1492.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.14 ms /    16 tokens (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_print_timings:        eval time =     650.36 ms /     1 runs   (  650.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.08 ms /    14 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     686.52 ms /     1 runs   (  686.52 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1420.73 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.86 ms /    16 tokens (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     664.54 ms /     1 runs   (  664.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1490.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.77 ms /    15 tokens (   52.78 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     664.52 ms /     1 runs   (  664.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1462.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     855.73 ms /    16 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =     637.55 ms /     1 runs   (  637.55 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1498.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.70 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     670.87 ms /     1 runs   (  670.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1510.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.97 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     716.09 ms /     1 runs   (  716.09 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1550.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.43 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     668.56 ms /     1 runs   (  668.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1492.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.18 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     662.52 ms /     1 runs   (  662.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.03 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     707.71 ms /     1 runs   (  707.71 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1541.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     862.26 ms /    16 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =     663.65 ms /     1 runs   (  663.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1531.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2159.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.51 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     668.06 ms /     1 runs   (  668.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2164.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.63 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     681.09 ms /     1 runs   (  681.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1513.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.62 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     685.26 ms /     1 runs   (  685.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1518.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.20 ms /    16 tokens (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:        eval time =     694.95 ms /     1 runs   (  694.95 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1511.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.47 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     663.00 ms /     1 runs   (  663.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1495.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     863.33 ms /    16 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =     689.44 ms /     1 runs   (  689.44 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1558.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.19 ms /    16 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     666.87 ms /     1 runs   (  666.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1511.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.40 ms /    15 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     720.28 ms /     1 runs   (  720.28 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1500.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     865.24 ms /    16 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =     688.50 ms /     1 runs   (  688.50 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1560.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.02 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     650.43 ms /     1 runs   (  650.43 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1481.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.47 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     693.98 ms /     1 runs   (  693.98 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1526.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.11 ms /    15 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =     713.22 ms /     1 runs   (  713.22 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1533.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.54 ms /    16 tokens (   71.28 ms per token,    14.03 tokens per second)\n",
      "llama_print_timings:        eval time =     698.30 ms /     1 runs   (  698.30 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1844.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.50 ms /    16 tokens (   73.84 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =     660.08 ms /     1 runs   (  660.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1846.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.41 ms /    16 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     660.27 ms /     1 runs   (  660.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1509.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.35 ms /    15 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     662.71 ms /     1 runs   (  662.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1442.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.12 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     654.76 ms /     1 runs   (  654.76 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.16 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     698.15 ms /     1 runs   (  698.15 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1524.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.06 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     656.15 ms /     1 runs   (  656.15 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1496.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.23 ms /    15 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     653.26 ms /     1 runs   (  653.26 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1440.57 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.28 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     691.86 ms /     1 runs   (  691.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1525.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.94 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     678.03 ms /     1 runs   (  678.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1506.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     892.13 ms /    16 tokens (   55.76 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =     695.56 ms /     1 runs   (  695.56 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1593.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.66 ms /    16 tokens (   50.85 ms per token,    19.66 tokens per second)\n",
      "llama_print_timings:        eval time =     655.24 ms /     1 runs   (  655.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1474.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.98 ms /    15 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     650.07 ms /     1 runs   (  650.07 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1431.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.09 ms /    16 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =     649.98 ms /     1 runs   (  649.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1498.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.19 ms /    16 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =     677.39 ms /     1 runs   (  677.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1539.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.62 ms /    16 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     700.77 ms /     1 runs   (  700.77 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1551.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.49 ms /    14 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     649.43 ms /     1 runs   (  649.43 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1388.56 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2547.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.45 ms /    15 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =     649.26 ms /     1 runs   (  649.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1445.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.46 ms /    16 tokens (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     665.65 ms /     1 runs   (  665.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1488.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     741.58 ms /    14 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     658.23 ms /     1 runs   (  658.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1405.22 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.74 ms /    16 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     706.03 ms /     1 runs   (  706.03 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1557.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     886.18 ms /    16 tokens (   55.39 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =     688.10 ms /     1 runs   (  688.10 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1579.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.15 ms /    16 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     674.92 ms /     1 runs   (  674.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1519.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.35 ms /    16 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =     672.26 ms /     1 runs   (  672.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1528.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.76 ms /    14 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     675.72 ms /     1 runs   (  675.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1412.34 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.40 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     651.41 ms /     1 runs   (  651.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1479.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     794.95 ms /    15 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =     667.10 ms /     1 runs   (  667.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1468.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.23 ms /    15 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     664.53 ms /     1 runs   (  664.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1467.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     860.78 ms /    16 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =     683.50 ms /     1 runs   (  683.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1550.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.96 ms /    16 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     683.26 ms /     1 runs   (  683.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1518.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.15 ms /    16 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     650.04 ms /     1 runs   (  650.04 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1493.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.45 ms /    16 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     671.60 ms /     1 runs   (  671.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1511.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.37 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     680.65 ms /     1 runs   (  680.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1515.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.64 ms /    16 tokens (   51.67 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     718.87 ms /     1 runs   (  718.87 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1551.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.85 ms /    15 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     671.24 ms /     1 runs   (  671.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1445.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.86 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     671.23 ms /     1 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     880.04 ms /    16 tokens (   55.00 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =     676.15 ms /     1 runs   (  676.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1562.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.00 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     672.72 ms /     1 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.74 ms /    16 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     648.65 ms /     1 runs   (  648.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1492.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     2 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.40 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     696.23 ms /     1 runs   (  696.23 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1521.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.58 ms /    16 tokens (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:        eval time =     647.78 ms /     1 runs   (  647.78 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1466.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.25 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     662.33 ms /     1 runs   (  662.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.39 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     660.55 ms /     1 runs   (  660.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1493.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.21 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     649.16 ms /     1 runs   (  649.16 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.98 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     727.01 ms /     1 runs   (  727.01 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1565.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.60 ms /    16 tokens (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:        eval time =     680.44 ms /     1 runs   (  680.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1500.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.59 ms /    16 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     659.34 ms /     1 runs   (  659.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1511.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.82 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     673.20 ms /     1 runs   (  673.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1500.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.79 ms /    15 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     651.11 ms /     1 runs   (  651.11 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1439.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.09 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     687.85 ms /     1 runs   (  687.85 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1528.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.27 ms /    15 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     705.08 ms /     1 runs   (  705.08 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1493.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.69 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     676.91 ms /     1 runs   (  676.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1505.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.89 ms /    16 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     696.67 ms /     1 runs   (  696.67 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1540.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2190.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.93 ms /    15 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =     683.81 ms /     1 runs   (  683.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1482.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.52 ms /    16 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     669.88 ms /     1 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1507.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.17 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     681.65 ms /     1 runs   (  681.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1508.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.09 ms /    16 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     651.73 ms /     1 runs   (  651.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1488.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.11 ms /    15 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     653.49 ms /     1 runs   (  653.49 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1444.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.03 ms /    16 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     650.42 ms /     1 runs   (  650.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1496.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.44 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     657.58 ms /     1 runs   (  657.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1494.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.18 ms /    16 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     677.88 ms /     1 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1511.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.96 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     668.88 ms /     1 runs   (  668.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1506.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.13 ms /    16 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     683.29 ms /     1 runs   (  683.29 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1530.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     804.01 ms /    15 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =     661.75 ms /     1 runs   (  661.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1471.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     863.76 ms /    16 tokens (   53.98 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =     663.26 ms /     1 runs   (  663.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1532.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.63 ms /    16 tokens (   53.66 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =     710.54 ms /     1 runs   (  710.54 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1576.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     883.97 ms /    16 tokens (   55.25 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =     658.18 ms /     1 runs   (  658.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1547.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.90 ms /    15 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =     664.33 ms /     1 runs   (  664.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1466.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.60 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     658.58 ms /     1 runs   (  658.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /     2 runs   (    0.51 ms per token,  1970.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.88 ms /    16 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     691.46 ms /     1 runs   (  691.46 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1541.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     794.16 ms /    15 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     664.73 ms /     1 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1464.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.77 ms /    15 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =     745.45 ms /     1 runs   (  745.45 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =    1561.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.85 ms /    15 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     723.54 ms /     1 runs   (  723.54 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1521.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.14 ms /    15 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =     658.98 ms /     1 runs   (  658.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1474.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2183.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     875.04 ms /    16 tokens (   54.69 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =     661.03 ms /     1 runs   (  661.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1541.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     747.16 ms /    14 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =     666.43 ms /     1 runs   (  666.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1420.15 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.99 ms /    16 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     662.89 ms /     1 runs   (  662.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1513.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.08 ms /    15 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     671.02 ms /     1 runs   (  671.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1456.35 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.37 ms /    16 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     704.95 ms /     1 runs   (  704.95 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1539.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /     2 runs   (    0.66 ms per token,  1524.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.98 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     666.16 ms /     1 runs   (  666.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1501.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.92 ms /    13 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =     677.29 ms /     1 runs   (  677.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1368.28 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.30 ms /    16 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =     710.02 ms /     1 runs   (  710.02 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1556.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     814.32 ms /    16 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     672.33 ms /     1 runs   (  672.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1492.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.40 ms /    15 tokens (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     704.43 ms /     1 runs   (  704.43 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1488.30 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.91 ms /    16 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     661.73 ms /     1 runs   (  661.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1487.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.97 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     651.26 ms /     1 runs   (  651.26 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1486.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2252.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.05 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     675.26 ms /     1 runs   (  675.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1498.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.55 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     676.08 ms /     1 runs   (  676.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1504.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.72 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     668.80 ms /     1 runs   (  668.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.73 ms /    16 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     652.71 ms /     1 runs   (  652.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1489.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.46 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     702.86 ms /     1 runs   (  702.86 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1526.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.85 ms /    16 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =     673.39 ms /     1 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1539.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.82 ms /    16 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     676.90 ms /     1 runs   (  676.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1511.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.01 ms /    16 tokens (   51.13 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     657.41 ms /     1 runs   (  657.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1481.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.57 ms /    15 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     661.81 ms /     1 runs   (  661.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1444.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.86 ms /    16 tokens (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     686.57 ms /     1 runs   (  686.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1513.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.65 ms /    16 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     672.80 ms /     1 runs   (  672.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1510.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.33 ms /    16 tokens (   51.27 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     655.46 ms /     1 runs   (  655.46 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.88 ms /    16 tokens (   51.18 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     659.26 ms /     1 runs   (  659.26 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.41 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     671.57 ms /     1 runs   (  671.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.48 ms /    16 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =     661.17 ms /     1 runs   (  661.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1531.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.06 ms /    16 tokens (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =     661.17 ms /     1 runs   (  661.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1479.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.72 ms /    16 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =     691.65 ms /     1 runs   (  691.65 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1540.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.00 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     645.76 ms /     1 runs   (  645.76 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1474.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.75 ms /    15 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =     771.45 ms /     1 runs   (  771.45 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =    1575.10 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.89 ms /    16 tokens (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     720.69 ms /     1 runs   (  720.69 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1552.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.60 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     692.13 ms /     1 runs   (  692.13 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1527.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.90 ms /    16 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     737.43 ms /     1 runs   (  737.43 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1562.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.93 ms /    16 tokens (   51.75 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     707.49 ms /     1 runs   (  707.49 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1541.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.69 ms /    16 tokens (   52.04 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     665.89 ms /     1 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1503.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2162.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.18 ms /    16 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     725.18 ms /     1 runs   (  725.18 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1566.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.92 ms /    15 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     653.66 ms /     1 runs   (  653.66 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1434.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.12 ms /    16 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =     672.21 ms /     1 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1535.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.27 ms /    15 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     670.09 ms /     1 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1453.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.15 ms /    15 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =     681.21 ms /     1 runs   (  681.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1498.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2132.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.33 ms /    16 tokens (   52.90 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =     662.12 ms /     1 runs   (  662.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1514.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.32 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     651.69 ms /     1 runs   (  651.69 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.72 ms /    16 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     691.87 ms /     1 runs   (  691.87 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1537.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.96 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     653.49 ms /     1 runs   (  653.49 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1490.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2173.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.03 ms /    15 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     665.74 ms /     1 runs   (  665.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1458.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.75 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     673.97 ms /     1 runs   (  673.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1501.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.50 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     683.05 ms /     1 runs   (  683.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1513.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2098.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.80 ms /    15 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     697.52 ms /     1 runs   (  697.52 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1480.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.37 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     672.49 ms /     1 runs   (  672.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1509.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     2 runs   (    0.65 ms per token,  1532.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.51 ms /    16 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     664.90 ms /     1 runs   (  664.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1505.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.25 ms /    15 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     677.84 ms /     1 runs   (  677.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1455.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.85 ms /    16 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     704.82 ms /     1 runs   (  704.82 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1540.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.37 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     668.97 ms /     1 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.40 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     711.23 ms /     1 runs   (  711.23 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1536.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.02 ms /    16 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     654.79 ms /     1 runs   (  654.79 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.51 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     666.57 ms /     1 runs   (  666.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1496.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2152.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.93 ms /    16 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =     694.30 ms /     1 runs   (  694.30 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1559.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.30 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     668.46 ms /     1 runs   (  668.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1501.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.02 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     672.23 ms /     1 runs   (  672.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1494.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     866.00 ms /    16 tokens (   54.13 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =     662.53 ms /     1 runs   (  662.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1533.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.21 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     647.49 ms /     1 runs   (  647.49 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.77 ms /    16 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     652.19 ms /     1 runs   (  652.19 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1492.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2557.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.57 ms /    15 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     700.27 ms /     1 runs   (  700.27 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1482.64 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.24 ms /    16 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     663.98 ms /     1 runs   (  663.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1508.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.65 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     663.85 ms /     1 runs   (  663.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.72 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     662.36 ms /     1 runs   (  662.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.50 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     658.67 ms /     1 runs   (  658.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.89 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     678.14 ms /     1 runs   (  678.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1505.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.55 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     691.54 ms /     1 runs   (  691.54 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1519.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.67 ms /    15 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     684.25 ms /     1 runs   (  684.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1467.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2234.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.26 ms /    16 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     705.31 ms /     1 runs   (  705.31 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1551.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.66 ms /    16 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     666.40 ms /     1 runs   (  666.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1499.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2328.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.93 ms /    16 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     650.44 ms /     1 runs   (  650.44 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1491.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     841.70 ms /    16 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     663.05 ms /     1 runs   (  663.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1510.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.11 ms /    16 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     678.36 ms /     1 runs   (  678.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1514.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.66 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     684.77 ms /     1 runs   (  684.77 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1520.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.17 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     694.39 ms /     1 runs   (  694.39 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1527.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.50 ms /    15 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =     663.41 ms /     1 runs   (  663.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1449.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.10 ms /    16 tokens (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     661.66 ms /     1 runs   (  661.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.21 ms /    15 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     662.96 ms /     1 runs   (  662.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1446.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2306.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.90 ms /    15 tokens (   54.79 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =     659.52 ms /     1 runs   (  659.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.76 ms /    16 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     667.14 ms /     1 runs   (  667.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.91 ms /    16 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     666.57 ms /     1 runs   (  666.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1507.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.44 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     646.64 ms /     1 runs   (  646.64 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1477.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.90 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     709.33 ms /     1 runs   (  709.33 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1532.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.35 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     666.88 ms /     1 runs   (  666.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1503.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.47 ms /    15 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     660.66 ms /     1 runs   (  660.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1450.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.77 ms /    16 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =     668.27 ms /     1 runs   (  668.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1522.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.04 ms /    16 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     649.32 ms /     1 runs   (  649.32 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1494.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2590.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.44 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     652.54 ms /     1 runs   (  652.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.58 ms /    14 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     649.15 ms /     1 runs   (  649.15 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1382.66 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.68 ms /    16 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     695.54 ms /     1 runs   (  695.54 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1544.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.55 ms /    16 tokens (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     654.84 ms /     1 runs   (  654.84 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.90 ms /    16 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     673.33 ms /     1 runs   (  673.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1506.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.62 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     663.68 ms /     1 runs   (  663.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1503.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.52 ms /    15 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =     640.01 ms /     1 runs   (  640.01 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =    1456.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.81 ms /    16 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     661.22 ms /     1 runs   (  661.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1503.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.05 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     656.44 ms /     1 runs   (  656.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.46 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     656.59 ms /     1 runs   (  656.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1479.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.22 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     670.43 ms /     1 runs   (  670.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1495.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.57 ms /    15 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =     650.49 ms /     1 runs   (  650.49 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1452.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.80 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     664.06 ms /     1 runs   (  664.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1486.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.80 ms /    15 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     644.83 ms /     1 runs   (  644.83 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1432.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.09 ms /    16 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     675.46 ms /     1 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1518.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.16 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     666.54 ms /     1 runs   (  666.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.44 ms /    14 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     658.91 ms /     1 runs   (  658.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1396.79 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.15 ms /    16 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     662.86 ms /     1 runs   (  662.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1518.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.61 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     649.93 ms /     1 runs   (  649.93 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1471.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.77 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     670.90 ms /     1 runs   (  670.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.52 ms /    16 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     653.78 ms /     1 runs   (  653.78 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1492.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.33 ms /    16 tokens (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     661.28 ms /     1 runs   (  661.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.11 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     665.70 ms /     1 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.25 ms /    16 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     651.85 ms /     1 runs   (  651.85 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1478.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.97 ms /    16 tokens (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     661.73 ms /     1 runs   (  661.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.81 ms /    15 tokens (   51.99 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     644.72 ms /     1 runs   (  644.72 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1430.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.58 ms /    16 tokens (   51.85 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =     680.44 ms /     1 runs   (  680.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1515.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.85 ms /    16 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     658.91 ms /     1 runs   (  658.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1504.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.88 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     681.24 ms /     1 runs   (  681.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1511.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     802.32 ms /    15 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =     648.66 ms /     1 runs   (  648.66 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1457.18 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.12 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     656.43 ms /     1 runs   (  656.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1484.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.46 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     676.87 ms /     1 runs   (  676.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1506.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.55 ms /    16 tokens (   51.53 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     654.54 ms /     1 runs   (  654.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.01 ms /    16 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     653.27 ms /     1 runs   (  653.27 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     838.75 ms /    16 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     675.57 ms /     1 runs   (  675.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1520.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.04 ms /    16 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     690.83 ms /     1 runs   (  690.83 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1531.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.32 ms /    16 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =     705.06 ms /     1 runs   (  705.06 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1544.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.52 ms /    15 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     672.43 ms /     1 runs   (  672.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1457.34 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.19 ms /    15 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     681.83 ms /     1 runs   (  681.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1468.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.63 ms /    16 tokens (   51.16 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:        eval time =     680.10 ms /     1 runs   (  680.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1504.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     862.02 ms /    16 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =     651.24 ms /     1 runs   (  651.24 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1519.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.28 ms /    16 tokens (   51.45 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     648.43 ms /     1 runs   (  648.43 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.98 ms /    16 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =     659.66 ms /     1 runs   (  659.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1513.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.16 ms /    15 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     646.55 ms /     1 runs   (  646.55 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1427.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.89 ms /    15 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     689.82 ms /     1 runs   (  689.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1481.84 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.03 ms /    16 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =     721.84 ms /     1 runs   (  721.84 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1559.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.10 ms /    16 tokens (   51.51 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     673.59 ms /     1 runs   (  673.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1503.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.60 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     676.42 ms /     1 runs   (  676.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1508.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.19 ms /    16 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =     670.26 ms /     1 runs   (  670.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1498.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2229.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.68 ms /    15 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =     659.98 ms /     1 runs   (  659.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1476.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     884.99 ms /    16 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =     658.37 ms /     1 runs   (  658.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1549.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.05 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     664.92 ms /     1 runs   (  664.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1491.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.34 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     678.92 ms /     1 runs   (  678.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1501.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.12 ms /    16 tokens (   51.45 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     638.97 ms /     1 runs   (  638.97 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =    1467.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.03 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     656.90 ms /     1 runs   (  656.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.93 ms /    16 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     712.07 ms /     1 runs   (  712.07 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1550.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.47 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     670.93 ms /     1 runs   (  670.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1501.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.22 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     652.24 ms /     1 runs   (  652.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1476.81 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.57 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     721.83 ms /     1 runs   (  721.83 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =    1552.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.31 ms /    16 tokens (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     661.11 ms /     1 runs   (  661.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.43 ms /    16 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     656.59 ms /     1 runs   (  656.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1511.57 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.52 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     651.39 ms /     1 runs   (  651.39 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1474.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.06 ms /    16 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     696.27 ms /     1 runs   (  696.27 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1531.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2181.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.43 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     653.02 ms /     1 runs   (  653.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.16 ms /    15 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     676.10 ms /     1 runs   (  676.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1455.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.83 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     668.30 ms /     1 runs   (  668.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1495.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.09 ms /    15 tokens (   52.07 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =     687.38 ms /     1 runs   (  687.38 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1474.64 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.11 ms /    16 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     671.56 ms /     1 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1506.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.42 ms /    16 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     670.39 ms /     1 runs   (  670.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.43 ms /    16 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     670.74 ms /     1 runs   (  670.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1500.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.39 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     670.69 ms /     1 runs   (  670.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1499.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.53 ms /    15 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =     671.85 ms /     1 runs   (  671.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1460.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.32 ms /    15 tokens (   51.55 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     686.59 ms /     1 runs   (  686.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1465.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.89 ms /    16 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =     664.31 ms /     1 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1530.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.23 ms /    16 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_print_timings:        eval time =     655.93 ms /     1 runs   (  655.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1477.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.68 ms /    16 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     652.88 ms /     1 runs   (  652.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1502.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.45 ms /    16 tokens (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     710.30 ms /     1 runs   (  710.30 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1538.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.53 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     682.68 ms /     1 runs   (  682.68 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1514.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.57 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     723.09 ms /     1 runs   (  723.09 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1548.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.94 ms /    15 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =     649.08 ms /     1 runs   (  649.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1464.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.96 ms /    16 tokens (   51.50 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     660.05 ms /     1 runs   (  660.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.22 ms /    16 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =     657.07 ms /     1 runs   (  657.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1501.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     855.57 ms /    16 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =     671.89 ms /     1 runs   (  671.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1532.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.16 ms /    16 tokens (   52.26 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     674.23 ms /     1 runs   (  674.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1515.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /     2 runs   (    0.94 ms per token,  1068.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.48 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     672.88 ms /     1 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1505.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     847.64 ms /    16 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     688.82 ms /     1 runs   (  688.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1542.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.62 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     668.22 ms /     1 runs   (  668.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.23 ms /    16 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =     659.36 ms /     1 runs   (  659.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.70 ms /    16 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =     648.02 ms /     1 runs   (  648.02 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1494.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2190.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.64 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     679.11 ms /     1 runs   (  679.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1510.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.74 ms /    16 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     658.13 ms /     1 runs   (  658.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1491.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     800.81 ms /    15 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =     666.11 ms /     1 runs   (  666.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1472.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.65 ms /    15 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =     681.63 ms /     1 runs   (  681.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1472.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.93 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     698.41 ms /     1 runs   (  698.41 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1527.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.73 ms /    15 tokens (   53.32 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =     651.96 ms /     1 runs   (  651.96 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1457.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.61 ms /    16 tokens (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     653.81 ms /     1 runs   (  653.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.81 ms /    16 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =     703.31 ms /     1 runs   (  703.31 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =    1556.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     745.11 ms /    14 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =     675.88 ms /     1 runs   (  675.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1426.59 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.20 ms /    15 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =     701.63 ms /     1 runs   (  701.63 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1515.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.87 ms /    16 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     668.25 ms /     1 runs   (  668.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1513.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.69 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     652.52 ms /     1 runs   (  652.52 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.65 ms /    13 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =     681.22 ms /     1 runs   (  681.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1386.56 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     900.45 ms /    16 tokens (   56.28 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =     712.84 ms /     1 runs   (  712.84 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1618.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.51 ms /    15 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =     668.76 ms /     1 runs   (  668.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1473.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2192.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.55 ms /    16 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =     644.53 ms /     1 runs   (  644.53 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1504.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.74 ms /    16 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_print_timings:        eval time =     662.96 ms /     1 runs   (  662.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1485.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.14 ms /    15 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     681.02 ms /     1 runs   (  681.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1477.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.48 ms /    16 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =     695.43 ms /     1 runs   (  695.43 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1555.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.02 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     663.34 ms /     1 runs   (  663.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.26 ms /    16 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     662.57 ms /     1 runs   (  662.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1496.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.91 ms /    16 tokens (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     647.58 ms /     1 runs   (  647.58 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1472.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.35 ms /    15 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =     673.10 ms /     1 runs   (  673.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1465.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     861.09 ms /    16 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =     662.51 ms /     1 runs   (  662.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1529.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     876.70 ms /    16 tokens (   54.79 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =     670.24 ms /     1 runs   (  670.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1553.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.83 ms /    15 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     674.81 ms /     1 runs   (  674.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1467.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     871.45 ms /    16 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =     648.64 ms /     1 runs   (  648.64 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1525.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2288.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.38 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     653.57 ms /     1 runs   (  653.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.43 ms /    16 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     665.89 ms /     1 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1522.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2567.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     824.67 ms /    16 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:        eval time =     663.04 ms /     1 runs   (  663.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.25 ms /    15 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     687.35 ms /     1 runs   (  687.35 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1490.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     794.43 ms /    15 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =     668.45 ms /     1 runs   (  668.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1468.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     750.28 ms /    14 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =     691.52 ms /     1 runs   (  691.52 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1447.92 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.00 ms /    16 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =     686.33 ms /     1 runs   (  686.33 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1546.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.38 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     654.13 ms /     1 runs   (  654.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.01 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     657.88 ms /     1 runs   (  657.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.53 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     654.34 ms /     1 runs   (  654.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.18 ms /    16 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     709.51 ms /     1 runs   (  709.51 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1531.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     866.40 ms /    16 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =     679.42 ms /     1 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1552.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.01 ms /    15 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     657.80 ms /     1 runs   (  657.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1454.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.63 ms /    16 tokens (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_print_timings:        eval time =     646.28 ms /     1 runs   (  646.28 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1472.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.47 ms /    16 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     672.46 ms /     1 runs   (  672.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1506.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.42 ms /    15 tokens (   51.69 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     668.89 ms /     1 runs   (  668.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1449.79 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.28 ms /    16 tokens (   53.21 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =     645.22 ms /     1 runs   (  645.22 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1502.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.91 ms /    16 tokens (   51.68 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     689.73 ms /     1 runs   (  689.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1522.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.70 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     658.46 ms /     1 runs   (  658.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.36 ms /    16 tokens (   51.21 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     672.16 ms /     1 runs   (  672.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.79 ms /    15 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     673.58 ms /     1 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1462.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.03 ms /    16 tokens (   51.56 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =     674.77 ms /     1 runs   (  674.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1505.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.13 ms /    16 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     679.85 ms /     1 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1522.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.28 ms /    16 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_print_timings:        eval time =     692.98 ms /     1 runs   (  692.98 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1514.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.55 ms /    16 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     651.68 ms /     1 runs   (  651.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1492.37 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2320.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.44 ms /    16 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =     671.83 ms /     1 runs   (  671.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1504.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.40 ms /    16 tokens (   51.77 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     680.32 ms /     1 runs   (  680.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1515.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.71 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     655.56 ms /     1 runs   (  655.56 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.52 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.97 ms /    16 tokens (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:        eval time =     751.79 ms /     1 runs   (  751.79 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =    1578.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.53 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     679.04 ms /     1 runs   (  679.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1507.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.38 ms /    16 tokens (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     658.67 ms /     1 runs   (  658.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1483.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.75 ms /    16 tokens (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     664.64 ms /     1 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1494.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.75 ms /    15 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =     664.64 ms /     1 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1448.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.10 ms /    16 tokens (   52.32 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     676.92 ms /     1 runs   (  676.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1519.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.93 ms /    15 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =     660.73 ms /     1 runs   (  660.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1463.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.44 ms /    16 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     649.14 ms /     1 runs   (  649.14 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.37 ms /    16 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =     660.66 ms /     1 runs   (  660.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1504.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.55 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     654.52 ms /     1 runs   (  654.52 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     736.60 ms /    14 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =     659.68 ms /     1 runs   (  659.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1402.46 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.84 ms /    15 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     665.05 ms /     1 runs   (  665.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1461.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.50 ms /    16 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =     752.32 ms /     1 runs   (  752.32 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =    1617.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.99 ms /    14 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =     683.31 ms /     1 runs   (  683.31 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1428.57 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.05 ms /    16 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =     699.82 ms /     1 runs   (  699.82 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1553.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.78 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     700.87 ms /     1 runs   (  700.87 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1528.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.88 ms /    15 tokens (   51.73 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =     666.63 ms /     1 runs   (  666.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1448.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.59 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     656.19 ms /     1 runs   (  656.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.71 ms /    16 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     662.24 ms /     1 runs   (  662.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1505.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2270.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.99 ms /    15 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     698.68 ms /     1 runs   (  698.68 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1487.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.23 ms /    16 tokens (   51.83 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     653.03 ms /     1 runs   (  653.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1487.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2344.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.60 ms /    16 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     659.34 ms /     1 runs   (  659.34 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1498.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2336.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     843.33 ms /    16 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =     675.62 ms /     1 runs   (  675.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1524.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.98 ms /    15 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     663.08 ms /     1 runs   (  663.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1440.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     848.83 ms /    16 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =     647.33 ms /     1 runs   (  647.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1501.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.87 ms /    16 tokens (   51.43 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     662.38 ms /     1 runs   (  662.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1491.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.16 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     654.78 ms /     1 runs   (  654.78 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.18 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     650.69 ms /     1 runs   (  650.69 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1476.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.64 ms /    16 tokens (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_print_timings:        eval time =     767.59 ms /     1 runs   (  767.59 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =    1589.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.88 ms /    16 tokens (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:        eval time =     715.47 ms /     1 runs   (  715.47 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1533.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.49 ms /    16 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =     715.54 ms /     1 runs   (  715.54 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1557.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.37 ms /    16 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     675.34 ms /     1 runs   (  675.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1520.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.47 ms /    16 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =     672.09 ms /     1 runs   (  672.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1526.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2224.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.48 ms /    16 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     668.57 ms /     1 runs   (  668.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1499.70 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.05 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     662.69 ms /     1 runs   (  662.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.55 ms /    16 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =     684.12 ms /     1 runs   (  684.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1509.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.58 ms /    16 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     666.25 ms /     1 runs   (  666.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1493.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.59 ms /    16 tokens (   51.47 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     650.69 ms /     1 runs   (  650.69 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1480.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.04 ms /    16 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     685.75 ms /     1 runs   (  685.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1531.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.21 ms /    16 tokens (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:        eval time =     661.72 ms /     1 runs   (  661.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1484.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.25 ms /    16 tokens (   51.20 ms per token,    19.53 tokens per second)\n",
      "llama_print_timings:        eval time =     654.55 ms /     1 runs   (  654.55 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.57 ms /    16 tokens (   51.35 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     658.62 ms /     1 runs   (  658.62 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.20 ms /    15 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =     664.37 ms /     1 runs   (  664.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1455.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     742.57 ms /    14 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =     672.66 ms /     1 runs   (  672.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1423.15 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.54 ms /    14 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =     697.65 ms /     1 runs   (  697.65 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1468.92 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.21 ms /    16 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =     666.14 ms /     1 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1516.90 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.08 ms /    16 tokens (   51.69 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     655.15 ms /     1 runs   (  655.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1487.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.70 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     669.19 ms /     1 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =    1496.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.19 ms /    15 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =     654.37 ms /     1 runs   (  654.37 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1442.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.41 ms /    16 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_print_timings:        eval time =     647.80 ms /     1 runs   (  647.80 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1477.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.01 ms /    16 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     650.65 ms /     1 runs   (  650.65 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1485.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.17 ms /    16 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =     650.22 ms /     1 runs   (  650.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1501.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.76 ms /    16 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     678.90 ms /     1 runs   (  678.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1514.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2239.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.04 ms /    15 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     652.37 ms /     1 runs   (  652.37 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1432.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.51 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     667.10 ms /     1 runs   (  667.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1504.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.57 ms /    16 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =     667.57 ms /     1 runs   (  667.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1504.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.49 ms /    16 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     698.47 ms /     1 runs   (  698.47 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =    1551.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     809.24 ms /    16 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =     662.52 ms /     1 runs   (  662.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1477.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.49 ms /    16 tokens (   51.22 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     663.14 ms /     1 runs   (  663.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1488.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.52 ms /    15 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     658.67 ms /     1 runs   (  658.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1441.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2312.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.53 ms /    16 tokens (   51.60 ms per token,    19.38 tokens per second)\n",
      "llama_print_timings:        eval time =     681.61 ms /     1 runs   (  681.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =    1513.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.24 ms /    16 tokens (   52.45 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     652.13 ms /     1 runs   (  652.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1497.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.40 ms /    14 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =     664.22 ms /     1 runs   (  664.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1408.67 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2185.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.31 ms /    16 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =     650.08 ms /     1 runs   (  650.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1495.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.82 ms /    16 tokens (   51.43 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     656.37 ms /     1 runs   (  656.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1485.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.51 ms /    16 tokens (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     693.38 ms /     1 runs   (  693.38 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1521.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2094.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.29 ms /    15 tokens (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =     667.18 ms /     1 runs   (  667.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1449.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.81 ms /    16 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =     632.94 ms /     1 runs   (  632.94 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =    1462.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.35 ms /    16 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     650.57 ms /     1 runs   (  650.57 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1496.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.04 ms /    16 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_print_timings:        eval time =     653.03 ms /     1 runs   (  653.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     834.61 ms /    16 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     685.76 ms /     1 runs   (  685.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =    1526.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     830.04 ms /    16 tokens (   51.88 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =     724.53 ms /     1 runs   (  724.53 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1560.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.11 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     655.57 ms /     1 runs   (  655.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1481.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.93 ms /    16 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     693.25 ms /     1 runs   (  693.25 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1519.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     800.97 ms /    15 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =     755.28 ms /     1 runs   (  755.28 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =    1561.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2333.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.69 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     674.94 ms /     1 runs   (  674.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1502.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     831.38 ms /    16 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =     663.47 ms /     1 runs   (  663.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1500.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     2 runs   (    0.95 ms per token,  1057.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.41 ms /    16 tokens (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     663.73 ms /     1 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1492.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.19 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     693.12 ms /     1 runs   (  693.12 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1519.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.84 ms /    16 tokens (   51.80 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =     675.68 ms /     1 runs   (  675.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =    1510.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.72 ms /    16 tokens (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_print_timings:        eval time =     651.03 ms /     1 runs   (  651.03 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1478.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.52 ms /    15 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =     648.25 ms /     1 runs   (  648.25 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1436.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.68 ms /    15 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =     662.54 ms /     1 runs   (  662.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1451.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2280.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.49 ms /    16 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =     656.77 ms /     1 runs   (  656.77 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1503.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.46 ms /    14 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =     646.91 ms /     1 runs   (  646.91 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1382.66 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     846.61 ms /    16 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =     663.07 ms /     1 runs   (  663.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1515.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.91 ms /    15 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     647.59 ms /     1 runs   (  647.59 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1430.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.23 ms /    16 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =     646.62 ms /     1 runs   (  646.62 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =    1472.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.00 ms /    16 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =     648.87 ms /     1 runs   (  648.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =    1494.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.19 ms /    16 tokens (   51.32 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     662.38 ms /     1 runs   (  662.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1489.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.96 ms /    16 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_print_timings:        eval time =     651.62 ms /     1 runs   (  651.62 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1480.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.45 ms /    15 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =     663.83 ms /     1 runs   (  663.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1467.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.35 ms /    16 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:        eval time =     708.33 ms /     1 runs   (  708.33 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =    1536.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.72 ms /    16 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     736.07 ms /     1 runs   (  736.07 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =    1560.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.73 ms /    16 tokens (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =     660.60 ms /     1 runs   (  660.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1494.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.46 ms per token,  2152.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.70 ms /    16 tokens (   52.04 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     663.82 ms /     1 runs   (  663.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =    1502.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.61 ms /    16 tokens (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:        eval time =     695.88 ms /     1 runs   (  695.88 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1521.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     822.75 ms /    16 tokens (   51.42 ms per token,    19.45 tokens per second)\n",
      "llama_print_timings:        eval time =     657.18 ms /     1 runs   (  657.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     826.68 ms /    16 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_print_timings:        eval time =     725.30 ms /     1 runs   (  725.30 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =    1557.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.96 ms /    16 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_print_timings:        eval time =     655.52 ms /     1 runs   (  655.52 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =    1479.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.61 ms /    16 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =     712.33 ms /     1 runs   (  712.33 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =    1554.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2594.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.56 ms /    16 tokens (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_print_timings:        eval time =     689.53 ms /     1 runs   (  689.53 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =    1512.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2178.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.69 ms /    15 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =     657.40 ms /     1 runs   (  657.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =    1443.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.16 ms /    16 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =     693.17 ms /     1 runs   (  693.17 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =    1526.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3512.73 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     2 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.63 ms /    16 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =     666.12 ms /     1 runs   (  666.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =    1521.13 ms /    17 tokens\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(f\"Completed {i} rows\")\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        prompt= f\"Is {df.iloc[i, 0]} prime?\"\n",
    "        \n",
    "        prompt_template=f'''You are a math assistant. I will ask you to find wheather given number is prime or not. Please answer in the correct format. For example, if I ask 'Is 5 prime?' , you should answer 'Yes' if 5 is a prime number or 'No' if 5 is not a prime number. Do not include any other information in your answer.\n",
    "\n",
    "        USER: {prompt}\n",
    "        \n",
    "        ASSISTANT:'''\n",
    "        \n",
    "        response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                    repeat_penalty=1.2, top_k=150,\n",
    "                    echo=False)\n",
    "        \n",
    "        with open('prime_test_prime.txt', 'a') as f:\n",
    "            answer=response[\"choices\"][0][\"text\"]\n",
    "            f.write(f\"{df.iloc[i, 0]} = {answer} \\n\")\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        \n",
    "        with open('prime_test_prime.txt', 'a') as f:\n",
    "            f.write(f\"{df.iloc[i, 0]} = Error \\n\")\n",
    "            \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viveksdmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
